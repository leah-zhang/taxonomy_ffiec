FFIEC Information Technology Examination Handbook 

Architecture, Infrastructure, and Operations 

JUNE 2021 

Contents 

INTRODUCTION ...................................................................................................1 

I ........................... ARCHITECTURE, INFRASTRUCTURE, AND OPERATIONS .....2 

II .......................... ARCHITECTURE, INFRASTRUCTURE, AND OPERATIONS GOVERNANCE ....................................................................................................3 

II.A Board and Senior Management Responsibilities ............................... 4 

II.A.1 Strategic Planning ................................................................................... 6 

II.A.2 Enterprise Risk Management .................................................................. 7 

II.B Other Roles and Responsibilities ........................................................ 7 

II.B.1 IT Management Responsibilities ............................................................. 8 

II.B.1(a) Chief Architect .................................................................................. 8 

II.B.1(b) Chief Data Officer ............................................................................. 9 

II.B.1(c) IT Operations Management .............................................................10 

II.B.2 IT Operations Personnel Responsibilities ............................................. 10 

II.C Policies, Standards, and Procedures ................................................ 11 

II.D Internal Audit, Independent Reviews, and Certification Processes 12 

II.E Communication ................................................................................... 13 

II.F Board and Senior Management Reporting ........................................ 13 

III ......................... COMMON AIO RISK MANAGEMENT TOPICS ......................... 15 

III.A Data Governance and Data Management .......................................... 15 

III.A.1 Data Identification and Classification .................................................... 16 

III.A.2 Database Management ......................................................................... 17 

III.A.2(a) Database Security ...........................................................................18 

III.A.3 Non-Production Environments .............................................................. 19 

III.A.4 Data Analytics ....................................................................................... 20 

III.B.1 Technology Asset Inventory .................................................................. 23 

III.B.1(a) Hardware Inventory .........................................................................24 

III.B IT Asset Management ......................................................................... 22 

III.B.1(b) Software Inventory ..........................................................................25 

III.B.2 IT Asset End-of-Life .............................................................................. 26 

III.B.3 Shadow IT ............................................................................................. 27 

III.C.1 Network Diagrams ................................................................................. 30 

III.C.2 Data Flow Diagrams .............................................................................. 31 

III.C IT and Business Environment Representations ............................... 28 

III.C.3 Business Process Diagrams and Narratives ......................................... 33 

III.D.1 Change Management ............................................................................ 35 

III.D.2 Transitioning From Strategic Change Management to Day-to-Day Operations............................................................................................. 37 

III.E Oversight of Third-Party Service Providers ...................................... 37 

III.F Resilience ............................................................................................ 38 

III.G Remote Access ................................................................................... 39 

III.H Personally Owned Devices................................................................. 41 

III.I File Exchange ...................................................................................... 41 

III.D Managing Change in AIO .................................................................... 34 

IV ........................ ARCHITECTURE ........................................................................ 43 

IV.A Architecture Plan ................................................................................ 44 

IV.B Design Objectives ............................................................................... 44 

IV.C IT Architecture Design ........................................................................ 46 

IV.D Enterprise Architecture ...................................................................... 47 

V.......................... INFRASTRUCTURE ................................................................... 49 

V.A Hardware .............................................................................................. 50 

V.B Network and Telecommunications .................................................... 50 

V.B.1 Network ................................................................................................. 51 

V.B.2 Telecommunications ............................................................................. 52 

V.B.2(a) Voice Communications ....................................................................53 

V.B.2(b) Data Communications .....................................................................54 

V.C Software ............................................................................................... 55 

V.C.1 Internally and Externally Developed Software ....................................... 55 

V.C.2 Software Types ..................................................................................... 56 

V.C.2(a) Open Source Software ....................................................................59 

V.C.2(b) Mainframe Security Software ...........................................................59 

V.C.2(c) Application Programming Interfaces ................................................60 

V.C.3 Software Hosting ................................................................................... 62 

V.D.1 Heating, Ventilation, and Air Conditioning ............................................. 64 

V.D.2 Smoke and Fire ..................................................................................... 64 

V.D.3 Water .................................................................................................... 65 

V.D.4 Power .................................................................................................... 65 

V.D Environmental Controls...................................................................... 63 

V.E Physical Access Controls .................................................................. 66 

VI ........................ OPERATIONS ............................................................................ 67 

VI.A Operational Controls .......................................................................... 67 

VI.A.1 Operating Centers ................................................................................. 68 

VI.A.2 Authorization Boundary ......................................................................... 69 

VI.A.3 Identity and Access Management ......................................................... 69 

VI.A.4 Personnel Controls ................................................................................ 70 

VI.B IT Operational Processes ................................................................... 71 

VI.B.1 Maintenance.......................................................................................... 71 

VI.B.2 Configuration Management ................................................................... 72 

VI.B.3 Vulnerability and Patch Management .................................................... 73 

VI.B.3(a) Vulnerability Management ...............................................................73 

VI.B.3(b) Patch Management .........................................................................74 

VI.B.4 Backup and Replication Processes ....................................................... 75 

VI.B.5 Scheduling ............................................................................................ 76 

VI.B.6 Capacity Management .......................................................................... 76 

VI.B.7 Log Management .................................................................................. 77 

VI.B.8 Disposal of Data and Media .................................................................. 78 

VI.C.1 Service Management ............................................................................ 79 

VI.C.2 Operational Support .............................................................................. 80 

VI.C.3 IT Support ............................................................................................. 80 

VI.C.4 Event, Incident, and Problem Management .......................................... 82 

VI.D.1 Monitoring and Reporting ...................................................................... 84 

VI.D.2 IT and Operations Key Performance Indicators .................................... 84 

VI.D.3 Control Self-Assessments ..................................................................... 85 

VI.D.4 Continuous Improvement ...................................................................... 85 

VI.D Ongoing Monitoring and Evaluation Processes ............................... 83 

VI.C Service and Support Processes ........................................................ 79 

VII ....................... EVOLVING TECHNOLOGIES .................................................... 87 

VII.A Cloud Computing ................................................................................ 87 

VII.A.1 Essential Characteristics ....................................................................... 87 

VII.A.2 Cloud Service Models ........................................................................... 88 

VII.A.3 Cloud Deployment Models .................................................................... 89 

VII.A.4 Shared Responsibilities ......................................................................... 90 

VII.A.5 Risk Considerations for Cloud Computing ............................................ 91 

VII.A.5(a) Access Control Considerations ........................................................92 

VII.B Zero Trust Architecture ...................................................................... 93 

VII.C Microservices ...................................................................................... 94 

VII.D Artificial Intelligence and Machine Learning .................................... 96 

VII.E Internet of Things ................................................................................ 97 

APPENDIX A: EXAMINATION PROCEDURES ................................................. 99 

APPENDIX B: GLOSSARY .............................................................................. 132 

APPENDIX C: ABBREVIATIONS..................................................................... 151 

APPENDIX D: REFERENCES .......................................................................... 153 

# INTRODUCTION 

The “Architecture, Infrastructure, and Operations” booklet is one in a series of booklets that compose the Federal Financial Institutions Examination Council (FFIEC)1 Information Technology Examination Handbook (IT Handbook). The IT Handbook is prepared for use by examiners.2 With the publication of this booklet, the FFIEC member agencies replace the “Operations” booklet issued in July 2004. The title change reflects the overall importance of an entity’s architecture, infrastructure, and operations (AIO). For IT Handbook purposes, the term “entities” includes depository financial institutions,3 nonbank financial institutions,4 bank holding companies,5 and third-party service providers.6 

This booklet discusses enterprise-wide, process-oriented approaches that relate to the design of technology within the overall business structure, implementation of IT infrastructure components, and delivery of services and value for customers. It discusses the following: 

* • Principles and practices for IT and operations as they relate to safety and soundness,
* • Processes for addressing risk related to the design and implementation of IT systems.
* • Principles to help examiners evaluate the delivery of financial products and services.
* • Management oversight of AIO and its related components, including governance; common consumer financial protection, and compliance with applicable laws and regulations. risk management topics; specific activities of AIO; and evolving technologies that examiners may encounter during their reviews.

This booklet does not impose requirements on entities. Instead, this booklet describes principles and practices that examiners review to assess an entity’s AIO functions. Appendix A of this booklet provides objectives-based examination procedures. The application of the principles and related examination procedures may vary according to an entity’s complexity and risk profile. 

1 The FFIEC was established on March 10, 1979, pursuant to Title X of the Financial Institutions Regulatory and Interest Rate Control Act of 1978, Pub. L. 95-630. The FFIEC members are the Board of Governors of the Federal Reserve System (FRB), the Consumer Financial Protection Bureau (CFPB), the Federal Deposit Insurance Corporation (FDIC), the National Credit Union Administration (NCUA), the Office of the Comptroller of the Currency (OCC), and the State Liaison Committee (SLC). 

2 Each FFIEC member agency uses the principles outlined in this booklet, consistent with the member agency’s supervisory authority. 

3 The term “depository financial institution” includes national banks, federal savings associations, state savings associations, state member banks, state nonmember banks, and credit unions. 

4 The term “nonbank financial institution” includes non-depository financial institutions under the jurisdiction of either state banking departments or the CFPB. 

5 The term “bank holding company” includes any company that has control over any bank or over any company that is or becomes a bank holding company as defined by the Bank Holding Company Act. 

6 The term “third-party service providers” means third parties that provide services, the provision of which is subject to examination under the Bank Service Company Act, the Home Owners’ Loan Act, the Dodd–Frank Wall Street Reform and Consumer Protection Act, or other relevant law. 

# I ARCHITECTURE, INFRASTRUCTURE, AND OPERATIONS 

This booklet provides a foundation for understanding the principles and practices within the functions of AIO. Architecture, infrastructure, and operations are separate but related functions that, together, management should oversee to appropriately manage an entity’s activities related to designing, building, and managing the entity’s technology. For the purposes of this booklet, the functions are referred to as AIO. The functions of AIO comprise a variety of activities, such as network and application design within architecture; selection and placement of physical and virtual technologies within infrastructure; and configuration, deployment, and maintenance of the infrastructure that supports the business within operations. The following definitions and descriptions provide an overview of the IT environment.7 

Architecture refers to the manner in which the strategic design of the hardware and software infrastructure components (e.g., devices, systems, and networks) are organized and integrated to achieve and support the entity’s business objectives. Planning and designing an effective IT architecture facilitate management’s ability to implement infrastructure that aligns with the entity’s strategic goals and business objectives. 

Infrastructure refers to the physical elements, products, and services necessary to provide and maintain ongoing operations to support business activity and includes the maintenance of physical facilities. The focus of this booklet is on IT infrastructure, which is a subset of infrastructure and includes hardware, network and telecommunications, software, IT environmental controls (e.g., power, heating, ventilation, and air conditioning [HVAC]), and physical access. Once built and implemented, IT infrastructure can be managed internally or by a third-party service provider as part of the operations function. 

Operations are the performance of activities comprising methods, principles, processes, procedures, and services that support business functions. Operations transform resource or data inputs into desired products, services, or results, and help in the creation and delivery of business value to internal and external customers. Operations include the ongoing maintenance, monitoring, and support for business systems, products, and services. This booklet addresses IT operations in the context of tactical management and daily delivery of services to support the overall business processes of the entity. 

The principles and practices of the AIO functions outlined in this booklet are important for an effective IT environment. They support an entity’s business lines and delivery of products and services to meet strategic business objectives. Inadequate coordination and oversight of these principles and practices may result in various risks (e.g., credit, liquidity, operational, compliance, and reputation). 

7 The IT environment is the environment in which the entity directly operates, including direct interactions with the entity’s third-party service providers. 

# II ARCHITECTURE, INFRASTRUCTURE, AND OPERATIONS GOVERNANCE 

This section provides information about the governance of the AIO functions, including board and senior management responsibilities. General information about governance and risk management is contained in the IT Handbook’s “Management” booklet and other member agency guidance. 

Management should implement a process, such as a life cycle approach, to continuously manage technology to support operational needs and mitigate AIO-related risks. Figure 1 identifies the actions associated with this process for changing the architecture design to address evolving strategic and technology needs, building infrastructure that accommodates architecture changes, and managing technology in day-to-day operations. 

To address risks, management should employ effective governance that includes the following: 

* • Delineation of board and senior management responsibilities.
* • Strategic planning.
* • Enterprise risk management (ERM).
* • Delineation of other roles and responsibilities.
* • Policies, standards, and procedures.
* • Internal audit, independent reviews, and certifications.
* • Communications.
* • Board and senior management reporting.

Figure 1. Example of Life Cycle Approach for Governing AIO Risk 

Design 

Architecture 

| 

Operations 

Infrastructure 

O 

« 

## Action Summary 

### II.A Board and Senior Management Responsibilities 

The board is responsible for overseeing, and senior management is responsible for implementing and maintaining, a safe and sound operating environment that supports the entity’s goals and objectives and complies with applicable laws and regulations. Management should establish responsibility and accountability for the administration of the day-to-day functions of the IT environment. 

Examiners should review for the following: 

* • Board regularly receives reports on AIO functions and activities from management.
* • Discussions regarding AIO with the board are captured in meeting minutes.
* • Tracking mechanisms and processes are in place to monitor issues related to AIO to their resolution.

The board,8 or its designated committee, and senior management should consider the entity’s business objectives when governing the functions of AIO, including functions performed by affiliates and third-party service providers. Management should identify and evaluate risks associated with AIO, set short- and long-term objectives, and create policies and procedures to mitigate those risks. Furthermore, management should consider security and resilience in the design of new products and services. 

8 Most financial institutions have boards of directors; not all third-party service providers do. When an entity does not have a board, the senior leaders may have the responsibilities of the board described in this booklet. 

Board oversight practices should include the following: 

* • Aligning AIO principles and practices with the board’s strategic plans and risk appetite.
* • Budgeting appropriate resources to support AIO activities.
* • Ensuring board members have appropriate knowledge of risks to provide a credible challenge9 to management responsible for AIO functions.
* • Enabling appropriate management training on AIO to carry out its responsibilities and manage risk.
* • Reviewing AIO operating results and performance through audit reports, testing results, and management assessments and reports.

Management oversight should include the following: 

* • Validating through audits and other independent assessments that the following are comprehensive, meet enterprise-wide business and strategic plan objectives, and can assist in the identification of AIO risks: 
	+ o Architectural designs and integration across the entity (e.g., business units and other departments).
	+ o Infrastructure testing (e.g., network performance, penetration testing, and vulnerability assessments).
	+ o Operational testing (e.g., functional testing and operational resiliency).
* • Addressing risks self-identified by management, from AIO-related audits, and from other independent assessments, including the following risks: 
	+ o Architectural risks, such as a lack of stakeholder communication, inadequate requirements planning, lack of documented architecture review, and insufficient planning for aging architecture.
	+ o Infrastructure-related risks, such as under- or over-provisioning because of poor capacity planning, hardware or software incompatibility, and migration problems.
	+ o Operational risks, such as deficient IT asset management (ITAM), inadequate access management processes, equipment failures, inadequate processes for system updates, computer attacks, insider threats, disasters, and lack of qualified operations personnel.
* • Assessing and updating management’s AIO strategies and plans to reflect the current business conditions and operating environment for continuous improvement.
* • Promoting alignment and integration between functions of AIO. 9 A credible challenge involves being actively engaged, asking thoughtful questions, and exercising independent judgment.
### II.A.1 Strategic Planning 

The board and senior management should evaluate whether the IT strategic plans align with the enterprise-wide business and strategic plan, as well as established priorities. Management should address the following key factors of strategic planning: 

* • Participation of senior management: Senior management should understand and support AIO activities and confirm the inclusion of those activities in the IT strategic plan. Senior management should continuously review the strategic planning process and incorporate changes, as appropriate.
* • Responsibilities within the AIO functions: Management should define the responsibilities in AIO and determine whether the IT strategic planning process enables personnel to work toward achieving enterprise-wide business and strategic plan objectives.
* • Evaluation of architecture: Management should evaluate the entity’s current architecture and determine whether it meets enterprise-wide business and strategic plan objectives. If necessary, management should adjust its architecture to meet those plan objectives.
* • Impact of IT infrastructure: Management should understand the relationship between IT infrastructure and the enterprise-wide business and strategic plan objectives. IT infrastructure should directly support IT operations activities to meet IT strategic needs.
* • Post-implementation evaluation: Management should perform a post-implementation evaluation of the performance and results of IT projects and initiatives to determine whether each project achieved the anticipated benefits and stayed on budget or provided justification for cost variances. The evaluation should be based on management-defined metrics.

When considering whether AIO elements meet strategic plans, and to align with IT and enterprise-wide strategies, management should do the following: 

* • Evaluate whether past and current IT performance can support the planned IT strategy or future IT activities.
* • Take steps to ensure and validate that the IT department is delivering services on time, within budget, and to business specifications.
* • Balance resource investments between systems that support current operations and systems that transform operations and enable business units to grow and compete in new areas.

At a larger or more complex entity that provides IT services internally (e.g., help desk or in- house development teams) or externally as a third-party service provider (e.g., core processing providers or cloud service providers), management may consider the following in the IT strategic planning process: 

* • IT services strategy management: Service strategy defines the perspective, position, plans, and patterns that can be used to meet business outcomes. An IT service strategy helps management meet the needs of the entity (e.g., performance increase or constraint removal) while also providing for availability, capacity, continuity, and security.
* • Financial management for IT services: Financial management for IT services is a method of allocating the cost of providing those services through contractual agreements or service- level agreements (SLAs). The scope of financial management for IT services could include budgeting to control income and expenses, accounting for expenditures, and customer billing.
* • Service portfolio management (SPM): SPM enables the entity to balance the investment in AIO with the ability to meet business outcomes. SPM provides for the following: 
	+ o Decisions regarding services offered (e.g., cost benefit analysis).
	+ o Service catalog, including services that support IT functions.
	+ o Customer evaluations of services provided.
	+ o Control of services provided.
	+ o Planning and periodic assessment for a service’s end-of-life (EOL).
* • Demand management: Demand management includes consideration of customer demand for services and the entity’s capacity to meet that demand.
### II.A.2 Enterprise Risk Management 

Management should implement an ERM structure that incorporates the functions of AIO. ERM should include a consistent and current review of the entity’s products, processes, applications, infrastructure, interconnectivity, and other related risks to business operations. Depending on the entity’s size and complexity, AIO may be incorporated into ERM in a less formal manner. For more information on ERM, refer to the IT Handbook’s “Management” booklet. 

Management should establish and maintain an effective risk management process for initiating and overseeing all AIO-related activities, including those that are outsourced. Management should consider doing the following when developing its risk management process for coverage of AIO risks: 

* • Perform an initial assessment of the entity’s AIO-related risk.
* • Design architecture to meet the entity’s business goals or objectives, including enterprise and IT alignment, integration and interoperability, change management, and IT performance.
* • Use infrastructure and appropriate implementation processes to support the entity’s strategic objectives.
* • Identify infrastructure assets (e.g., hardware and software) and associated interconnectivity critical to business and IT operations.
* • Perform ongoing monitoring to identify and evaluate changes in risk from the initial assessment and periodically update the assessment.
* • Identify and document roles, responsibilities, procedures, and reporting mechanisms for risk management in AIO activities.
* • Define risk tolerances and risk and performance metrics for AIO activities.
### II.B Other Roles and Responsibilities 

Board oversight of IT, and subsequently the IT environment, is discussed in the IT Handbook’s “Management” booklet. There are, however, specific governance topics related to operational oversight discussed in this booklet. Entities may use different titles than those illustrated within this booklet; the responsibilities described, however, should be appropriately assigned. Common responsibilities and those responsibilities specific to architecture, infrastructure, and operations are described within the relevant sections. 

### II.B.1 IT Management Responsibilities 

IT management is composed of individuals with responsibility for overseeing the management, maintenance, and use of IT resources. While the titles of these individuals may vary, common titles include chief information officer (CIO) or chief technology officer (CTO). For more information about CIO and CTO roles, refer to the IT Handbook’s “Management” booklet. The CIO or CTO may also be responsible for overseeing the architecture function, implementing and maintaining the entity’s infrastructure, and managing IT operations in an integrated IT environment. A specific individual (e.g., IT manager or chief architect) or a team (e.g., enterprise architecture [EA]) can carry out the architecture function’s responsibilities. Generally, management should assign responsibilities based on the complexity of the entity’s architecture needs. Responsibilities for architecture and data management may fall to a chief architect or a data officer; however, in smaller or less complex entities, these responsibilities may be rolled into one or more other roles. In such cases, management should maintain appropriate separation of duties. Regardless of how they are assigned, common responsibilities are described in the following sections. 

#### II.B.1(a) Chief Architect 

A chief architect or enterprise architect is an individual responsible for the IT architecture process that reviews how IT functions can be centralized, allowing departments across the entity to work together seamlessly. This individual should understand interrelationships between IT and the entity’s business functions. The chief architect may be a C-level executive and, depending on the entity’s complexity, may oversee and coordinate the efforts of other technology-specific architects, (e.g., chief security architect, chief data architect, and chief cloud architect). Architecture responsibilities typically include the following: 

* • Developing and maintaining the enterprise model and repository and establishing a common understanding, vocabulary, and blueprint for all stakeholders. In smaller or less complex entities, a formal chief architect may not be named, but the responsibilities should be addressed according to the entity’s size and complexity.
* • Maintaining responsibility for designing the entity’s IT architecture to achieve the enterprise- wide business and strategic plan objectives.
* • Designing the architecture to accommodate IT changes in a way that maximizes value and minimizes issues associated with changes.
* • Communicating to the board and senior management any challenges (e.g., changing industry trends or resource constraints) in meeting those goals.
* • Maintaining representations (e.g., blueprints, network diagrams, and topologies) of the entity’s IT environment to help ensure that geographically diverse business units and divisions operate in an integrated manner.
* • Reviewing existing infrastructure and operations and working with other members of management to determine the capabilities needed by IT systems to deliver new products and services.
* • Working with other members of management to evaluate the implication of strategic planning (e.g., significant changes to architecture) on the entity’s technology landscape.10
* • Maintaining process and technical knowledge about security, storage, data management, and network service delivery.
* • Utilizing appropriate knowledge of IT architecture, structural design (e.g., layout and capacity to meet business needs), business operations, and current technologies.

The chief architect typically reports directly to the CIO or other senior management and often works with the CIO to do the following: 

* • Develop IT architecture policy and terminology.
* • Oversee IT architecture product development, use, and refinement.
* • Serve as owner of the IT architecture repository.
#### II.B.1(b) Chief Data Officer 

Typical responsibilities of a chief data officer (CDO) include enterprise-wide governance and use of information or data as an asset and assisting in protecting that data and deriving maximum value from it. Other responsibilities may include development of data-related policies, data life cycle management, data asset management (e.g., standardizing data formats and sharing data assets), oversight of compliance with applicable laws and regulations, and conformance with data management industry practices. The CDO provides input to the chief architect in the design of IT systems to promote alignment with enterprise-wide business and strategic plan objectives. This individual may be a C-level or senior executive who also reports to and works with other C- level personnel to manage risk. In smaller or less complex entities, this role may not be separate. Regardless, the responsibilities should be addressed. The CDO also performs the following: 

* • Oversees data management and data analysis and manages data-related projects (e.g., migrating data to the cloud or implementing a data analytics program).
* • Analyzes whether the entity’s products and services meet enterprise-wide business and strategic plan objectives from a data perspective.
* • Makes data and reporting tools accessible to the entity’s stakeholders, maintains data quality, and enables trust in data integrity.
* • Owns the entity’s strategic use of data and helps the entity perform more efficiently, improve productivity and revenue, and create business opportunities and innovation.
* • Communicates information about the entity’s data and analytics to appropriate stakeholders.
* • Defines a data strategy to enable information sharing and meet compliance objectives and the entity’s security requirements.
* • Evaluates data and its usage across the enterprise rather than serving a specific business unit. When developing products, considers planning the data and analytics platform first, then defining the release plan and road map. 10 An entity’s technology landscape includes the entity’s IT environment in which they directly operate, any direct interactions with the entity’s third-party service providers, and other technology considerations outside of the entity (e.g., global security issues, competitor IT initiatives, and new technologies).
* • Develops the metrics for monitoring data activities to meet customer needs, not just performance related to projects or programs.
#### II.B.1(c) IT Operations Management 

IT operations management is responsible for overseeing the IT environment, including performing and administering the day-to-day technology operations, security, and resilience. It is responsible for managing the capacity, performance (e.g., speed and flow of data), and availability of the components used in an entity’s infrastructure, including hardware, networks and telecommunications, software, and storage. Whether centralized or decentralized, IT operations management should support line-of-business and functional operations by facilitating enterprise information systems reporting, product and service development, service delivery, and transaction processing. 

### II.B.2 IT Operations Personnel Responsibilities 

IT operations personnel are responsible for the day-to-day operating and maintenance of the infrastructure components to support the entity’s business operations. The following are some examples of their responsibilities and functions: 

* • Network infrastructure management 
	+ o Network and connectivity for internal and external communication.
	+ o Remote access.
	+ o Internal and external telecommunications management.
	+ o Port management.
	+ o Network monitoring and issue resolution.
* • Server and device management 
	+ o Servers (on premises and off premises).
	+ o Storage solutions.
	+ o Entity-supported devices (e.g., desktops, laptops, and mobile devices) and personally owned devices (e.g., mobile devices and personal assistants) where used.
* • IT environment management 
	+ o Facility management, including data centers and connectivity to third-party service providers.
	+ o Help desk management.
	+ o Identity and access management (IAM).
	+ o Backup and replication management.
	+ o Configuration management.
	+ o IT environment resilience.
	+ o Cyber and information security.
	+ o IT project management.

The following are examples of common titles, roles, and responsibilities within IT operations: 

* • Database administrator (DBA): An individual or department responsible for the maintenance of security and information classification of the data stored on a database system(s). This responsibility includes the design, build, maintenance, and performance tuning of the database. DBAs use specialized software tools to store and organize data to support the entity’s business needs.
* • Systems analyst: An IT professional who coordinates with stakeholders to promote the effective and efficient functioning of infrastructure. Systems analysts research problems, develop solutions, and recommend appropriate courses of action. Systems analysts serve as translators between business and IT personnel by communicating each stakeholder’s requirements and constraints. Systems analysts use their knowledge of the entity’s computer systems, procedures, and technology needs to help IT personnel design systems that support the enterprise-wide business and strategic plan objectives. They may manage projects or assist with activities related to third-party service providers.
* • Client support specialist: An individual who assists employees, clients or customers, and third parties. Client support specialists use computer software and equipment to facilitate business needs and troubleshoot software and hardware issues. Client support specialists may also be referred to as user support specialists or “help desk” depending on the type of users they assist. In entities with a service management function, the role of the client support specialist may be carried out by service request or problem management personnel.
* • Systems administrator: An individual or group responsible for overseeing the day-to-day operability of a computer system or network. Systems administrators install and maintain information systems, support effective system utilization, and implement policies, procedures, and security controls.
* • Network administrator: Manages a network within an organization. Responsibilities include network security, software installation, distribution of software upgrades, daily activity monitoring, enforcement of licensing agreements, development of a storage management program, and performance of routine backups. Network administrators may design and analyze network infrastructures and make decisions regarding hardware and software upgrades.
### II.C Policies, Standards, and Procedures 

Management should document and maintain policies, standards, and procedures related to AIO. Smaller or less complex entities may have one policy and related procedures that encompass AIO, while larger or more complex entities may have multiple policies, standards, and procedures covering various aspects of AIO or various divisions or departments. Regardless of the entity’s size and complexity, management should implement policies, standards, and procedures that address scope, responsibilities, accountability, authority, and guidance to develop and maintain effective processes related to AIO. With respect to AIO, documentation should include the following: 

* • Policies11 that provide the guiding principles by which an organization designs, builds, and operates its information and technology assets and set the foundation for meeting the entity’s objectives. For example, an entity may have policies outlining the types of hardware or software it will or will not use (e.g., “We will not use any unapproved software.”). 11 The National Institute of Standards and Technology's (NIST) Glossary defines policies as statements, rules, or assertions that specify the correct or expected behavior of an entity.
* • Standards12 that build on the policies and provide more granular information for AIO
* • Procedures13 that describe the specific ways for personnel to perform AIO activities. For activities. For example, standards may explain the types of data that are allowed to reside in the cloud or the types of controls to be implemented to mitigate the risks of data residing in the cloud. example, AIO-related procedures may cover topics including how to harden new systems or perform architecture reviews with the necessary steps for personnel to follow.
### II.D Internal Audit, Independent Reviews, and Certification Processes 

#### Action Summary 

The board and senior management should engage internal audit or other independent personnel or third parties to review AIO functions and activities and validate effectiveness of controls. Effective AIO auditing assists the board and senior management with oversight, helps verify compliance with applicable laws and regulations, and helps ensure adherence to contractual agreements and entity policies, standards, and procedures to mitigate risks. 

Examiners should review for the following: 

* • Independence of AIO-related audits or other reviews.
* • Appropriate scope and detail of AIO-related audits or other reviews.
* • Applicable reporting of the AIO-related audit results to the board.
* • Evaluation of third-party service providers’ AIO-related audit or review reports.
* • Qualifications of auditors reviewing AIO functions and activities.

The board and senior management should engage audit or use other independent reviews to assess the AIO design, implementation, and operational effectiveness, including the adequacy of policies and procedures and the effectiveness of controls. In many cases, the review of AIO functions and activities will be included within other audits. Audit should review the entity’s AIO functions and activities and management’s ability to oversee and control risks related to those functions and activities. Auditors should be qualified and knowledgeable to review AIO functions and activities. For example, if an entity uses cloud environments, the auditor should have training and experience reviewing cloud infrastructures. Auditors should be independent of the AIO functions and activities being reviewed. Audit scope and frequency depend on the complexity of the AIO functions and activities; the entity’s risk profile; and design, implementation, and operational changes that the entity may experience. Larger or more complex entities may have multiple audits covering various departments or aspects of AIO functions and activities. Smaller or less complex entities may include a review of AIO within an IT general controls audit. 

12 The NIST Glossary defines standards as rules, conditions, or requirements that describe the following information for products, systems, services, or practices: (1) classification of components, (2) specification of materials, performance, or operations, or (3) delineation of procedures. 

13 The ISACA Glossary defines a procedure as a document containing a detailed description of the steps necessary to perform specific operations in conformance with applicable standards. Procedures are defined as part of processes. 

Audit or independent review reports to the board and senior management should provide an independent assessment of management’s ability to oversee the entity’s AIO functions and activities. For example, as part of their assessment, auditors or reviewers should perform the following: 

* • Evaluate supporting documents demonstrating that management has based AIO decisions on the entity’s business strategy, security, and resilience needs.
* • Leverage system and organization controls (SOC)14 reports and other external audit reports for the entity’s third-party service providers to evaluate potential risks to the entity, such as interconnectivity and supply chain risks.
* • Identify and report AIO issues to senior management and the board.

Some entities may choose to achieve an external certification (e.g., International Organization for Standardization [ISO] or Payment Card Industry Data Security Standard [PCI DSS]) to demonstrate the effectiveness of controls. These certifications can be reviewed along with audit reports or other independent reviews. Certifications are often a point-in-time assessment, however, and do not replace audit reports. 

### II.E Communication 

Effective communication helps ensure that key issues are understood across the entity, objectives are received and acknowledged by management and staff, and everyone understands his or her role. Effective communication of AIO concepts is critical to bridge discussions and decision- making between technical staff and management. The significance of IT, in terms of investment and potential impact on the entity’s business operations, highlights the importance of communicating the risks associated with IT and progress of IT strategic initiatives. Management is responsible for communicating relevant AIO information (e.g., disruptions, initiatives progress, or issue status) to the entity’s staff, applicable customers, and third parties. 

### II.F Board and Senior Management Reporting 

Management should report to the board periodically on the status of AIO-related initiatives, progress, issues, and metrics. The board should regularly monitor strategy, security, and resilience activities to verify that they are implemented as envisioned and reviewed (periodically and as changes occur). Board minutes should reflect significant AIO-related discussions, including credible challenges and approvals. 

14 “In 2017, the [American Institute of Certified Public Accountants (AICPA)]…introduced the term system and organization controls (SOC) to refer to the suite of services practitioners may provide relating to system-level controls of a service organization and system or entity-level controls of other organizations. Formerly, SOC referred to service organization controls. By redefining that acronym, the AICPA enables the introduction of new internal control examinations that may be performed (a) for other types of organizations, in addition to service organizations, and (b) on either system-level or entity-level controls of such organizations.” (AICPA, SOC 2 Examinations and SOC for Cybersecurity Examinations: Understanding the Key Distinctions.) 

A fundamental element for reporting includes setting baseline metrics against which management can measure performance and risks. Developing, implementing, and monitoring metrics for AIO functions and activities are key for evaluating progress toward achieving strategic goals and business objectives. Common metrics reported to senior management and the board help to identify the following: 

* • Performance of IT and AIO activities.
* • Return on investment for IT.
* • Anomalies.
* • Areas for improvement (e.g., cost, system, process, or service) providing opportunities for AIO.
# III COMMON AIO RISK MANAGEMENT TOPICS 

IT systems are designed, built, and implemented to achieve strategic goals and business objectives. While there are risks specific to each of the AIO functions, certain risks are common to all three. Common AIO risk management topics are discussed in the following sections: 

* • Data governance and data management.
* • ITAM.
* • Business and IT environment representation.
* • Managing change in AIO and change management.
* • Oversight of third-party service providers.
* • Resilience.
* • Remote access.
* • Personally owned devices.
* • File exchange.

## III.A Data Governance and Data Management 

### Action Summary 

Management should promote a culture that takes a data-centric approach for AIO functions and define responsibility and controls as part of data governance and data management processes. 

Examiners should review for the following: 

* • Data identification and classification processes.
* • Data management controls for safeguarding data in physical and digital form.
* • Effectiveness of processes for monitoring new and existing databases, noncompliant or misconfigured databases, and changes to the databases.
* • Effectiveness of processes for securing databases, analytics tools, and reports.
* • Processes for controlling non-masked data in non-production environments.
* • Processes for patching databases and monitoring whether the patch level of the production database is up to date.

The AIO functions are critical to planning for and implementing IT activities to meet business needs for one of the entity’s most critical and valuable assets—data. Management should, therefore, govern and manage data based on the entity-assigned data classification described in the “Data Identification and Classification” section of this booklet. 

Data governance and data management are fundamental to maintaining the confidentiality, integrity, and availability of information. Data governance is a set of processes for formally managing data assets throughout the entity. It establishes authority, management, and decision- making parameters related to the data that the entity produces or manages. Additionally, data governance involves the process for setting and enforcing the business and IT priorities for managing data.15 The data management process involves the development and execution of policies, standards, and procedures to acquire, validate, store, protect, and process data. Effective data management ensures that the required data are accessible, reliable, and timely to meet user needs. When data are no longer used, management should have a process for the data’s removal or destruction and validate the effectiveness of that process. 

In larger or more complex entities, data governance and data management are formally managed with defined responsibilities and functions. In smaller or less complex entities, these functions may be included in the responsibilities of a business line manager. Regardless of the entity’s size or complexity, business line management, which generally is the most knowledgeable about the entity’s data usage, should be consulted to assist in data classification, the development of recovery standards, and control validation by personnel responsible for these activities. Management should define responsibilities and processes for governing data, including the identification, management, and oversight of any metadata. Someone may be able to infer sensitive information from the metadata that could lead to misuse of the information. For example, third-party service providers could sell the metadata, providing an unauthorized individual with information about the entity’s customers or business strategies. This could increase legal and reputation risks because the metadata could be used to compromise (e.g., through social engineering) the entity or its customers. 

Effective data management continuously evolves as the entity grows or transforms to meet business objectives. Management should promote a culture that takes a data-centric approach, including for AIO functions. 

## III.A.1 Data Identification and Classification 

Data identification and data classification are important components of data management. To effectively manage data, it is important to identify what data the entity has, particularly to identify sensitive customer and entity information. The data identification process includes structured data, managed by a system of record, as well as unstructured data (e.g., physical loan files, emails, documents, images, presentations, or free-form text comment fields in applications) created or processed by end users. There are inventory tools available to assist management with the data identification process. Once the data is accurately identified, it should be appropriately classified. 

Data classification is the process of categorizing data based on the expected damage to operations following loss or compromise of the identified information. Classification is based on its level of confidentiality (i.e., sensitivity), integrity, and availability, as well as the value and criticality to the entity. Management should identify and understand the nature of the entity’s data to classify it effectively, including the following: 

15 Refer to the U.S. Department of the Treasury’s Data Governance Board Charter. 

* • Sensitivity, criticality, and importance of the data for the entity, its business units, or its customers on a day-to-day basis.
* • Frequency, recurrence, and use of data by the entity and its business lines.
* • Format in which data are maintained (e.g., database, online files, or paper copies).

Management should use the results of the data classification process for implementing controls to safeguard data, whether in physical (e.g., paper and storage media) or digital form. Management should understand where data reside and maintain the effectiveness of controls over those data, including controls over databases. Management should regularly update the information and technology asset inventory (described in the “IT Asset Management” section of this booklet) for new assets (e.g., data, hardware, systems and software, and databases) regardless of whether the asset and its data are maintained in-house or by a third-party service provider. For more information, refer to the IT Handbook’s “Information Security” booklet. 

## III.A.2 Database Management 

When evaluating AIO, it is important to evaluate database management. Databases are used to store data so that they can be organized, easily accessed, effectively managed, and readily updated. Often, an entity’s data are stored in databases and accessed or used by software. Databases can exist on mainframes, within internal networks, in a cloud environment, and on standalone computers. 

Databases typically contain critical and sensitive data, including customer account data. Therefore, databases pose unique risks (e.g., data corruption, data misuse, data errors, or unauthorized changes). For that reason, securely designing, building, and operating databases are important to protecting the data itself. Management should implement a process to adequately secure and oversee the entity’s databases to minimize the potential for unintentional or unauthorized modification, destruction, or disclosure of sensitive customer or entity information. 

As part of understanding where data reside, management should ascertain the effectiveness of database controls, and assign appropriate staff to update the data and technology inventories. Management should determine whether databases are appropriately located and structured, have sufficient capacity, and are resilient. Management should regularly monitor for new databases or significant changes (including data loss) to existing database(s) and report on misconfigured databases or those that are out of compliance with the entity’s configuration standards. 

Databases are also an important building block used to construct information for use by business lines, customers, third-party service providers, and partners (e.g., joint ventures). It is important to understand how databases interconnect throughout the entity when developing an architectural design and selecting appropriate infrastructure. 

In addition to databases, there are other methods (e.g., data warehouse, database server, tape, and paper) and formats (e.g., structured data and unstructured data) for storing data when considering database management control implementation. Regardless of how the data are stored, the focus should be on identifying, managing, and securing the data as well as identifying business uses for the data and providing access to authorized lines of business. 

Responsibilities for database management controls typically are managed by a DBA; however, in smaller or less complex entities, these responsibilities may be assigned to other personnel. A DBA is typically responsible for database configuration, including security configuration, access controls, and maintenance, as well as training employees on databases. Additionally, this individual monitors the databases and maintains awareness of normal operations. A DBA should work with the information security officer to strengthen database security. 

A DBA should monitor for anomalous database activities, which could indicate errors or fraud. For example, delays in response time for user queries may indicate the presence of malware or corrupted data. In preparation for such a scenario, the DBA should be familiar with procedures to protect sensitive information, restore normal operations, and notify the information security officer. As DBAs have highly privileged access to databases, use of accounts belonging to DBAs should be limited and independently monitored. 

### III.A.2(a) Database Security 

Databases often store sensitive information; therefore, they are frequent targets of malicious activity by internal and external sources. As part of database management activities, management should implement effective database security controls. Examples of database security controls include the following: 

* • Change passwords for default user accounts and, subsequently, disable or delete those accounts when possible.
* • Track and monitor activity for default accounts that cannot be disabled or deleted.16
* • Restrict account access (e.g., to view or modify data, to modify the database or data structure, and to change access rights) and limit privileges and permissions to only those necessary to carry out job responsibilities and automated functions.
* • Implement password management tools or activities (e.g., password changes after a determined time frame, vaulting of system-level passwords, and use of password complexity rules).
* • Employ an appropriate level of encryption on data in transit and data at rest based on the type and criticality of the information according to the entity’s data classification policy.
* • Configure and review audit logs (e.g., configuration settings, access control, and log review processes).
* • Regularly monitor database activity logs to track account access and activity, including activity that modifies sensitive information and alters the database security parameters or structure (e.g., modifying or deleting database tables or connections).
* • Independently monitor DBA and privileged account activities (e.g., use of or changes to system privileges).
* • Classify data maintained within the database. 16 Default accounts often come with the hardware, software, databases, or operating systems. While it is a good practice to disable or delete these accounts, at times system-level default accounts cannot be deleted without affecting the system functionality. In such cases, default passwords on the account should be changed and any activity performed by those accounts monitored.
* • Restrict and monitor data extraction (e.g., limiting and monitoring data queries, user abilities, and the use of standardized business intelligence tools17 to query databases to provide standardized reporting).
* • Implement and adhere to patch management processes to maintain a current and secure database and underlying operating system (OS).
* • Implement OS controls (e.g., configuration settings and access control).
* • Monitor OS-level privileged account activities.
* • Manage application-level access (e.g., access by and through applications).

The DBA may use automated tools to help implement controls and monitor the database environment. These tools include database discovery, security scanning, configuration lockdown, automated remediation, and security reporting. For more information, refer to the IT Handbook’s “Information Security” booklet. 

## III.A.3 Non-Production Environments 

Entities often have environments beyond the production environment. This allows management to make changes and perform testing in a way that does not impact the entity’s production environment. For example, entities that develop their own software often have multiple environments to support their development processes. These non-production environments, commonly used for development, testing (either for testing changes or exploring the feasibility of potential new technologies, products, and services), or quality assurance, provide alternate information processing environments; allowing an entity to develop and test system changes without impacting production. While production environments pose significant risks to the entity and its customer information, non-production environments are not without risks. These risks include: 

* • Privacy and misuse of data. Entities sometimes copy production data into non-production environments, potentially allowing individuals to access information beyond what is needed for their job description.
* • Security tradeoffs. To facilitate rapid changes or for development and testing of functionality, management may disable or omit security.
* • Data corruption. Stale or incorrect data may inadvertently corrupt production data if non- production data are not appropriately segregated from production data.
* • Transition to production. Failure to enable production levels of security may introduce vulnerabilities into the production environment.
* • Secondary use. At times, non-production environments or data may be used for other than their intended purposes (e.g., training), which could expose sensitive data unnecessarily. Additionally, data used may not be appropriately secured.
* • Data breach. If non-production environments are not properly secured, malicious actors may gain access and use that access as a conduit into production environments. Additionally, malicious actors may be able to access sensitive data contained within non-production environments. 17 Business intelligence tools can be used to help management gather and analyze its data (e.g., transactions that match fraudulent activity patterns) and can expand the entity’s attack surface because of their access to an entity’s databases.

Management should consider design, placement, and effective security controls for non- production environments. Non-production environments should be independent of production environments to maintain data integrity and resilience. Management should use simulated synthetic data in non-production environments when possible. When production data must be used for testing, it should be masked, or sanitized whenever feasible. In cases where masking data is not feasible, management should require approval by the appropriate level and implement controls similar to those used in production environments. Controls could include IAM, password controls, and logging and monitoring of activity within non-production environments. For more information, refer to the IT Handbook’s “Information Security” booklet. 

## III.A.4 Data Analytics 

Data analytics is the process of evaluating and organizing data sets to draw conclusions, make predictions, and reveal trends. The results of data analytics may be used to improve decision- making, optimize processes, and increase efficiency. Data analytics can help management discover hidden patterns, correlations, security threats, trends, customer preferences, and other useful business information. Management should consider the uses and risks of data analytics. While management may use data analytics to make business decisions (e.g., introducing a new product or analyzing security logs), data analytics reports could expose sensitive data. Therefore, management should limit access to analytics tools and related outputs and incorporate confidentiality, integrity, and availability when designing or selecting analytics tools. Management also should inventory the data sources, assess the information type according to the entity’s data classification policy, and appropriately secure those sources according to the data’s risk classification. 

Management should develop design requirements and parameters for analytics. Data analytics results can be produced as dashboards and reports, which may be available on demand. Management and personnel using data analytics should have sufficient knowledge to interpret dashboards and reports. Insufficient dashboards or reports, or incomplete data, can lead to a misunderstanding or misuse of the data in decision-making processes. Management should consider the following when implementing and using data analytics: 

* • Document the types of data maintained, data owners and users, and purpose for reports.
* • Determine usage needs by stakeholders (e.g., internal personnel and customers) and the ability of analytics reports to meet them.
* • Determine whether there are opt-in considerations based on the information type in the analytics reports.
* • Determine disclosure requirements (e.g., to regulatory agencies, internal stakeholders, and customers) in the event of a security incident.
* • Implement access controls and activity monitoring over analytics tools and reports.
* • Define processes to remove or destroy data when no longer used in the data analytics tools.
* • Identify data that are subject to applicable laws and regulations (e.g., “Interagency Guidelines Establishing Information Security Standards” [Information Security Standards],18 the Fair Credit Reporting Act, and the Equal Credit Opportunity Act) or other relevant industry standards (e.g., PCI DSS).
* • Identify data analytics processes used by the entity to comply with applicable laws and regulations (e.g., Bank Secrecy Act/anti-money laundering, the Office of Foreign Assets Control, or the Sarbanes–Oxley Act [SOX]).

According to the National Institute of Standards and Technology (NIST), the growth of data is outpacing the abilities of current data analytics systems to process the data. 19 This exponential growth of data has produced larger and more varied pools of data, often referred to as big data,20 which need to be analyzed more rapidly. 

Big data can be mined for information and is notable for the volume of data (including large amounts of sensitive customer information), the speed at which the data is processed, the variation in data types, or the variability (e.g., the change to a data set’s data flow rate, format, or volume). Specialized tools and software have enabled complex and high-volume data analytics, especially for big data. Risks associated with big data include unintended uses of information or patterns (specifically with sensitive customer and entity information); concerns with the maintenance, use, and protection of sensitive customer and entity information; third-party access to data; and compliance risks. As part of its mitigation strategy, management should implement appropriate security policies, standards, and procedures, along with data access and security controls in accordance with the entity’s data classification policy. Refer to the IT Handbook’s “Information Security” booklet for more information. 

18 Refer to 12 CFR 30, appendix B (OCC); 12 CFR 208, appendix D-2 and 225, appendix F (FRB); 12 CFR 364, appendix B (FDIC); and 12 CFR 748, appendix A (NCUA) (collectively referenced in this booklet as the Information Security Standards). 

19 NIST Big Data Interoperability Framework: 

Volume 1, Definitions. 

20 Ibid. 

## III.B IT Asset Management 

### Action Summary 

Management should have appropriate ITAM processes to track, manage, and report on the entity’s information and technology assets. 

Examiners should review for the following: 

* • Policies, standards, and procedures.
* • Technology asset inventories. 
	+ o Hardware inventory, including telecommunications.
	+ o Software inventory.
* • Processes to address IT asset EOL.
* • Processes to prevent and detect unknown or unapproved technology (called shadow IT).

ITAM is the process to track, manage, and report on information and technology assets21 throughout their entire life cycle. ITAM plays a significant role in the AIO functions, demonstrated by the following examples. In architecture, if management is aware of the entity’s current inventories, it can determine the necessary design changes to meet strategic goals and objectives. For infrastructure, ITAM allows management to acquire hardware or software components that are interoperable with the entity’s existing infrastructure. With respect to operations, the ITAM inventories help management know what systems need to be patched and the patch time frames, what hardware or software is nearing its EOL, where the entity’s vulnerability management focus should be, or when any additional security measures are necessary. 

Management should have a comprehensive inventory of its electronic (or digital) and physical information assets to adequately safeguard them against reasonably foreseeable threats. An inventory will assist management as it develops and maintains the entity’s information security program as described in the Information Security Standards. 22 As part of the entity’s information and technology asset inventory, management should specifically identify the entity’s information assets, determine the assets’ appropriate classification, and protect the assets according to the entity’s data classification process. Refer to the IT Handbook’s “Information Security” booklet for more information on methods for safeguarding sensitive customer information. 

21 Information and technology assets can include hardware, software, mobile devices, virtual and cloud assets, physical assets (e.g., cabinets, locks, and hard copy information assets), digital information assets (e.g., data), and third-party managed assets. 

22 Refer to 12 CFR 30, appendix B (OCC); 12 CFR 208, appendix D-2 and 225, appendix F (FRB); 12 CFR 364, appendix B (FDIC); and 12 CFR 748, appendix A (NCUA). Section III.C of the Information Security Standards requires each financial institution to have a comprehensive written information security program designed to manage and control risk where each institution shall design its information security program to control the identified risks, commensurate with the sensitivity of the information as well as the complexity and scope of the institution’s activities. Each institution must consider whether the security measures set forth in III.C.1 are appropriate for the institution. 

Management should implement policies, standards, and procedures to govern all aspects of ITAM, including information and technology assets. The ITAM process includes identifying the technology assets that the entity possesses and manages, determining each asset’s status (e.g., active or inactive), and identifying the life cycle phase of those assets. Management should regularly review and validate the accuracy of the inventories. The ITAM process also includes identifying personally owned technology assets that are allowed to connect to the entity’s network, with considerations such as the design, implementation, and controls over the assets’ use. Management may use ITAM to help make informed, business-driven decisions for entity- owned and personally owned IT assets. 

The inventories help management identify or understand the following aspects of ITAM: 

* • License utilization.
* • Support costs related to maintenance, utilization, and obsolescence.
* • Existence of unauthorized devices operating on the entity’s networks.
* • Potential vulnerabilities, such as hardware and software that are in need of upgrade or are reaching EOL.
* • Compliance with internal configuration and security standards, as well as contractual requirements.
* • Critical interdependencies (e.g., third-party service providers, software, hardware, and business units).

As part of ITAM, management should use appropriate inventory mechanisms to track and validate the entity’s information and technology assets. Smaller or less complex entities may use informal methods (e.g., spreadsheets) to track IT assets. Larger or more complex entities may use more sophisticated methods or automated tools to assist with ITAM. Automated tools can provide a variety of functionality, such as logging and vital asset statistics. Some automated tools alert management when a new or unapproved device is connected to the entity’s network. Because automated inventory methods or tools may not identify all IT assets that connect to the network, management may need to manually inventory those types of devices (e.g., internet of things [IoT] devices). 

## III.B.1 Technology Asset Inventory 

Building technology asset inventories is a foundational process that management uses to identify entity-owned IT assets. The inventories should include information regarding the entity’s hardware, software, and telecommunications. Management also should consider IT assets that do not fall into traditional hardware or software inventories, such as internet assets (e.g., website addresses owned, certificates employed, domains used, or rights to audio or video files). Smaller or less complex entities may have one comprehensive inventory that contains all of its technology assets. Larger or more complex entities may have multiple inventories to track their technology assets. Management can leverage the technology asset inventories for the following purposes: 

* • Supporting the entity’s risk assessments (e.g., information security, SOX, continuity and resilience, or business unit).
* • Evaluating the design of the infrastructure and IT environment supporting business processes.
* • Identifying potential security weaknesses (e.g., assets reaching EOL or operating on outdated versions of software).
* • Managing vulnerabilities by identifying necessary versions and patch levels for continuity of operations.
* • Aligning with strategic planning (e.g., acquiring specific technology for current and future business needs).
* • Assisting in audit risk assessments and building the audit universe and scope.

There are tools that may help management identify and manage hardware (including telecommunications) and software in the entity’s IT environment. For example, automated asset management tools can scan an entity’s IT environment for unauthorized hardware, software, and devices (sometimes called shadow IT). Smaller or less complex entities may use manual asset inventory processes; these processes, however, should allow management to effectively document, track, and oversee the entity’s technology assets. 

ITAM policies, standards, and procedures should outline a process to update the technology inventories after changes to IT infrastructure or operations. All inventories should be periodically reviewed to verify that they accurately capture the entity’s technology assets. 

### III.B.1(a) Hardware Inventory 

Management should maintain a hardware23 inventory that identifies the entity’s hardware assets. The hardware inventory should identify equipment owned and managed by third parties on the entity’s behalf that may be located within the entity’s environment (e.g., wire transfer routers, core processing hardware, and third-party security monitoring devices). The hardware inventory should include entity-owned and entity-managed virtual infrastructures (e.g., virtual servers on the entity’s premises or virtual servers in a cloud environment). To the extent possible, hardware items should be assigned a unique identifier (e.g., labels or bar codes) to allow management to identify, account for, and monitor for changes to hardware assets. 

The entity’s hardware inventory should contain information about the entity’s network and telecommunications equipment. The information includes the type, use, and configuration of the equipment and related software that provides internal and external network connections. 

The following are examples of information to include in the hardware inventory: 

* • Vendor and model.
* • OS version or release level.
* • Function or use. 23 For the purposes of this booklet, hardware includes devices, mainframes, servers, storage equipment, desktops, and printers.
* • Status (e.g., active, nearing EOL, or decommissioned).
* • Memory and storage size.
* • Processor speed.
* • Owner or contact information.
* • Network connectivity.
* • Physical location.
* • Identifiers (e.g., internet protocol [IP] address and media access control [MAC] address).
* • Criticality classification.
* • Upstream and downstream connections.
* • Environment (e.g., production, test, or development).
* • Firmware version.
* • Most recent maintenance date.
* • EOL date, if applicable.
* • Network and telecommunications equipment, including: 
	+ o Routers.
	+ o Firewalls.
	+ o Intrusion detection and prevention systems (IDS/IPS).
	+ o Virtual private networks (VPN).
	+ o Telecommunication lines.
	+ o Provider.

In addition to hardware, additional information should be considered when evaluating the network (e.g., network segments and associated attributes, such as IP addresses, domains, network protocols, and third-party network contractual arrangements) and these can also tie to the entity’s software inventory. 

### III.B.1(b) Software Inventory 

Similar to a hardware inventory, management should maintain an accurate software inventory. The software inventory provides detailed information on software used within the entity’s IT environment. The following are examples of information to include in the software inventory: 

* • Application or database name and type (e.g., general ledger or payroll).
* • Developer (e.g., developer name or internally developed).
* • Vendor name, if not the developer.
* • Install date.
* • License renewal date.
* • EOL (e.g., end-of-support) date and expected software life, if applicable.
* • Serial number.
* • Version.
* • Patch level.
* • Last patch date.
* • Number of copies, licenses, and users allowed, if applicable.
* • Environment where software runs (e.g., production, test, or development).
* • Owner or contact information.
* • Internally run or hosted at a third-party service provider and where, if applicable.
* • Criticality based on the software assessment (e.g., line of business use, interconnectivity, and recovery priority).
* • Data classification based on data type (e.g., sensitive customer or entity information).
* • Physical or virtual location.
## III.B.2 IT Asset End-of-Life 

With respect to technology, EOL is a time frame usually defined by a technology vendor to describe when an asset has reached the end of its useful life cycle or when the vendor will no longer support the asset or continue to sell or license it. All technology, including hardware, software, and assets in the cloud, has an asset life cycle. NIST states that an asset’s typical life cycle24 includes enrollment, operation, and EOL phases. Each IT asset should be captured in the entity’s ITAM inventory, tracked throughout its operational life to monitor for changes (e.g., vendor announcements regarding support or changes in functionality, reliability, or processing speed) in the asset or the changing needs of the entity, and prepared for physical removal at the end of its useful life. Management should implement policies, standards, and procedures to identify assets and their EOL time frames, to track assets’ EOLs, and to replace, or upgrade, the asset. Failure to maintain effective identification, tracking, and replacement processes could have operational or security implications (e.g., unavailable or unapplied security updates [patches] that make technology vulnerable to disruption). 

EOL for hardware (e.g., servers, routers, and cables) refers to the end of its useful life when the hardware is no longer capable of supporting the entity’s strategic objectives. Hardware EOL may be due to issues such as wear and tear, capacity or speed issues, or obsolescence of hardware components. Alternatively, software EOL refers to the time frame when a software development company no longer provides automatic fixes, updates, or software support for the product (e.g., OS or application software). Management should address EOL in contract provisions with its third-party service providers. For more information on contract provisions, refer to the IT Handbook’s “Outsourcing Technology Services” booklet. 

With respect to existing technology, effective EOL management should include the following: 

* • Adding assets to the information and technology inventories and tracking changes made to assets.
* • Conducting risk assessments to help determine the EOLs of existing assets.
* • Reviewing EOL time frames for existing assets to determine accuracy and relevance.
* • Developing replacement plans for assets nearing obsolescence.
* • Establishing procedures for the secure destruction or data wiping of hardware (e.g., hard drives; copy machines; servers, desktops, and laptops; or mobile devices) and software (e.g., databases) to prevent the inadvertent disclosure of sensitive information.

For new technology assets, effective EOL management should include the following: 

24 Refer to NIST Special Publication (SP) 1800-5, IT Asset Management. 

* • Incorporating EOL considerations in strategic planning.
* • Planning for obsolescence during initial project stages (e.g., during requests for proposals or proofs of concept).
* • Registering and tracking assets in the information and technology asset inventories, including available EOL information.
* • Developing plans for maintaining operational viability and security of IT assets beyond EOL, if necessary.
## III.B.3 Shadow IT 

Shadow IT refers to IT devices, software, or services operating within the entity’s environment without the knowledge, approval, or control of IT management. Shadow IT can also be identified within a third-party service provider’s environment. Unapproved devices, software, or services should not be running at the entity, but they could be placed there by the following: 

* • Business units to support their specific needs in contravention to the enterprise’s needs.
* • Third-party service providers to support services provided to the entity or to collect data for the service providers.
* • Individuals (internal or external) for convenience to allow them to use entity resources (e.g., wireless network) or for malicious purposes (e.g., to steal data or processing power).
* • Incomplete decommissioning process for legacy systems (e.g., business unit systems that were never decommissioned because of software compatibility limitations).

Failure to address the risks of shadow IT may lead to an unknown attack vector due to management’s lack of awareness of unapproved devices, software, or services. Therefore, management should understand and communicate the following risks of shadow IT to the entity’s personnel: 

* • Security weaknesses, data breaches, or data loss from using unapproved devices, software, or services.
* • Inability to maintain or update (e.g., apply patches to) unknown devices or software resulting in vulnerable devices or software.
* • Costs related to identifying, diagnosing, and mitigating security issues.
* • Inability to back up and recover unknown devices or software.
* • Unintentionally performing automatic backups of unapproved and possibly infected devices or software leading to the spread of malware.
* • Penalties for using software or services without a license.
* • Legal risks related to data use or data ownership (e.g., data residing on devices outside of the ownership or control of the entity).
* • Potential nullification of cyber insurance.

Management should establish IT governance practices and security controls along with consistent policies, standards, and procedures to mitigate risks of shadow IT. Security awareness training should include the risks of shadow IT and the rationale for preventing its use. Such training may deter deployment of shadow IT, encourage personnel to notify management of its use, and inform personnel of notification procedures (e.g., how and when to notify). 

Identification of shadow IT on an entity’s network or systems often occurs through regular review of the network’s assets, comparing the results of the review to approved assets on the inventories and diagrams. Using IT detection tools may allow management to monitor for and identify shadow IT (e.g., unauthorized IoT devices or rogue Wi-Fi connections). When connected to the cloud, software or hardware tools (e.g., cloud access security brokers) can be used to discover unknown applications. In addition, management should employ appropriate data protection and data loss prevention tools to minimize the potential for exfiltration or misuse of sensitive customer and entity information. 

The identification of shadow IT does not eliminate it. Shadow IT remains until management appropriately addresses it. While shadow IT should be addressed in a timely manner, there is a risk that removing shadow IT could negatively affect a department process. The entity’s reputation, product and service delivery, and revenue stream could be affected if shadow IT is removed without an appropriate plan. Management should perform the following when determining appropriate methods to address shadow IT: 

* • Identify security risks associated with shadow IT in use and determine whether there is malicious intent.
* • Identify the reason for use (e.g., compatibility issues or preference for specific device type).
* • Determine the clients or processes shadow IT may be supporting.
* • Verify interconnectivity with third-party service providers and integration with other entity software.
* • Determine the appropriate disposition of shadow IT (e.g., remove or transition to entity- managed infrastructure and add to the ITAM process).
* • Review policies, processes, and tools to understand any gaps that may allow shadow IT to occur.

Without appropriate identification of shadow IT, independent reviews (e.g., penetration tests, vulnerability assessments, or audits) may not be comprehensive. While audit processes typically do not identify shadow IT, internal audit should evaluate management’s processes to monitor, identify, and remove unapproved devices, software, or services. 

## III.C IT and Business Environment Representations 

Common types of documentation maintained to represent the entity’s IT and business environments are network diagrams, data flow diagrams, business process flow diagrams, and business process narratives. Management should document and maintain accurate representations of the current IT and business environments and should employ processes to update representations after the implementation of significant changes. Representations may assist management by identifying the following: 

* • Physical and virtual technology assets (e.g., hardware and software), including locations, version and model numbers, and whether the assets are still supported.
* • Information (digital and physical, as appropriate) assets (e.g., location and flow of sensitive customer information and data storage locations), including interdependencies of assets, data classification, owner designation, and environment details (e.g., production, test, or development).
* • Hardware and connections for network maintenance, troubleshooting, and recovery from disruptions.
* • Interconnectivity and process flows between and among the following: 
	+ o Lines of business.
	+ o Entity and external parties (e.g., third-party service providers and customers).
	+ o Network access points (e.g., VPN connections).
	+ o Other devices.
* • Points of internal or external connectivity that may need protection or additional controls that may be appropriate.
* • Locations of sensitive data at rest and security points for data in transit.
* • Potential for expansion (e.g., new technologies), reconfiguration, or removal of technology assets.
* • Opportunities for business process improvements (e.g., incompatible business line process flows).

While various representations may be used for different purposes, management should coordinate the development of representations among stakeholders. This coordination allows management to obtain a holistic view of the entity’s IT environment and understand how it supports business processes. The diagrams and narratives should be aligned with each other and across lines of business. For example, if the business flow diagram refers to a particular function, or application, other diagrams and narratives should use similar naming conventions to refer to that function for reference purposes. 

Management should periodically review documented diagrams and narratives to verify the accuracy of the representations of the IT and business environments. Inaccurate information could result in incorrect decisions, which could lead to security vulnerabilities, maintenance issues, or recovery delays. Management should provide for the resilience of this documentation by maintaining current and accurate backups. 

Management should appropriately restrict access and editing privileges to the representations due to the confidential or sensitive information they contain (e.g., IP addresses, location, or interconnectivity of network elements). Management should consider developing versions of the diagrams or narratives with only the information needed for entity and third-party service provider personnel to perform their duties. 

For larger or more complex entities, manual documentation and monitoring processes may not be effective at identifying all pertinent information. Therefore, automated tools may be used to document and assist in the management of the IT and business environment. 

## III.C.1 Network Diagrams 

A network diagram (also called a network map or network topology) is a visual representation of nodes and connections in a computer network. Figure 2 is an example of a network diagram. An entity’s network diagram may include the following: 

* • Hardware (e.g., critical systems, routers and switches, and storage devices) and virtual components (e.g., virtual servers and cloud infrastructure).
* • Internal and external connections (e.g., internet access, cloud access, remote access, and third-party access).
* • Network segments and associated trust level (e.g., trusted, semi-trusted, untrusted, or restricted), including boundary protections.
* • Bandwidth of connectivity within and between network segments.
* • Infrastructure used to support specific business units.
* • Geographical locations of infrastructure.
* • Connectivity (e.g., fiber optic, multiprotocol label switching (also known as MPLS), VPN, dial-up, and wireless).
* • Security elements (e.g., firewalls and IDS/IPS).
* • IP addresses of specific infrastructure elements.
* • Connection points for third-party service providers and customers.
* • Encrypted or other secure communication channels.

Figure 2. Example of a Network Diagram 

| 

$) 

Remote users via VPN 

Guest Wi-Fi 

Database server 

Mail server 

| | 

| 

| 

Firewall 

Antivirus/ 

IDS/IPS 

Firewall 

| | 

| | 

| 

« 

A 

Internet 

Border router 

Demilitarized zone (DMZ) 

E 

Bank website 

Application server 

Note: Figure 2 is for illustrative purposes only and shows components a network diagram may contain. 

# III.C.2 

## Data Flow Diagrams 

A data flow diagram is a graphical representation of the flow of data internally through the entity’s network(s), business units, products, and software, and to third parties, as applicable. (Refer to figure 3.) Data flow diagrams and network diagrams may include similar information (e.g., critical hardware) but have different purposes. Data flow diagrams show how the entity’s data flows between critical hardware on the network, not just where a piece of hardware resides. 

Figure 3. Example of a Data Flow Diagram 

Applicant 

Application 

### 1.0 

Applicant completes application 

Complete application 

### 2.0 

Entity receives 

application 

Complete 

application 

### 3.0 

Update 

applicant file 

Applicant 

data 

Applicant 

File 

* - Applicant data

Selection report 

Hiring 

agreement 

### 4.0 

Select 

candidates 

Human 

Resources 

Employee 

File 

Applicant data 

5.0 Update 

applicant and employee file 

Offer and acceptance data of new hires 

New 

-employee 

data 

Offer and acceptance data 

#### 6.0 

Create 

management reports 

New hire 

report with 

biographical 

data 

Management 

Note: Figure 3 is for illustrative purposes and does not show every step in the process. 

In smaller or less complex IT environments, data flow diagrams and network diagrams may be combined. In larger or more complex IT environments, the entity generally has multiple data flow diagrams and network diagrams broken out in a variety of ways (e.g., lines of business, geographic locations, network segments, and business functions). Data flow diagrams may include the following: 

* • Storage locations of data (i.e., data at rest), especially sensitive data, and where data flow between equipment and systems (i.e., data in transit).
* • Data sharing between applications.
* • References to network diagrams for details of internal and external connectivity.
* • Specific operational or business processes and any single points of failure.
* • Data flow within the entity (e.g., operational or business process interaction and interdependencies) and between the entity and its third-party service providers.
## III.C.3 Business Process Diagrams and Narratives 

Business process diagrams depict the relationships between an entity’s business processes and control points, including interactions and interdependencies. The diagrams illustrate processes, functions, and decision points for a business activity, such as those depicted in figure 4. The diagrams often depict the handoff between departments that have a role in carrying out different parts of the business activity. 

Figure 4. Example of Process Flow Diagram 

Bank Account Opening Process 

Start 

Send PIN A 

Receive open new 

account request 

Send bank 

card 

Notify customer of 

availability of funds 

Yes 

Accept or reject 

| Accept -> 

Open 

account 

Make credit 

decision 

X 

Notify customer of 

insufficient funds 

Care 

Customer 

Office 

Back 

Reject Notify customer 

File 

rejection 

End 

Create 

account 

Perform credit 

assessment 

Update customer 

account 

Business process narratives, on the other hand, describe the entity’s business processes and related control points, often to support control reporting, such as for SOX or SOC reports. Business process narratives often align with and help provide additional information about business process diagrams and control objectives and may be useful for understanding how an entity’s business units function. 

## III.D Managing Change in AIO 

An entity’s IT environment and its products and services, whether internally or externally provided, should be adaptable to change. Management generally makes changes to meet strategic goals and objectives (e.g., adding new products or services, growing the entity’s business, providing integration and centralization of functionality, expanding to new geographic areas, or expanding operational capabilities) or to deliver financial, performance, or security improvements. Changes may be accomplished by implementing new technology (e.g., systems or software) to support new or changing products and services. Once management initiates changes, it relies on involvement from architecture for design, infrastructure to build, and operations to deploy the changes needed to meet the strategic goals. Depending on the type, complexity, and impact of the change, stakeholders across the entity should have input into the change process. 

For complex changes (e.g., core conversions, migrations to cloud-based environments, or implementing a system to support a new product), formal planning and management oversight processes are warranted. For routine changes (e.g., implementation of patches), management may follow a less extensive process. Regardless of the type, management should ensure that changes to any IT system or service are supported by an orderly, adaptable, documented, and measurable process. Such a process can minimize risk, maintain the integrity and security of the entity’s IT infrastructure, maintain or enhance the value to the business, and maintain uninterrupted delivery of the service. For more information on implementing technology changes, refer to the IT Handbook’s “Development and Acquisition” booklet. 

## III.D.1 Change Management 

Change management is the continuous process of maintaining the integrity of hardware, software, firmware, and documentation, and controlling and approving changes (e.g., addition, modification, or elimination) to information or technology assets or related infrastructure. Change management is an operational process that involves the implementation and management of changes to meet the strategic goals of the entity. Some changes to the IT environment may occur within the entity’s infrastructure (e.g., hardware, software, and telecommunications), while others may involve third-party service providers (e.g., cloud or managed security service providers). While some change management activities may involve longer-term strategic planning and IT architecture, other changes, such as remediating vulnerabilities or responding to malicious events, may require more rapid action. 

The entity’s policies, standards, and procedures should address change management, including each step of the change process. Policies, standards, and procedures should categorize changes by severity, specify corresponding approval processes, and identify responsible staff, applicable stakeholder working groups, or entity committees. Management should identify metrics (e.g., implementation time, success rates, and the number of planned versus unplanned changes) to track the efficiency and success of the change management process. 

An entity’s change management process should ensure that changes are implemented with the goal of preserving the IT environment’s confidentiality, integrity, and availability. Management should incorporate appropriate segregation of duties and monitoring throughout the change management process as outlined in the IT Handbook’s “Information Security” and “Development and Acquisition” booklets. Ideally, the change management process consists of the following: 

* • Request:
* • Review:
* • Approve:
* • Design and build: Management should follow formal processes to preserve integrity
* • Test:
* • Implement:
* • Verify and close: After deployment, management should perform a post-implementation A documented request should outline the reasons for change (e.g., business justification) and include details of the change (e.g., system to be changed, impact analysis to identify risks and affected systems, change time frame, and back-out plan). 

Management should review requests to determine viability and business practicality.25 Requests may be prioritized during this stage or may be returned to the request originator for more information. 

There should be a documented hierarchy for approving change requests. 

Appropriate approval mechanisms26 should be commensurate with the scope, cost, urgency, and overall risk to the entity and its IT environment. throughout the development life cycle and ensure adequate controls (e.g., restrictions for moving code from staging to production). 

Management should document that the change performs as intended, identify any flaws (e.g., integrity issues), and verify that the change integrates with other systems. 

Management should follow a formal process to deploy the change during off- peak hours or planned system outages. review to verify that the change was implemented successfully and achieved performance objectives. After verification, management should follow processes to document the change’s closure. 

Changes can pose risks to the confidentiality, integrity, and availability of the entity’s IT environment. Therefore, management should preserve systems’ security throughout the change management process. Improperly tested changes or changes implemented without approvals or documentation may cause systems to crash, return unanticipated results, allow the insertion of malicious code, or make it difficult for management to troubleshoot future problems. To minimize these risks, management should have processes to implement changes based on the change type. Entities often have the following types of changes:27
* • Planned changes: These changes follow the entity’s complete process, often using most of
* • Routine changes: These changes (e.g., installation of patches) are generally performed
* • Emergency changes: For this type of change (e.g., to restore a failed hardware component, the steps outlined in the preceding bullets, thereby addressing risks (e.g., potential for errors, unintended impacts to interrelated systems, or business process issues related to the unavailability of critical systems). frequently or regularly and follow standard procedures. They may be pre-approved. respond to an ongoing cyber event, or address a service interruption), certain components of the change management process may be truncated or omitted out of necessity. Changes that are implemented because of an urgent need may carry substantial risk, given the lack of advance planning and testing. Therefore, all emergency changes should be reviewed and approved after implementation. 25The review may be performed by IT management, stakeholders (e.g., service owner, technical staff, or financial personnel), or a formal committee (e.g., IT steering or operations) depending on the proposed change’s scope, costs, risks, impact, and implementation time frame. 

26 Refer to the NIST Glossary. Approval mechanisms may include a change advisory (or control) board, IT steering committee, management committee, or other personnel, depending on the entity’s size and complexity. 

27 Entities often use different words to refer to these types of changes (sometimes even using the same words to refer to different types of changes). During examinations, examiners should use the entity’s terminology.

For more information, refer to the IT Handbook’s “Development and Acquisition” booklet. 

## III.D.2 Transitioning From Strategic Change Management to Day-to-Day Operations 

Management should implement a process to transition system changes from a strategic change management process to day-to-day operations. The transition of responsibilities and knowledge should be part of the overall system development life cycle process as discussed in the IT Handbook’s “Development and Acquisition” booklet. Knowledge about IT processes gained through the change management process should be effectively transferred in a useful format to personnel responsible for operating the systems and processes. The efficient aggregation and organization of information allows management to reduce repeat service request inquiries, increase instances of self-driven problem solving, and encourage the level of overall knowledge within the entity. 

## III.E Oversight of Third-Party Service Providers 

Many entities outsource the AIO activities to one or more third-party service providers, often depending on the entity’s size and complexity and the level of expertise available in-house. Management should identify the internal and external roles and responsibilities for AIO activities and implement processes to oversee the activities performed by third-party service providers on the entity’s behalf. The responsibility and oversight, if properly assigned and defined, should interact as seamlessly as possible to ensure that management identifies and addresses all risks according to contracts and other agreements (e.g., SLAs). Management should be aware of the data destruction processes maintained by the entity’s third-party services providers, including cloud service providers. 28 The SLA should outline that the third-party service providers take adequate measures to ensure data destruction occurs in a manner that would prevent unauthorized disclosure of information. 

Management should review independent audit or other assurance reports demonstrating the third- party service provider’s ability to meet the entity’s AIO needs and provide services in a safe and sound manner. Management should report to the board on the effectiveness of any AIO activities performed by third-party service providers and any issues uncovered through the entity’s third- party risk management processes. 

28 See the FFIEC Joint Statement: “Security in a Cloud Computing Environment.” 

## III.F Resilience 

A secure and resilient IT environment,29 including AIO functions, is essential to the delivery of an entity’s critical services. An entity’s AIO functions should be integrated into the entity’s business continuity management (BCM) program to help management mitigate threats, respond to and recover from disruptions, and incorporate lessons learned to strengthen the entity’s resilience. 

Resilience of an entity’s AIO functions extends beyond recovery capabilities. Resilience is achieved by taking proactive measures to maintain confidentiality, integrity, and availability and mitigating the risk of a disruptive event through system design (including backup systems), infrastructure selection, and IT deployment. The threats related to disruptive events may pose risks from multiple attack types (e.g., cyber and physical), duration (e.g., advanced persistent threat30 [APT]), and delivery via deception (e.g., simultaneous distributed denial of service [DDOS] and business email compromise attacks). Management should design, implement, and operate its IT systems and processes to provide resilience for critical business activities. As part of its consideration for resilience of AIO functions, management should determine its reliance on people, processes, and technology, including third-party service providers, to assist in its assessment of risk. 

Management should design systems and software with resilience (e.g., redundancy, additional layers of defense, and resilient backup systems) and information and cybersecurity (e.g., inspect and detect vulnerabilities and attacks) at the beginning of the architecture process. Management may include activities related to ITAM (e.g., inventory, audit, and testing) to demonstrate resilience effectiveness. Management may have differing design risks and oversight responsibilities in a cloud environment (i.e., because a cloud service provider often has different types of clients co-located, an entity may be affected by attacks aimed at other industry segments). 

The entity’s infrastructure should support varying levels of resilience depending on the criticality of the systems and software to ongoing business operations. For instance, management may use redundant servers, have alternate data centers, or employ backup as a service to provide the appropriate level of resilience. For both architecture design and infrastructure implementation, it is important to follow the entity’s project management processes to appropriately integrate resilience throughout the enterprise. Following formal processes to integrate resilience may help inform strategic decision-making and effectively address resilience needs for the entity’s core business lines. To maintain resilience, infrastructure should be implemented in a way that allows for secure remote administration and maintenance, for situations when personnel are unable to perform operations on-site. 

29 For larger or more complex entities, refer to the interagency paper Sound Practices to Strengthen Operational Resilience released by FDIC, FRB, and OCC. 

30 Refer to NIST SP 800-160 Volume 2, Developing Cyber Resilient Systems: A Systems Security Engineering Approach. 

Management should address resilience in operations to prevent data loss, protect sensitive customer information from unauthorized disclosure or manipulation, minimize disruption to service delivery, and prevent the loss of situational awareness of the entity’s operations. This involves having adaptable and comprehensive operational controls, operational processes (e.g., vulnerability and patch management), service delivery and support processes (e.g., resilience in supply chain), and ongoing monitoring and evaluation capabilities (e.g., monitoring for indicators of an APT). 

When operating in, or planning a migration to, a cloud environment, management should not assume that systems are resilient. During migration to cloud services, management should identify the assets, applications, and services located in the cloud. Management should verify that resilience is covered in contracts with cloud service providers. Additional risk mitigation options may be available in a cloud environment, such as tools to enable backups or the ability to store backups in multiple locations. For more information, refer to the IT Handbook’s “Business Continuity Management” booklet. 

## III.G Remote Access 

NIST defines remote access as access by users (or information systems) communicating external to an information system security perimeter. Examples of remote access include remote administration, access to the entity’s network by third-party service providers, teleworker access, and customer access. Management should consider the implications of remote access in AIO. 

When designing the entity’s IT architecture for remote access capabilities, management should plan for the methods and access points that will be used across the enterprise to maintain security and control access to entity resources. Architectural design considerations include tunneling, web portals, direct application access, and remote desktop access. 

* • Tunneling involves establishing a secure communications tunnel, via encryption, between a telework client device and remote access servers within an entity, typically a virtual private network (VPN) gateway. When determining whether to use tunneling31 as a remote access method, management should consider the communications tunnel via encryption and the endpoints to which it is connected, as well as its capability to authenticate users and restrict access to IT systems.
* • A portal32 is a server that offers access to one or more applications through a single centralized interface. A remote user accesses a portal client (e.g., a web browser) on a client device to access the portal. When determining whether to use a portal, management should consider whether it adequately protects communications between the client devices and the portal, and also whether it can authenticate users and restrict access to the entity’s internal resources. There is an important difference between tunnels and portals—the location of the application client software and associated data (i.e., in a tunnel, the software and data are on the client device; in a portal, they are on the portal server).33 31 Refer to NIST ITL Bulletin, Security for Enterprise Telework, Remote Access, and Bring Your Own Device (BYOD) Solutions. 

32 Examples of portals include web-based portal, terminal access server, or virtual desktop infrastructure. Refer to NIST ITL Bulletin, Security for Enterprise Telework, Remote Access, and Bring Your Own Device (BYOD) Solutions.
* • Direct application access (e.g., webmail) occurs by accessing an individual application directly from most types of client devices without using remote access software. When determining whether to use this form of remote access, management should consider the security provided by the application, such as communications encryption and user authentication.
* • Remote desktop access provides the ability to remotely control a particular desktop computer at the entity—most often, the user’s own computer at the organization’s office—from a telework client device. When determining whether to implement remote desktop access, management should consider limiting this method for exceptional use cases and implementing appropriate security controls (e.g., IAM and activity monitoring).

There are a number of risks associated with remote access, including unauthorized access, unrestricted privileged access, modification of information, inadequate monitoring, unencrypted communications, unpatched remote devices, and uncontrolled personally owned devices. Management should protect remote access technologies because they generally have a higher exposure to external threats compared with technologies accessed from inside the organization.34 As more people work remotely, the scale of risk from remote access may increase. To mitigate risks associated with remote access, management should do the following: 

* • Develop and enforce a remote access policy that includes tiered levels of remote access and risk-based security controls over different types of remote access (e.g., remote administration and telework).
* • Implement IAM based on job type and access and use appropriate authentication techniques (e.g., multi-factor authentication) for privileged access and activities, such as remote administration tasks.
* • Use validated encryption technologies to protect communications between the entity and the remote user and encryption of sensitive data stored on the devices used for remote access.
* • Securely configure remote access servers, including application of timely patch updates.
* • Secure entity-owned telework client devices—including desktop and laptop computers, smartphones, and tablets—against common threats.
* • Implement mitigating controls on the use of personally owned devices used to remotely access entity resources.

For more information on mitigating risks associated with entity-owned and personally owned devices, refer to the IT Handbook’s “Information Security” booklet. 

33 Ibid. 34 Ibid. 

## III.H Personally Owned Devices 

Personally owned and controlled user devices used for the entity’s business purposes are known as bring your own device (also referred to as BYOD) resources. Personally owned devices may be used for remote access. They generally are not managed by the entity, creating the potential for an unsecured device to pose risks to the information that the user accesses and the entity’s other connected systems and networks.35 For example, a device compromised by a malicious user could be used to remotely access to the entity’s network. 

Before allowing the use of personally owned devices, management should perform due diligence on the types of devices that can be used. Management should consider the architecture of the entity’s IT systems, to determine where and how personally owned devices will access the entity’s network, in order to maintain appropriate security, segmentation, and access. Additional infrastructure (e.g., hardware and software) may be necessary to support the secure use of personally owned devices to access services. Management should determine the controls needed to adequately safeguard the network. Technical policy enforcement may ensure devices utilize anti-virus software and current operating systems, and that devices are not jailbroken.36 For more information, refer to the IT Handbook’s “Information Security” booklet. 

## III.I File Exchange 

File exchange (also known as file sharing) is a method of sending and receiving files inside the entity and with other parties through email attachments, file sharing services, and other means. Risk considerations in file exchange include the following:37 

* • Security deficiencies in file exchange methods (e.g., lack of encryption or use of weak encryption).
* • File storage on untrusted servers controlled by third-party service providers leading to unauthorized access of the stored files and unapproved copies of the files.
* • Files traversing untrusted networks, leading to unauthorized access (e.g., man-in-the-middle attacks or eavesdropping).
* • Alteration (e.g., modification with incorrect information or injection of malicious code) of any file, even files without sensitive information.
* • Solutions that are often difficult for users to set up and use (e.g., if the sender and recipient need to install software to exchange cryptographic keys).
* • Use of unapproved, insecure, or ad hoc file exchange methods (e.g., shadow IT),
* • Access to shared file repositories resulting in version control or unauthorized access issues.
* • Identification of root causes of data exposure and measures to reduce the likelihood of its occurrence. 35 Ibid. 

36 Refer to FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet Glossary for a definition of the term jailbreaking. 

37 NIST ITL Bulletin, “Security Considerations for Exchanging Files Over the Internet.”

Management should implement the following basic actions to improve the security of the entity’s file exchange38 activities: 

* • Identify user needs for exchanging files, both internally and externally. Identifying needs should include the senders and recipients, frequency of exchange, and nature of data being exchanged (e.g., public information, personally identifiable information, or proprietary).
* • Design the client server architecture to provide for confidentiality, integrity, availability, and resilience. Examples of design considerations include the following: 
	+ o File size and data complexity (e.g., XML or JSON (Java)).
	+ o Frequency of file updates.
	+ o File and data flows.
	+ o File usage by the various systems and by end users, including business unit usage.
	+ o Maintenance of security for files in transit and at rest.39
* • Identify the infrastructure, including the appropriate systems and software, necessary to support file exchange activities. File exchange solutions include email, file sharing services, managed file transfer, and custom applications (e.g., web and mobile). Often, entities may use more than one solution to meet their file exchange needs, in order to balance security and usability. Additionally, management should have appropriate infrastructure to support monitoring of the entity’s file exchange activities. Some risk considerations in choosing a monitoring system include the following: 
	+ o Monitoring for all methods of transferring files to third parties, including e-mail, copying information to external media, or use of shadow IT, which may not be visible to network security controls.
	+ o Capturing file exchanges between servers and between client devices and servers.
	+ o Monitoring beyond email to include monitoring of file exchanges happening through other means.
* • Provide the appropriate operational controls, such as the following: 
	+ o Conduct monitoring to ensure approved solutions are being used when needed to protect file exchanges, to avoid shadow IT solutions.
	+ o Include detection controls (e.g., IDS/IPS and firewalls) for inappropriate file sharing.
	+ o If using a third-party service provider file exchange solution, use only a trusted provider that employs appropriate controls for file exchange and storage solutions.
	+ o Consider solutions (e.g., cloud access security brokers (CASBs) for monitoring cloud- based file exchange and sharing capabilities) for providing visibility into cloud applications and their associated risks.
	+ o Define appropriate policies, standards, and procedures for file exchange activities.
	+ o Provide training to employees on approved solutions. 38 Ibid. 
	
	39 Refer to the IT Handbook’s “Information Security” booklet for more information.
# IV ARCHITECTURE 

## Action Summary 

Management should design, apply, and align its IT architecture to meet the strategic and business objectives of the enterprise. The architecture plan should meet the entity’s needs for confidentiality, integrity, and availability to minimize operational and reputational risks resulting from poorly designed systems. 

Examiners should review for the following: 

* • Identification of the entity’s information and technology assets.
* • Assessment of future enterprise IT needs.
* • Documentation of the architecture plan, including policies, standards, and procedures.
* • Development of appropriate design objectives, including changes, EOL, and identification of shadow IT.
* • Design of IT architecture (e.g., in-house, virtualization and cloud, or hybrid).
* • Documentation of EA elements.

Architecture refers to the manner in which the strategic design of the hardware and software infrastructure components (e.g., devices, systems, and networks) are organized and integrated to achieve and support the entity’s business objectives. Planning and designing an effective IT architecture facilitate management’s ability to implement infrastructure that aligns with the entity’s strategic goals and business objectives. 

Management should implement architecture principles that can be applied enterprise wide. When designing an entity’s architecture, management should balance the mitigation of risks to various stakeholders, considering both the enterprise’s needs as well as the needs of individual business units. Regardless of how management designs the entity’s architecture, it should align the architecture with IT and business objectives, for example, providing maximum benefits with lowest risks and acceptable costs. The architecture’s design should meet the entity’s needs for confidentiality, integrity, and availability and adhere to the entity’s policies, standards, and procedures. In addition, management should consider the entity’s architecture requirements for its existing technology and any planned changes. 

Management should clearly define its mission and any strategic initiatives for architecture. Business units should understand their portion of the design, which should align with management’s mission and strategic initiatives. In determining its future architecture, management should first identify the entity’s IT assets and external constraints, as well as industry IT architecture trends. Once management understands the entity’s current state of architecture, management should perform a gap analysis to determine the requirements to reach its future state. 

Management should have policies, standards, and procedures to govern the entity’s architecture design process. The design process should address the following: 

* • Definition of responsibilities and decision-making.
* • Identification of functional requirements.
* • Assessment of alignment with the entity’s IT and strategic plans.
* • Evaluation of the inventory of current IT assets and the purpose of those assets.
* • Performance of a cost-benefit analysis of the architecture plan or project.
* • Acquisition of approvals for the initiative.
* • Implementation and maintenance of the architecture.
* • Resolution of disputes or architectural issues.

Poorly designed architecture can lead to issues with confidentiality, integrity, and availability in both infrastructure and operations. 

## IV.A Architecture Plan 

Management should have a documented and approved architecture plan that identifies the entity’s current state. The architecture plan should align with the entity’s strategic plan to support the business and strategic objectives of the entity. Management should have policies, standards, and procedures that govern architecture initiatives and changes to the architecture plan. There should be processes including obtaining approvals for initiatives, making changes to the plan, and reporting to management or the board as appropriate. 

Smaller or less complex entities may have a less structured architecture plan and generally have fewer initiatives or changes to the plan. Larger or more complex entities often have complex architecture plans, architecture review processes, and architecture boards or planning groups to ensure that initiatives are carried out according to architectural principles. 

When the entity is planning larger or more complex architecture changes, implementation of those changes should maintain and follow a project management process that includes the following phases: 

* • Plan (e.g., identify requirements and functional specifications and design technical architecture).
* • Execute (e.g., build and implement solution and monitor and control risks).
* • Closeout (e.g., update documentation and incorporate lessons learned into the architecture plan).
## IV.B Design Objectives 

An architecture process creates a systematic approach to streamline the design process and provides management with a plan to organize and integrate new hardware and software with existing infrastructure. When designed properly, the process can help maintain agility and flexibility in meeting changing business needs. Hardware and software selection and implementation rely on the collaboration between IT and business line management. A fundamental step is to define terminology to provide a common set of terms used by IT and business unit personnel to design the entity’s architectural process. 

Management should evaluate its needs and consider the following: 

* • Collaboration between IT and business units.
* • Prioritization of investments.
* • Comparison of existing architecture with long-term goals and anticipated future needs and
* • Establishment of processes to evaluate and procure technology.
* • Storage (e.g., network-attached storage and storage area network [SAN]), backup, and
* • Whether the architecture will support internet-facing applications, internal network changes. capacity needs to accommodate the entity’s strategic plans. applications, or both.

Management should include the following aspects in its architecture design: 

* • Performance and reliability (e.g., system processing at normal and peak loads, response time, load balancing, and uptime required by end users).
* • Integrity (e.g., validation checks to promote accuracy).
* • Availability and resilience (e.g., meeting recovery time objective [RTO] and recovery point objective [RPO] requirements, providing redundancy, and avoiding single points of failure).
* • Scalability (e.g., the ability of systems and software to accommodate growth).
* • Flexibility (e.g., the ability of systems and software to accommodate changes without requiring new hardware or code changes).
* • Security and privacy throughout the entity’s network (e.g., IAM controls and data loss prevention).
* • Interoperability40 and integration (e.g., among OSs, databases, networks, and user interfaces, and loose coupling).
* • Ability to integrate and align with one or more third-party service providers.41
* • Testing (e.g., integration and business continuity testing) internally and with third-party service providers as appropriate.
* • Auditability (e.g., audit trails and logs).
* • Advancements in technology.

The design objectives should include considerations for avoiding the potential for shadow IT. Management should design its systems to provide the capability to monitor and alert for the use of shadow IT because shadow IT uses entity resources and could provide unknown avenues for exploitation. Management should consider how evolving technologies (e.g., cloud, IoT, and artificial intelligence [AI] and machine learning [ML]) can affect its systems’ design. 

40 For supervisory purposes, interoperability refers to the ability of data, systems, or software to work with or on multiple systems or software. 

41 Situations where the entity’s IT architectural design does not align with the third-party service provider’s systems, resulting in difficulty managing integration (e.g., costs of making manual changes, security issues, and errors and omissions) between the entity and its third-party service provider. 

Management should plan for obsolescence, EOL, and decommissioning of systems to understand the resource requirements throughout any system’s expected life cycle. Planning for obsolescence and EOL allows management to consider how it will protect the confidentiality, integrity, and availability of the information on a system. The architectural process should include planning for system decommission, including the migration from the old system and disposal of all critical components, services, and information when systems need to be replaced. If management does not plan for system obsolescence, EOL, and decommissioning, sensitive information may be retained on discarded components. Unnecessary and potentially unprotected system components may unknowingly remain connected to the network, using resources and providing a potential avenue for compromise, similar to what happens with shadow IT. 

## IV.C IT Architecture Design 

IT architecture design includes determining the appropriate deployment environments. Design environments may be managed in-house or by a third-party service provider, including a cloud service provider. Whether in-house or outsourced, management may use a combination of physical and virtual design environments and should consider the risks and benefits of both. For example, if management is considering moving some operations to the cloud, management should determine how the entity will benefit from virtualization or a cloud-based solution and the design implications, personnel responsibilities, and security provisions of that decision. Physical and virtual design environments may not differ substantially; the differences will be apparent in the design’s implementation. 

Designing the architecture of an entity’s IT systems may include “the placement of the virtualization solution and the selection of virtualization software.”42 Entities may incorporate virtualization into their architecture design to reduce costs and risks of maintaining and managing multiple pieces of physical hardware. Virtualization allows virtual elements to be transferrable between different pieces of hardware within physical or third-party-hosted environments, including cloud environments. In designing the entity’s virtual environment, management should consider the design risks associated with the following elements: 

### • Virtual machines (VM). 

To address the lack of visibility and control over the entity’s virtual environment, management should design secure virtual infrastructures, including the ability to oversee the interconnectivity and segmentation of VMs. 

### • Hypervisors. 

To ensure visibility and control of the environment and address the susceptibility to unauthorized access, malware, and mismanaged traffic, management should design where the hypervisors sit and the connectivity between hypervisors and VMs. 

### • Containers. 

To manage container vulnerabilities, unintentional interactions (e.g., between containers and applications or containers and host OSs), and container failures (e.g., security misconfiguration, application programming interface [API] disconnection, and lack of portability), management should have vulnerability management processes, employ segmentation, and provide the ability to monitor containers. Additionally, to avoid having to re-create data when updating and replacing containers, management should design for storing data outside of the container. 

42 Refer to NIST SP 800-125, Guide to Security for Full Virtualization Technologies. 

### • Microservices. 

To address the risks to application compatibility and functionality, management should have a design process that allows for the use of microservices as an integrated component of overall IT operations. Additionally, management should address the risks to security (e.g., having multiple microservices can increase the financial institution’s attack surface), reliability (e.g., ability to re-use and API alignment with business processes), and latency (e.g., fault tolerance and scalability) in the entity’s development process. For more information, refer to the IT Handbook’s “Development and Acquisition” booklet. 

Other considerations include the placement and selection of storage, design of network topology, availability of bandwidth, and need for management reporting systems. Management also should consider designing its systems to allow for the implementation of monitoring tools (e.g., identifying node and system failures in the cloud). 

## IV.D Enterprise Architecture 

EA is the description of an entity’s entire set of information systems: 

* • How they are configured.
* • How they are integrated.
* • How they interface to the external environment at the enterprise’s boundary.
* • How they are operated to support the enterprise mission.
* • How they contribute to the enterprise’s overall security posture.

EA includes an entity’s current state (also called baseline architecture), a future state (also called target architecture), and a plan to achieve the future state to meet the business objectives. EA provides a logical structure allowing management to classify, organize, and document elements of the entity’s systems, functions, and information. 

Smaller or less complex entities may not have EA, but those entities still should manage their existing architecture needs and planned changes. As an entity becomes larger or more complex and different systems are needed to support that growth, management should consider the implementation of EA to align its architecture with the entity’s strategic plans and business functions. Regardless of entity size or complexity, management should evaluate the best approach to implement security and resilience and build these characteristics throughout its architecture. When legacy systems exist, management should analyze the functionality, including security and resilience, of current systems and identify gaps. This helps management determine whether the legacy system should be maintained, replaced, or retired and what effect that will have on EA. 

Management may designate internal staff to design and manage EA, employ a third-party service provider, or use a combination of internal staff and third-party resources. For a larger or more complex entity, the chief architect’s role typically includes EA responsibilities. The architect may help management analyze the current architecture using an industry framework to better align the architecture with the entity’s strategic objectives. In a larger or more complex entity, a formal group (e.g., architecture review board) may assist in oversight of EA. Management may use aspects of industry frameworks43 as appropriate for the entity’s business needs. A framework may have different characteristics (e.g., informal, formal, prescriptive, principles-based, or a hybrid). 

43 Some examples of industry architecture frameworks include The Open Group Architecture Framework (also known as TOGAF) and Federal Enterprise Architecture. 

# V INFRASTRUCTURE 

## Action Summary 

Management should implement an IT infrastructure that achieves and promotes the objectives of confidentiality, integrity, and availability, and meets the entity’s business objectives. Management should develop, document, and implement infrastructure control policies, standards, and procedures to safeguard facilities, technology, data, and personnel. IT infrastructure implementation practices should include redundancy and resilience for physical infrastructure elements and related products, services, and telecommunications. 

Examiners should review for the following: 

* • Processes to identify, track, and monitor infrastructure components.
* • Contractual arrangements addressing infrastructure, if applicable.
* • Sufficient resources with infrastructure knowledge, skills, and expertise.
* • Network configuration management and change control processes.
* • Security and monitoring processes to analyze data traffic and detect anomalous activity.
* • Software planning to address: 
	+ o Scalability, interoperability, and portability.
	+ o Adequate software controls.
	+ o Use of and controls over open source software.
* • Mainframe controls, if applicable, to address unique risks associated with mainframes.
* • Security controls for the use of application programming interfaces (API).
* • Environmental and physical access controls.

As previously stated, infrastructure refers to the physical elements, products, and services necessary to provide and maintain ongoing operations to support business activity and includes the maintenance of physical facilities. IT infrastructure includes hardware, network and telecommunications, software, IT environmental controls (e.g., power and HVAC), and physical access that allow for an enterprise IT environment’s operation and management. IT infrastructure implementation should include considerations for server and data redundancy and resilience of telecommunications lines. Planning and designing an effective IT architecture facilitates management’s ability to implement an IT infrastructure that achieves and promotes the objectives of confidentiality, integrity, and availability and supports the entity’s business operations. IT infrastructure may be managed internally or externally by a third-party service provider, including a cloud service provider. 

## V.A Hardware 

NIST defines hardware as “the physical components of an information system.”44 Hardware devices can be an ideal target for malicious actors. Therefore, management should track and monitor all hardware assets (whether or not they are connected to the network) to maintain an accurate and current record of the technology assets in its environment. This is often done with an accurate hardware inventory. Without an accurate inventory, management may encounter challenges in protecting hardware assets, managing cyber risks, and recovering from and responding to incidents. For more information, refer to the “IT Asset Management” section of this booklet. 

Management should identify unauthorized technology assets and determine their disposition (e.g., remove, isolate (quarantine), or add them to the inventory). If an asset is determined to be unauthorized, management should evaluate how the device gained access and what, if any, compromise may have occurred. Management should determine whether the policy or procedures should be updated or whether additional training is necessary. Automated tools can assist management in maintaining the accuracy and availability of hardware components. Network discovery tools identify assets connected to the network and compare them to an inventory of authorized hardware assets. Advanced asset discovery tools (e.g., using dynamic host configuration protocol [DHCP] on servers or asset management tools using IP addresses) may be used to provide oversight of the entity’s technology asset inventory. 

## V.B Network and Telecommunications 

Networks are systems implemented with a collection of interconnected components. Such components may include routers, hubs, cabling, telecommunications controllers, key distribution centers, and technical control devices. Management should document and maintain a current inventory of network and telecommunications hardware and software and the network configuration. For more information, refer to the “IT Asset Management” section of this booklet. 

NIST defines telecommunications as “the preparation, transmission, communication, or related processing of information (writing, images, sounds, or other data) by electrical, electromagnetic, electromechanical, electro-optical, or electronic means.” Given the critical nature of telecommunications, management should ensure appropriate redundancy capabilities in the entity’s telecommunications infrastructure and should understand the limitations of the entity’s third-party telecommunications providers’ infrastructure. Network and telecommunications infrastructure form the backbone for the entity’s data and voice communication, including information sharing and data transfer, and facilitate the integration of technology systems. 

44 Refer to the NIST Glossary. 

## V.B.1 Network 

Network infrastructure consists of components (e.g., hardware and software) that transport data, support software functions, deliver services, and provide communications. Entity and customer traffic pass through these components, which include the following: 

* • Hubs and switches.
* • Load balancers.
* • Routers.
* • Domain name system.
* • Servers.
* • Firewalls.
* • IDS/IPS.
* • SANs.

Once management has an accurate inventory that contains network components and information, management should document the network’s baseline configuration, including processes to review and approve changes. Management should regularly assess and document compliance with the entity’s baseline configuration45 to validate that settings are in place and commensurate with the board’s risk appetite. Intentional or unintentional misconfigurations can lead to system issues or exploitation of vulnerable services and settings by malicious actors. To reduce exposure to potential vulnerabilities and failures arising from unused services, management should implement appropriate network configuration management and change control processes. Configuration rules allowing traffic to pass through the network should be documented with the necessary detail to justify the business need. Management should periodically review the configurations of network devices. Tools are available to verify that network devices are using approved configurations and notify management when unauthorized changes are detected. 

Network devices are often delivered with enabled services, open ports, and commonly known default passwords. Management should appropriately control networked devices by managing ports (e.g., close unnecessary ports), protocols (e.g., deactivate unsecure protocols), and services (e.g., disable unnecessary services) to minimize exposure to vulnerabilities or errors. For more information on these and other system “hardening” activities, refer to the IT Handbook’s “Information Security” booklet. Ports, services, and protocols should be mapped to the technology asset inventory. Automated tools are available to perform port scans to validate that only approved ports, protocols, and services are in use. The latest version of security-related updates should be installed on network devices, when appropriate. For more information, refer to the “Patch Management” section of this booklet. 

A server is a computer or device on a network that manages network resources. Examples include file servers (to store files), print servers (to manage one or more printers), network servers (to manage network traffic), and database servers (to process database queries). A server’s standard, or baseline, image is the approved set of server configurations, applications, and systems, which can be used to deploy servers consistently and rebuild them more easily and quickly, when necessary. Management should maintain standard images (or templates) of the entity’s servers. Standard images of servers should be stored securely, and if a server needs to be rebuilt (e.g., upon discovery of an infected system), management should use clean, trusted images to restore the server. Deviations from the standard image should be documented, reviewed, and approved. 

45 Guidance for implementing best practices for server configurations can be found at the NIST National Checklist Program and through other industry sources (e.g., Center for Internet Security). 

Management should implement security and monitoring throughout the entity’s network to monitor system components, analyze incoming and outgoing data traffic, and alert authorized personnel if anomalous activity is detected. To accomplish this, security and monitoring mitigation strategies include the following: 

* • Use of software tools to protect against and monitor for malicious actors scanning for internet-accessible services or open ports.
* • Implementation of firewalls and packet filtering to limit internet traffic to exclude services and ports (e.g., whitelist and blacklist).
* • Deployment of IDS/IPS that use signature-based detection, anomaly-based detection, and stateful protocol analysis to detect and prevent attacks against the network or attacks against services, systems, applications, or data. IDS/IPS alert personnel to potential attacks, while IPS can be configured to take an action predefined by management, such as blocking various types of activities.
* • Use of internal tools (e.g., data loss prevention, email content filtering, and internal IDS/IPS) to detect, identify, and prevent misuse by entity personnel.

When possible, management should perform administrative activities from dedicated workstations (used exclusively by administrators to manage the network’s technology devices) located on an isolated portion of the network not used for regular business activity. Management should use multifactor authentication over encrypted network connections for administrators accessing and managing network devices. 

## V.B.2 Telecommunications 

Telecommunications infrastructure should be appropriate for current and anticipated internal traffic needs and have sufficient connectivity to facilitate external communications. Telecommunications infrastructure includes both voice and data transmissions that are broken up into multiple packets to facilitate transmission of those packets over shared paths. Telecommunications packets typically incorporate message content and completion validation messages. Between telecommunications endpoints, packets can be lost, encounter interference, or arrive out of order. Capacity, latency, and connectivity issues can affect the arrival of packets or completion of messages. Therefore, management should monitor telecommunications traffic. In addition, administrators should periodically review network devices to identify any that are operating in promiscuous mode or acting as packet “sniffers” for network traffic. 

Management should physically secure telecommunications equipment46 and restrict and monitor access (e.g., through access devices, logs, and cameras). Changes to telecommunications equipment and configurations should follow enterprise change control standards, including approval, testing, and migration to production. Identification, authorization, and authentication to access (including remote access) telecommunications systems should follow entity policies, standards, and procedures, including approval and documentation of exceptions. Documented wiring strategies (e.g., schematics and color coding) and organized cables facilitate easy troubleshooting, repair, and upgrade. 

An entity’s telecommunications infrastructure components should be designed and built for resilience. Loss of telecommunications can have a material impact on the ability of an entity to function, exposing it to legal, reputation, and financial risks. Management has little direct control over the telecommunications services beyond the entity’s network. The telecommunications lines are subject to environmental risks (e.g., weather or natural disasters) and other risks (e.g., terrorism, sabotage, or accidents), which can damage communications cables and equipment at the entity, the telecommunications service provider, or in between. Where available, the entity’s selection of infrastructure components and telecommunications providers should ensure access to a diversity of suppliers and connectivity to avoid a single point of failure. Management should implement route diversity, where available, to ensure data can travel along an alternate route if its primary path is blocked. For more information, refer to the IT Handbook’s “Business Continuity Management” booklet. 

The telecommunications services sector is designated as a critical infrastructure sector for national security and emergency preparedness. The telecommunications services sector provides support for the clearing, payment, and settlement processes, which are considered critical activities in another critical infrastructure sector, the financial services sector. For more information, refer to the IT Handbook’s “Business Continuity Management” booklet. 

### V.B.2(a) Voice Communications 

Voice communications are critical to meeting business needs by facilitating understanding and interactions among personnel, internal and external entity customers, and third-party service providers. Regardless of the type of voice communication solution (e.g., voice over internet protocol [VoIP], dial-up, or mobile), risks include quality of service degradation (e.g., echo or dropouts), resilience (e.g., loss of voice communication), and security (e.g., eavesdropping), which can lead to reputation risks (e.g., failure to address time-sensitive issues) and loss of business. Therefore, management should address these risks through their development and acquisition processes and in their written policies, procedures and practices. 

Entities often use VoIP for internal and external voice communications.47 VoIP refers to the transmission of voice communications over the internet rather than through the public switched telephone network (PSTN). When a telephone call is made using VoIP, the caller’s voice is translated into a stream of data packets. The data packets are transmitted over the internet and converted to a voice signal on the other end of the communication. In addition to an IP-enabled telephone, VoIP systems include call managers, gateways, routers, firewalls, and protocols. The call manager performs the functions of a traditional phone network and is the core of the VoIP system. A VoIP gateway provides conversion of calls between the data network and the PSTN. Routing and switching infrastructure provides the basic network connectivity and transport. 

46 Typically, telecommunications equipment is located in a separate telecommunications closet or room. 

47 For the purposes of this booklet, voice communications refers to the transmission of speech over communication (e.g., telephone) lines. 

As with telecommunications in general, the risks associated with VoIP include service quality (e.g., packet delays resulting in garbled communication), failure of communication (e.g., loss of voice communication), and security issues. Security issues include configuration weaknesses in VoIP devices and underlying OSs that enable denial of service (DOS) attacks, eavesdropping, voice alteration (hijacking), and toll fraud (theft of service). VoIP is susceptible to the same risks as data networks that use the internet, such as exposure to viruses, worms, trojans, and man-in- the-middle attacks. Each of these can result in the loss of confidentiality, integrity, and availability. 

Management should perform a comprehensive risk assessment to ensure the confidentiality, integrity, and availability of voice communications using VoIP technology. When considering VoIP in the design of its network architecture, management should implement physical and logical controls in the VoIP environment and evaluate options for backup systems (e.g., hard- wired communication lines) that will provide redundancy in communication during power outages.48 Traditional security controls may not provide appropriate security for VoIP systems, therefore, management should consider control solutions specific to VoIP, such as VoIP-ready firewalls. 

### V.B.2(b) Data Communications 

Data communications is the transfer of data over networks49 using a combination of telecommunications services and network devices. Networks connect devices within a single geographic site or can connect multiple geographically dispersed entity and third-party service provider sites. They connect servers, end user devices (e.g., workstations, laptops, and mobile devices), wireless routers, and network security devices, such as firewalls and IDS/IPS. 

Entities contract with telecommunications service providers for the physical connection supporting data communications among network sites. Given the network’s importance to the entity’s infrastructure, management should monitor incoming and internal data communications traffic for problems such as outages, connectivity degradation, throughput issues, capacity concerns, and other anomalies. Inadequate maintenance or an inadequate response to problems may lead to degraded data communications service levels. Management should implement redundant telecommunications services (e.g., alternate telecommunications providers or lines) where appropriate and establish work-around procedures for situations where redundant telecommunications are not feasible. 

48 Widely accepted practices are available in NIST SP 800-58, Security Considerations for Voice Over IP Systems. 

49 Networks can be composed of local area networks, wide area networks (WAN), and metropolitan area networks (MAN). WANs or MANs extend a data network to geographically dispersed offices, operations centers, service providers, and partners. 

## V.C Software 

NIST defines software as computer programs (which are stored in and executed by computer hardware) and associated data (which also are stored in the hardware) that may be dynamically written or modified during execution. As part of infrastructure planning, management should determine the types of software needed to implement the entity’s strategic objectives. Software implementation planning is fundamental to the confidentiality, integrity, and availability of the entity’s data that interact with software. Management should consider the software’s scalability, interoperability, and portability. As with its other infrastructure elements, management should perform the following: 

* • Track and monitor the entity’s software assets whether they rely on network connectivity or are strictly isolated to individual workstations.
* • Maintain an accurate and current record of the software assets in its environment, often through the use of software inventories.
* • Periodically review existing software to meet changes in the entity’s strategic objectives and operational goals.

The following sections describe the various developed or acquired software types and associated risks with the use of each. 

## V.C.1 Internally and Externally Developed Software 

Understanding the types of software needed to meet the entity’s infrastructure and operational requirements is key to successful software implementation. In addition to choosing software, management should consider whether it develops the software internally or obtains the software from a third party. Options include the following: 

* • Internally developed software: An entity’s internal development team can develop software or management can engage third-party development teams to develop software on the entity’s behalf. Management is responsible for maintaining the software; therefore, entity personnel should have the resources and expertise to stay abreast of vulnerabilities and develop software updates and patches to promote the security and resilience to meet business needs. Refer to the IT Handbook’s “Development and Acquisition” booklet for more information on internally developed software.
* • Externally developed software: Externally developed software is available in multiple forms. These include the following: 
	+ o Commercial off-the-shelf (COTS) software: COTS is a software and/or hardware product that is commercially ready-made and available for sale, lease, or license to the general public. COTS is also referred to as off-the-shelf. COTS software is built with default functionality and configurations to accommodate a variety of uses. It offers several advantages, such as lower cost and easier installation, and generally includes software support. COTS software may not, however, meet the entity’s needs or security requirements. For example, COTS software may not integrate easily with existing software and may require further configuration to meet the entity’s needs.
	+ o Custom software: Custom software (e.g., core processing software) is developed for entities to provide custom functionality. Custom functionality can be developed by the entity or a third party (e.g., vendor or third-party service provider) by changing existing software through modules or functionality extended by add-ons (e.g., software extensions) to meet the entity’s needs. Regardless of how custom software is developed, it should be designed to integrate with the existing enterprise software, hardware, and data. Risks associated with custom software may include higher support costs for modifying outdated software. Regular updates and maintenance of custom software may be more difficult because of the customization or lack of expertise.

Management should approve the software’s use and ensure that the software meets the entity’s infrastructure requirements (e.g., hardware requirements) and strategic objectives. Management should allocate resources to support the software (e.g., costs to maintain the software or support personnel), and personnel should have the expertise needed to maintain and patch the software. Refer to the IT Handbook’s “Development and Acquisition” booklet for more information on software development and acquisition risk management. 

## V.C.2 Software Types 

Entities use a variety of software to support day-to-day operations. These are common software types that support the infrastructure needs and business objectives. Regardless of the software used, management should be aware of and implement risk mitigations for general risks associated with software in the entity’s infrastructure environment. To mitigate software vulnerabilities, management should keep the software current and appropriately patched. To mitigate unauthorized access to sensitive information, management should implement appropriate IAM controls, including activity monitoring. Risks associated with development, information security, and third-party service providers are discussed in the IT Handbook’s “Development and Acquisition,” “Information Security,” and “Outsourcing Technology Services” booklets. 

Software types found in server-based or cloud-based infrastructure environments typically include OS, core processing, productivity, enterprise, security, and system auditing software. The software types described in the following bulleted list can be proprietary (i.e., development is performed by designated employees or vendors) or open source, which is described in a sub- section after the bulleted list. There are also software types to address risks and controls specific to mainframe security and APIs described in the following sub-sections. 

The following are general types of software found in both server-based and cloud-based infrastructure environments: 

* • OS software: An OS is a program that runs on a computer and provides a software platform on which other programs (e.g., application software and utility software50) can run. An OS manages computer hardware resources and provides common services (e.g., access and security controls, file system maintenance, and communications management). There are numerous server, desktop, and laptop OSs, as well as mobile (e.g., tablet and smartphone) OSs. Regardless of the type used, if the OS is not maintained, other software may not function adequately or at all, which affects the entity’s ability to conduct business. Therefore, management should oversee and maintain the OS, including testing and installing patches when appropriate. Because having access to the OS, including utility software, provides access to applications running on the OS platform, management should restrict and monitor administrator access to the OS and should limit the use of utility software.51
* • Core processing software: Core processing software enables the processing of key banking functions (i.e., taking deposits and making loans) and other functions (e.g., statement rendering, payment processing, calculating interest, and customer relationship management [CRM]), and interfaces to other software (e.g., general ledger systems and reporting tools). This software should be appropriately restricted based on job responsibility and its use monitored because of the sensitive nature of the entity’s and the customer’s information and the impact on other systems (e.g., general ledger and customer and management reporting). Management should select core processing software with adequate capacity to support strategic goals and objectives (e.g., customer base growth or geographic diversity). The software should support usage spikes (e.g., daily, monthly, and quarterly), expected peak usage times (e.g., holidays), and future growth.
* • Productivity software: Productivity software can refer to any software that helps to produce and manage data and improve the user’s productivity. Management should consider using productivity software in its infrastructure environment to enable personnel to perform their job functions. Examples can include word processing, spreadsheet, database, video conferencing, and presentation software. “The line between web applications and locally installed applications has blurred over time to the point where a number of web application providers offer web versions of common desktop productivity tools, including word processors, spreadsheets, and calendars. ... As such, these web applications may need to support the ability to store and process mobile code associated with office documents (or any user-generated files), opening up web applications to many [risks associated with web applications].”52 “Common management and operational controls used to safeguard systems against other security threats also apply to active content.”53 These controls include IAM, configuration management, and monitoring of logs. There is a risk that data may fail to synchronize correctly, which could negatively affect data integrity. An attacking entity may intercept messages in transit and modify their contents, substitute other contents, or simply replay the transmission dialogue later in an attempt to disrupt the synchronization or integrity of the information.54 Mitigation strategies to address synchronization issues include version control, group collaboration, and other synchronization capabilities within a cloud (e.g., autosynch or file management).55 50 Utility software includes file compression, defragmentation, diagnostics, and performance optimization. 

51 Some utility software can provide privileged access to other programs and data residing on the system. 

52 Refer to NIST SP 800-28 Version 2, Guidelines on Active Content and Mobile Code. 53 Ibid.
* • Enterprise software: Enterprise software helps management make better and more informed decisions through enterprise data aggregation. Enterprise software examples include communication, collaboration (e.g., SharePoint), CRM, digital and content creation, enterprise resource planning, project and portfolio management, and supply chain management. Enterprise software can encompass a vast array of subjects, methods, models, and reporting. Management should consider how enterprise software integrates in the entity’s infrastructure environment. Because of the sensitive or critical nature of the information available within this type of software, management should limit access and editing capabilities and monitor user activity.
* • Security software: Security software is designed with the goal of preventing an attacker from reaching the intended target or limiting the damage of an attack. The software can be designed to track the damage incurred from an attack. Malicious code continuously evolves; therefore, management should use security software that is current, deployed effectively, and designed to keep up with the evolution of malicious code. The software can be controlled by either a third-party service provider or the entity. Because of the sensitive security information contained within the software or technology assets being monitored by the software, administrative access to this type of software should be restricted. Security software types may include the following: 
	+ o IAM.
	+ o Antivirus.
	+ o Encryption management.
	+ o Application firewall.
	+ o IDS/IPS.
	+ o Log management.
	+ o Security information and event management.
	+ o Patch and vulnerability management.For more information, refer to the IT Handbook’s “Information Security” booklet.
* • System auditing software: System auditing software refers to automated programs that perform a variety of audit functions, such as database sampling and source code checks. Its purpose is to highlight exceptions to data and, in return, identify potential errors. Results can produce false positives and may require human intervention to verify that results are not accurate and make adjustments to reduce false positives over time. Management should use system auditing software to augment audit personnel and assist in the identification of gaps in infrastructure security and resilience. Once validated, audit results from the software can be used in conjunction with ML and AI. For example, the number of false positives can be reduced over time and the software can take certain actions to mitigate risk. Management should document software intended for system audit use and define its purpose to ensure continued usefulness and reliability. For more information, refer to the IT Handbook’s “Audit” booklet. 54 Ibid. 

55 Refer to NIST SP 800-146, Cloud Computing Synopsis and Recommendations.

### V.C.2(a) Open Source Software 

Unlike proprietary software, open source software56 can be accessed, used, modified, and shared by anyone.57 Management may leverage a variety of open source software. Open source software may provide several advantages, including cost and availability. Management should identify unique security issues (e.g., public availability of the code, ability for users to alter the code, licensing issues, difficulty in tracking patches, and publicized exploits) with the use of open source software. Management should implement security controls and procedures to mitigate risks, including the following: 

* • Defining acceptable use (or restriction) guidelines, if appropriate, for open source software, including documenting a process for modifying and reviewing the code.
* • Restricting access to unapproved shareware sites.
* • Using tools to help discover unapproved open source software.
* • Identifying the type and version of open source software in use, where it is used within the entity, and its purpose.
* • Implementing version and patch control guidelines for open source software in use.
* • Monitoring for vulnerabilities of the open source software employed by the entity.

Open source components may be present in third-party software used by the entity; therefore, management should evaluate the implications of those components and address their use in contract provisions. Information regarding open source software or components should be evaluated by management during its software due diligence. Refer to the IT Handbook’s “Development and Acquisition” booklet for further information. 

### V.C.2(b) Mainframe Security Software 

Using a mainframe computer in the infrastructure environment presents specific security risks. Mainframes may provide a single point of control or access point to an entity’s systems, applications, and information repositories. The risks include inappropriate user access, unauthorized access to mission-critical data, inappropriate audit log settings, inadequate monitoring and alerting, untimely patch management, and ineffective auditing of mainframe security. To mitigate these risks, management should implement the following: 

* • Access controls, including role-based access control, segregation of duties, and multifactor authentication. 56 Examples of open source software include the following: CRM (e.g., Flowlu, HubSpot CRM, and YetiForce); project management (e.g., Trello); blockchain (e.g., Ethereum, Hyperledger, and IOTA); internet browser (e.g., Firefox); productivity (e.g., LibreOffice and GIMP); OS (e.g., Linux, BSD, and Unix); and security (e.g., Nessus, Snort, Nagios, Nmap, Metasploit, Wireshark, and Kali Linux). 

57 Refer to NIST Suborder 6106.01, “Open Source Code.”
* • Security controls (e.g., password complexity, inactivity timeout, and login restrictions).
* • Encryption of sensitive information.
* • Activity log settings that include user access, failed login attempts, and security setting changes.
* • Real-time monitoring and alerting of mainframe activity.
* • Timely patch management processes.
* • Mainframe security auditing (e.g., regular review of security controls and validation of privileges, roles, and access profiles to limit excessive access and provide for timely removal of unnecessary access).

System and security administrator access (e.g., super user privileges) are necessary to perform specific mainframe activities; such access, however, creates a potential for misuse. Management should have an independent method to closely monitor the use of these privileged accounts. 

There are several software-based access control security tools58 available for managing security of critical mainframe system resources. These tools are generally add-on software products that provide security for a mainframe and protect system resources by granting access only to authorized users. Tools provide the ability to do the following: 

* • Identify, authorize, and authenticate users.
* • Safeguard sensitive information.
* • Log and report attempts of unauthorized access to sensitive information.
* • Provide system and security administrator controls.

Mainframe experts may not be readily available. Therefore, management should maintain appropriate expertise to understand the unique security features of mainframe computers. 

### V.C.2(c) Application Programming Interfaces 

APIs are software code that allows two or more different programs to communicate with each other. Entities use APIs (considered a form of middleware) to connect services and to transfer data. Broken, exposed, or compromised APIs can be exploited by malicious actors and used in data breaches (e.g., compromise of financial and personal data) or for other purposes (e.g., preventing availability) by exposing the endpoints or compromising the authentication tokens. Security needs for APIs should be assessed and implemented to mitigate risks of exposing sensitive customer or entity information.59 Therefore, management should address authorization, authentication, and encryption; API security tools and gateways with controls for requests and responses; sensitive data filtering; restriction on size and number of resources requested; identification of API request checkpoints for information leaving the network; and appropriate API logging and monitoring. Examples of security controls include the following: 

58 Examples of industry tools include Resource Access Control Facility (RACF) from IBM, CA Access Control Facility (ACF2) from Broadcom, and CA Top Secret from Broadcom. 

59 The OWASP API Security Project discusses API security issues and controls. 

* • Secure IPs (e.g., HTTPS) to encrypt data during transmission from the web browser to a web server.
* • Password hashing to validate the integrity of the message.
* • Restriction of secret information (e.g., API keys, session tokens, and user IDs) from website addresses to prevent unnecessary information transmission.
* • Industry standard authorization protocols60 to securely authenticate users.
* • Strong validation to ensure a user knows what to input (i.e., client-side validation) and on the web server to ensure data are accurate and in the correct format (i.e., server-side validation) to help mitigate malicious attacks.
* • Time stamping of API requests to provide traceability of the request.
* • Rate limiting of API calls to protect against malicious attacks (e.g., DDOS).
* • API traffic monitoring to determine the locations from where requests originate allowing the ability to take action (e.g., monitor activity or block IP addresses).
* • API gateways configured appropriately throughout the entity’s IT environment to facilitate principles of least privilege to information and services.

There are three primary types of APIs. An entity may use more than one of the following within its infrastructure: 

### • Internal or private APIs: 

Internal or private APIs are restricted from external access. They are used by internal teams or business units to access internal data, services, and tools. Advantages of using internal APIs include the following: 

* o Standardization of connections to internal services (e.g., eliminating hard-coded connections).
* o Decreased code development time through use of existing and already tested APIs.
* o Control over coding practices (e.g., secure coding).
* o Access restrictions over the API.
* o Auditability of API access and requests.

Management should implement an appropriate level of security before internal APIs are made available for use by other entity business units. 

#### • Public or open APIs: 

Public or open APIs (also referred to as third-party APIs) are accessible by external parties (e.g., developers). External parties register for access with the entity and, in return, receive an API key.61 In some cases, however, no registration is required. Management should implement adequate security and restrictions to protect sensitive customer and entity data. Management should perform appropriate testing to verify the adequacy of security controls before and after going public. 

#### • 

APIs between customers and unaffiliated third parties: In this situation, the relationship is between the customer and a third party (e.g., a fintech firm that is separate from the financial institution where the customer has the account). This type of API has a specific purpose and may have a fee associated with its usage. As part of its customer awareness program,62 management should make security awareness information (including the protection of customer information) available to its customers. The security awareness information should address protections available and not available when the customer allows access to its data through the use of unaffiliated third-party API services. Better-informed customers bolster the safety and soundness of an entity, consumer financial protection, and compliance with applicable laws and regulations. 

60 For an example refer to Internet Engineering Task Force, RFC 7591, OAuth 2.0 Dynamic Client Registration Protocol, DOI 10.17487/RFC7591, July 2015. 

61 An API key allows access to certain services and data. 

## V.C.3 Software Hosting 

Software can be hosted internally at the entity, externally at the entity’s third-party service provider, or in a combination of the two (e.g., using cloud infrastructure to manage capacity or for continuity and resilience purposes). Risks associated with software hosting include internal and external malicious actors. Threat modeling may help management determine the relevant risks from these actors and implement appropriate security controls to mitigate those security risks. Refer to the IT Handbook’s “Information Security” booklet for more information. 

* • Internally hosted software: Internally hosted (also referred to as on-premise) software refers to software that the entity hosts and manages. Usually, the internal IT department is responsible for software administration. When hosting software internally, there is a risk that the entity personnel does not have the appropriate skills and expertise to effectively manage the hosting environment. Management should identify personnel (e.g., internal or third party) with relevant skills and expertise and allocate resources to provide necessary training to maintain their knowledge. If the entity develops software, management should use a system development life cycle that incorporates security to limit the number and severity of vulnerabilities in the software.
* • Externally hosted software: Externally hosted software (also known as hosted services) is hosted at an entity’s third-party service provider. Access generally occurs through an internet connection. Hosted services may include core processing, web hosting (e.g., online banking and website), off-site backup, and virtual desktop infrastructure. Possible risks with externally hosted software include a lack of control over the infrastructure and any changes made to it by the third-party service provider. Management should have contract provisions addressing the notification of infrastructure changes and the third party’s use of any subcontractors (sometimes referred to as “fourth parties”). For more information, refer to the IT Handbook’s “Outsourcing Technology Services” booklet.
* • Hybrid hosted software arrangement: A hybrid hosted software arrangement refers to an agreement involving software that resides at the entity (on premise) and on the third-party service provider’s servers (e.g., productivity software as a service). Examples of this arrangement include the following: 
	+ o Internally deployed software at the entity where all data are maintained on the third- party service provider’s servers. 62 See FFIEC Authentication in an Internet Banking Environment and FFIEC Supplement to Authentication in an Internet Banking Environment for additional information.
	+ o Software intellectual property hosted on the third-party service provider’s servers and available in an “offline”63 implementation (e.g., productivity software) at the entity. The software has the ability to synchronize once the user has reconnected to the third- party service provider.
	+ o Use of a cloud service provider’s infrastructure for additional capacity or for continuity and resilience purposes, when necessary, although most of the infrastructure is managed at the entity.

When operating in a hybrid hosted software arrangement, the entity may not have complete access to the software intellectual property or its data. For hybrid and externally hosted software, if full functionality of the software or data is necessary and the connection to the third-party service provider is interrupted, the entity could experience significant loss (e.g., data, functionality, or business), depending on the arrangement. Even though a level of offline functionality may be available to the entity, that functionality may be limited. When an entity depends on the third-party service provider’s ability to function adequately, management should perform an adequate risk assessment to prepare for a potential service interruption. 

## V.D Environmental Controls 

Environmental controls are mitigating strategies designed to detect and prevent against natural, mechanical, and man-made risks and threats to the entity’s buildings and facilities and the affected personnel and infrastructure within them. Environmental controls include the following: 

* • HVAC.
* • Smoke and fire.
* • Water.
* • Power.

Without effectively designed and implemented environmental controls, an entity’s infrastructure may be exposed to risks that could reduce system resilience and reliability.64 Environmental controls help management identify and mitigate infrastructure and operational issues, such as loss of connectivity and availability of processing caused by theft, fire, flood, mechanical failure, and power failures, in a timely manner. Management should develop, document, and implement environmental control policies and procedures to safeguard facilities, technology, data, and people. For more information, refer to the IT Handbook’s “Business Continuity Management” booklet. 

Remote monitoring systems are available to monitor the entity’s infrastructure environmental controls and allow management to receive timely notifications and monitoring reports. Alerts can be sent via email or text message. These systems can be managed and monitored internally or through a third-party service provider. Any environmental controls (including IoT devices used for environmental monitoring) that can be managed through remote access, whether by a third- party service provider or not, should have appropriate access controls, monitoring of remote access activity, and regular review of privileges. Third-party service provider access for maintenance (e.g., system repair) and administrative purposes (e.g., billing) also should be appropriately controlled. For more information, refer to the IT Handbook’s “Outsourcing Technology Services” and “Information Security” booklets. 

63 Offline in this manner means that the application is still available for use when disconnected from the third-party service provider. 

64 Refer to ISO/IEC 27002:2013 Information Security Management Chapter 11: Physical and Environmental Security. 

## V.D.1 Heating, Ventilation, and Air Conditioning 

Management should implement controls to maintain appropriate temperature and humidity levels at facilities (e.g., data centers and server rooms) hosting the entity’s IT infrastructure. Management should monitor HVAC. Automatic temperature and humidity controls help management identify and mitigate fluctuations that may adversely affect IT infrastructure. Commensurate with risk to the entity, management should consider implementing automated monitoring and mitigating controls that provide an alarm or notification of significant temperature changes. Management also should consider the entity’s need for redundant HVAC equipment components. For more information, refer to the IT Handbook’s “Business Continuity Management” booklet. 

## V.D.2 Smoke and Fire 

Risks of smoke and fire to an entity’s infrastructure include failed or suppressed performance of systems or complete destruction of its infrastructure. Various methods are available to detect, suppress, or extinguish fire (e.g., portable fire extinguishers or systems for air sampling, active fire suppression, wet pipe, dry pipe, pre-action,65 gas, chemical, 66 or oxygen-removal). Management should evaluate the following: 

* • Determining the most appropriate smoke and fire detection systems for the entity, based on
* • Installing smoke and fire detectors in appropriate locations throughout the facility (e.g., data
* • Implementing devices and systems for smoke detection, fire suppression, and fire detection
* • Inspecting facilities for potential fire hazards using authorized and qualified inspectors and
* • Training personnel on their roles and responsibilities. the design and contents of its facilities and infrastructure. centers, business offices, and computer rooms). that are supported by an independent energy source. resolving identified deficiencies within an agreed-upon time frame.

All systems should be evaluated for their advantages and disadvantages. For example, wet pipe, dry pipe, or pre-action systems will suppress fire, but they may create problems associated with water in the facility. To provide continuous protection of facility assets, the fire suppression system should be operational even after business hours. If an entity’s fire suppression system includes oxygen removal, management should be aware of potential risks to personnel with that system type and implement compensating personnel protection controls. Smoke and fire detection provisions should be addressed in the contract for the entity’s third-party hosted infrastructure. 

65 According to NIST NCSTAR 1-4B, Fire Suppressions Systems, pre-action systems are different than both wet- pipe and dry-pipe sprinkler systems. In pre-action systems, water is not normally stored in the system piping like a wet-type sprinkler system. The water is kept out of the system of piping by a pre-action (deluge) valve until the system response is required as a result of the opening of a sprinkler and/or the activation of a detection device. 

66 These systems are also known as clean agent systems. 

## V.D.3 Water 

Water use (e.g., fire suppression system, break room, restrooms, and HVAC systems) in the facility can cause damage to an entity’s infrastructure. Water damage caused by environmental issues (e.g., flood or hurricane) is addressed in the IT Handbook’s “Business Continuity Management” booklet. Water leaks under raised floors or in ceilings are not easily visible and can cause serious damage to computer equipment and cabling. For this reason, management should consider use of water detectors in both spaces to alert management in a timely manner. Commensurate with risk to the organization, management should consider automated mechanisms to detect the presence of water near IT infrastructure and provide alerts to appropriate personnel. 

## V.D.4 Power 

Power compatibility and quality issues (e.g., appropriate power supply, power surges or sags, or inconsistent power delivery) can damage computer equipment or cause data loss or corruption. Management should take reasonable steps to protect computing equipment from inconsistent and “dirty power”67 sources as equipment should have a consistent power source. Management should consider a long-term alternate power supply for information systems that provides the necessary operational capability in the event of extended power loss.68 Long-term backup power can be manually or automatically activated. Management should consider using the following: 

* • Independent electrical feeds drawing from separate power grids. When multiple feeds or backup power generators are used, automatic fail-over to a live power source should be considered. When power is available only through one grid or one provider, management should evaluate and mitigate the risk in other ways (e.g., using generator(s) or batteries).
* • Methods to monitor, condition, or stabilize the electricity source voltage to minimize the effects of power fluctuations with specialized devices (e.g., surge protectors or capacitors).
* • Appropriate power configurations based on the entity’s power needs.
* • Alternative, or backup, power sources for IT facilities independent of local power grids. Those sources could include a combination of uninterruptible power supply (also referred to as UPS) and generators69 powered by diesel or natural gas, and management should consider the risks of these options. These may be used to mitigate disruptions, allow an orderly power down of systems, or transition systems to a longer-term alternate power source. 

67 Refer to Martzloff, François, “A New IEC Standard on the Measurement of Power Quality Parameters.” The report uses dirty power to describe a power line where disturbances (e.g., outages, voltage spikes, and drop-outs) occur. NIST, 2000. 

68 Refer to NIST SP 800-53 Rev. 5, Security and Privacy Controls for Federal Information Systems and Organizations - PE-11 Emergency Power. 

69 The generator should run on something other than electricity.
* • Processes to power down IT systems in an orderly manner to maintain critical information for later recovery, in cases where power cannot be maintained (e.g., during emergencies).
* • Automated emergency lighting that activates to illuminate the entity’s critical infrastructure, evacuation routes, and emergency exits, in the event of a power outage or disruption.
## V.E Physical Access Controls 

Physical access controls are mitigations that protect an entity’s facilities, physical assets, and technology assets.70 Unauthorized access can negatively affect the confidentiality, integrity, and availability of the entity’s information and technology assets and the business operations supported by them. Therefore, management should consider physical access controls when building or modifying an entity’s infrastructure environment. Management should implement appropriate physical access controls such as the following for the infrastructure and for locations that house the infrastructure: 

* • Generate and maintain a list of approved individuals with authorized physical access to the facilities housing IT infrastructure.
* • Validate access authorizations before granting access to restricted spaces (e.g., data centers, computer rooms, and sensitive work areas).
* • Issue credentials (e.g., badges, ID cards, and smart cards) for entity personnel and visitor badges for non-entity personnel (e.g., third-party service provider personnel).
* • Maintain and review logs of individuals that access restricted spaces.
* • Monitor physical intrusion alarms and surveillance equipment.
* • Escort visitors and monitor visitor activity.
* • Secure combinations, keys, and other physical access devices, and change combinations or keys when combinations are compromised, keys are lost, or staff is transferred or terminated. Any electronic user credentials should be removed or updated in a timely manner.
* • Review inventory of physical access devices at regular intervals.
* • Review access lists regularly and remove access for individuals who no longer require access.
* • Implement alternative physical access processes in case electronic controls fail (e.g., during power failures). 70 Refer to NIST SP 800-53 Rev. 5, Security and Privacy Controls for Information Systems and Organizations - PE- 3 Physical Access Control.
# VI OPERATIONS 

Operations are the performance of activities comprising methods, principles, processes, procedures, and services that support business functions. For the purposes of this booklet, IT operations include the tactical management of technology assets and daily delivery of services to capture, transmit, process, and store transactions and information that support the entity’s overall business processes. 

The operational environment includes the systems and facilities that the entity uses to run its business processes and operations. Operations functions are sometimes referred to as “back- office” functions because they are traditionally carried out in locations away from customer- facing functions. Operations functions are the “nerve center” of an entity and encompass the day- to-day processing and support functions, service delivery and service management, and control processes to support both the operations and overall mission of the entity. The operational environment is addressed in the following subsections: 

* • Operational controls.
* • IT operational processes.
* • Service and support processes.
* • Ongoing monitoring and evaluation processes.

## VI.A Operational Controls 

### Action Summary 

Management should develop and implement operational controls to safeguard the entity’s operational environment. These controls should be designed to protect the overall environment, including the physical facilities, infrastructure supporting the entity’s operations, systems and software, and personnel. 

Examiners should review for the following: 

* • Effective controls over the entity’s operating centers, including physical and logical controls.
* • Defined and appropriately administered authorization boundaries containing the entity’s systems, software, and information.
* • IAM methods used to appropriately identify and authenticate authorized users.
* • Personnel controls (e.g., hiring and retention practices, maintaining appropriate skillsets and knowledge, and activity monitoring processes) to maintain an effective workforce.
* • Controls allowing for the use of personally owned devices.

Operational controls are the day-to-day procedures and mechanisms used to protect operational systems and software. Operational controls affect the system and software environment. Because the system and software environment(s) are the foundation for the entity’s business processes, management should define processes and implement controls to protect the entity’s operational environment(s). This includes the use of operating centers, authorization boundaries, IAM controls, personnel controls, and controls for the use of personally owned devices. 

## VI.A.1 Operating Centers 

Operating centers can be physical or cloud-based and either entity-owned or outsourced. In entity-owned operating centers, management is responsible for the physical location as well as the on-premise equipment and systems. Operating centers may be owned and managed by a third party or may be on the entity’s premises but managed by a third party. In outsourced operating centers, management may be responsible for the equipment, but not the physical location. If a third party is involved in operating center activities, the contract should specify equipment ownership and responsibility. Regardless of the operating center type or its ownership, management remains responsible for the oversight of those activities. Typical operating centers include the following: 

* • Data center: The location where the entity houses and maintains its processing, data, storage, and communications systems and equipment. Data centers may be on premise, at a third-party location, co-located, or operate in the cloud.
* • Network operations center (also referred to as NOC): The NOC is the organization responsible for monitoring the health and performance of the network, including analyzing and maintaining network traffic.
* • Security operations center (also referred to as SOC): The SOC is the organization responsible for monitoring the entity’s network for security issues and responding to cyber attacks.

In smaller or less complex entities, there may not be separate operating centers. For example, the entity may have only a server room or closet. The key responsibilities and functions (e.g., security and network management) in operating centers should still be addressed. 

Management should maintain operating centers in physical locations less prone to environmental threats (e.g., away from flood plains or terrorist targets). Management should use appropriate security and environmental controls within its infrastructure to meet the entity’s operational needs: 

* • Smoke, water, and power detection and mitigation devices and systems, as well as fire suppression systems.
* • Security zones to limit access within restricted spaces.
* • Physical security controls (e.g., security partitions that reach the ceiling and windows that do not open).
* • Devices to restrict and log access to the site (e.g., badges, access cards and systems, keypads, and cameras).
* • Procedures outlining appropriate site maintenance (e.g., dust-free environment, limitation of paper or cardboard box storage, and restrictions on flammable chemicals or materials).

Management should designate responsibilities for implementing these security and environmental controls. Whether centralized or decentralized, operating center responsibilities also should include training staff to operate and maintain the entity’s equipment and systems (e.g., monitoring of environmental systems and procedures for manual intervention and overrides), deploying appropriate connectivity, and managing incidents and events. As part of its responsibilities, operating center personnel often provide logistical support for disaster recovery and business continuity testing for the operating center and business lines. Logistical support may include switching processing from production to alternate sites and systems. Refer to the IT Handbook’s “Business Continuity Management” booklet for more information. 

## VI.A.2 Authorization Boundary 

An authorization boundary is important in maintaining the confidentiality, integrity, and availability of the entity’s sensitive customer and corporate information. Within each boundary are discrete, identifiable technology assets that represent the building blocks of the information system. In conjunction with the entity’s ITAM inventories, management should define the necessary authorization boundaries and implement appropriate security controls. Maintaining multiple authorization boundaries can help mitigate the spread of malware infiltration during a breach. Management should implement appropriate controls (e.g., VPN or demilitarized zone) over internal and external communication systems within and across the entity’s authorization boundaries and with third parties (e.g., service providers and other external entities). Authorization boundaries are composed of the following: 

* • Physical, logical, and environmental controls.
* • Perimeter protection devices.
* • Internal and external communication systems.
* • People and processes supporting the entity’s missions and business functions.

Defining authorization boundaries provides management with the ability to centrally and consistently manage its systems and facilities. It enhances visibility across the entity’s segmented infrastructure and operations environment for mitigation, maintenance, and incident response within a particular authorization boundary. 

## VI.A.3 Identity and Access Management 

IAM encapsulates people, processes, and products, including technology, to identify and manage the data used in an information system to authenticate users and grant or deny access rights to data and system resources. Management should implement appropriate IAM to provide access to the entity’s resources. Given the sensitivity of the data residing on the entity’s assets, management should consider enhanced authentication, especially for privileged access. Management should consider its implementation of cloud services and address the unique access control requirements for cloud environments (refer to the “Access Control Considerations” section of this booklet). Regardless of the type of operational environment, management should maintain a policy and implement related standards and procedures to identify users and restrict their access (e.g., physical, logical, cloud-based, or privileged) by job function and operational need. For more information, refer to the IT Handbook’s “Information Security” booklet. 

## VI.A.4 Personnel Controls 

Personnel controls are critical given the reliance on the operating centers for entity operations. Safe and sound operations rely on skilled personnel, appropriate training, and suitable technology solutions. In coordination with the operations and human resources functions, management should ensure that processes for employee recruitment, hiring, and placement provide for thorough applicant screening and background checks at the time of employment. Background checks should be performed periodically during employment at a frequency consistent with the sensitivity of the position. In addition, management should implement the following personnel controls: 

* • Clearly define duties, responsibilities, expectations, and accountability to help minimize employee turnover. Turnover disrupts workflow, degrades service and production quality, and increases training resource demands. Staff stability improves employee morale and the effectiveness of operations.
* • Implement dual control and segregation of duties to prevent any one person from performing a complete process. The implementation of dual controls and segregation of duties deter employee dishonesty, fraud, or harm to the entity’s information and technology assets and serve as a quality control mechanism.
* • Independently monitor activities to prevent personnel from validating the accuracy of their own work or that of a superior.
* • Implement rotation of duties to facilitate cross-training, improve depth of personnel skill, and augment succession planning.

Adequate segregation of duties is a challenge in smaller or less complex entities. In such circumstances, appropriately implemented rotation of duties can be an effective compensating control. Management should closely review and monitor activities to provide effective supervision, facilitate training, and validate control effectiveness. 

## VI.B IT Operational Processes 

### Action Summary 

Management should implement effective IT operational processes to reduce the number of potential operational failures and minimize the impact of issues that occur. Management should evaluate the effectiveness of those IT operational processes and adjust them as needed. 

Examiners should review for the following: 

* • Appropriate preventive maintenance or operational restoration processes for equipment within the facilities that support the entity’s business objectives.
* • Configuration management processes.
* • Effective vulnerability and patch management processes.
* • Backup and replication processes that facilitate recovery.
* • Scheduling processes to manage and effectively use IT resources (e.g., hardware and processing time).
* • Capacity management processes that support the entity’s current and future strategic objectives.
* • Log management processes that allow management to capture system, software, and physical access activities.
* • Processes for the appropriate disposal of data and media.
## VI.B.1 Maintenance 

Maintenance is any act that either prevents the failure or malfunction of equipment or restores its operating capability. Preventive maintenance allows management to proactively address situations that may cause issues or disruptions. Preventive maintenance on equipment minimizes equipment failure and can lead to early detection of potential problems. It can include minor maintenance, such as cleaning peripheral equipment, and more extensive maintenance provided by the manufacturer, vendor, or maintenance contractor. Preventive maintenance includes general housekeeping to keep the data center and its equipment clean and orderly. Unless specifically authorized by management, computer operators should not repair equipment or perform other than the most routine maintenance. Even if computer operators have the requisite knowledge and experience, many hardware and software warranties disclaim liability for unauthorized maintenance or alteration. Routine maintenance by data center employees should be performed according to manufacturers’ recommendations. 

Maintenance schedules may vary considerably depending on the number and variety of IT systems and the volume of work processed. Preventive maintenance should follow a predetermined schedule. Operations employees should document both internal routine (if any) and externally provided maintenance in logs and other records. Management review of these records will aid in monitoring any maintenance performed. 

Usually, the manufacturer or vendor performs maintenance under contract. For leased equipment, maintenance may be part of the lease arrangement. When equipment is owned or leased from a third party, management should obtain a separate maintenance or service agreement between the entity and the equipment manufacturer or the third party. The service or maintenance agreement should detail the preventive maintenance to be performed, provide for repair services, and include a schedule for maintenance, as well as a time frame for repair. 

Management should schedule time and resources for preventive maintenance and coordinate that schedule with production. During scheduled maintenance, management should: 

* • Limit the service representative’s access to the minimum necessary for maintenance on the system.
* • Have at least one computer operator present when the service representative is in the computer room or data center.
* • Review system activity logs to monitor access to programs or data during maintenance.

When an entity uses hardware from more than one manufacturer, it may be helpful to have an arrangement with a single contractor to manage the entity’s preventive maintenance and repair services. The contract or agreement should guarantee timely performance of maintenance. 

Some vendors can perform computer maintenance online. Operations personnel should be aware of the online maintenance schedule, so it does not interfere with normal operations and processing. Whether maintenance occurs online or in person, the entity’s operations and information security personnel should follow established security procedures to ensure they grant only the necessary access to authorized maintenance personnel at predetermined times to perform specific tasks. 

Operations personnel should maintain a log of all hardware or software problems and downtime encountered between maintenance sessions. A periodic report on the nature and frequency of problems is an important management tool and can be valuable for vendor selection, equipment benchmarking, replacement decisions, or planning for increased equipment capacity. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for additional information on managing activities performed by third-party service providers. 

## VI.B.2 Configuration Management 

Configuration management is a collection of activities focused on establishing and maintaining the integrity of IT products and information systems, through control of processes for initializing, changing, and monitoring the configurations of those products and systems throughout the system development life cycle. For a configuration management process to be effective, management should have policies, standards, and procedures and define and implement appropriate configuration settings. In the context of configuration management, configuration settings are the set of parameters that can be changed in hardware, software, or firmware that affect the security posture and/or functionality of the information system.71 Defining and applying configuration settings on IT products are important components in operational assurance, along with assessing security controls and conducting a continuous monitoring program. Management should ensure that systems and software used to support the operations of the entity not only have appropriate configuration management capabilities, including configuration of audit log settings, but that the configuration management is enforced. Refer to the IT Handbook’s “Information Security” and “Development and Acquisition” booklets for more information on configuration management. 

## VI.B.3 Vulnerability and Patch Management 

Vulnerability management is a process to continuously acquire, assess, and take action on new information to identify vulnerabilities, remediate, and minimize the window of opportunity for attackers. Part of vulnerability management is patch management. Patch management is the systematic notification, identification, deployment, installation, and verification of OS and application software code revisions.72 Vulnerability and patch management are shared responsibilities among an entity’s operations and information security personnel. Management should establish procedures to stay abreast of system vulnerabilities and software vendor patches, test the patches in a segregated environment, and install them when appropriate. Refer to the IT Handbook’s “Information Security” booklet for more information on vulnerability and patch management. 

### VI.B.3(a) Vulnerability Management 

To have systems that are operationally functional and secure and perform as intended, management should implement a vulnerability management program that identifies systems and software vulnerabilities, prioritizes the vulnerabilities and the affected systems in order of risk, and performs timely remediation, according to the risk associated with the vulnerability. The program should include an entity’s systems and software73 operating in the cloud for which the entity is responsible and those managed by the entity on its premises. Management should monitor industry third parties (e.g., United States Computer Emergency Readiness Team [US- CERT74], NIST, and Financial Services Information Sharing and Analysis Center [FS-ISAC75]) that report vulnerability exposures and address any relevant exposures within the entity’s systems and software. 

71 Refer to NIST SP 800-53 Rev. 5, Security and Privacy Controls for Information Systems and Organizations - PE- 3 Physical Access Control. 

72 Examples of software code revisions include patches, hot fixes, and service packs. 

73 Examples of systems and software include a port, web application, database, wireless, Bluetooth, and container orchestration. 

74 The US-CERT is an organization within the Department of Homeland Security’s (DHS) Cyber Security and Infrastructure Security Agency (CISA). 

75 Refer to FS-ISAC. 

Management should implement a process to periodically assess systems and software for vulnerabilities using scanners that are updated with a current vulnerability list. The scans should include all systems and software in the entity’s hardware, software, and telecommunications inventories. As with other software tools and utilities, management should implement appropriate controls over vulnerability scanning tools. Controls to protect against unauthorized use or access to sensitive information through the tools include separation of duties, logical security, configuration management, and log review.76 The team or person performing the scans should use a dedicated account for authenticated vulnerability scans,77 which should not be used for any other administrative activities. 

Vulnerabilities are not limited to system or software. Inadequate operational processes can create additional vulnerabilities, exposing entities to unnecessary risk. These vulnerabilities can include weaknesses in security procedures, physical layout, or internal controls that malicious users could exploit to gain unauthorized access to systems or information or to disrupt critical services. Management should have a method to track and report on the remediation progress of all identified vulnerabilities. 

### VI.B.3(b) Patch Management 

An important function within operations is patch management. In conjunction with other cyber hygiene practices, a patch management program will allow management to proactively address technology-related system vulnerabilities. An entity’s change management procedures should include documentation of any patch installations. 

Keeping up with patches in a timely manner is labor-intensive and difficult to manage even for less complex entities; therefore, management should implement automated patch management systems and software to ensure that all network components (e.g., servers, VMs, routers, switches, mobile devices, and firewalls) are appropriately updated. Management should maintain a record of the versions in place and regularly monitor the internet and other resources for information on product enhancements, security issues, patches or upgrades, or other problems with versions of the software in the entity’s inventory. Management should be aware of and communicate with its third-party service providers on the need to integrate the entity’s patch management program with the third-party service provider’s patches or other changes. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet. For entities using a cloud environment, management may employ a highly automated update and patch process. Systems and software are often completely rebuilt rather than updated or patched. Refer to the IT Handbook’s “Information Security” booklet for more information on patch management. 

76 Refer to the Center for Internet Security (also referred to as CIS) Control 3, Continuous Vulnerability Management. 

77 The University of California at Berkeley’s Information Security Office defines an authenticated scan as an essential tool to obtain accurate vulnerability information on covered devices by authenticating to scanned devices to obtain detailed and sensitive information about the OS and installed software, including configuration issues and missing security patches. 

## VI.B.4 Backup and Replication Processes 

A backup is a copy of files and programs made to facilitate recovery. For systems, the backup process includes copying information to a redundant system (e.g., hardware, services, devices, or media) that can provide the same processing capability when the primary system is unavailable. Backups give management the ability to recover operations within a specified time frame, allowing business continuity with limited disruption. Replication involves the use of redundant software or hardware elements to provide availability and fault-tolerant capabilities. Backup and replication processes are shared responsibilities among an entity’s operations and business continuity personnel. The decision to implement a specific backup method, including replication, should be based on the risk and criticality of the systems and data. 

Management should maintain the following: 

* • Policies, standards, and procedures that document the entity’s backup methodologies, delineate responsibilities of personnel, and promote uniform performance throughout the entity.
* • Inventories of backup media, storage location, and access controls for the media or physical location.
* • Documented periodic physical reviews to confirm that all relevant backup material is available.
* • Procedures to verify adherence to backup schedules.
* • Processes to regularly test backup copies for readability.
* • Capability to restore operations to a previous trusted state.
* • Backups of configurations and data off-site and on a separate system or media.
* • VM versioning, replication, and life cycle policies for backup processes.
* • Data encryption and access controls to protect backup or replicated data from unauthorized access, destruction, or corruption.78
* • Proper sanitization79 and disposal of data when they are no longer needed to prevent the disclosure of information to unauthorized users.

For entities that rely on third-party service providers, including cloud service providers, to manage backup and replication processes, management should validate that the third-party service provider performs the processes above. 

Refer to the IT Handbook’s “Business Continuity Management” and “Information Security” booklets for more information on backup and replication processes. 

78 Refer to the U.S. Department of Homeland Security’s Cloud Security Strategy: .gov Cloud Security Baseline. 

79 NIST SP 800-53 Rev. 5, Security and Privacy Controls for Information Systems and Organizations., states that “sanitization techniques, including clearing, purging, cryptographic erase, and destruction, prevent the disclosure of information to unauthorized individuals when such media is reused or released for disposal.” 

## VI.B.5 Scheduling 

In IT, job scheduling is the planning and managing of the execution of software tasks that are required as part of an IT service. IT operations management is responsible for scheduling, which is often automated using software tools that run batch or online tasks at specific times of the day, week, month, or year. Scheduling allows management to allocate resources to limit downtime and ensure adequate use of servers and processing equipment. Management should implement policies, standards, and procedures for creating and changing job schedules and analyzing and maximizing the entity’s resources. Automated scheduling tools can help improve management’s ability to analyze and maximize scheduling efficiency. In addition to routine scheduling, these tools may be used to assign priorities and allocate computer resources to non-routine processing. 

## VI.B.6 Capacity Management 

Capacity management is the process of planning and monitoring an entity’s technology resources to support current and future strategic objectives. It involves the use of baseline performance data to model and project an entity’s future needs. Capacity management should be closely integrated with the budgeting and strategic planning processes. Management should implement capacity management processes that address internal factors (e.g., growth, mergers, acquisitions, new product lines, and implementation of new technologies) and external factors (e.g., shift in customer preferences, competitor capability, and market requirements). 

Capacity management activities can be supported by automated tools to allow management to more easily analyze the information it receives. Management should routinely assess capacity against baselines to ensure adequate performance in the following: 

* • Platform processing speed.
* • Primary working memory80 for each platform’s central processing unit (CPU).
* • Additional data storage capacity.
* • Voice and data communication bandwidth.

Management should analyze capacity trends to ensure that capacity continues to meet entity needs. When appropriate, management should analyze help desk records to determine whether incidents were caused by capacity issues. Management should periodically analyze projected versus actual capacity to determine whether capacity planning processes are appropriate or should be adjusted. 

As part of its planning processes, management should consider testing applications and systems to verify that they will meet the entity’s demands during periods of high volume. Periodically, IT management should meet with business line management to determine whether future projects may affect the entity’s capacity needs. When building or acquiring new technology, management should consider flexibility to accommodate the entity’s future capacity requirements. As a part of sound capacity planning, management should evaluate third-party service providers’ performance in combination with internal performance to help determine whether existing demands are being met and future demands can be achieved. 

80 For the purposes of this booklet, primary working memory refers to the temporary storage or memory needed to run software applications that is shipped with the CPU and is generally supplemented by additional data storage (i.e., long-term storage). 

## VI.B.7 Log Management 

Log management is the process to generate, transmit, store, analyze, and dispose of log data. With respect to operations, a log is a record of events occurring within an entity’s systems and networks. Management should have a process to use logs to identify, track, analyze, and resolve problems that occur during day-to-day operations. Logs may record activity performed on the entity’s systems and software (e.g., OS, software application, network device, or security system). The entity may use specifically designed monitoring software or devices to capture logs. Logs are often used to track user access, system messages, and device performance and capacity. Examples of logs include: 

* • Occurrence (e.g., successful backups, last malware scanned, signature updates, patch installation, and system events).
* • Anomaly (e.g., failed backups, failed log-on attempts, and suspicious activity).
* • Usage (e.g., capacity).
* • Activity (e.g., intrusion detection and protection actions taken, authentication success and failure, and blocked traffic).

Analyzing logs allows management to troubleshoot problems, investigate malicious activity, understand the entity’s baseline activities, and support improvement activities. A challenge of log management is balancing the amount of data collected, the storage and capacity available, the ability to analyze the data, and the capability to respond to issues raised through that analysis. At times, the amount of data collected can make it difficult to identify anomalies. Another issue management should address is identifying and dispositioning false positives. Once false positives are identified, management should adjust logging parameters to minimize the volume of false positives in future log reviews. Log management is a shared responsibility among an entity’s operations and information security personnel. Management should implement policies, standards, and procedures for log management activities that address the following: 

* • Objectives for logging.
* • Types of logs to be collected.
* • Controls to restrict access to log settings.
* • Response time for log review (e.g., real-time).
* • Retention time frames and storage policies of logs.
* • Escalation processes for anomalies.

Management should configure logging to match the entity’s risk and complexity and identify and address anomalies. Because logs can be large and difficult to analyze by humans, management should consider using tools to automate log analysis and extract important events or patterns. Automated tools can help identify anomalies and automatically alert management to potential issues or events. Management should implement controls to protect logs to preserve their integrity and prevent log information from being misused. Refer to the IT Handbook’s “Information Security” booklet for more information. 

## VI.B.8 Disposal of Data and Media 

Management should implement policies, standards, and procedures to address media81 and equipment disposal or transfer. Disposal processes are a shared responsibility among several of an entity’s functions, including operations, information security, and third-party service provider management. Controls involved in the disposal process should be risk-based relative to the sensitivity of the information as defined by the entity’s data classification82 policy and the type of media used. The procedures should define methods for disposal based on the type of data to be removed. For example, management may choose to physically destroy media that contain customer sensitive information to prevent data recovery and misuse. Management should consider using techniques to remove data even when transferring the media between internal departments, as not all internal departments require access to sensitive or confidential information. For example, often media is reused after an employee leaves the entity; if someone in a customer-facing function with access to sensitive customer information leaves the entity, the information should be removed from the laptop before issuing it to other employees. Management should have appropriate procedures for the disposal of equipment (e.g., printers), which may contain residual data. Periodically, management should perform a review to ensure the timely disposal of decommissioned equipment. 

The disposal of records stored on electronic media presents unique challenges because residual data can remain on the media after erasure. As technology evolves, techniques previously used may no longer be effective. For example, degaussing was an effective tool to remove data stored on magnetic media, but degaussing is not effective for non-magnetic media, such as flash drives. Even magnetic media has evolved to a point that additional techniques beyond degaussing should be considered. Because data can be recovered, additional disposal techniques (e.g., data destruction) should be applied to remove sensitive information. Refer to the IT Handbook’s “Information Security” booklet for more information. 

81 In the context of this booklet, media includes physical media (e.g., paper), electronic media (e.g., hard drives, disks, and removable drives), and virtualized copies. 

82 For example, the Information Security Standards direct each financial institution to develop, implement, and maintain, as part of its information security program, appropriate measures to properly dispose of “customer information” and “consumer information.” Refer to 12 CFR 30, appendix B (OCC); 12 CFR 208, appendix D-2 and 225, appendix F (FRB); 12 CFR 364, appendix B (FDIC); and 12 CFR 748, appendix A (NCUA). 

## VI.C Service and Support Processes 

### Action Summary 

Management should develop and implement service and support processes. These processes should be designed to support an entity’s strategic goals and objectives by preventing issues, ensuring continuous reliability and resilience, and supporting users (e.g., business lines, personnel, and customers). 

Examiners should review for the following: 

* • Effective planning processes for service management that consider services offered, SLAs and contractual provisions, known limitations, and metrics and measurements.
* • Communication processes with business line management.
* • Operational support processes, controls, and mechanisms to report transmission and processing errors.
* • Processes to document and track issues through resolution.
* • Documented event, incident, and problem management processes.
## VI.C.1 Service Management 

Service management is the process of overseeing and managing an entity’s activities and resources to allow management of IT functions to support and service the entity’s strategic goals and objectives. The success of service management is normally gauged by the overall quality of service and proactive identification and resolution of problems. Service management functions should be designed with an emphasis on preventing issues and ensuring continuous reliability and resilience where possible. As part of its planning, management should consider the following: 

* • Services offered and SLAs, operational level agreements (OLAs), or contractual provisions.
* • Activities performed by third-party service providers.
* • Known limitations that may affect service management functions and activities (e.g., capacity issues or resource constraints).
* • Applicable legal and regulatory requirements.
* • Resources (e.g., human, technical, equipment, and capacity) necessary to carry out service management functions and activities.
* • Metrics and measurements used to evaluate service management effectiveness.

The service management function ensures that business functions have technology available to support business objectives and end users have the resources to perform their jobs efficiently and effectively. Many entities develop service catalogs to outline the services and functions offered. The catalogs often describe the services and dependencies between services or functions. 

SLAs, referred to as OLAs when used for internal service delivery, often outline business line expectations for service management and support functions (e.g., uptime requirements and response times). Documented OLAs are less common in smaller or less complex entities; business line management, however, should still communicate and coordinate its business requirements to personnel responsible for the execution of service management functions. OLAs and requirements may act as a baseline for any SLAs with third-party service providers. When an entity uses third-party service providers, management should coordinate its processes with them to ensure seamless functionality to the entity’s lines of business. 

As technology continues to evolve, more entities are aligning IT with business processes to simplify IT activities and to increase business line satisfaction. For example, several entities have implemented staff self-service processes to handle support tasks, such as hardware or software requests or password resets. 

Periodically, the process owners from both business and technology functions should meet to discuss known issues, changes in progress, and future changes. These meetings help ensure that service management continues to support operations and the lines of business. 

## VI.C.2 Operational Support 

Operational support personnel perform activities that either directly or indirectly support the entity’s lines of business. Management in the lines of business may not have insight into the activities performed by operational personnel or into supporting systems or software. Management should implement the following: 

* • Processes to verify that incoming data transmissions and processing are complete and accurate.
* • Controls to verify that external data transmissions and processing are securely received in accordance with entity policies, procedures, and standards.
* • Controls to verify that data were not corrupted during transmission or as a result of processing failures.
* • Mechanisms to report transmission and processing errors.

Operational support personnel should report any errors or problems with the systems or software to management in the lines of business and provide frequent updates on the resolution of issues. 

## VI.C.3 IT Support 

IT support provides the entity’s personnel and clients with technical assistance; troubleshooting advice regarding software, hardware, or networks; and assistance with events, incidents, or problems. In some entities, this function may be referred to as client support, help desk, or service desk. IT support may consist of dedicated staff trained in problem resolution, equipped with issue tracking software, and supported with knowledge-based systems that serve as a resource for common problems. In smaller or less complex entities, IT support may consist of a single person or a small staff or provided through a contract with a third-party service provider. 

Larger or more complex entities often use documented service requests within a system to track their activities and the actions taken. Smaller or less complex entities often track and fulfill business requests through less formal processes. A tracking system helps management prioritize issues, track problems through resolution, and analyze the problem database for systemic concerns. A tracking system can be used to monitor IT support performance. Some tracking systems allow users to monitor problem resolution. Known issues and related fixes or resolutions should be documented in the system. 

IT support should record and track incoming issues, whether handled by human operators or automated systems. Tracking requests creates a historical record and allows management to perform trend analysis. The tracking system documentation should include the following: 

* • User name and contact information.
* • Problem description.
* • Request type and category.
* • Affected system (e.g., hardware, software, or other device).
* • Prioritization code.
* • Current status toward resolution.
* • Individual or group responsible for resolution.
* • Root cause, when identified.
* • Target resolution time frame.
* • Comments related to user interaction (e.g., number of calls for resolution) with IT support and any other pertinent information (e.g., resolution attempts).

Management should maintain well-trained and knowledgeable IT support personnel to effectively support clients and users. If IT support software is used, IT support personnel should have appropriate training to perform their duties. IT support should follow procedures to authenticate users to prevent unauthorized access to information or credentials. The entity may choose to use different levels of authentication depending on the method of contact (e.g., telephone, website, or chat), the problem reported, the type of action requested, or the platform, system, or data involved. Management should consider layered security and supplemental authentication techniques,83 including out-of-band methods for changes to account maintenance activities (e.g., address or password changes) and for those involving high-risk transactions84 to limit attempted fraud through social engineering or identify theft. Refer to the IT Handbook’s “Information Security” booklet for more information. 

If the IT support function is outsourced, management should include management’s IT support expectations and responsibilities for the third-party service provider in the contract. Responsibilities may include information access level, functions it will perform, controls for security and confidentiality, and reporting and metrics to be provided. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for more information. 

83 Techniques include multifactor authentication, pre-established personal identification numbers (PIN) or passphrases, and call-backs at established numbers. 

84 Refer to the FFIEC’s Supplement to Authentication in an Internet Banking Environment. 

## VI.C.4 Event, Incident, and Problem Management 

Entities face a variety of events, incidents, and problems throughout the normal course of business. Managing these situations is important to minimizing disruptions on the entity’s daily operations and its ability to service customers. Therefore, management of these situations is a shared responsibility among several of an entity’s functions, including operations, information security, business continuity management, and third-party service provider management. Entity management may define and execute event, incident, and problem management processes differently throughout the entity (e.g., within the IT environment, at the business unit level, or at the enterprise level). To minimize confusion, management should implement processes to coordinate and define roles and responsibilities and conduct testing to identify interdependencies. 

Event management is the process used to track issues that occur in the IT infrastructure and detect and escalate those issues. Incident management is the process of identifying, analyzing, and correcting disruptions to operations and preventing future recurrences. The goal of incident management is to limit the disruption and restore operations as quickly as possible. Problem management is the process employed to manage the life cycle of an entity’s problems. Its goal is to proactively prevent problems from becoming incidents and lessen the impact of incidents that management cannot prevent. 

Management should implement processes to plan for and manage events, incidents, and problems. Management should establish and maintain appropriate processes and controls to help protect the entity from financial, operational, reputation, and other risks. These processes should include the following: 

* • Identifying the event, incident, or problem.
* • Determining the impact (e.g., number of customers and employees affected, revenue lost, expenses incurred, SLAs or OLAs breached, and reputation damaged).
* • Assigning a severity rating based on risk (e.g., breach of confidentiality, integrity, or availability of customer or entity data).
* • Performing root cause analysis to prevent repeat incidents.
* • Identifying, logging, tracking, and analyzing events, incidents, and problems that occur during day-to-day operations.
* • Maintaining contact information for individuals and groups (e.g., regulators, law enforcement, internal public relations, and affected lines of business) who should be notified and the circumstances under which they should be notified.
* • Informing the help desk of the event, incident, or problem and how to respond (e.g., using a script to provide information on the situation).
* • Resolving the event, incident, or problem, including approval processes for system or software changes to correct the issue.
* • Documenting any interim actions, compensating controls, and, if necessary, risk acceptance for issues that cannot be immediately resolved.
* • Developing longer-term action plans to monitor and address issues that cannot be resolved in a timely manner.
* • Reporting on the progress of the action plans to senior management.
* • Implementing procedures for escalation and reporting to management and stakeholders.
* • Implementing procedures to correlate events to determine whether there are underlying issues preventing resolution and allowing events to recur.

Management should consider performing periodic trend analysis to determine whether there are recurring or related issues that may be tracked to a common root cause. This would allow management to maintain systems and software and make timely changes to prevent future issues. The analysis also helps management support continuous improvement processes (refer to the “Continuous Improvement” section of this booklet for more information). 

Event, incident, and problem management plans should cover hardware, software, and security devices. Situations may include issues related to confidentiality (e.g., security breaches), integrity (e.g., out-of-balance conditions or logging issues), and availability (e.g., production program failures or database corruption). Processes to manage these and other situations should be communicated and readily available to appropriate personnel.85 Processes should be coordinated and included within the entity’s incident response program, as discussed in the IT Handbook’s “Information Security” and “Business Continuity Management” booklets. 

## VI.D Ongoing Monitoring and Evaluation Processes 

### Action Summary 

Management should develop processes to oversee operations functions, evaluate the effectiveness of controls, and identify opportunities for improvement. 

Examiners should review for the following: 

* • Implementation of processes to monitor and report on control effectiveness.
* • Stakeholder input into the types of reports and metrics produced.
* • Defined objectives for IT, operations, and key performance indicators (KPI).
* • KPIs that align with the entity’s ERM processes.
* • Processes for reporting KPIs to the board.
* • Implementation of corrective action plans when KPIs do not meet established targets.
* • Processes to recommend changes in operations processes and controls.
* • Strategies for service and process improvement and methods to measure the results of those improvement efforts. 85 Appropriate personnel include IT operations personnel, entity management, internal audit, fraud and loss prevention department, information security, computer security incident response teams, and personnel from third- party service providers.
## VI.D.1 Monitoring and Reporting 

Management should implement processes to monitor IT operations and periodically report on the effectiveness of established controls to senior management and other stakeholders. They should have input into the types of reports and metrics produced and reports should be understandable and useful to them. Regular monitoring can help management identify risk within operations (e.g., ineffective controls, inefficient processes, insufficient or inefficient use of resources, and substandard service delivery). The operations team should report performance metrics to senior management and other stakeholders. Operations management should meet periodically with senior management and other stakeholders to assess the value of the monitoring and reporting and to identify any changes (e.g., stakeholders, requirements, objectives, and metrics). 

Monitoring and reporting support proactive systems management activities to position the entity to meet its current needs and plan for periods of growth, mergers, or expansion of product lines. Examples of IT operations reports include the following: 

* • Hardware and data communications capacity utilization.
* • System information (e.g., system availability, system response times, and on-time processing).
* • Transaction processing completeness and accuracy.
* • Security-related information, such as vulnerability management metrics.
* • Service-level benchmarks compared to actual service performance.
* • KPIs, discussed further in the next section.

Management should monitor third-party service providers as part of the entity’s third-party risk management program. Reports from third-party service providers should include effectiveness of security controls, performance metrics, resolved versus outstanding issues, and root causes of problems. Management should monitor the third-party service provider’s ability to meet defined SLAs, compliance with identified action plans when they are not met, and remuneration of penalty fees when appropriate. 

Entities that have migrated to a cloud computing environment may find that traditional operations monitoring and reporting tools and techniques are no longer effective. For example, encryption or containers may impede the operation and accuracy of some tools. Management should explore the use of tools designed for cloud computing, either by the cloud service provider or external vendors. Some examples of these tools include cloud service provider- offered monitoring services and third-party applications (such as CASBs or agent-based monitoring). 

## VI.D.2 IT and Operations Key Performance Indicators 

KPIs are measures that determine how well the process is performing in enabling the goal to be reached. Management should define objectives for IT and operations and KPIs to help management measure those objectives. KPIs should align with the entity’s ERM processes and allow management to assess the performance of IT and operations across the entity. 

Management should set KPI benchmarks it wants to achieve and analyze deviations from those benchmarks. The collection of KPIs should be automated to the extent possible. Examples of IT and operations KPIs may include the following: 

* • Resource utilization by application or time of day.
* • Network availability (e.g., uptime).
* • Response time, access types by service, or average connect time.
* • Voice response unit call capacity.
* • Mobile and internet banking capacity.
* • System failures.
* • Help desk performance metrics (e.g., number of calls answered, average talk and wait times, total ticket duration, mean time to resolve, and percent of first contact resolution).
* • Virtualization metrics (e.g., memory availability and network bandwidth).
* • Change management metrics (e.g., total number of changes and number of emergency or unplanned changes).

Information gained from analysis supports daily management of operations and early alerting of potential operational issues. As part of the entity’s monitoring and review processes, management should regularly review KPI reports and provide appropriate reporting up to the board, if necessary. Management should implement corrective action plans to address the deviations or negative trends, assign individuals responsible, and monitor progress to completion. Periodically, management should meet with stakeholders to review the IT and operations KPIs. Management should determine whether the KPIs are appropriate indicators to demonstrate the ability to meet the entity’s strategic objectives. 

In conjunction with KPIs, a common method of measuring operational risk is through the use of key risk indicators (KRI). KRIs are a subset of risk indicators that are highly relevant and possess a high probability of predicting or indicating important risk. Refer to the IT Handbook’s “Management” booklet for more information on KRIs. 

## VI.D.3 Control Self-Assessments 

A control self-assessment, sometimes referred to as a risk control self-assessment, is a technique that allows managers and work teams directly involved in business units, functions, or processes to participate in assessing the entity’s risk management and control processes. Management can use these assessments to monitor the effectiveness of IT operations controls as well as to gauge performance, assess the criticality of systems, and identify existing risks. Control self- assessments do not eliminate the need for independent audits. The results should be evaluated by management and used to continuously improve the entity’s operations. 

## VI.D.4 Continuous Improvement 

Continuous improvement is the ongoing effort to improve an entity’s products, services, or processes to meet business objectives. An entity’s reliance on technology involves continuous innovation and the need for updated and more advanced systems. Improvement efforts in operations can be gradual (where management makes incremental changes over time) or all at once. Regardless, continuous improvement relies on management and personnel; therefore, management should have a process in place to recommend changes. 

To improve the management and governance of operations, management should develop improvement strategies for operations and prioritize projects. Management should make decisions related to improvement based on the potential benefit and ease of implementation, with a focus on important IT processes and core competencies. 

Management should have a process to measure the results of continuous improvement efforts. This can be accomplished by establishing a scorecard with KPIs to measure current performance and monitor the results of new improvements. Validating these measurements could include the following: 

* • Implementation of organizational structures that support improvement.
* • Designation of risk management responsibilities.
* • Facilitation for sharing vital business information.
* • Communication of strategies and goals. There are several types of continuous improvement, including for processes and services.
* • Process improvement: Process improvement includes the actions taken to improve the quality of the organization’s processes aligned with the business needs and the needs of other concerned parties. It should be an ongoing practice as part of the entity’s continuous improvement efforts. Results can include improved quality, strengthened security, increased productivity and efficiency, and improved employee skills.
* • Service improvement: Service improvement includes the actions taken to identify and execute methods to improve an entity’s services and align them with its business objectives. It should be implemented enterprise-wide and augment the entity’s ability to provide value to its stakeholders and customers. Management can facilitate the entity’s continuous improvement efforts through the following: 


	+ o Maturity assessments.
	+ o Gap analyses.
	+ o Benchmarking.
	+ o Improvement planning.
# VII EVOLVING TECHNOLOGIES 

Entities use a variety of evolving technologies (e.g., cloud, zero trust architecture [ZTA], AI and ML, and IoT) that may impact architecture, infrastructure, and operations functions. This section provides general information relating to these evolving technologies and, when appropriate, certain risks and control principles discussed in prior sections of this booklet. 

# VII.A Cloud Computing 

Cloud computing environments are enabled by virtualization technologies, which allow cloud service providers to segregate and isolate multiple clients on a common set of physical or virtual hardware. NIST defines cloud computing as “a model for enabling ubiquitous, convenient, on- demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or third-party service provider interaction.”86 Cloud systems provide several benefits, including scalability of resources and consistency in deployment of controls across systems and software. 

For the purposes of this section of the booklet, when the term “cloud service provider” is used, it refers to the provider offering cloud computing services. When the term “entity” is used, it refers to the client receiving cloud computing services. 

As defined by NIST, “cloud computing has five essential characteristics, three service models, and four deployment models.”87 

# VII.A.1 Essential Characteristics 

According to the NIST definition, cloud implementations take advantage of all of the following five “essential characteristics.”88 Some entities may characterize their environment as “cloud computing” without it exhibiting all five characteristics. NIST describes the five essential characteristics as follows: 

* • On-demand self-service: A consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with each third-party service provider.
* • Broad network access: Capabilities are available over the network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, tablets, laptops, and workstations). 86 Refer to NIST SP 800-145, The NIST Definition of Cloud Computing: Recommendations of the National Institute of Standards and Technology. 

87 Ibid. 

88 Ibid.
* • Resource pooling: The cloud service provider’s computing resources are pooled to serve
* • Rapid elasticity: Capabilities can be elastically provisioned and released, in some cases
* • Measured service: Cloud systems automatically control and optimize resource use by multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to consumer demand. The customer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location (e.g., country, state, or data center). Examples of resources include storage, processing, memory, and network bandwidth. automatically, to scale rapidly outward and inward commensurate with demand. To the consumer, the capabilities available for provisioning often appear to be unlimited and can be appropriated in any quantity at any time. leveraging a metering capability (e.g., storage, processing, bandwidth, and active user accounts) appropriate to the type of service. Resource usage can be monitored, controlled, and reported, providing transparency for the provider and consumer of the utilized service.
# VII.A.2 Cloud Service Models 

There are generally three key cloud service models89 used in cloud computing implementations.90 The optimal architecture for a given application or service is determined by consideration of the entity’s requirements, including data classification, data residency, service or application availability, and interfaces with external services and data stores. 

NIST describes the service models91 as follows: 

* • Software as a service (SaaS): SaaS allows entities to use applications running on a cloud
* • Platform as a service (PaaS): PaaS provides entities with the ability to deploy applications
* • Infrastructure as a service (IaaS): IaaS provides entities with the ability to provision infrastructure. The entity does not control or manage the applications or the environment in which the applications are running, including the network, servers, OSs, storage, or individual application capabilities. In this model, the end user and the entity generally have limited ability to customize the user interface of the cloud service, with the exception of some user-specific application configuration settings. created or acquired by the entity using programming languages, libraries, services, and tools supported by the cloud service provider. The entity does not manage or control the cloud infrastructure (e.g., network, servers, OSs, or storage); it does control the deployed applications and possibly the configuration settings. processing, storage, networks, and other fundamental computing resources where the entity is able to deploy and run software, which can include OSs and applications. The entity does not manage or control the underlying cloud infrastructure; it does control OSs, storage, and deployed applications. Entities have the maximum flexibility to customize their cloud services and user interfaces. 89 Refer to NIST SP 500-316, Framework for Cloud Usability. 

90 There are a variety of other cloud service models (e.g., disaster recovery as a service, backup as a service, and desktop as a service). The focus for the purposes of this booklet are the key cloud service models used here as a baseline for most others. 

91 Refer to NIST SP 500-316, Framework for Cloud Usability.

Management may choose to leverage the cloud in different ways. Some entities outsource certain applications or processes, such as storage or data backup to the cloud (as part of SaaS). Others may choose to develop their own applications; these entities, however, rely on the cloud service provider to provide and maintain the OS (as part of PaaS). Still others may choose to outsource only the physical hardware to cloud service providers, while maintaining the OS and applications themselves (as part of IaaS). 

# VII.A.3 Cloud Deployment Models 

As with cloud service models, management can deploy cloud services in different ways. NIST describes the deployment models as follows:92 

* • Private cloud: The private cloud infrastructure is provisioned for exclusive use by a single
* • Community cloud: The community cloud infrastructure is provisioned for exclusive use by
* • Public cloud: The public cloud infrastructure is provisioned for open use by the general
* • Hybrid cloud: The hybrid cloud infrastructure is a composition of two or more distinct cloud entity with multiple business units. The private cloud infrastructure may be owned, managed, and operated by the entity, a third party, or some combination of the two, and it may exist on or off premises. a specific community (e.g., government agencies, financial services, or banks) of entities that have shared concerns (e.g., mission, security requirements, policy, and compliance considerations). The community cloud infrastructure may be owned, managed, and operated by one or more of the constituents in the community, a third party, or some combination of the two, and it may exist on or off premises. public. The public cloud infrastructure may be owned, managed, and operated by a business or an academic or government organization, or some combination of the two. It exists on the premises of the cloud service provider. infrastructures (e.g., private, community, or public) that are unique entities but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds).

Entities may use more than one cloud service provider for different operations or to augment continuity and resilience for operations in the cloud. The use of multiple cloud service providers may reduce single-provider reliance. Entities may rely on cloud bursting93 capabilities for situations requiring increased capacity or for business continuity purposes. Entities may use a cloud broker to act as an informed intermediary between management and the cloud service provider. The use of a cloud broker may also supplement the capabilities of entity management and staff. 

92 Refer to NIST SP 800-145, The NIST Definition of Cloud Computing: Recommendations of the National Institute of Standards and Technology. 

93 The goal of cloud bursting is to maintain required service levels for an entity’s data-center hosted process, by dynamically allocating or deallocating cloud computer or storage resources to service current demands. 

# VII.A.4 Shared Responsibilities 

In cloud computing environments, entities may outsource the management of different controls over information and technology assets and operations to the cloud service provider. Careful review of the contract between the entity and the cloud service provider along with an understanding of the division of shared responsibilities and related risks are important for implementing appropriate controls. The contract defines the service-level expectations and control responsibilities for both the entity and the cloud service provider. To maintain security consistent with an entity’s internal standards, there may be a need for controls in addition to those a cloud service provider contractually offers. 

Depending on the service and deployment model used, management should understand the shared responsibilities associated with cloud computing. As presented by NIST, “compared to traditional IT systems, where one organization has control over the whole stack of computing resources94 and the entire life cycle of the systems, cloud service providers and cloud consumers collaboratively design, build, deploy, and operate cloud-based systems. The split of control means both parties now share the responsibilities in providing adequate protections to the cloud- based systems.” It is important to understand what controls are implemented by the cloud service provider for the cloud service provider’s own operations and what security controls are implemented and operated to ensure the security of the entity’s content and applications. 

For each service model, there are typically different shared responsibilities between the entity and the cloud service provider for implementing and managing controls. The following includes some of the controls that are the responsibility of either the entity or the cloud service provider, or both in some cases, depending on the service model and contract provisions. 

* • Managing the underlying cloud infrastructure systems (e.g., network, servers, or storage) or software.
* • Managing and implementing controls over the hypervisor(s).
* • Provisioning and configuring cloud platform resources.
* • Implementing user-specific application configuration settings and user access and identity management.
* • Managing entity data (e.g., classifying assets and employing encryption).
* • Developing and deploying software residing on the cloud service provider’s platforms.
* • Managing the physical data center, including environmental controls (e.g., heating, cooling, and fire and flood protection), power, physical security, and data communications connections.
* • Implementing controls over data access, theft of user credentials, regulatory compliance, and data leakage. 94 NIST SP 500-292, NIST Cloud Computing Reference Architecture:

Recommendations of the National Institute of Standards and Technology, states, “In cloud computing, a stack of computing resources refers to the group of services that the institution purchases from a cloud computing service provider.” 

Figure 5. Example of Shared Responsibilities in a Cloud Computing Environment 



|  | On Premise Responsibility | laas Responsibility | Paas Responsibility | SaaS (and Traditional Outsourcing) Responsibility Risk Mgmt |
| --- | --- | --- | --- | --- |
| Risk Management | Risk Mgmt Strategy | Risk Mgmt Strategy | Risk Mgmt Strategy | Strategy |
| (Mgmt) / | Policy | Policy | Policy | Policy |
|  | Organization | Organization | Organization | Organization |
| Administrative Controls | App. Administration IAM/Access Controls | App. Administration IAM/Access Controls | App. Administration IAM/Access Controls | App. Administration IAM/Access Controls |
|  | Applications | Applications | Applications | Applications |
|  | Data | Data | Data | Data |
|  | Runtime | Runtime | Runtime | Runtime |
| Technical | Middleware | Middleware | Middleware | Middleware |
| Controls | Os | Os | OS | OS |
|  | Virtualization | Virtualization | Virtualization | Virtualization |
|  | Servers | Servers | Servers | Servers |
|  | Storage | Storage | Storage | Storage |
|  | Networking | Networking | Networking | Networking |
| Physical Controls | Facility | Facility | Facility | Facility |

Note: Based on a diagram from the Cloud Security Alliance, FFIEC members augmented the diagram by adding the layer of risk management and administrative controls. This chart is an example of how the responsibilities may be divided between the entity and the cloud service provider as defined in the contract. Dark blue boxes represent the entity’s responsibility. White boxes represent the cloud service provider’s responsibility. Boxes shaded in light blue are examples of responsibilities that may be assigned to either or both the entity and the cloud service provider. 

Regardless of the environment or service model used, the entity retains overall responsibility for the safety and soundness of cloud services and the protection of sensitive customer and entity information.95 Refer to the IT Handbook’s “Outsourcing Technology Services” and “Information Security” booklets for more information on third-party service provider oversight. 

# VII.A.5 Risk Considerations for Cloud Computing 

Cloud computing is exposed to the same threats, vulnerabilities, and risks as other technology environments, whether the cloud computing environment is managed internally at the entity or at a third-party service provider. Cloud computing may involve different security control configurations and processes than those employed in more traditional network architectures. Simply moving existing network technology to the cloud may not be appropriate. Controls, policies, and procedures may not translate effectively to a cloud-based environment. There are tools (e.g., cloud access security broker) designed specifically to assist with the implementation of security controls in a cloud environment. 

95 Refer to the Information Security Standards:12 CFR 30, appendix B (OCC); 12 CFR 208, appendix D-2, and 12 CFR 225, appendix F (FRB); 12 CFR 364, appendix B (FDIC); and 12 CFR 748, appendix A (NCUA). 

Another risk consideration is the aspect of tenancy. Applications or services can exist in single or multi-tenant environments. Control requirements may vary by tenant, with some requiring a higher level of security than others. Misuse or abuse by one tenant could potentially weaken the security posture of other tenants. Inadvertent or deliberate failure of a security control could adversely affect other tenants in the same environment. For example, a DOS attack on the cloud service provider, or even a single tenant, could affect the other tenants. 

Third-party assurance reviews (e.g., SOC reviews, penetration tests, and vulnerability assessments) can provide an understanding of the cloud service provider’s control environment and its ability to meet an entity’s control expectations (e.g., compliance with applicable laws and regulations). Refer to the FFIEC’s joint statement96 for more information. 

## VII.A.5(a) Access Control Considerations 

“Access control dictates how subjects (i.e., users and processes) can access objects based on defined access control policies to protect sensitive data and critical computing objects in the cloud systems.”97 While cloud computing offers significant flexibility, security considerations can be complicated by the various service and delivery models and shared responsibilities. In general, access control considerations for IaaS are also applicable to PaaS and SaaS, and access control considerations for PaaS are also applicable to SaaS, although variations do exist. 

Challenges of access control system design are tied to the essential characteristics of cloud computing mentioned previously, plus risk from data sharing. These challenges and risk considerations include those applied to the following elements in cloud environments: 

* • Network
* • Hypervisor
* • VMs
* • APIs
* • Multi-tenancy
* • Attribute and role management
* • Data replication and destruction

When addressing these elements, additional considerations of access control in a cloud environment include: 

* • Cloud virtualization adds access control and security management concerns, as risk may be compounded by the volume of VMs created and changed in the cloud.
* • Access control lists for networks and network boundaries, hypervisors, VMs, and APIs to define and implement appropriate levels of access on different users.
* • Access control security and privacy offered by the PaaS provider to protect the applications and data from potential leaks, such as data in OS memory caches. 96 FFIEC, Security in a Cloud Computing Environment. 

97 Refer to NIST SP 800-210, General Access Control Guidance for Cloud Systems.
* • In SaaS, the provider should not have unnecessary or inappropriate access to SaaS systems or customer data residing on or accessible by them.
* • The design of access control should include multi-tenancy situations to ensure appropriate segregation of entity data from other clients’ applications.

For more information on access control and security in cloud environments, refer to NIST.98 Refer to the IT Handbook’s “Information Security” and “Outsourcing Technology Services” booklets for additional information. 

# VII.B Zero Trust Architecture 

According to NIST, ZTA is “an enterprise cybersecurity architecture that is based on zero trust principles and designed to prevent data breaches and limit internal lateral movement.”99 As an entity’s complexity increases, the entity may operate several internal networks, remote offices with their own local infrastructure, remote or mobile personnel, and cloud services. 100 Legacy methods of perimeter-based network security may no longer be appropriate in a more complex IT environment. If an entity’s perimeter-based and internal network security is not fully effective, a breach of the perimeter can allow unhindered lateral movement inside the network. These concerns have led to the development of a model for cybersecurity known as zero trust.101 

ZTA assumes all networks are untrusted, including internal networks. Within ZTA, implicit trust is not granted to systems and users based on their physical or network location (e.g., LANs or the internet). Access to data resources is granted only when the resource is required and authentication (for both users and devices) is performed before the connection is established. ZTA focuses on protecting resources, rather than network segments using authentication and authorization, while minimizing reliance on implicit trust zones. Additionally, it focuses on reducing delays caused by authentication methods that are not located within an entity-owned network boundary.102 

Designing for zero trust enables entities to securely accommodate the complexity of a diverse set of business cases by informing virtually all access decisions and interactions between systems.103 Management may consider adoption of zero trust principles in architecture decisions. ZTA principles include the following:104 

98 Ibid. 

99 NIST SP 800-207, Zero Trust Architecture. 100 Ibid. 

101 Ibid. 102 Ibid. 103 Ibid. 

104 Principles are derived from NIST SP 800-207, Zero Trust Architecture. 

* • All data sources and computing services are considered resources.
* • All communication is secured regardless of network location.
* • Access to individual entity resources is granted on a per-session basis and in a secure manner regardless of network location, user, or device.
* • Authentication and authorization for access to resources are determined by user and device analytics and behavioral attributes (e.g., network location, device characteristics, and access time or day) compared to deviations from baselined patterns.
* • Rigorous access controls (e.g., using least privilege and granular trust zones around an entity’s digital resources) are enforced. These controls include data-level protections, robust identity architecture, and strategic micro-segmentation.
* • Owned and associated devices are monitored to ensure that they remain in the most secure state possible. The entity continually inspects, monitors, and logs network traffic and uses the information to improve its security posture.
* • Evaluation of access requests and network traffic behaviors occurs in real time over the length of open connections while continually and consistently reassessing access to the entity’s resources.
# VII.C Microservices 

Microservices are a set of containers that work together to compose an application. Essentially, each microservice is an independent building block used for building an application, including the communications and authentication. Each microservice is a mini application loosely coupled105 to serve a singular function (e.g., database access or messaging) that can be integrated to collectively build an application. During the communication events of any pair of interactions (e.g., client-to-microservice, microservice-to-microservice, or microservice-to-egress service), each party has distinct identities and performs mutual authentication. 

Each microservice typically implements one (rarely more) distinct business process or functionality (e.g., storing customer details or displaying a product catalog). NIST 800-204A106 states that a microservice has two broad functions: 

* • Business logic, which implements the business functionalities, computations, and service composition or integration logic.
* • Network functions, which manage the inter-service communication mechanisms and are built on top of the underlying OS level network stack.

Microservices software is used in architecture designs where complex applications are composed of small, independent services that exchange data and procedural requests. Microservices-based application architectures provide inherent scalability, agility of deployment, and availability of tools to facilitate error-free configuration and deployment. Although a microservices-based application can be implemented purely as an enterprise application, it is generally identified as a cloud-native application that includes service-based architecture, API-driven communications, and container-based infrastructure.107 

105 NIST SP 800-204, Security Strategies for Microservices-based Application Systems, states, “For large applications, splitting the application into loosely coupled components enables independence between the developer teams assigned to each component. Each team can then optimize by choosing its own development platform, tools, language, middleware, and hardware based on their appropriateness for the component being developed.” 

106 Refer to NIST SP 800-204A, Building Secure Microservices-based Applications Using Service-Mesh Architecture. 

The implementation of microservices infrastructure differs from legacy distributed systems as there are multiple services configured to operate at designated locations (IP address and port number). When using microservices-based applications, the following are key elements108 to consider in the entity’s infrastructure: 

* • There are a substantial number of services and many instances associated with each service
* • The number of instances associated with a service can vary based on the load fluctuations
* • A feature to discover a service while making a service request. A common approach to
* • Each of the microservices may be implemented in VMs or as containers, which may be
* • Load balancing is needed for multiple instances of the same service where the loads on these
* • Microservices take advantage of a variety of features,111 including: with dynamically changing locations. using features such as autoscaling. implementing this feature is the use of a service registry.109 assigned dynamic IP addresses, especially when they are hosted in an IaaS or SaaS cloud service. instances should be evenly distributed to avoid delayed responses or service crashes due to overload.110
	+ o Circuit breakers.112
	+ o Rate limiting, or throttling.
	+ o Version control.
	+ o Canary releases. 113

The increasing adoption of microservices-based applications in cloud and large enterprise environments has prompted the identification of an infrastructure that provides a comprehensive, consistent, and coordinated set of support services.114 Service mesh and API gateways are examples of this infrastructure. In operations related to microservices, there are additional security considerations,115 including the following: 

107 Refer to NIST SP 800-204, Security Strategies for Microservices-based Application Systems. 

108 NIST discusses several key elements for consideration in NIST SP 800-204A, Building Secure Microservices- based Applications Using Service-Mesh Architecture. 

109 A service registry consists of a directory where new service instances created for the microservices-based application register themselves while service instances going offline are deleted from it. 

110 Refer to NIST SP 800-204A, Building Secure Microservices-based Applications Using Service-Mesh Architecture. 

111 Ibid. 

112 Using circuit breakers involves setting a threshold for the failed responses from an instance of a microservice and cutting off forwarding requests to that instance when the failure is above the threshold (e.g., when the circuit breaker trips). 

113 Canary releases serve as an early warning system for potential problems with the microservices. 

* • The sheer number of microservices results in more interconnections and more communication links to be protected, such as through the use of ingress and egress controllers.
* • The short-term and promiscuous (i.e., used by many different applications and platforms) nature of microservices calls for secure service discovery mechanisms to make sure they are registered correctly when created and removed when replaced with a new version.
* • The detailed level at which microservices are built should include the ability to support the entity’s security and authorization policies.
* • The supporting services (e.g., authentication, authorization, and security monitoring) for microservices-based applications should be coordinated through a dedicated infrastructure.
* • There is no concept of a network perimeter.
* • All microservices should be treated as non-trustworthy.

The detailed nature of microservices may prompt management to centrally define security policies and configurations to enable uniform, consistent implementation across all microservices. 

# VII.D Artificial Intelligence and Machine Learning 

AI refers to the theory and development of systems that perform tasks or functions normally associated with human intelligence, such as reasoning, learning, and self-improvement. ML is a subset of AI in which components of AI systems are used to design a sequence of actions, which could improve upon and optimize algorithms automatically through experience, to perform tasks with limited human intervention. 

AI algorithms can analyze large data sets quickly and identify complex patterns, which may be used to solve problems and generate predictions or categorizations. AI can allow management to personalize customer products and services and, in certain cases, analyze real-time data to help anticipate future customer behavior. AI can also augment decision-making by identifying patterns that a human may miss when analyzing data. The automation of recurring processes and decision making can result in operational and productivity efficiencies (e.g., time and personnel reduction) by reducing human intervention. 

Entities may use AI for several activities, including the following examples: 

* • Detection and prevention of fraud or misconduct (e.g., anti-money laundering, account compromise, and insider fraud) to reduce losses. 114 Refer to NIST SP 800-204A, Building Secure Microservices-based Applications Using Service-Mesh Architecture. 

115 Ibid.
* • Identification, notification, and mitigation of cybersecurity breaches.
* • Facilitation of automated trading (e.g., algorithmic trading).116
* • Automation and augmentation of loan origination process, including consumer credit scoring.
* • Risk management and business decision-making.
* • Strengthening security controls (e.g., logical and physical access anomaly analysis and use of facial recognition for authentication).
* • Compliance with applicable laws and regulations.

There are a number of risks related to the use of AI or ML. It relies on large amounts of available data, which, if breached, can result in misuse of data, fraud, financial loss, impact to an entity’s reputation, or harm to consumers. There is the potential for human errors of omission or commission in the development of algorithms that can lead to incorrect decisions. Also, there is the potential for bias (intentional or unintentional) in algorithm development and use if it is not tested and validated, as well as used appropriately. For additional information on testing and validation in development, refer to the IT Handbook’s “Development and Acquisition” booklet. 

AI can lack transparency, or explainability, meaning the processing approach is difficult to follow and it can be unclear how inputs are translated into outputs. This lack of explainability can limit the understanding of the approach and affect the confidence in the reliability of the results of AI. It can also result in unintended consequences (e.g., noncompliance with applicable regulations or exceeding the entity’s risk tolerance). 

Another potential risk with AI is the ability to evolve on its own. This provides the ability to modify existing (or introduce new) AI variables or features without human interaction. This is known as dynamic updating, which can present challenges to monitoring and independently reviewing AI. 

# VII.E Internet of Things 

IoT refers to the collection of technologies that allow information to be sent to and received from physical devices (e.g., security systems, HVAC systems, intelligent personal assistants, smart televisions, and other appliances), not considered previously to be IT assets, using the internet. These devices have the ability to send and receive data over a network without necessarily requiring human-to-human or human-to-computer interaction, using embedded computing capability and network connectivity and unique identifiers (e.g., IP address). IoT leverages cloud computing, mobile computing, big data, and other emerging technologies to deliver functionality. Data gathered through IoT can be used by the entity to aid in management’s decision-making through improved statistical models and algorithms. IoT is found in every sector, ranging from mobile payment systems on watches and phones to internet-connected medical devices and home security devices. 

116 In algorithmic trading, firms use computers programmed with specific algorithms—sequences of steps—to identify trading opportunities and execute orders. 

Because IoT includes computing devices connected to the internet and can execute code, there are a number of risks related to their use.117 

* • IoT devices interact with the physical world in ways conventional IT devices usually do not. IoT devices can make changes to physical systems; operational requirements for confidentiality, integrity, and availability of these devices, however, may be at odds with common cybersecurity and privacy practices for conventional IT devices. For example, security requirements for online and mobile payment channels often are more stringent than making purchases or payments using an intelligent personal assistant device.
* • Many IoT devices cannot be accessed, managed, or monitored in the same ways as conventional IT devices. For example, most IoT devices do not support standardized mechanisms for centralized management. Administrators may not be able to fully manage an IoT device’s firmware, OS, and applications. Unavailable features may include the ability to acquire, verify the integrity of, install, configure, store, retrieve, execute, terminate, remove, replace, update, and patch software. Some IoT devices lack application or human user interfaces for device use and management. When such interfaces do exist, they may not provide the functionality usually offered by conventional IT devices. In some cases, only manufacturers can perform maintenance, such as installing patches.
* • An IoT device’s software may be automatically reconfigured when an adverse event occurs, such as a power failure or a loss of network connectivity. For example, the security settings for an IoT device may all be reset to the default settings.
* • The entity may not know what capabilities an IoT device can provide or is currently providing. The device may transfer data to manufacturer-provided cloud-based service processing and storage. Data may be sent to a cloud service to aggregate data from multiple IoT devices in a single location. These cloud services may provide access to portions of or all the devices’ data, or even access to and control of the devices, for monitoring, maintenance, and troubleshooting purposes.
* • There may be little or no information available about device ownership. The lack of accountability limits individuals’ abilities to locate the source of and correct or delete information about themselves, or to address other problems (e.g., privacy).
* • Data may still be available on some IoT devices after disposing of or transferring ownership of a device.
* • IoT devices used in an entity may not be inventoried, registered, or otherwise provisioned via the normal IT processes. Previous iterations of those devices did not have networking capabilities (e.g., smart TVs that connect to an entity’s network to provide teleconferencing capabilities). IoT devices often use protocols that cybersecurity and privacy controls for conventional IT cannot understand and analyze; therefore, standard network scanning devices may not recognize IoT devices (including personally owned IoT devices).

IoT devices have a number of often-unknown capabilities; therefore, it is important to understand those capabilities, the related risks, and the data devices can access. As IoT devices are relatively easy to install, it is important to understand how many devices there are and where they are used and should be considered in an entity’s ITAM inventory process. 

117 These risks are derived from NIST IR 8228, Considerations for Managing Internet of Things (IoT) Cybersecurity and Privacy Risks. 

# APPENDIX A: EXAMINATION PROCEDURES 

## Examination Objectives 

These examination procedures (also known as the work program) are intended to assist examiners in determining the quality and effectiveness of the entity’s AIO functions and their related activities. Examiners are not limited118 by the examination procedures presented here and may choose to use only certain components of the work program based on the size, complexity, and nature of the entity’s business. Depending on the examination scope and objectives, examiners may sample processes related to a particular line of business or review the process at an enterprise level. 

Objective 1: Determine the appropriate scope and objectives for the examination. 

* 1. Review past reports for outstanding issues or previous problems. Consider the following: 
	+ a. Regulatory reports of examination.
	+ b. Internal and external audit reports.
	+ c. Reports by independent risk management.
	+ d. Independent assurance and security reports (e.g., penetration tests and vulnerability assessments) and internal reports that self-identify concerns related to AIO issues. e. Regulatory, audit, and SOC reports on the entity’s third-party service providers.
	+ f. The entity's overall risk assessment and profile.
* 2. Review management’s response to issues identified during or subsequent to the last examination. Consider the following: 
	+ a. Adequacy and timing of corrective action.
	+ b. Resolution of root causes rather than symptoms.
	+ c. Status of uncorrected issues.
	+ d. Retesting to validate corrective action.
* 3. Interview management and review responses to pre-examination information requests to identify changes to the entity’s technology related to new products and services that could affect the areas of review within AIO. Consider the following to identify changes: 
	+ a. Any significant changes in business strategy or activities that could affect the AIO environment (e.g., new lines of business or a decision to move from in-house to a cloud service provider).
	+ b. Products or services delivered to either internal or external users.
	+ c. Network diagrams, including configuration or component changes and the entity’s internal and external connections. d. Hardware, software, and telecommunications inventories. 
	
	118 Examiners may use system- or technology-specific technical references from authoritative sources, as appropriate. 
	
	
		- e. Loss of, addition to, or change in duties of key personnel, as well as any key management changes.
		- f. Lists of third-party service providers and software vendors and the services or software provided.
		- g. Changes to internal business processes.
		- h. Changes based on industry changes or threat intelligence.Objective 2: Management promotes and provides effective governance of AIO functions through defined responsibilities, accountability, and adequate resources to support these functions. (II, “Architecture, Infrastructure, and Operations Governance”) 
	
	
		- 1. Determine whether management implemented a process to continuously manage technology to support operational needs and mitigate AIO-related risks. Determine whether the entity’s risk management processes include the following governance mechanisms: 
			* a. Delineation of board and senior management responsibilities.
			* b. Strategic planning.
			* c. ERM.
			* d. Delineation of other roles and responsibilities. e. Policies, standards, and procedures.
			* f. Internal audit, independent reviews, and certifications.
			* g. Communications.
			* h. Board and senior management reporting.
		- 2. Determine whether oversight includes the following: 
			* a. Board and senior management consideration of the entity’s business objectives, including functions performed by affiliates and third-party service providers.
			* b. Management identification and evaluation of AIO-related risks, definition of short- and long-term objectives, and creation of policies and procedures to mitigate those risks.
			* c. Management consideration of security and resilience in the design of new products and services.
		- 3. Determine whether board oversight includes the following: 
			* a. Aligning AIO principles and practices with the board’s strategic plans and risk appetite.
			* b. Budgeting appropriate resources to support AIO activities.
			* c. Ensuring board members have appropriate knowledge of risks to provide a credible challenge to management.
			* d. Enabling appropriate management training on AIO to carry out its responsibilities and manage risk.
			* e. Reviewing AIO operating results and performance (e.g., audit reporting, testing results, and management and assessment reports).
		- 4. Determine whether management oversight includes the following: 
			* a. Validating through audits and other independent assessments that the following are comprehensive, meet enterprise-wide business and strategic plan objectives, and can assist in the identification of AIO-related risk. 
				+ • Architectural designs and integration across the entity.
				+ • Infrastructure testing.
				+ • Operational testing.
			* b. Addressing risks self-identified by management, from AIO-related audits, and from other independent assessments.
			* c. Assessing and updating management’s strategies and plans for AIO functions.
			* d. Promoting alignment and integration between functions of AIO.
		- 5. Determine whether the board and senior management evaluate whether the IT strategic plan aligns with the enterprise-wide business and strategic plan, as well as established priorities and whether the planning addresses the following: 
			* a. Participation of senior management by supporting AIO activities, confirming that those activities are in the IT strategic plan, reviewing the strategic planning process, and incorporating changes.
			* b. Responsibilities within the AIO functions through defining those responsibilities and determining the effectiveness of the IT strategic planning process.
			* c. Evaluation of architecture, including the entity’s current architecture and whether it meets enterprise-wide business and strategic plan objectives.
			* d. Impact of IT infrastructure by understanding the relationship between IT infrastructure and the entity’s needs.
			* e. Post-implementation evaluation of the performance and results of IT projects and initiatives to determine whether each project achieved the anticipated goals.
		- 6. As part of the evaluation of question 5, determine whether management does the following: 
			* a. Evaluates whether past and current IT performance demonstrates an ability to support IT strategic plans.
			* b. Takes steps to ensure and validate that IT services are delivered on time, within budget, and to business specifications.
			* c. Balances resource investments.
		- 7. If an entity provides IT services internally or externally as a third-party service provider, determine whether management considers the following in the IT strategic planning process: 
			* a. IT services strategy management that helps management to meet the needs of the entity while also providing for availability, capacity, continuity, and security.
			* b. Financial management for IT services to allocate the cost of providing services.
			* c. SPM that enables the entity to balance investment in AIO with the ability to meet business outcomes.
			* d. Demand management, which balances customer demand for services with the capacity to meet that demand.
		- 8. This examination procedure may be coordinated with related examination procedures in the “Management” booklet. Determine whether the entity’s ERM structure incorporates the functions of AIO. Evaluate whether, as part of ERM, there is the following: 
			* a. Consistent and current review of the entity’s products, processes, applications, infrastructure, interconnectivity, and other related risks to business operations.
			* b. An effective risk management process for initiating and overseeing all AIO-related activities, including those that are outsourced, that includes: 
				+ • Initial assessment of the AIO-related risk.
				+ • Architecture designed to meet the entity’s goals or objectives.
				+ • Infrastructure that supports the entity’s strategic objectives.
				+ • Identification of infrastructure assets (e.g., hardware and software) and associated interconnectivity critical to business and IT operations.
				+ • Ongoing monitoring that identifies and evaluates changes in risk and periodic updates to the risk profile assessment.
				+ • Roles, responsibilities, procedures, and reporting mechanisms for risk management in AIO activities.
				+ • Risk tolerances and risk and performance metrics for AIO activities.
		- 9. Determine whether management assigned responsibilities for the AIO functions based on the complexity of the architecture needs and assess the effectiveness of the entity’s separation of duties across the functions, particularly in situations where architecture responsibilities are combined with other functions. Evaluate the effectiveness of the assignment of the following responsibilities: 
			* a. Architecture-related responsibilities: 
				+ • Review of the centralization processes for the IT functions and understanding of interrelationships between the entity’s IT and business functions.
				+ • Development and maintenance of the enterprise model, including a common understanding, vocabulary, and blueprint for all stakeholders.
				+ • Responsibility for designing the IT architecture and accommodating IT changes.
				+ • Communication of challenges to the board and senior management.
				+ • Maintenance of representations (e.g., blueprints, network diagrams, and topologies) of the IT environment, review of existing infrastructure and operations to determine IT systems capabilities and needs.
				+ • Working with other members of management to evaluate architectural changes.
				+ • Maintenance and use of IT architecture knowledge.
				+ • Development of IT architecture policy and terminology.
				+ • Oversight of IT architecture product development, use, and refinement.
				+ • Maintenance and ownership of the IT architecture repository.
			* b. Data-related responsibilities: 
				+ • Governance and use of information or data, protection of that data, and derivation of maximum value from it.
				+ • Development of data-related policies, management of the data life cycle and the entity’s data assets, oversight of compliance with applicable laws and regulations, and conformance with industry practices.
				+ • Provision of input to the chief architect in the design of IT systems to promote alignment with enterprise-wide business and strategic plan objectives.
				+ • Oversight of data management and data analysis and management of data-related projects.
				+ • Analysis of whether the entity’s products and services meet enterprise-wide business and strategic plan objectives from a data perspective.
				+ • Use of data and reporting tools, maintenance of data quality, and promotion of data integrity.
				+ • Ownership of the entity’s strategic use of data and communication of information and data analytics.
				+ • Definition of a data strategy, evaluation of data and its usage (including the consideration of data planning and the analytics platform), and development of metrics for monitoring data activities.
			* c. Operations-related responsibilities: 
				+ • Oversight of the IT environment.
				+ • Management of the capacity, performance, and availability of the components used in an entity’s infrastructure.
				+ • Support for line-of-business and functional operations.
				+ • Day-to-day operation and maintenance of infrastructure components.
				+ • Management of network infrastructure (e.g., network and connectivity, remote access, and telecommunications management) and server and device management (e.g., servers, storage, and devices).
				+ • Management of the IT environment (e.g., facilities, help desk, IAM, backup and replication, configuration management, resilience, and cyber and information security).
				+ • IT project management.
				+ • Database administration, systems analysis, client support, systems administration, and network administration.
		- 10. Determine whether management documents, implements, and maintains policies, standards, and procedures related to AIO that address the following: 
			* a. Scope.
			* b. Responsibilities.
			* c. Accountability.
			* d. Authority.
			* e. Guidance to develop and maintain effective processes related to AIO.
		- 11. Determine whether the board and senior management engage qualified audit or use other independent review functions to assess the AIO design, implementation, and operational effectiveness, including the adequacy of policies and procedures and the effectiveness of controls. Evaluate the appropriateness of the following: 
			* a. Review of the entity’s AIO functions and activities and management’s ability to oversee and control AIO-related risks.b. Qualifications, training, and experience of auditor (or independent reviewer) in reviewing the functions and activities of AIO. 
		
		
			* c. Independence of auditor from the AIO functions and activities being reviewed.
			* d. Reports to the board and senior management containing the results of audits or other independent reviews and an assessment of management’s ability to oversee the entity’s AIO functions and activities. Validate whether the review scope and frequency are appropriate for the complexity of the entity’s AIO functions.
			* e. Whether auditors or reviewers: 
				+ • Evaluate that management’s AIO decisions align with the entity’s business strategy, security, and resilience needs.
				+ • Leverage SOC and other external audit reports from third-party service providers.
				+ • Identify and report AIO issues to senior management and the board.
		- 12. Determine whether management effectively communicates relevant AIO information to the entity’s staff, applicable customers, and third parties.
		- 13. Determine the effectiveness and comprehensiveness of board and senior management reporting related to AIO. Evaluate whether the following activities are performed: 
			* a. Management reports to the board periodically on the status of AIO initiatives, progress, issues, and metrics.
			* b. The board regularly monitors strategy, security, and resilience activities.
			* c. Board minutes reflect significant AIO-related discussions, credible challenge, and approvals.
			* d. Management measures performance and risks against defined baseline metrics.The next 10 objectives (3–12) are related to section III, “Common AIO Risk Management Topics.” Each of these topics has its respective examination objective because there are risks from each area that affect the functions of AIO.Objective 3: Management understands the common risks and mitigating controls related to data governance and data management. (III.A, “Data Governance and Data Management”) 
	
	
		- 1. Determine whether management governs and manages data based on the entity-assigned data classification.
		- 2. Evaluate whether management has an effective process for data removal or destruction when data are no longer used.
		- 3. Evaluate whether business line management is consulted to assist in data classification, recovery standards development, and appropriate control validation.
		- 4. Determine whether management has data governance and data management processes that include defining responsibility and processes for governing data, including the identification, management, and oversight of any metadata, and promoting a culture that takes a data-centric approach.
		- 5. Determine whether management identifies and classifies the entity’s data effectively. Determine whether management does the following: 
			* a. Identifies and understands the nature of the entity’s data, including: 
				+ • Sensitivity, criticality, and importance of the data.
				+ • Frequency, recurrence, and use of the data.
				+ • Format in which data are maintained.
			* b. Uses the results of the data classification process to implement controls to safeguard data, including sensitive data.
			* c. Understands where data reside and maintains the effectiveness of controls over that data.
			* d. Regularly updates the information and technology asset inventories for new assets, both internal assets and those residing at third-party service provider locations.
		- 6. Determine whether management has effective database management, including the following: 
			* a. Securely designs, builds, and operates databases.
			* b. Implements a process to secure and oversee databases.
			* c. Ascertains the effectiveness of database controls and updates the information asset and technology inventories.
			* d. Ensures databases are appropriately located and structured, have sufficient capacity, and are resilient.
			* e. Regularly monitors for new or changed databases and reports on misconfigured or out-of- compliance databases.
			* f. Understands how databases interconnect throughout the entity.
			* g. Focuses on identifying, managing, and securing the data; identifying business uses; and providing appropriate access regardless of how the data are stored.
			* h. Has appropriate staff (e.g., DBAs) that 
				+ • Is responsible for database configuration, access controls, and maintenance, as well as training.
				+ • Monitors databases and maintains normal operations.
				+ • Works with information security staff.
				+ • Monitors for anomalous database activities.
				+ • Is familiar with procedures to protect sensitive information, restores normal operations, and notifies the information security officer when necessary.
			* i. Limits and independently monitors accounts belonging to DBAs.
		- 7. Verify that management implemented effective database security controls, such as the following: 
			* a. Changes passwords for default user accounts and, subsequently, disables or deletes those accounts where possible.
			* b. Tracks and monitors activity for default accounts that cannot be disabled or deleted.
			* c. Restricts account access and limits privileges and permissions.
			* d. Implements password management tools or activities.
			* e. Employs an appropriate level of encryption according to the entity’s data classification policy.
			* f. Configures and reviews audit logs.
			* g. Regularly monitors database activity logs.
			* h. Independently monitors DBA and privileged account activities.
			* i. Classifies data maintained within the database.
			* j. Restricts and monitors data extraction.
			* k. Implements and adheres to patch management processes.
			* l. Implements OS controls.
			* m. Monitors OS-level privileged account activities.
			* n. Manages application-level access.
		- 8. Determine whether management considers design, placement, and effective security controls for non-production environments (e.g., development, test, and quality assurance). Consider the following: 
			* a. Independence of non-production environments from production environments to maintain data integrity and resilience.
			* b. Use of simulated synthetic data in non-production environments, when possible.
			* c. Controls to prevent testing in production environments to maintain confidentiality, integrity, and availability of data.
			* d. Use of masked or sanitized test data in non-production environments when production is used; if this is not feasible, approvals to use non-sanitized data with implementation of the same level of controls in non-production environments as in production environments.
		- 9. Determine whether management appropriately considers the uses and risks of data analytics and performs the following: 
			* a. Limits access to analytics tools and related outputs.
			* b. Incorporates confidentiality, integrity, and availability when designing or selecting analytics tools.
			* c. Inventories the data sources, assesses the information type according to the entity’s data classification policy, and appropriately secures those sources.
			* d. Develops design requirements and parameters for analytics.
			* e. Obtains sufficient knowledge for management and personnel to interpret dashboards and reports.
			* f. Considers the following when implementing and using data analytics: 
				+ • Documentation of the data types maintained, data owners and users, and purposes of reports.
				+ • Determination of stakeholders’ usage needs.
				+ • Determination of potential opt-in considerations, based on information type, in analytics reports.
				+ • Determination of disclosure requirements in the event of an incident.
				+ • Implementation of access controls and activity monitoring over analytics tools and reports.
				+ • Definition of processes to remove or destroy data when no longer used in the data analytics tools.
				+ • Identification of data subject to applicable laws and regulations or other relevant industry standards.
				+ • Identification of data analytics processes used to enable compliance with applicable laws and regulations.
				+ • This examination procedure may be coordinated with related examination procedures in the “Information Security” booklet. If the entity uses big data, implementation of appropriate security policies, standards, and procedures, along with data access and security controls in accordance with the entity’s data classification policy.Objective 4: Management implements appropriate ITAM processes to track, manage, and report on the entity’s information and technology assets. (III.B, “IT Asset Management”) 
	
	The examination procedures in this objective may be coordinated with related examination procedures in the “Information Security” booklet. 
	
	
		- 1. Determine whether management has a comprehensive inventory of its electronic (or digital) and physical information assets, in accordance with the Information Security Standards. Evaluate whether management specifically identifies its information assets, determines the appropriate classification of those assets, and protects them according to the entity’s data classification process.
		- 2. Determine whether management implemented policies, standards, and procedures to govern all aspects of ITAM, including information and technology assets. Assess whether those processes include the following: 
			* a. Identifying the technology assets the entity possesses and manages.
			* b. Determining each asset’s status (e.g., active or inactive).
			* c. Specifying the life cycle phase of those assets.
			* d. Regularly reviewing and validating the accuracy of the inventories.
			* e. Identifying personally owned technology assets that are allowed to connect to the entity’s network.
		- 3. Determine whether management uses appropriate inventory mechanisms to effectively document, track, and oversee the entity’s information and technology assets, including its hardware and software. As part of the technology asset inventory, determine whether management considers IT assets that do not fall into traditional hardware or software inventories. Evaluate whether management has a process to periodically review and update the inventories. Assess the adequacy of management’s technology asset inventory process for the following: 
			* a. Hardware inventory process that does the following: 
				+ • Identifies the entity’s hardware assets.
				+ • Identifies equipment owned and managed by third parties on the entity’s behalf.
				+ • Includes entity-owned and entity-managed virtual infrastructures.
				+ • Assigns a unique identifier for hardware assets.
				+ • Contains information about the network and telecommunications equipment.
				+ • Contains appropriate information on each piece of hardware.
			* b. Software inventory process that does the following: 
				+ • Provides detailed information on software used in the entity’s IT environment.
				+ • Contains appropriate information on the entity’s software.
		- 4. Assess whether each IT asset is captured in the entity’s ITAM inventory, tracked throughout its operational life, and prepared for physical removal at the end of its useful life. Determine whether management implemented policies, standards, and procedures to identify assets and their EOL time frames, to track assets’ EOLs, and to replace or upgrade the asset. Determine the effectiveness of EOL management through the following: 
			* a. Addresses EOL in contract provisions with its third-party service providers.
			* b. Adds assets to the inventories and tracks changes made to assets.
			* c. Conducts risk assessments to determine assets’ EOLs.
			* d. Reviews EOL time frames for existing assets to determine accuracy and relevance.
			* e. Develops replacement plans for assets nearing obsolescence.
			* f. Establishes procedures for the secure destruction or data wiping of hardware and software.
			* g. Considers the following when reviewing new technology assets: 
				+ • Incorporates EOL considerations in strategic planning.
				+ • Plans for obsolescence during initial project stages (e.g., during requests for proposals or proofs of concept).
				+ • Registers and tracks assets in the inventories and includes EOL information.
				+ • Develops plans for maintaining IT assets beyond EOL, if necessary.
		- 5. Determine whether management understands and communicates the risks of shadow IT to entity personnel. Additionally, determine whether internal audit evaluates management’s processes to monitor, identify, and remove unapproved devices, software, or services. Assess whether management performs the following: 
			* a. Establishes IT governance practices and security controls for shadow IT, including policies, standards, and procedures.
			* b. Includes shadow IT in security awareness training.
			* c. Considers the use of IT detection tools to monitor for and identify shadow IT.
			* d. Employs appropriate data protection and data loss prevention tools.
			* e. Considers appropriate methods to address shadow IT, including: 
				+ • Identifying security risks associated with shadow IT in use and determining whether there is malicious intent.
				+ • Identifying the reason for its use.
				+ • Determining clients or processes supported by shadow IT.
				+ • Verifying interconnectivity between shadow IT and third-party service providers or existing software integration.
				+ • Determining appropriate disposition of shadow IT.
				+ • Reviewing policies, processes, and tools to understand any gaps that may allow shadow IT to occur.
			* f. Has processes to monitor, identify, and remove shadow IT that can be evaluated by internal audit.Objective 5: Management understands the documentation maintained to represent the entity’s IT and business environment. (III.C, “IT and Business Environment Representations”) 
	
	
		- 1. Determine whether management documents and maintains accurate representations (e.g., network diagrams, data flow diagrams, business process flow diagrams, and business process narratives) of the current IT and business environments and employs processes to update the representations.
		- 2. With the representations, assess whether management does the following: 
			* a. Coordinates the development of representations among stakeholders.
			* b. Aligns diagrams and narratives with each other and across the entity’s lines of business.
			* c. Periodically reviews documented diagrams and narratives to confirm the accuracy of the representations of the IT and business environment.
			* d. Provides for the resilience of this documentation by maintaining current and accurate backups.
			* e. Implements appropriate access and editing privileges to the representations.Objective 6: Management fosters effective management of change across the AIO functions. (III.D, “Managing Change in AIO”) 
	
	The examination procedures in this objective may be coordinated with related examination procedures in the “Development and Acquisition” booklet. 
	
	
		- 1. Determine whether the IT environment and its products and services, whether internally or externally provided, are adaptable to change, and stakeholders from across the entity have input into the change process.
		- 2. Depending on the complexity of the change, determine the adequacy of the processes to manage the change. Verify that changes to any IT system or service are supported by an orderly, adaptable, documented, and measurable process. 
			* a. If the entity implements more complex types of changes (e.g., core conversions, migrations to cloud-based environments, or implementing a system to support a new product), assess whether formal planning and management oversight processes are in place and adequate.
			* b. If the entity implements less complex, but planned changes (e.g., implementation of patches), assess the appropriateness of the change process.
		- 3. Determine whether the entity’s policies, standards, and procedures address change management, including each step of the change process. Assess whether the process includes the following: 
			* a. Categorization of changes by severity.
			* b. Specification of corresponding approval processes.
			* c. Identification of responsible staff, applicable stakeholder working groups, or entity committees.
			* d. Preservation of the IT environment’s confidentiality, integrity, and availability.
			* e. Identification of metrics to track the efficiency and success of the change.
			* f. Implementation of changes with the goal of preserving confidentiality, integrity, and availability.
			* g. Incorporation of appropriate segregation of duties and monitoring throughout the change management process.
		- 4. Review and evaluate the entity’s change management process to implement changes that preserve systems’ security and are based on the change type (e.g., planned, routine, and emergency). Determine whether management follows pre-defined processes, such as the following: 
			* a. Request that includes the reasons for the change and details of the change.
			* b. Review of requests to determine viability, business practicality, and prioritization.
			* c. Approval through the appropriate documented hierarchy commensurate with the scope, cost, urgency, and overall risk.
			* d. Design and build, including formal processes to preserve integrity throughout the development life cycle and ensure adequate controls.e. Testing, which documents that the change performs as intended, identifies flaws, and verifies that the change integrates with other systems. 
		
		
			* f. Implementation that includes a formal process to deploy the change.
			* g. Verification and closure, including a post-implementation review and processes to document the change’s closure.
		- 5. When reviewing change management, evaluate the following transition processes: 
			* a. Management implements a process to transition system changes from a strategic change management process to day-to-day operations.
			* b. Knowledge is adequately transferred to personnel who will be responsible for operating the systems and processes.
			* c. Change management processes allow for the transition of responsibilities and knowledge and are part of the overall system development life cycle.Objective 7: Management maintains effective oversight of the entity’s third-party service providers responsible for activities related to AIO functions. (III.E, “Oversight of Third-Party Service Providers”) 
	
	
		- 1. Determine whether management identifies internal and external roles and responsibilities for AIO activities and implements processes to oversee those activities performed by third-party service providers. Assess whether management appropriately assigned and defined the responsibility and oversight of those activities.
		- 2. Verify whether management identifies and addresses all risks according to contracts and other agreements (e.g., SLAs).
		- 3. With respect to data destruction processes at the third-party service provider, determine the following: 
			* a. Management is aware of the data destruction processes maintained by the entity’s third- party services providers, including cloud service providers.
			* b. SLAs outline adequate third-party service providers’ data destruction measures.
		- 4. Determine whether management reviews independent audit or other assurance reports demonstrating the third-party service provider’s ability to meet the entity’s AIO needs.
		- 5. Verify that management reports to the board on the effectiveness of any AIO activities performed by third-party service providers. Assess whether the reporting included any issues uncovered through the entity’s third-party risk management processes.Objective 8: Management adequately considers and implements resilience as part of the entity’s risk mitigation strategy for AIO. (III.F, “Resilience”) 
	
	
		- 1. Evaluate whether management integrates the entity’s AIO functions into the entity’s BCM program to mitigate threats, respond to and recover from disruptions, and incorporate lessons learned to strengthen the entity’s resilience.
		- 2. Determine whether management designs, implements, and operates its IT systems and processes to provide resilience for critical business activities. Assess whether management does the following: 
			* a. Determines its reliance on people, processes, and technology, including third-party service providers, to assist in its assessment of risk.
			* b. Ensures the entity’s business strategy and reliance on business functions drive the design for the entity’s resilience.
			* c. Designs systems and software with resilience and information and cybersecurity at the beginning of the architecture process.
			* d. Uses infrastructure that supports varying levels of resilience depending on the criticality of the systems and software to ongoing business operations.
			* e. Implements infrastructure to allow for secure remote administration and maintenance, for situations where personnel are unable to perform operations on site.
			* f. Addresses resilience in operations to prevent data loss, protect sensitive customer information from unauthorized disclosure or manipulation, minimize disruption to service delivery, and prevent the loss of situational awareness of the entity’s operations. Evaluate whether this operational resilience includes having: 
				+ • Operational controls.
				+ • Operational processes (e.g., vulnerability and patch management).
				+ • Service delivery and support processes (e.g., resilience in supply chain).
				+ • Ongoing monitoring and evaluation capabilities (e.g., monitoring for indicators of an APT).
			* g. Avoids making assumptions on the resilience of the entity’s systems simply because they are operating in the cloud.
			* h. Identifies assets, applications, and services located in the cloud, if operating in the cloud.
			* i. Verifies that resilience is covered in contracts with cloud service providers.Objective 9: Management has appropriate AIO processes for managing remote access. (III.G, “Remote Access”) 
	
	
		- 1. Evaluate whether management considers the implications of remote access in AIO and does the following: 
			* a. Designs for remote access capabilities, including: 
				+ • Plans for the methods and access points to maintain security and control access to entity resources.
				+ • Considers appropriate methods (e.g., tunneling, web portals, direct application access, and remote desktop access).
				+ • Considers protection of communications and security needs (e.g., encryption, authentication, access restrictions, application security, and activity monitoring).
			* b. Uses remote access technologies that can be protected.
			* c. Employs effective risk mitigation for remote access, including: 
				+ • Remote access policy that includes tiered levels of remote access and risk-based security controls.
				+ • IAM based on job type and access and appropriate authentication techniques.
				+ • Encryption technologies to protect communications.
				+ • Securely configured and patched remote access servers.
				+ • Secure entity-owned telework client devices.
				+ • Controls on the use of personally owned devices used to remotely access entity resources.Objective 10: Management incorporates AIO considerations into the decision to use and use of personally owned devices. (III.H, “Personally Owned Devices”) 
	
	
		- 1. Determine whether management adequately considered AIO in the decision to allow the use of personally owned devices. Specifically, evaluate the effectiveness of the following: 
			* a. Due diligence to determine types of devices that can be used.
			* b. Consideration of the architecture of the entity’s IT systems, such as where and how the devices will access the bank’s network.
			* c. Determination of additional infrastructure needed to support the secure use of personally owned devices.
			* d. Controls needed to adequately safeguard the network.
			* e. Use of technical policy enforcement to manage or restrict devices used.Objective 11: Management incorporates AIO considerations into the design, implementation, and use of file exchange. (III.I, “File Exchange”) 
	
	
		- 1. Determine whether management considers risks related to exchange files and implements effective mitigation, such as the following: 
			* a. Identification of user needs for exchanging files, both internally and externally.
			* b. Design of client server architecture to provide for confidentiality, integrity, availability, and resilience.
			* c. Identification of the infrastructure, including the appropriate systems and software, necessary to support file exchange activities.
			* d. Inclusion of appropriate infrastructure to support monitoring of the entity’s file exchange activities.
			* e. Implementation of appropriate operational controls, such as: 
				+ • Monitoring for authorized file exchange.
				+ • Use of detection controls.
				+ • Use of only a trusted provider for third-party file exchange and storage solutions.
				+ • Consideration of solutions that provide visibility into cloud applications.
				+ • Definition of appropriate policies, standards, and procedures for file exchange activities.
				+ • Provision of training to employees on approved solutions.Objective 12: Management designs, applies, and aligns its IT architecture to meet the strategic and business objectives of the enterprise. (IV, “Architecture”) 
	
	
		- 1. Determine whether management established enterprise-wide architecture principles that balance the mitigation of risks to various stakeholders and align with the entity’s strategic goals and business objectives; meet the entity’s needs for confidentiality, integrity, and availability; and adhere to the entity’s policies, standards, and procedures. Determine whether the architecture design involves the following: 
			* a. Consideration of the entity’s architecture requirements for its existing technology and any planned changes.
			* b. Understanding by business units of their portion of the design.
			* c. Alignment with management’s defined mission and any strategic initiatives for architecture.
			* d. Identification of the entity’s IT assets, external constraints, industry IT architecture trends, and the entity’s needs for the desired future state.
		- 2. Determine whether management has policies, standards, and procedures to govern the entity’s architecture design process and whether the design process addresses the following: 
			* a. Definition of responsibilities and decision-making.
			* b. Identification of functional requirements.
			* c. Assessment of alignment with the entity’s IT and strategic plans.
			* d. Evaluation of the inventory of current IT assets and the purpose of those assets.
			* e. Performance of a cost-benefit analysis of the architecture plan or project.
			* f. Acquisition of approvals for the initiative.
			* g. Implementation and maintenance of the architecture.
			* h. Resolution of disputes or architectural issues.
		- 3. Evaluate the adequacy of the entity’s documented and approved architecture plan. Consider whether management considers the following in relationship to the plan: 
			* a. Alignment with the entity’s strategic plan and support for the business and strategic objectives of the entity.
			* b. Development of policies, standards, and procedures to govern architecture initiatives and changes to the architecture plan.
			* c. Inclusion of processes for obtaining approvals, making changes to the plan, and reporting, as appropriate.
			* d. Alignment of the formality of the architecture plan and processes with number and complexity of the architecture initiatives.
			* e. For larger or more complex architecture changes, maintenance of a project management process that includes the following: 
				+ • Planning.
				+ • Execution.
				+ • Closeout.
		- 4. With respect to design objectives, determine whether management does the following: 
			* a. Uses defined terminology.
			* b. Evaluates its needs and considers: 
				+ • Collaboration between IT and business units.
				+ • Prioritization of investments.
				+ • Comparison of existing architecture with anticipated future changes.
				+ • Establishment of processes to evaluate and procure technology.
				+ • Storage, backup, and capacity needs to accommodate the entity’s strategic plans.
				+ • Type of applications the architecture will support.
			* c. Includes the following aspects in its architecture design: 
				+ • Performance and reliability.
				+ • Integrity.
				+ • Availability and resilience.
				+ • Scalability.
				+ • Flexibility.
				+ • Security and privacy.
				+ • Interoperability and integration.
				+ • Ability to integrate and align with one or more third-party service providers.
				+ • Testing internally and with third-party service providers, as appropriate.
				+ • Auditability.
				+ • Advancements in technology.
			* d. Includes considerations for avoiding the potential for shadow IT and the capability to monitor and alert for its use.
			* e. Considers how evolving technologies (e.g., cloud, IoT, and AI/ML) can affect its design.
			* f. Plans for obsolescence, EOL, and decommissioning of systems.
		- 5. Evaluate whether management has a process to determine appropriate deployment environments (e.g., in-house or serviced, virtualization and cloud, or hybrid) as part of the design process. Determine whether the process includes the following considerations: 
			* a. Identification of risks and benefits of each type of deployment environment.
			* b. Use of physical versus virtual components in the design.
			* c. Type of virtualization solution and design risks associated with the following elements: 
				+ • VMs and the design of secure virtual infrastructures to provide the ability to oversee the interconnectivity and segmentation of VMs.
				+ • Hypervisors and the design of where the hypervisors sit and the connectivity between hypervisors and VMs.
				+ • Containers, including the design for storing data outside of the container and implementation of vulnerability management processes, segmentation, and the ability to monitor containers.
				+ • Microservices, including a design process that allows for the use of microservices as an integrated component to overall IT operations and the ability to address the risks of security, reliability, and latency in the entity’s development process.
			* d. Placement and selection of storage, design of network topology, availability of bandwidth, and need for management reporting systems, as well as implementation of monitoring tools.
		- 6. In larger or more complex entities, determine whether management considered using EA to align its architecture with the entity’s strategic plans and business functions. Describe management’s implementation of EA and use of architecture frameworks, if appropriate. Regardless of entity size, determine whether management incorporated the following: 
			* a. Evaluation of approaches to implement and build security and resilience throughout its architecture.
			* b. Analysis of the functionality, including security and resilience, of legacy systems and identification of gaps.
			* c. Identification of necessary roles to support the EA function.Objective 13: Management implements an IT infrastructure that achieves and promotes the objectives of confidentiality, integrity, and availability, and meets the entity’s business objectives. (V, “Infrastructure”) 
		
		
			* 1. Determine whether the entity’s IT infrastructure implementation includes considerations for server and data redundancy and resilience of telecommunications lines.
			* 2. This examination procedure may be performed in coordination with the examination procedures in Objective 4 (ITAM). Determine whether management has effective processes related to ITAM to track and monitor all hardware assets (whether or not they are connected to the network) to maintain an accurate and current record of the technology assets in its environment. As part of these processes, determine whether management does the following: 
				+ a. Identifies unauthorized technology assets and determines their disposition.
				+ b. Evaluates how unauthorized devices gained access and whether any compromise occurred.
				+ c. Updates the related policy or procedures or provides additional training.
			* 3. This examination procedure may be performed in coordination with the examination procedures in Objective 4 (ITAM). Determine whether management documents and maintains a current inventory of network and telecommunications hardware and software and the standard network configuration for them. Additionally, determine whether management does the following: 
				+ a. Implements appropriate redundancy capabilities for the entity’s telecommunications infrastructure.
				+ b. Understands the limitations of the entity’s third-party telecommunications providers’ infrastructure.
				+ c. Documents the network’s baseline configuration, including processes to review and approve changes.
				+ d. Regularly assesses and documents compliance with the entity’s baseline configuration.
				+ e. Appropriately controls networked devices by managing ports, protocols, and services and maps them to the devices on the technology asset inventory.
				+ f. Installs the latest version of security-related updates on network devices, when appropriate.
				+ g. Maintains standard images of the entity’s servers and stores them securely. Uses clean (i.e., trusted) images to restore the server if a server needs to be rebuilt and documents, reviews, and approves deviations from the standard image.
				+ h. Implements security and monitoring throughout the entity’s network, analyzes incoming and outgoing data traffic, and alerts authorized personnel if anomalous activity is detected. Additionally, determine whether the following security and monitoring mitigation strategies are in place: 
					- • Use of software tools to protect against and monitor internet-accessible services or open ports.
					- • Implementation of firewalls and port filtering.
					- • Deployment of IDS/IPS.
					- • Use of internal tools to detect, identify, and prevent misuse by entity personnel.
				+ i. Performs administrative activities from dedicated workstations.
				+ j. Uses multi-factor authentication over encrypted network connections for administrators accessing and managing network devices.
				+ k. Monitors telecommunications traffic and periodically reviews network devices.
				+ l. Appropriately controls telecommunications equipment, including: 
					- • Physically securing it and restricting and monitoring access to it.
					- • Following enterprise change control standards.
					- • Following entity policies, standards, and procedures for identification, authorization, and authentication to access telecommunications systems.
				+ m. Designs and builds telecommunications infrastructure components for resilience (e.g., implement route diversity), including selecting infrastructure components and telecommunications providers that help avoid a single point of failure.
				+ n. Addresses voice communications risks through development and acquisition processes, and in written policies, standards, and procedures. If the entity uses VoIP for voice communications, determine whether management performs a comprehensive risk assessment to ensure confidentiality, integrity, and availability in voice communications.
				+ o. Implements physical and logical controls in the VoIP environment, evaluates options for backup systems, and considers control solutions specific to VoIP, such as VoIP-ready firewalls.
				+ p. Monitors incoming and internal data communications traffic for problems.
				+ q. Implements redundant telecommunications services and establishes work-around procedures for situations where needed.
			* 4. Evaluate whether management determines the types of software needed to implement the entity’s strategic objectives and considers the software’s scalability, interoperability, and portability. As part of its software infrastructure planning, determine whether management performs the following: 
				+ a. Tracks and monitors the entity’s software assets.
				+ b. Maintains an accurate and current record of its software assets (e.g., with a software inventory).
				+ c. Periodically reviews existing software.
			* 5. This examination procedure may be performed in coordination with related examination procedures in the “Development and Acquisition” booklet. Determine whether management appropriately chooses software (e.g., to meet the entity’s infrastructure and operational requirements) and considers whether to develop software internally or obtain it from a third party. 
				+ a. With internally developed software, evaluate whether management is responsible for maintaining the software, and entity personnel have the resources and expertise to stay abreast of vulnerabilities and develop software updates and patches.
				+ b. With externally developed software, evaluate whether management performed the following: 
					- • Determined whether COTS software meets the entity’s needs and security requirements or if it will integrate with existing software and require further configuration.
					- • Determined whether custom software was designed to integrate with the existing enterprise software, hardware, and data, and whether management considered issues related to obsolescence, patching, and availability of expertise.
				+ c. Regardless of the type of externally developed software selected, determine whether management performed the following: 
					- • Approved the selected software’s use and determined that it met the entity’s infrastructure requirements and strategic objectives.
					- • Allocated resources to support the software (e.g., financial and personnel) and determined that personnel have the expertise to maintain and patch the software.
			* 6. This examination procedure may be performed in coordination with related examination procedures in the “Development and Acquisition,” “Information Security,” and “Outsourcing Technology Services” booklets. Determine whether management is aware of and implements risk mitigations for general risks (e.g., software vulnerabilities and unauthorized access) associated with software in the entity’s infrastructure environment. With respect to specific software types, determine whether management does the following: 
				+ a. For OS software: 
					- • Oversees and maintains the OS, including testing and installing patches when appropriate.
					- • Restricts and monitors administrator access to the OS.
					- • Limits the use of utility software.
				+ b. For core processing software: 
					- • Restricts software based on job responsibility.
					- • Monitors its use.
					- • Selects core processing software with adequate capacity.
					- • Chooses software that can support usage spikes, expected peak usage times, and future growth.
				+ c. For productivity software: 
					- • Considers the use of it to enable personnel to perform their job functions.
					- • Safeguards systems against security threats and employs IAM, configuration management, and log monitoring.
					- • Employs mitigation strategies to address synchronization issues.
				+ d. For enterprise software: 
					- • Considers how enterprise software integrates in the entity’s infrastructure environment.
					- • Limits access and editing capabilities.
					- • Monitors user activity.
				+ e. For security software: 
					- • Uses security software that is current, deployed effectively, and designed to keep up with the evolution of malicious code.
					- • Restricts administrative access to this type of software.
				+ f. For system auditing software: 
					- • Uses system auditing software to augment audit personnel.
					- • Uses the software to assist in the identification of gaps in infrastructure security and resilience.
					- • Documents software for system audit use and defines its purpose.
				+ g. For open source software: 
					- • Identifies security issues with its use.
					- • Implements security controls and procedures to mitigate risks, including the following: 
						* o Defining acceptable use (or restriction) guidelines and documenting a process for modifying and reviewing the code.
						* o Restricting access to unapproved shareware sites.
						* o Using tools to help discover unapproved open source software.
						* o Identifying the type and version of open source software in use, where it is used within the entity, and its purpose.
						* o Implementing version and patch control guidelines for open source software in use.
						* o Monitoring for vulnerabilities of the open source software employed by the entity. addresses their use in contract provisions.
					- • Evaluates open source software components during software due diligence.
				+ h. For mainframe security software: 
					- • Implements access controls (e.g., role-based access, segregation of duties, and multi-factor authentication). setting changes). controls, privileges, roles, and access profiles). administrators).
					- • Evaluates implications of open source components in third-party software and
					- • Uses security controls.
					- • Encrypts sensitive information.
					- • Enables activity log settings (e.g., user access, failed login attempts, and security
					- • Implements real-time monitoring and alerting.
					- • Performs timely patch management.
					- • Verifies mainframe security auditing (e.g., regular review and validation of security
					- • Independently monitors privileged accounts (e.g., system and security
					- • Maintains appropriate mainframe security expertise.
				+ i. For APIs: 
					- • Assesses and implements security needs for APIs.
					- • Addresses authorization, authentication, and encryption.
					- • Implements API security tools and gateways with controls for requests and responses.
					- • Performs sensitive data filtering.
					- • Places restrictions on size and number of resources requested.
					- • Identifies API request checkpoints for information leaving the network.
					- • Performs appropriate API logging and monitoring.
					- • Implements other security controls (e.g., secure IPs, password hashing, restriction of secret information, authorization protocols, validation mechanisms, time stamping, rate limiting, API traffic monitoring, and API gateway configuration) as appropriate for internal APIs.
					- • Implements adequate security and restrictions over the use of public APIs to protect sensitive customer and entity data and performs appropriate testing to verify the adequacy of security controls over a third party’s APIs.
					- • As part of its customer awareness program, makes security awareness information available to its customers using unaffiliated third-party API services. Determine whether the information addresses protections available and not available when the customer allows access to its data.
			* 7. This examination procedure may be performed in coordination with related examination procedures in the “Outsourcing Technology Services” booklet. Determine whether management performs the following, depending on the type of software hosting involved: 
				+ a. For internally hosted software, determine whether management: 
					- • Identifies personnel (e.g., internal or third-party) with relevant skills and expertise.
					- • Allocates resources for necessary training to maintain knowledge.
					- • Follows a system development life cycle that incorporates security if the entity develops software in-house.
				+ b. For externally hosted software, determine whether management: 
					- • Has contract provisions addressing the notification of infrastructure changes and the third party’s use of any subcontractors.
				+ c. For hybrid hosted software arrangements, determine whether management: 
					- • Performs an adequate risk assessment to prepare for a potential service interruption.
			* 8. This examination procedure may be performed in coordination with related examination procedures in the “Business Continuity Management” booklet. Determine whether management developed, documented, and implemented environmental control policies, standards, and procedures to safeguard facilities, technology, data, and people. Specifically, determine whether management has effective environmental controls to identify and mitigate risks from infrastructure and operational issues. Evaluate whether remotely available environmental controls (including IoT devices used for environmental monitoring), whether by a third-party service provider or not, have appropriate access controls, monitoring of remote access activity, and regular review of privileges. Additionally, determine whether third-party service provider access for maintenance and administrative purposes are appropriately controlled.
			* 9. Review the effectiveness of management’s mitigation of the risks associated with the following: 
				+ a. HVAC controls, including: 
					- • Maintaining appropriate temperature and humidity levels.
					- • Monitoring HVAC.
					- • Implementing automated monitoring and providing an alarm or notification of significant temperature changes.
					- • Considering the entity’s need for redundant HVAC equipment components.
				+ b. Smoke and fire mitigation strategies, including: 
					- • Appropriate smoke and fire detection systems.
					- • Smoke and fire detectors in appropriate locations.
					- • Devices and systems for smoke detection, fire suppression, and fire detection supported by an independent energy source.
					- • Inspections of facilities for potential fire hazards and resolution of identified deficiencies.
					- • Training.
					- • Evaluation of all systems for their advantages and disadvantages.
					- • Knowledge of potential risks of fire suppression systems.
					- • Contract provisions for smoke and fire detection in third-party hosted infrastructure situations.
				+ c. Water detection controls, including: 
					- • Use of water detectors in raised floors or in ceilings to alert management.
					- • Consideration of automated mechanisms to detect the presence of water and provide alerts.
				+ d. Power issues mitigation, including: 
					- • Steps to protect computing equipment from inconsistent and dirty power sources.
					- • Consideration of long-term alternate power supply to provide operational capability during extended power outages.
					- • Appropriate power configurations based on the entity’s power needs.
					- • Use of independent electrical feeds drawing from separate power grids and automatic fail-over to a live power source, where multiple feeds or backup power generators are used.
					- • Evaluation and mitigation of the risk from one grid or one provider in other ways (e.g., using generator(s) or batteries).
					- • Methods to monitor, condition, or stabilize the electricity source voltage and minimize effects of power fluctuations.
					- • Use of alternative power sources independent of local power grids.
					- • Processes to power down IT systems in an orderly manner to maintain critical information for later recovery, in cases where power cannot be maintained (e.g., during emergencies).
					- • Activation of automated emergency lighting of critical infrastructure, evacuation routes, and emergency exits.
				+ e. Physical access controls, including: 
					- • List of approved individuals with authorized physical access to the IT infrastructure facilities.
					- • Validation of access authorizations before granting access to restricted spaces.
					- • Use of credentials for entity personnel and visitor badges for visitors.
					- • Logs of individuals that access restricted spaces.
					- • Use of physical intrusion alarms and surveillance equipment.
					- • Visitor escorts and visitor activity monitoring.
					- • Security over combinations, keys, and other physical access devices; processes to change combinations or keys as needed; and removal of electronic user credentials, when appropriate.
					- • Inventory of physical access devices at regular intervals.
					- • Regular reviews of access lists and removal of unnecessary access.
					- • Alternative physical access processes if electronic controls fail.The next four objectives (14–17) are related to section VI, “Operations.” Examination objectives for this section were divided into four sub-sections: “Operational Controls,” “Operational Processes,” “Service and Support Processes,” and “Ongoing Monitoring and Evaluation Processes,” following the layout in the booklet.Objective 14: Management develops and implements operational controls to safeguard the entity’s operational environment. (VI.A, “Operational Controls”) 
	
	The examination procedures in this objective may be performed in coordination with related examination procedures in the “Information Security” booklet. 
	
	
		- 1. With respect to operating centers, describe the entity’s operating center type and key responsibilities and determine whether functions such as security and network management are addressed. Evaluate the appropriateness of the entity’s processes and controls, such as the following: 
			* a. Responsibility for the physical location as well as the on-premise equipment and systems in entity-owned versus outsourced operating centers.
			* b. Contract(s) specifying equipment ownership and responsibility, if management of the operating center is outsourced.
			* c. Operating centers located in areas less prone to environmental threats.
			* d. Appropriate security and environmental controls within the entity’s infrastructure, including: 
				+ • Use of smoke, water, and power detection and mitigation devices and systems, as well as fire suppression systems.
				+ • Use of security zones limiting access within restricted spaces.
				+ • Implementation of physical security controls.
				+ • Use of devices to restrict and log access to the site.
				+ • Procedures for appropriate site maintenance.
			* e. Responsibilities for implementing security and environmental controls.
			* f. Operating center responsibilities, including: 
				+ • Training staff to operate and maintain the entity’s equipment and systems.
				+ • Deploying appropriate connectivity.
				+ • Managing incidents and events.
		- 2. Determine whether management defines the entity’s authorization boundary(ies) and implements appropriate security controls according to the contents of the authorization boundary, including controls over the following: 
			* a. Internal and external communication systems within and across the entity’s authorization boundary(ies).
			* b. The connection between the entity and its third parties. c. Physical, logical, and environmental controls.
	+ d. Perimeter protection devices.
	+ e. People and processes supporting the entity’s missions and business functions.
* 3. Determine whether management implements appropriate IAM processes and does the following: 
	+ a. Appropriately provides access to the entity’s resources.
	+ b. Considers enhanced authentication, especially for privileged access.
	+ c. Considers its implementation of cloud services and addresses the unique access control requirements for cloud environments, as appropriate.
	+ d. Maintains a policy and implements related standards and procedures to identify users and restrict their access.
* 4. Determine whether management has processes for employee recruitment, hiring, and placement and provides for thorough applicant screening and background checks at the time of employment. Review the following and evaluate their effectiveness: 
	+ a. Performance of background checks at an appropriate frequency.
	+ b. Definition of duties, responsibilities, expectations, and accountability.
	+ c. Implementation of dual control and segregation of duties.
	+ d. Independently monitoring activities.
	+ e. Implementation of rotation of duties.
	+ f. Reviewing and monitoring of activities performed during rotation of duties.

### Objective 15: Management implements effective IT operational processes to reduce the number of potential operational failures and minimize the impact of issues that occur. (VI.B, “IT Operational Processes”) 

The examination procedures in this objective may be performed in coordination with related examination procedures in the “Information Security” and “Outsourcing Technology Services” booklets. 

* 1. Determine whether management has assigned responsibility for the performance of maintenance on the entity’s equipment. Evaluate whether the following is effective: 
	+ a. Routine maintenance by data center employees is performed according to manufacturers’ recommendations.
	+ b. Preventive maintenance follows a predetermined schedule.
	+ c. Operations employees document both internal routine (if any) and externally provided maintenance in logs and other records.
	+ d. Management reviews maintenance records.
	+ e. For equipment owned or leased from a third party, management obtains a separate agreement to manage maintenance. The agreement includes: 
		- • Preventive maintenance to be performed.
		- • Provisions for repair services.
		- • Schedule for maintenance and time frame for repair.
	+ f. Management provides time and resources for scheduled preventive maintenance, which includes: 
		- • Limiting the service representative’s access to the minimum necessary.
		- • Having at least one computer operator present when the service representative is on site.
		- • Reviewing system activity logs to monitor access to programs or data during maintenance.
		- • Following established security procedures to ensure representatives have only the necessary access at predetermined times to perform specific tasks.
	+ g. If there is an arrangement with a contractor to manage the entity’s preventive maintenance and repair services, the contract or agreement guarantees timely performance of maintenance.
	+ h. If computer maintenance is performed online, the online maintenance schedule is available to prevent interference with normal operations and processing.
	+ i. Maintain a log of all hardware or software problems and downtime encountered between maintenance sessions.
* 2. Evaluate whether management has policies, standards, and procedures for configuration management and defines and implements appropriate configuration settings. In addition, verify whether management does the following: 
	+ a. Appropriately defines and applies configuration settings on IT products at the entity.
	+ b. Ensures that systems and software used to support entity operations have appropriate configuration management capabilities, including configuration of audit log settings, and enforces configuration management.
* 3. Determine whether management establishes procedures to stay abreast of system vulnerabilities and software vendor patches, tests patches in a segregated environment, and installs them when appropriate. Additionally, determine the effectiveness of the following: 
	+ a. Management implements a vulnerability management program that identifies systems and software vulnerabilities, prioritizes the vulnerabilities and the affected systems in order of risk, and performs timely remediation according to the risk of the vulnerability. The vulnerability management program includes the following: 
		- • Systems and software operating in the cloud for which the entity is responsible as well as those managed by the entity on its premises.
		- • Processes to monitor industry third parties (e.g., US-CERT, NIST, and FS-ISAC) that report vulnerability exposures and address any relevant exposures within the entity’s systems and software.
		- • Processes to periodically assess systems and software for vulnerabilities using scanners with current vulnerability lists.
		- • Vulnerability scans of all systems and software in the entity’s hardware, software, and telecommunications inventories.
		- • Appropriate controls over vulnerability scanning tools, including controls to protect against unauthorized use or access to sensitive information.
		- • Use of dedicated accounts for authenticated vulnerability scans.
		- • Methods to track and report on nonconformance to entity policies and the timeliness and remediation progress of all identified vulnerabilities, including those related to security procedures, physical layout, or internal controls.
	+ b. Management implements a patch management program that includes documentation of any patch installations. The patch management program includes the following: 
		- • Processes to document patch installations as part of the entity’s change management procedures.
		- • Systems and software for automated patch management or other demonstrated effectiveness in keeping up with patch identification, testing, and installation.
		- • Records of the system and software versions in place and regular monitoring of online and industry resources for information on product enhancements, security or other issues, patches, or upgrades.
		- • Communication and integration with the entity’s third-party service providers to align the entity’s patch management program with those of the third-party service providers.
* 4. This examination procedure may be coordinated with the examination procedures in the “Business Continuity Management” and “Information Security” booklets. Determine whether management implements backup methods, including replication, based on the risk and criticality of the systems and data. 
	+ a. As part of its backup and replication processes, determine whether management maintains the following: 
		- • Policies, standards, and procedures.
		- • Inventories of backup media, storage location, and access controls for the media or physical location.
		- • Documented periodic physical reviews to confirm that all relevant backup material is available.
		- • Procedures to verify adherence to backup schedules.
		- • Processes to regularly test backup copies for readability.
		- • Capability to restore operations to a previous trusted state.
		- • Backups of configurations and data off-site and on a separate system or media.
		- • VM versioning, replication, and life cycle policies for backup processes.
		- • Data encryption and access controls to protect backup or replicated data from unauthorized access, destruction, or corruption.
		- • Proper sanitization and disposal of data when it is no longer needed to prevent the disclosure of information to unauthorized users.
	+ b. When using third-party service providers for backup and replication, determine whether management validates that the third-party service provider performs the processes above.
* 5. To meet scheduling needs, determine whether management implements policies, standards, and procedures for creating and changing job schedules and analyzing and maximizing the entity’s resources.
* 6. Determine whether management implements adequate capacity management processes. Additionally, evaluate whether the processes provide for the following: 
	+ a. Integration with the budgeting and strategic planning processes.
	+ b. Addressing internal and external factors.
	+ c. Routine assessment of capacity against baselines to ensure adequate performance in the following: 
		- • Platform processing speed.
		- • Primary working memory for each platform’s CPU.
		- • Additional data storage capacity.
		- • Voice and data communication bandwidth.
	+ d. Analysis of capacity trends (e.g., increasing capacity usage) to understand capacity usage.
	+ e. Analysis of help desk records, as appropriate, for capacity issues.
	+ f. Periodic analysis of projected versus actual capacity.
	+ g. Verification through testing to ensure systems and software meet the entity’s demands during periods of high volume.
	+ h. Meeting between IT management and business line management to determine future projects that may impact capacity needs.
	+ i. Consideration of flexibility to accommodate the entity’s future capacity requirements.
	+ j. Evaluation of third-party service providers’ performance in combination with internal performance to determine whether capacity can meet existing and future demands.
* 7. Determine whether management has a log management process to use logs to identify, track, analyze, and resolve problems that occur during day-to-day operations. Describe how management collects and collates logs and how management uses logs to respond to issues. Evaluate how management addresses the following: 
	+ a. Identification and disposition of false positives and adjustment of logging parameters to minimize the volume of false positives in future log review.
	+ b. Implementation of policies, standards, and procedures for log management activities that address the following: 
		- • Objectives for logging.
		- • Types of logs to be collected.
		- • Controls to restrict access to log settings.
		- • Response time for log review.
		- • Retention time frames and storage policies of logs.
		- • Escalation processes for anomalies.
	+ c. Configuration of logging to match the entity’s risk and complexity of the entity and identify and address anomalies.
	+ d. Consideration of tools to automate log analysis and extract important events or patterns.
	+ e. Implementation of controls to protect logs.
* 8. Determine whether management implements policies, standards, and procedures to address media and equipment disposal or transfer. Evaluate whether management addresses the following: 
	+ a. Controls involved in the disposal process that are risk-based relative to the sensitivity of the information as defined by the entity’s data classification policy and the type of media used.
	+ b. Defined methods for disposal based on the type of data to be removed.
	+ c. Consideration of techniques to remove data even when transferring the media between internal departments.
	+ d. Implementation of appropriate procedures for the disposal of equipment (e.g., printers).
	+ e. Performance of periodic reviews to ensure the timely disposal of decommissioned equipment.
	+ f. Application of additional disposal techniques (e.g., data destruction) to remove sensitive information when traditional removal methods are not fully effective.Objective 16: Management develops and implements service and support processes to support an entity’s strategic goals and objectives by preventing issues, ensuring continuous reliability and resilience, and supporting users. (VI.C, “Service and Support Processes”) 


	+ 1. Determine whether management designs the entity’s service management functions with an emphasis on preventing issues and ensuring continuous reliability and resilience where possible. Evaluate whether management performs the following: 
		- a. Considers the following as part of its service management planning: 
			* • Services offered and SLA, OLA, or contractual provisions.
			* • Activities performed by third-party service providers.
			* • Known limitations (e.g., capacity or resources) that may affect service management activities.
			* • Applicable legal and regulatory requirements.
			* • Resources necessary to carry out service management functions and activities.
			* • Metrics and measurements used to evaluate service management effectiveness.
		- b. Utilizes documented OLAs or another method to communicate and coordinate the entity’s business requirements to personnel responsible for the execution of service management functions.
		- c. Coordinates its processes with third-party service providers, when used, to ensure seamless functionality to the entity’s lines of business.
		- d. Coordinates meetings between process owners from both business and technology functions to discuss known issues, changes in progress, and future changes.
	+ 2. As part of the entity’s operational support processes, determine whether the following is performed: 
		- a. Management implements the following: 
			* • Processes to verify that incoming data transmissions and processing are complete and accurate.
			* • Controls to verify that external data transmissions and processing are securely received.
			* • Controls to verify that data were not corrupted during transmission or processing failures.
			* • Mechanisms to report transmission and processing errors.
		- b. Operational support personnel report errors or problems with the systems or software and provide updates on resolution.
	+ 3. Determine whether the entity has an IT support function. If there is, evaluate it for the following: 
		- a. Processes for recording and tracking incoming issues, whether handled by human operators or automated systems.
		- b. Tracking system documentation that includes: 
			* • User name and contact information.
			* • Problem description.
			* • Request type and category.
			* • Affected system.
			* • Prioritization code.
			* • Current status toward resolution.
			* • Individual or group responsible for resolution.
			* • Root cause, when identified.
			* • Target resolution time frame.
			* • Comments related to user interaction with IT support and other information.
		- c. Well-trained and knowledgeable IT support personnel.
		- d. Appropriate training for IT support personnel to perform their duties, if IT support software is used.
		- e. Procedures to authenticate users to prevent unauthorized access to information or credentials.
		- f. Layered security and supplemental authentication techniques for changes to account maintenance activities and for high-risk transactions.
		- g. For outsourced IT support functions, management’s IT support expectations and responsibilities for the third-party service provider are included in the contract.
	+ 4. This examination procedure may be coordinated with related examination procedures in the “Business Continuity Management” and “Information Security” booklets. Determine whether management has processes to manage events, incidents, and problems. Evaluate the effectiveness of the following: 
		- a. Implementation of entity processes to plan for and manage events, incidents, and problems, including: 
			* • Coordinating and defining roles and responsibilities.
			* • Conducting testing to identify interdependencies.
		- b. Establishment and maintenance of appropriate processes and controls, including: 
			* • Identifying the event, incident, or problem.
			* • Determining the impact.
			* • Assigning a severity rating based on risk.
			* • Performing root cause analysis.
			* • Identifying, logging, tracking, and analyzing events, incidents, and problems.
			* • Maintaining contact information for individuals and groups for notification purposes.
			* • Informing the help desk of the event, incident, or problem and how to respond.
			* • Resolving the event, incident, or problem, including approval processes for system or software changes to correct the issue.
			* • Documenting any interim actions, compensating controls, and risk acceptance for issues that cannot be immediately resolved.
			* • Developing longer-term action plans to monitor and address issues.
			* • Reporting on the progress of the action plans to senior management.
			* • Implementing procedures for escalation and reporting.
			* • Implementing procedures to correlate events.
		- c. Performance of periodic trend analysis to find recurring or related issues that may be tracked to a common root cause.
		- d. Maintenance of management plans that cover hardware, software, and security devices.
		- e. Communication of processes to manage events, incidents, and problems to appropriate personnel.
		- f. Coordination and inclusion of processes with the entity’s incident response program.
### Objective 17: Management develops processes to oversee operations functions, evaluate the effectiveness of controls, and identify opportunities for improvement. (VI.D, “Ongoing Monitoring and Evaluation Processes”) 

* 1. Determine whether management implements processes to monitor IT operations and periodically reports on the effectiveness of established controls to senior management and other stakeholders. Evaluate the following: 
	+ a. Senior management and other stakeholders have input into the types of reports and metrics produced, and reports are understandable and useful to them.
	+ b. The operations team reports performance metrics to senior management and other stakeholders.
	+ c. Operations management meets periodically with senior management and other stakeholders on monitoring and reporting.
	+ d. If the entity has outsourcing arrangements, evaluate whether management does the following: 
		- • Monitors third-party service providers as part of the entity’s third-party risk management program.
		- • Receives reports that include effectiveness of security controls, performance metrics, resolved versus outstanding issues, and root causes of problems in reports from third-party service providers.
		- • Monitors third-party service provider’s ability to meet defined SLAs, compliance with identified action plans when they are not met, and remuneration of penalty fees when appropriate.
	+ e. If an entity has outsourcing arrangements in the cloud, determine whether management explores the use of tools designed for cloud computing.
* 2. Determine whether management defines objectives for IT and operations and KPIs to help management measure those objectives. Additionally, evaluate whether management does the following: 
	+ a. Aligns KPIs with the entity’s ERM processes and uses those KPIs to assess the performance of IT and operations across the entity.
	+ b. Sets KPI benchmarks to achieve and analyzes deviations from those benchmarks.
	+ c. Automates the collection of KPIs, where possible.
	+ d. Has a useful set of KPIs.
	+ e. Regularly reviews KPI reports and provides appropriate reporting up to the board.
	+ f. Implements corrective action plans to address deviations or negative trends, assigns individuals responsible, and monitors progress to completion.
	+ g. Meets with stakeholders to review IT and operations KPIs to determine whether they are appropriate indicators of the ability to meet the entity’s strategic objectives.
* 3. Determine whether management uses control self-assessments, risk control self-assessments, or other methods to monitor the effectiveness of IT operations controls and gauge performance, assess the criticality of systems, and identify existing risks. Determine whether management evaluates results and uses them to continuously improve the entity’s operations.
* 4. Determine whether management has a continuous improvement process in place to recommend changes to the entity’s IT environment. Evaluate whether management does the following: 
	+ a. Develops improvement strategies for operations and prioritizes projects.
	+ b. Bases improvement decisions on the potential benefit and ease of implementation, with a focus on important IT processes and core competencies.
	+ c. Maintains a process to measure the results of continuous improvement efforts and includes the following: 
		- • Ongoing practice of process improvement.
		- • Enterprise-wide practice of service improvement that augments the ability to provide value to its stakeholders and customers.Objective 18: Discuss corrective action and communicate findings. 


	+ 1. Review preliminary conclusions with the examiner-in-charge regarding the following: 
		- a. Apparent violations of laws and regulations.
		- b. Significant issues warranting inclusion in the report of examination.
		- c. Proposed Uniform Rating System for IT (URSIT) support and delivery component rating and the potential impact of the examiner's conclusions on composite or other URSIT component ratings.
		- d. Potential impact of the examiner's conclusions on the entity's risk assessment(s).
	+ 2. Discuss findings with management and obtain proposed corrective action for significant deficiencies.
	+ 3. Document conclusions in a memorandum to the examiner-in-charge that provides report- ready comments for all relevant sections of the report of examination and clarifying guidance to future examiners.
	+ 4. Organize work papers to show clear support for significant findings by examination objective.
# APPENDIX B: GLOSSARY 

The purpose of the glossary is to define technical terms used in the FFIEC IT Examination Handbook booklets in the context of supervisory activities for the entities over which FFIEC members have supervisory authority. The FFIEC members strive to align terminology in the glossary with appropriate authoritative standards, including the NIST Computer Security Resource Center Glossary (NIST Glossary) as the primary source for cyber-related definitions, as appropriate. FFIEC members employed the following process to select, modify, or develop definitions. 

When a NIST definition existed: 

* • If NIST had a defined term and modifications to the definition were unnecessary, the FFIEC
* • If NIST had a defined term, but the definition needed additional clarity for supervisory members included the NIST definition in this glossary. When multiple NIST definitions were available for the same term, the FFIEC members selected a definition for supervisory purposes. purposes to assist with the identification of safety and soundness and enterprise risks related to IT, the FFIEC members included both the NIST definition and the FFIEC-adapted definition. Definitions of this nature are labeled “FFIEC Adapted for Supervisory Purposes” in this glossary’s source column.

When a NIST definition did not exist or the definition was not appropriate for supervisory purposes: 

* • If NIST did not have a defined term, but there was an appropriate authoritative third-party
* • If NIST did not have a defined term and there was not an appropriate authoritative third-party source (e.g., the ISO Glossary), the FFIEC members included that authoritative definition. source, the FFIEC members developed a definition for supervisory purposes. Definitions of this nature are labeled “FFIEC Developed for Supervisory Purposes” in this glossary’s source column.

Note: Due to the constantly evolving nature of IT and its associated risks, the FFIEC members may update definitions to maintain alignment with other government agencies and the financial services industry. 



| Term | Definition | Source |
| --- | --- | --- |
|  | A |  |
| Access control | Procedures and controls that limit or detect access to critical information resources. This can be accomplished through software, biometrics devices, or physical access to a controlled space. | NIST Glossary |
| Add-on | Additional code that provides extra features to a program, extends certain functions, or provides additional capabilities. | FFIEC Developed for Supervisory Purposes |



| Term | Definition | Source |
| --- | --- | --- |
| Anomaly-based detection | The process of comparing definitions of what activity is considered normal against observed events to identify significant deviations. | NIST SP 800-94 Rev. 1 |
| Antivirus software | A program specifically designed to detect many forms of malware and prevent them from infecting computers, as well as cleaning computers that have already been infected. | NIST Glossary |
| Application | A system for collecting, saving, processing, and presenting data by means of a computer. The term application is generally used when referring to a component of software that can be executed. The terms application and software application are often used synonymously. | NIST Glossary |
| Application firewall | A firewall that uses stateful protocol analysis to analyze network traffic for one or more applications. | NIST Glossary |
| Application programming interface (API) | A system access point or library function that has a well-defined syntax and is accessible from application programs or user code to provide well-defined functionality. | NIST Glossary |
|  | Software code that allows two or more different programs to communicate with each other. | FFIEC Adapted for Supervisory Purposes |
| Architecture | Refers to the manner in which the strategic design of the hardware and software infrastructure components (e.g., devices, systems, and networks) are organized and integrated to achieve and support the entity’s business objectives. | FFIEC Developed for Supervisory Purposes |
| Artificial intelligence (AI) | Refers to the ability of machines to perform tasks that normally require human intelligence—for example, recognizing patterns, learning from experience, drawing conclusions, making predictions, or taking action—whether digitally or as the smart software behind autonomous physical systems. | U.S. Department of Defense |
| Authentication | A process that establishes the source of information, provides assurance of an entity’s identity or provides assurance of the integrity of communications sessions, messages, documents or stored data. | NIST Glossary |
|  | A process designed to establish the source of the information, validity of a transmission, message, or originator, or a means of verifying an individual’s authorization to receive specific categories of information. | FFIEC Adapted for Supervisory Purposes |
| Authorization | The granting or denying of access rights to a user, program, or process. | NIST Glossary |
| Authorization boundary | All components of an information system to be authorized for operation by an authorizing official, and excludes separately authorized systems, to which the information system is connected. | NIST Glossary |
| Availability | Ensuring timely and reliable access to and use of information. | NIST Glossary |
|  | B |  |
| Backup | A copy of files and programs made to facilitate recovery, if necessary. | NIST Glossary |
| Bandwidth (utilization) | The range between the highest and lowest transmittable frequencies. It equates to the transmission capacity of an electronic line and is expressed in bytes per second or Hertz (cycles per second). | ISACA Glossary |



| Term | Definition | Source |
| --- | --- | --- |
| Baseline configuration | A set of specifications for a system, or configuration item within a system, that has been formally reviewed and agreed on at a given point in time, and which can be changed only through change control procedures. The baseline configuration is used as a basis for future builds, releases, and/or changes. | NIST Glossary |
| Big data | Extensive datasets—primarily in the characteristics of volume, variety, velocity, and/or variability—that require a scalable architecture for efficient storage, manipulation, and analysis. | NIST Big Data Interoperability Framework: Volume 1 |
| Blacklist | A list of discrete entities, such as hosts or applications that have been previously determined to be associated with malicious activity. | NIST Glossary |
|  | C |  |
| Capacity management | The process of planning and monitoring an entity’s technology resources to support current and future strategic objectives. | FFIEC Developed for Supervisory Purposes |
| Capacity planning | Systematic determination of resource requirements for the projected output, over a specific period. | NIST Glossary |
| Capture | The act of recording in a permanent file. | Merriam-Webster |
| Central processing unit (CPU) | Computer hardware that houses the electronic circuits that control/direct all operations of the computer system. | ISACA Glossary |
| Change control | Change control is the process through which all requests to change the approved baseline of a project, program, or portfolio are captured, evaluated and then approved, rejected, or deferred. | Association for Project Management |
|  | Change control is the process through which all requests to change the approved baseline of a project, program, or portfolio are documented, evaluated and then approved, rejected, or deferred. Change control is an element in an overall change management process. | FFIEC Adapted for Supervisory Purposes |
| Change management | The continuous process of maintaining the integrity of hardware, software, firmware, and documentation and controlling and approving changes (e.g., addition, modification, or elimination) to information or technology assets or related infrastructure. | U.S. CERT |
| Cloud access security broker (CASB) | A software tool or service that sits between an entity’s on-premises infrastructure and a cloud service provider’s infrastructure as a “gatekeeper” to monitor activity and enforce the entity’s security policies (e.g., authentication, single sign-on, authorization, credential mapping, and encryption) as the cloud-based resources are accessed. | FFIEC Developed for Supervisory Purposes |
| Cloud broker | An entity that manages the use, performance, and delivery of cloud services, and negotiates relationships between cloud service providers and cloud consumers. | NIST SP 500-291 |
| Cloud bursting | The ability of an entity with in-house infrastructure to use the public cloud during peak periods. | FFIEC Developed for Supervisory |
| Cloud computing | A model for enabling ubiquitous, convenient, on-demand network access to a shared pool of configurable computing resources (e.g., | NIST Glossary |


Purposes 



| Term | Definition | Source |
| --- | --- | --- |
| service | networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or service provider interaction. |  |
| Cloud provider | Referred to as a cloud provider. A service provider who offers customers storage or software solutions available via a public network, usually the internet. | (ISC)2 Certified Cloud Security Professional Study Guide |
|  | A third-party service provider who offers clients services over the public internet. Examples of services could be applications (SaaS), operating systems (PaaS), or infrastructure (IaaS). | FFIEC Adapted for Supervisory Purposes |
| Commercial off- the-shelf (COTS) software | A software and/or hardware product that is commercially ready-made and available for sale, lease, or license to the general public. It is also referred to as off-the-shelf. | NIST Glossary |
| Community cloud | The community cloud infrastructure is provisioned for exclusive use by a specific community (e.g., government agencies, financial services, or banks) of entities that have shared concerns (e.g., mission, security requirements, policy, and compliance considerations). The community cloud infrastructure may be owned, managed, and operated by one or more of the constituents in the community, a third party, or some combination of them, and it may exist on or off premises. | NIST Glossary |
| Compromise | The unauthorized disclosure, modification, substitution, or use of sensitive data (e.g., keying material and other security related information). | NIST Glossary |
| Confidentiality | The property that sensitive information is not disclosed to unauthorized entities. | NIST Glossary |
| Configuration | The selection of one of the sets of possible combinations of features of a system. | NIST Glossary |
|  | The selection of combinations of conditions, parameters, features, and specifications of a system. | FFIEC Adapted for Supervisory Purposes |
| Configuration management | A collection of activities focused on establishing and maintaining the integrity of information technology products and information systems, through control of processes for initializing, changing, and monitoring the configurations of those products and systems throughout the system development life cycle. | NIST Glossary |
| Configuration settings | The set of parameters that can be changed in hardware, software, or firmware that affect the security posture and/or functionality of the information system. | NIST Glossary |
| Container | A method for packaging and securely running an application within a virtualized environment. | NIST Glossary |
| Content filtering | The process of monitoring communications such as email and web pages, analyzing them for suspicious content, and preventing the delivery of suspicious content to users. | NIST Glossary |
| Continuous improvement | In operations, the ongoing effort to improve an entity’s products, services, or processes to meet business objectives. | FFIEC Developed for Supervisory Purposes |



| Term | Definition | Source |
| --- | --- | --- |
| Cyber risk | Risk of financial loss, operational disruption, or damage from the failure of the digital technologies employed for informational and/or operational functions introduced to a manufacturing system via electronic means from the unauthorized access, use, disclosure, disruption, modification, or destruction of the manufacturing system. | NIST Glossary |
| Dashboard | D | |
|  | A tool that consolidates and communicates information relevant to the entity in near real-time. It is generally visual and often uses a variety of charts. | NIST SP 800-137 |
| Data | A representation of information as stored or transmitted. | NIST Glossary |
|  | A physical or digital representation of information processed, stored (at rest), or transmitted (in transit). | FFIEC Adapted for Supervisory Purposes |
| Data analytics | The systematic process of evaluating and organizing data sets to draw insights, make predictions, and reveal trends using logical analysis. | FFIEC Developed for Supervisory Purposes |
| Data center | A facility that houses virtual and/or physical information technology infrastructure(s) (e.g., computer, server, and networking systems and components) designed to store, process, and serve large amounts of data in support of an entity’s strategic and business objectives. A data center may be a dedicated facility or an area or room that contains computer, server, and networking systems and components, and may | FFIEC Developed for Supervisory Purposes |
| Data classification | Categorizing data based on its level of sensitivity (e.g., confidentiality, integrity, or availability), value, and criticality to the entity. | FFIEC Developed for Supervisory Purposes |
| communications Data governance | telecommunication services and network devices. A set of processes that ensures that data assets are formally managed | for Supervisory Purposes NIST Glossary |
|  | authority and management and decision-making parameters related to the data produced or managed by the enterprise. | DHS Lexicon Terms and |
| Data management | The practice of putting into place policies, procedures and best practices to ensure that data is understandable, trusted, visible, accessible and interoperable. | Definitions |
|  | The practice of putting into place policies, procedures, and best practices to ensure that data are understandable, trusted, visible, accessible, and interoperable to ensure that user needs are met. | FFIEC Adapted for Supervisory Purposes |

Risk of financial loss, operational disruption, or damage from the 

failure of the digital technologies employed for informational and/or 

operational functions introduced to a system via electronic means 

from the unauthorized access, use, disclosure, disruption, modification, or destruction of the system. 

FFIEC Adapted for 

Supervisory 

Purposes 

be private or shared (e.g., a co-location facility). 

Data 

The transfer of data over networks using a combination of 

FFIEC Developed 

throughout the enterprise. A data governance model establishes 

Database A repository of information or data, which may or may not be a 

traditional relational database system. 

NIST Glossary 



| Term | Definition | Source |
| --- | --- | --- |
|  | A repository of information or data organized to be accessed, managed, and updated. | FFIEC Adapted for Supervisory Purposes |
| Denial of service (DOS) attack | An assault on a service from a single source that floods it with so many requests that it becomes overwhelmed and is either stopped completely or operates at a significantly reduced rate. | ISACA Glossary |
| Device | A piece of equipment or a mechanism designed to serve a special purpose or perform a special function. | Merriam-Webster |
| Dirty power | A term used to describe a power line where disturbances (e.g., outages, voltage spikes, and drop-outs) occur. | A New IEC Standard on the Measurement of Power Quality Parameters |
| Distributed denial of service (DDOS) | A denial of service technique that uses numerous hosts to perform the attack. | NIST Glossary |
| Domain name | A domain name is a human-friendly name (such as “www.dhs.gov”) that is resolved (i.e., translates domain names into Internet Protocol [IP] addresses) by a network of domain name service servers to a specific IP address, which is in turn, associated with a single host (referring to a single server or server cluster). | DHS Directives System |
|  | A unique identifier for a network address. | FFIEC Adapted for Supervisory Purposes |
| Domain name system (DNS) | A distributed computing system that enables access to Internet resources by user-friendly domain names rather than IP addresses, by translating domain names to IP addresses and back. Also known as domain name service (DNS). | NIST SP 800-81-2 |
| Dynamic host configuration protocol (DHCP) | A protocol used by networked computers (clients) to obtain IP addresses and other parameters, such as the default gateway, subnet mask and IP addresses of domain name system servers from a DHCP server. The DHCP server ensures that all IP addresses are unique. IP address pool management is done by the server and not by a human network administrator. | ISACA Glossary |
|  | E |  |
| Encryption | text to prevent anyone but the intended recipient from reading that data. Any procedure used in cryptography to convert plain text into cipher | NIST Glossary |
| End-of-life (EOL) | With respect to technology, a time frame usually defined by a technology vendor to describe when an asset has reached the end of its useful life cycle and when the vendor will no longer maintain and support the asset or continue to sell or license it. | FFIEC Developed for Supervisory Purposes |
| Enterprise architecture | The description of an enterprise’s entire set of information systems: how they are configured, how they are integrated, how they interface to the external environment at the enterprise’s boundary, how they are operated to support the enterprise mission, and how they contribute to the enterprise’s overall security posture. | NIST Glossary |



| Term | Definition | Source |
| --- | --- | --- |
| Enterprise resource planning system | A packaged business software system that allows an enterprise to automate and integrate the majority of its business processes, share common data and practices across the entire enterprise, and produce and access information in a real-time environment. | ISACA Glossary |
| Event | Occurrence or change of a particular set of circumstances. | NIST Glossary |
|  | An occurrence or change in circumstances that may affect operations. An event can be physical, cyber, or a combination of both. | FFIEC Developed for Supervisory Purposes |
| F | | |
| False positive | A result that has been mistakenly identified as a problem when, in reality, the situation is normal. | ISACA Glossary |
| File exchange | (Also known as file sharing) A method of sending and receiving files inside the entity and with other parties through email attachments, file sharing services, and other means. | NIST Security Considerations for Exchanging Files Over the Internet |
| Firewall | A gateway that limits access between networks in accordance with local security policy. | NIST Glossary |
| Functional testing | Testing that verifies that an implementation of some function operates correctly. | NIST Glossary |
| G | | |
| Gateway | more) computer networks that have similar functions but dissimilar implementations and that enables either one-way or two-way communication between the networks. An intermediate system (interface, relay) that attaches to two (or | NIST Glossary |
| Hardening | H A process to eliminate as many security risks as possible by removing all nonessential software programs, protocols, services and utilities from the system. (Referred to as system hardening) A process intended to eliminate as many security risks as possible by implementing security controls (e.g., changing default passwords, | ISACA Glossary FFIEC Adapted for Supervisory |
| Hardware | The physical components of an information system. | NIST Glossary |
| Hashing | produce a numeric value that is representative of that data. The process of using a mathematical algorithm against data to | NIST |
|  |  | Glossary |
| Hub | A common connection point for devices in a network. Hubs commonly are used to pass data from one device (or segment) to another. | NIST |
|  |  | Glossary |
| Hybrid cloud | The hybrid cloud infrastructure is a composition of two or more distinct cloud infrastructures (e.g., private, community, or public) that | NIST Glossary |

enabling security settings, and protecting privileged accounts), 

patching vulnerabilities, turning off nonessential services, and removing all nonessential software programs, protocols, and utilities from the system. 

Purposes 

ISACA Glossary 

or employees that provides information, assistance and troubleshooting advice regarding software, hardware or networks. 

Help desk A service offered via telephone/Internet by an enterprise to its clients 



| Term | Definition | Source |
| --- | --- | --- |
|  | are unique entities, but are bound together by standardized or proprietary technology that enables data and application portability (e.g., cloud bursting for load balancing between clouds). |  |
| Hybrid-hosted- software arrangement | An agreement where software resides at both the entity (also referred to as on-premise) and on the third-party service provider’s servers (e.g., software as a service). | FFIEC Developed for Supervisory Purposes |
| Hypervisor | The virtualization component that manages the guest operating systems (OSs) on a host and controls the flow of instructions between the guest OSs and the physical hardware. | NIST Glossary |
|  | I |  |
| Identity and access management (IAM) | Encapsulates people, processes, and products to identify and manage the data used in an information system to authenticate users and grant or deny access rights to data and system resources. | ISACA Glossary |
| Incident | An occurrence that actually or potentially jeopardizes the confidentiality, integrity, or availability of a system or the information the system processes, stores, or transmits or that constitutes a violation or imminent threat of violation of security policies, security procedures, or acceptable use policies. | NIST Glossary |
| Incident management | The process of identifying, analyzing, and correcting disruptions to operations and preventing future recurrences. The goal of incident management is to limit the disruption and restore operations as quickly as possible. | FFIEC Developed for Supervisory Purposes |
| Information security | The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability. | NIST Glossary |
| Information technology asset management (ITAM) | Refers to a set of policies and procedures that an organization uses to track, audit, and monitor the state of its IT assets, and maintain system configurations. | NIST SP 1800-5 |
| Infrastructure | System of facilities, equipment, and services needed for the operation of an organization. | ISO 22300:2018(en) |
|  | The physical elements, products, and services necessary to provide and maintain ongoing operations to support business activity and includes the maintenance of physical facilities. | FFIEC Adapted for Supervisory Purposes |
| Infrastructure as a service (IaaS) | IaaS provides entities with the ability to provision processing, storage, networks, and other fundamental computing resources where the entity is able to deploy and run software, which can include operating systems and applications. The entity does not manage or control the underlying cloud infrastructure; however, it has control over operating systems, storage, and deployed applications. Entities have the maximum flexibility to customize their cloud services and user interfaces. | NIST SP 500-316 |

Integrity A property whereby data has not been altered in an unauthorized 

manner since it was created, transmitted or stored. 

NIST Glossary 



| Term | Definition | Source |
| --- | --- | --- |
| Interdependencie s | When two or more departments, processes, functions, or third-party providers interact to successfully complete a task, business function, or process. | FFIEC Developed for Supervisory Purposes |
| Internet of things (IoT) | Refers to the collection of technologies that allow information to be sent to and received from physical devices (e.g., security systems, HVAC systems, intelligent personal assistants, and kitchen appliances), that were not traditionally thought of as IT assets, using the internet. These devices have the ability to send and receive data over a network without necessarily requiring human-to-human or human-to-computer interaction using embedded computing capability and network connectivity and unique identifiers (e.g., IP address). | FFIEC Developed for Supervisory Purposes |
| Intrusion detection system (IDS) | A security service that monitors and analyzes network or system events for the purpose of finding, and providing real-time or near real- time warning of, attempts to access system resources in an unauthorized manner. | NIST Glossary |
| Intrusion prevention system (IPS) | A system that can detect an intrusive activity and can also attempt to stop the activity, ideally before it reaches its targets. | NIST Glossary |
| IP address | A unique binary number used to identify devices on a TCP/IP network. | ISACA Glossary |
| IT infrastructure | A subset of infrastructure that includes hardware, network and telecommunications, software, IT environmental controls (e.g., power, cooling, and ventilation), and physical access. | FFIEC Developed for Supervisory |
|  | Purposes J | |
| Jailbreaking (also known as rooting) | To allow the device’s owner to remove manufacturer or carrier restrictions, to gain full access to the root of the operating system and access all the features. | FFIEC Developed for Supervisory Purposes |
| Job scheduling | Generally an automated process to allocate system resources and execute processes based on the priority and processing resources available. | FFIEC Developed for Supervisory Purposes |
| Latency | Time delay in processing voice packets. | NIST Glossary |
|  | Time delay in processing voice and data packets. | FFIEC Adapted for Supervisory Purposes |
| License | A permission granted by competent authority to engage in a business or occupation or in an activity otherwise unlawful. | Merriam-Webster |
| Load balancing | Load balancers distribute HTTP requests over multiple Web servers, allowing organizations to increase the capacity of their Web site by transparently adding additional servers. Load balancers act as virtual servers, receiving all HTTP requests to the Web site. These requests are forwarded, based on the load balancer’s policy, to one of the servers that hosts the Web site. The load balancer’s policy attempts to ensure that each server receives a similar number of requests. Many load balancers are capable of monitoring the servers and compensating if one of the servers becomes unavailable. | NIST SP 800-44 v.2 |

L 



| Term | Definition | Source |
| --- | --- | --- |
|  | The distribution of processing (e.g., network traffic, processing requests or power) across equipment to ensure that any one device is not overwhelmed by high demand. | FFIEC Adapted for Supervisory Purposes |
| Local area network (LAN) | A group of computers and other devices dispersed over a relatively limited area and connected by a communications link that enables any device to interact with any other on the network. | NIST Glossary |
| Log | A record of events occurring within an entity’s systems and networks. | NIST Glossary |
| Log management | The process to generate, transmit, store, analyze, and dispose of log data. | NIST Glossary |
| Loose coupling | An approach to designing systems so that linked components of networks, software, and services can be scaled to operate as independently as possible, in order to avoid issues with one component adversely affecting others. | FFIEC Developed for Supervisory Purposes |
|  | M |  |
| Machine learning (ML) | The process of using an algorithm(s) to help computers learn without being explicitly programmed and identify patterns within data. Those patterns are then used to create a data model that can make predictions. | FFIEC Developed for Supervisory Purposes |
| Mainframe | A large, high-speed computer, especially one supporting numerous workstations or peripherals. | ISACA Glossary |
| Maintenance | Any act that either prevents the failure or malfunction of equipment or restores its operating capability. | NIST Glossary |
| Malicious code | Unwanted files or programs that can cause harm to a computer or compromise data stored on a computer. Various classifications of malicious code include viruses, worms, and Trojan horses. | DHS, CISA Security Tip (ST18-004) |
| Malware | A program that is inserted into a system, usually covertly, with the intent of compromising the confidentiality, integrity, or availability of the victim’s data, applications, or operating system or of otherwise annoying or disrupting the victim. | NIST Glossary |
| Man in the middle (MitM) attack | An attack where the adversary positions himself in between the user and the system so that he can intercept and alter data traveling between them. | NIST Glossary |
| Masking | The process of systematically removing a field or replacing it with a value in a way that does not preserve the analytic utility of the value, such as replacing a phone number with asterisks or a randomly generated pseudonym. | NIST Glossary |
| Media access control (MAC) | Applied to the hardware at the factory and cannot be modified, MAC is a unique, 48-bit, hard-coded address of a physical layer device, such as an Ethernet local area network (LAN) or a wireless network card. | ISACA Glossary |
| Media access control (MAC) address | A unique identifier assigned to network interfaces for communications on the physical network segment. | ISACA Glossary |
|  | A unique identifier assigned to network interfaces for communications on the physical network segment. MAC is a 48-bit, | FFIEC Adapted for Supervisory Purposes |



| Term | Definition | Source |
| --- | --- | --- |
| Metadata | hard-coded address applied to the hardware at the factory and cannot be modified. Data about data. For file systems, metadata is data that provides | NIST Glossary |
|  | Data about data. Examples of metadata include purpose of the data, creator or owner of the data, file size, location where the data were created, and source of the data. | FFIEC Adapted for Supervisory Purposes |
| Microservices | A set of containers that work together to compose an application. | NIST Glossary |
| Mobile computing | Extends the concept of wireless computing to devices that enable new kinds of applications and expand an enterprise network to reach places in circumstances that could never have been done by other means. Mobile computing is comprised of personal digital assistants (PDAs), cellular phones, laptops and other technologies of this kind. | ISACA Glossary |
| Mobile device | A portable computing device that: (i) has a small form factor such that it can easily be carried by a single individual; (ii) is designed to operate without a physical connection (e.g., wirelessly transmit or receive information); (iii) possesses local, non-removable data storage; and (iv) is powered-on for extended periods of time with a | NIST Glossary |
| Multi-factor authentication | Authentication using two or more factors to achieve authentication. Factors include: (i) something you know (e.g., password or personal identification number (PIN)); (ii) something you have (e.g., cryptographic identification device or token); or (iii) something you are (e.g., biometric). | NIST Glossary |
|  | Design where one or more entities and their information and technology assets reside in a shared environment. The instances (tenants) are logically isolated, but physically integrated. | FFIEC Developed for Supervisory Purposes |
| Multi-tenancy |  |  |
|  | N |  |
| Network | A system implemented with a collection of interconnected components. Such components may include routers, hubs, cabling, telecommunications controllers, key distribution centers, and technical control devices. | NIST Glossary |
| Network attached storage (NAS) | Dedicated storage devices that centralize storage of data. These storage devices generally do not provide traditional file, print, or application services. These devices could be physical or virtual. | ISACA Glossary |
| Network backbone | The main communication channel of a network that interconnects one or more network segments and provides a path for the exchange of data between devices. A backbone can span any geographic area. | FFIEC Developed for Supervisory Purposes |
| Network diagram | A network diagram (also called a network map or network topology) is a visual representation of nodes and connections in a computer network. | FFIEC Developed for Supervisory Purposes |
| Network operations center (NOC) | The central location or department responsible for monitoring the health and performance of the network, including analyzing and maintaining network traffic, telecommunications, and network disruptions. | FFIEC Developed for Supervisory Purposes |

information about a file’s contents. 


self-contained power source. 



| Term | Definition | Source |
| --- | --- | --- |
| Network performance | Refers to the speed and response time of a network. | for Supervisory Purposes FFIEC Developed |
| Node | Point at which terminals are given access to a network. | ISACA Glossary |
| Non-production environment | Systems (e.g., applications, infrastructure, networks, operating systems) that are not used for production purposes. For example, systems that are used as development or test environments for new software or technologies or changes to existing software or technologies. | FFIEC Developed for Supervisory Purposes |
|  | O |  |
| Open source software | Open source software is software that can be accessed, used, modified, and shared by anyone. | NIST S 6106.01 |
| Operating system (OS) | The software “master control application” that runs the computer. It is the first program loaded when the computer is turned on, and its main component, the kernel, resides in memory at all times. The operating system sets the standards for all application programs (such as the Web server) that run in the computer. The applications communicate with the operating system for most user interface and file management operations. | NIST Glossary |
| Operational controls | The day-to-day procedures and mechanisms used to protect operational systems and software. Operational controls affect the system and software environment. | NIST Glossary |
| Operational level agreement (OLA) | An internal agreement covering the delivery of services that support the IT organization in its delivery of services. | ISACA Glossary |
| Operational resilience | The ability of systems to resist, absorb, and recover from or adapt to an adverse occurrence during operation that may cause harm, destruction, or loss of ability to perform mission-related functions. | NIST Glossary |
|  | The ability of an entity’s personnel, systems, telecommunications networks, activities, or processes to resist, absorb, and recover from or adapt to an incident that may cause harm, destruction, or loss of ability to perform mission-related functions. | FFIEC Adapted for Supervisory Purposes |
| Operations | The performance of activities comprising methods, principles, processes, procedures, and services that support business functions. | FFIEC Developed for Supervisory Purposes |
| Operations management | The process of overseeing the methods, activities, or performance of practical work, and application of principles, processes, procedures, and services of an entity, utilizing business resources. | FFIEC Developed for Supervisory Purposes |
| Out-of-band | Communication between parties utilizing a means or method that differs from the current method of communication. | NIST Glossary |
|  | P |  |
| Packet | A logical unit of network communications produced by the transport layer. | NIST Glossary |
| Packet sniffers | Software that monitors network traffic on wired or wireless networks and captures packets. | NIST Glossary |



| Term | Definition | Source |
| --- | --- | --- |
| Patch | Fixes to software programming errors and vulnerabilities. | ISACA Glossary |
| Patch management | The systematic notification, identification, deployment, installation, and verification of operating system and application software code revisions. These revisions are known as patches, hot fixes, and service packs. | NIST Glossary |
| Penetration testing | A test methodology in which assessors, using all available documentation (e.g., system design, source code, manuals) and working under specific constraints, attempt to circumvent the security features of an information system. | NIST Glossary |
| Physical access controls | Mitigations that protect an entity’s facilities, physical assets, and technology assets. | NIST 800-53 Rev. 5 |
| Platform | A computer or hardware device and/or associated operating system, or a virtual environment, on which software can be installed or run. | NIST Glossary |
| Platform as a service (PaaS) | The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment. | NIST Glossary |
| Policies | Statements, rules or assertions that specify the correct or expected behavior of an entity. | NIST Glossary |
| Port | The entry or exit point from a computer for connecting communications or peripheral devices. | NIST Glossary |
| Portability | * 1) The ability to transfer data from one system to another without  being required to recreate or reenter data descriptions or to modify significantly the application being transported. 2) The ability of software or of a system to run on more than one type or size of computer under more than one operating system. | ATIS Telecom Glossary |
| Power sag (aka voltage sag) | A brief reduction in voltage, often caused by a short circuit, overload or loose connection. | FFIEC Developed for Supervisory Purposes |
| Primary working memory | For the purposes of this booklet, primary working memory refers to the temporary storage or memory needed to run software applications that is shipped with the CPU and is generally supplemented by additional data storage (i.e., long-term storage). | NIST Glossary |
| Private cloud | The cloud infrastructure is provisioned for exclusive use by a single entity with multiple business units. The private cloud infrastructure may be owned, managed, and operated by the entity, a third party, or some combination of them, and it may exist on or off premises. | NIST Glossary |
| Problem | In IT, the unknown underlying cause of one or more incidents. | ISACA Glossary |
| Procedures | A document containing a detailed description of the steps necessary to perform specific operations in conformance with applicable standards. Procedures are defined as part of processes. | ISACA Glossary |



| Term | Definition | Source |
| --- | --- | --- |
| Process improvement | Process improvement includes the actions taken to improve the quality of the organization’s processes aligned with the business needs and the needs of other concerned parties. | ISO/IEC 33001:2015(en) |
| Promiscuous mode | A configuration setting for a network interface card that causes it to accept all incoming packets that it sees, regardless of their intended destinations. | NIST SP 800-94 |
| Protocol | A set of rules (i.e., formats and procedures) to implement and control some type of association (e.g., communication) between systems. | NIST Glossary |
| Provisioning | The activity of obtaining the equipment and resources you need for a particular activity. | Cambridge Dictionary |
|  | The activity of obtaining, modifying, and making available the equipment, resources, software, or services a user needs to carry out a particular activity. | FFIEC Adapted for Supervisory Purposes |
| Public cloud | The public cloud infrastructure is provisioned for open use by the general public. The public cloud infrastructure may be owned, managed, and operated by a business, academic, government organization, or some combination of them. It exists on the premises | NIST Glossary |
| Q | | |
| Query | combination of tables. In databases, a request for data or information from a table or | FFIEC Developed for Supervisory Purposes |
| R | | |
| Rate limiting | A process used to control the rate of network traffic (e.g., incoming and outgoing). Its purpose is to prevent a failure of service (e.g., from a DOS attack or system overload). | FFIEC Developed for Supervisory Purposes |
| Release | A collection of new and/or changed configuration items, which are tested and introduced into a production environment together. | NIST Glossary |
| Remote access | Access to an organizational information system by a user (or an information system) communicating through an external, non- organization-controlled network (e.g., the Internet). | NIST Glossary |
| Replication | provide availability and fault-tolerant capabilities. In a database context, replication involves the sharing of data between databases to reduce workload among database servers, thereby improving client performance while maintaining consistency among all systems. Involves the use of redundant software or hardware elements to | ISACA Glossary |
| Report | A detailed account or statement. For the purposes of IT, the report provides analysis that supports informed decision-making. | Merriam-Webster |
| Resilience | The ability to prepare for and adapt to changing conditions and withstand and recover rapidly from disruptions. Resilience includes the ability to withstand and recover from deliberate attacks, accidents, or naturally occurring threats or incidents. | NIST Glossary |
| Role-based access | A model for controlling access to resources where permitted actions on resources are identified with roles rather than with individual subject identities. | NIST Glossary |

of the cloud service provider. 



| Term | Definition | Source |
| --- | --- | --- |
| Router | On a network, a device that determines the best path for forwarding a data packet toward its destination. The router is connected to at least two networks and is located at the gateway where one network meets another. | NIST Glossary |
|  | A device that determines the best path for forwarding a data packet toward its destination on a network or between networks. The router is connected to at least two network segments and is located at the gateway where one network segment meets another. | FFIEC Adapted for Supervisory Purposes |
| Routing | In computer networking, the process of selecting a path for traffic within a network or between multiple networks. | FFIEC Developed for Supervisory Purposes |
|  | S |  |
| Sanitization | Actions taken to render data written on media unrecoverable by both ordinary and, for some forms of sanitization, extraordinary means. | NIST Glossary |
| Scalability | Refers to how well a hardware and software system can adapt to increased demands. For example, a scalable network system would be one that can start with just a few nodes but can easily expand to thousands of nodes. Scalability can be a very important feature because it means the entity can invest in a system with confidence they will not quickly outgrow it. | FFIEC Developed for Supervisory Purposes |
| Scheduling | A method used in the information processing facility to determine and establish the sequence of computer job processing. | ISACA Glossary |
| Security | The state in which the integrity, confidentiality, and accessibility of information, service or network entity is assured. | NIST Glossary |
| Security operations center (SOC) | The centralized unit or department responsible for monitoring and improving the entity’s network for security issues and preventing, detecting, and responding to potential incidents or cyber attacks. | FFIEC Developed for Supervisory Purposes |
| Server | A computer or device on a network that manages network resources. Examples include file servers (to store files), print servers (to manage one or more printers), network servers (to manage network traffic), and database servers (to process database queries). | NIST Glossary |
| Service improvement | The actions taken to identify and execute methods to improve an entity’s services and align them with its business objectives. | FFIEC Developed for Supervisory Purposes |
| Service level agreement (SLA) | Defines the specific responsibilities of the service provider and sets the customer expectations. | NIST Glossary |
|  | A formal agreement between two parties that records a common understanding about products or services to be delivered, priorities, responsibilities, guarantees, and warranties between the parties. In addition, the agreement describes the nature, quality, security, availability, scope, and timeliness of delivery and response of the parties, the point(s) of contact for end-user problems, and the metrics by which the effectiveness of the process is monitored and approved, and may include other measurable objectives. The agreement should cover not only expected day-to-day situations, but also unexpected or adverse events, as the need for the service may vary. | FFIEC Adapted Definition for Supervisory Purposes |



| Term | Definition | Source |
| --- | --- | --- |
| Service management | The process of overseeing and managing an entity’s activities and resources to allow management of IT functions to support and service the entity’s strategic goals and objectives. Activities involved in this process include planning, designing, transitioning, delivering, and improving services. | FFIEC Developed for Supervisory Purposes |
| Shadow IT | Refers to unauthorized hardware and other devices, software, or services operating in an entity’s IT environment. | FFIEC Developed for Supervisory Purposes |
| Signature | A recognizable, distinguishing pattern associated with an attack, such as a binary string in a virus or a particular set of keystrokes used to gain unauthorized access to a system. | NIST Glossary |
| Signature-based detection | The process of comparing signatures against observed events to identify possible incidents. | NIST SP 800-94 Rev. 1 |
| Single point of failure | An element in the design, configuration or implementation of a system that can cause the entire system to fail if it stops working. | FFIEC Developed for Supervisory Purposes |
| Social engineering | The act of deceiving an individual into revealing sensitive information, obtaining unauthorized access, or committing fraud by associating with the individual to gain confidence and trust. | NIST Glossary |
| Software | hardware) and associated data (which also is stored in the hardware) that may be dynamically written or modified during execution. Computer programs (which are stored in and executed by computer | NIST Glossary |
| Software as a service (SaaS) | The capability provided to the consumer is to use the provider’s applications running on a cloud infrastructure. The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration | NIST Glossary |
| Standard image | The approved set of server configurations, applications, and systems, which can be used to deploy servers consistently and rebuild them more easily and quickly, when necessary. | FFIEC Developed for Supervisory Purposes |
| Standards | Rules, conditions, or requirements describing the following information for products, systems, services or practices: (i) Classification of components. * (ii) Specification of materials, performance, or operations; or (iii) Delineation of procedures. | NIST Glossary |
| Stateful protocol analysis | The process of comparing predetermined profiles of generally accepted definitions of benign protocol activity for each protocol state against observed events to identify deviations. | NIST SP 800-94 Rev. 1 |
| Storage area network (SAN) | A variation of a local area network (LAN) that is dedicated for the express purpose of connecting storage devices to servers and other computing devices. SANs centralize the process for the storage and administration of data. These devices could be physical or virtual. | ISACA Glossary |
| Structured data | Data that has a predefined data model or is organized in a predefined way. | NIST SP 1500-1 Rev. 2 |


settings. 



| Term | Definition | Source |
| --- | --- | --- |
| Supply chain | A system of organizations, people, activities, information, and resources, possibly international in scope, that provides products or services to consumers. | NIST Glossary |
| Supply chain risk management | The implementation of processes, tools, or techniques to minimize the adverse impact of attacks that allow the adversary to utilize implants or other vulnerabilities inserted prior to installation in order to infiltrate data, or manipulate information technology hardware, software, operating systems, peripherals (information technology products) or services at any point during the life cycle. | NIST Glossary |
|  | The implementation of processes, tools, or techniques to minimize the adverse impact of attacks that allow the adversary to exploit vulnerabilities inserted prior to installation. This is done in order to infiltrate data, or manipulate information technology hardware, software, operating systems, peripherals (information technology products) or services at any point during the supply chain (e.g., initial production, packaging, handling, storage, transport, mission operation, and disposal). | FFIEC Adapted for Supervisory Purposes |
| Switch | segments. A network device that filters and forwards packets between LAN | NIST Glossary |
| System | more stated purposes. A combination of interacting elements organized to achieve one or | NIST Glossary |
| System and organization controls (SOC) | The suite of services practitioners may provide relating to system- level controls of a service organization and system- or entity-level controls of other organizations. Formerly, SOC referred to service organization controls. By redefining that acronym, the AICPA enables the introduction of new internal control examinations that may be performed (a) for other types of organizations, in addition to service organizations, and (b) on either system-level or entity-level controls of such organizations. | AICPA |
| System development life cycle (SDLC) | The scope of activities associated with a system, encompassing the system’s initiation, development and acquisition, implementation, operation and maintenance, and ultimately its disposal that instigates another system initiation. | NIST Glossary |
|  | T | |
| Tele- communications | The transmission, between or among points specified by the user, of information of the user’s choosing, without change in the form or content of the information as sent and received. | NIST Glossary |
| Tenant | One who has the occupation or temporary possession of lands or tenements of another. | Merriam-Webster |
|  | In the context of a computing environment, a customer that utilizes assets (e.g., shared applications or computing resources) or occupies space of another (e.g., cloud service provider). | FFIEC Adapted for Supervisory Purposes |
| Test | An evaluation tool that uses quantifiable metrics to validate the operability of a system or system component in an operational environment specified in an IT plan. | NIST Glossary |



| Term | Definition | Source |
| --- | --- | --- |
| Third-party service provider | Any independent party to whom an entity outsources activities that the entity itself is authorized to perform, including a technology service provider. | FFIEC Developed for Supervisory Purposes |
| Timestamp | A token or packet of information that is used to provide assurance of timeliness; the timestamp contains timestamped data, including a time, and a signature generated by a Trusted Timestamp Authority. | NIST Glossary |
| Transmission | An act, process, or instance of transmitting. | Merriam-Webster |
|  | The act of sending or conveying data, voice, audio, or video from one person or place to another. | FFIEC Adapted for Supervisory Purposes |
| Transmission control protocol/internet protocol | A set of communications protocols used for the exchange of information over networks and especially over the Internet. | Merriam-Webster |
| Trojan horse (trojan) | A useful or seemingly useful program that contains hidden code of a malicious nature that executes when the program is invoked. | NIST Glossary |
| Trusted timestamp | An entity that is trusted to provide accurate time information. | NIST Glossary |
| Tunneling | Technology enabling one network to send its data via another network’s connections. Tunneling works by encapsulating a network protocol within packets carried by the second network. | NIST Glossary |
|  | U | |
| Uninterruptible power supply (UPS) | A device with an internal battery that allows connected devices to run for at least a short time when the primary power source is lost. | NIST Glossary |
| Unstructured data | Data that does not have a predefined data model or is not organized in a predefined way. | NIST SP 1500-1 Rev. 2 |
| Uptime | Time during which a piece of equipment (such as a computer) is functioning or able to function. | Merriam-Webster |
| Useful life | The normal expected operating life of an asset. | Service Internal Revenue |
| Utility software (utilities) | Type of system software that allow users to perform maintenance types of tasks, usually relating to managing a computer’s devices or programs. Most OSs include several utility programs, including file compression, defragmentation, diagnostics, and performance optimization. | FFIEC Developed for Supervisory Purposes |
|  | V | |
| Virtualization | The simulation of the software and/or hardware upon which other software runs. | NIST Glossary |
| Virtual machine * (VM) | Software that allows a single host to run one or more guest operating systems. | NIST Glossary |

(TCP/IP) 

authority 

Term Definition Source 

A simulated environment created by virtualization using software that 

allows a single host to run one or more guest operating systems. 

A technology that allows you to make voice calls using a broadband 

Internet connection instead of a regular (or analog) phone line. An automated telephone answering system consisting of hardware 

and software that allows a caller to interact with a phone keypad or 

through voice recognition. Sometimes referred to as an interactive 

voice response (IVR) unit. 

internal controls, etc., that could be accidentally triggered or intentionally exploited and result in a violation of the system’s security policy. FFIEC Adapted for 

Supervisory Purposes 

Federal 

Communications 

Commission (FCC) 

FFIEC Developed 

Definition for 

Supervisory 

Purposes 

NIST Glossary 

Voice over 

internet protocol 

(VoIP) 

Voice response 

unit (VRU) 

Vulnerability Weakness in system security procedures, design, implementation, 

Vulnerability 

assessment 

Systematic examination of an information system or product to 

determine the adequacy of security and privacy measures, identify security and privacy deficiencies, provide data from which to predict the effectiveness of proposed security and privacy measures, and confirm the adequacy of such measures after implementation. 

NIST Glossary 

Vulnerability 

management Vulnerability management (continuous) is a process to (continuously) 

acquire, assess, and take action on new information in order to 

identify vulnerabilities, remediate, and minimize the window of opportunity for attackers. Center for Internet 

Security Glossary 

W 

Z 

NIST Glossary 

for requester entities, enabling them to access Web services transparently from any device at virtually any location. 

numbers, runtime processes, or applications that are authorized to be present or active on a system according to a well-defined baseline. 

NIST Glossary 

Worm A computer program that can run independently, can propagate a 

complete working version of itself onto other hosts on a network, and may consume computer resources destructively. 

NIST Glossary 

Workstation A computer used for tasks such as programming, engineering, and 

design. 

NIST Glossary 

Web portal Provides a single point of entry into the [service-oriented architecture] 

Whitelist A list of discrete entities, such as hosts, email addresses, network port 

Zero trust 

architecture 

An enterprise cybersecurity strategy that is based on zero trust 

principles and designed to prevent data breaches and limit internal lateral movement. 

NIST SP 800-207 

# APPENDIX C: ABBREVIATIONS 

ACF2 Access Control Facility 

AI artificial intelligence 

AICPA American Institute of Certified Public Accountants 

AIO architecture, infrastructure, and operations 

API application programming interface 

BYOD bring your own device 

CDO chief data officer 

CFPB Consumer Financial Protection Bureau 

CIO chief information officer 

CIS Center for Internet Security 

COTS commercial off-the-shelf 

CPU central processing unit 

CRM customer relationship management 

CTO chief technology officer 

DBA database administrator 

DHCP dynamic host configuration protocol 

DNS domain name system or domain name service 

DDOS distributed denial of service 

DOS denial of service 

EA enterprise architecture 

EOL end-of-life 

ERM enterprise risk management 

ERP enterprise resource planning 

FDIC Federal Deposit Insurance Corporation 

FFIEC Federal Financial Institutions Examination Council 

FRB Board of Governors of the Federal Reserve System 

HVAC heating, ventilation, and air conditioning 

IaaS infrastructure as a service 

IAM identity and access management IDS/IPS intrusion detection and prevention system 

IoT internet of things 

IP internet protocol 

ISO International Organization for Standardization 

IT information technology 

ITAM information technology asset management 

KPI key performance indicator 

KRI key risk indicator 

LAN local area network 

MAC media access control 

MAN metropolitan area network 

ML machine learning 

NCUA National Credit Union Administration 

NIST National Institute of Standards and Technology 

NOC network operations center 



| OCC | Office of the Comptroller of the Currency |
| --- | --- |
| OS | operating system |
| PaaS | platform as a service |
| PCI DSS | Payment Card Industry Data Security Standard |
| PIN | personal identification number |
| PSTN | public switched telephone network |
| RACF | Resource Access Control Facility |
| SaaS | software as a service |
| SAN | storage area network |
| SCM | supply chain management |
| SIEM | security information and event management |
| SLA | service-level agreement |
| SLC | State Liaison Committee |
| SOC | security operations center |
| SOC | system and organization controls |
| SOX | Sarbanes–Oxley Act |
| SPM | service portfolio management |
| TCP/IP | transmission control protocol/internet protocol |
| TOGAF | The Open Group Architecture Framework |
| UPS | uninterruptible power supply |
| VM | virtual machine |
| VoIP | voice over internet protocol |
| VPN | virtual private network |
| WAN | wide area network |
| ZTA | zero trust architecture |

# APPENDIX D: REFERENCES 

Laws 

12 U.S.C. 1861–1867, “Bank Service Company Act” 12 U.S.C. 1882, “Bank Protection Act” 

12 U.S.C. 5481(14) and (26), 5514, 5515, and 5531, “Consumer Financial Protection Act of 2010” 

15 U.S.C. 1681w, “Fair and Accurate Credit Transactions Act” 15 U.S.C. 6801 and 6805(b), “Gramm–Leach–Bliley Act” 

18 U.S.C. 1030, “Fraud and Related Activity in Connection With Computers” 

Consumer Financial Protection Bureau 

## Regulations 

12 CFR 1005, “Electronic Fund Transfers (Regulation E)” 

12 CFR 1016, “Privacy of Consumer Financial Information (Regulation P)” 12 CFR 1022, “Fair Credit Reporting Act (Regulation V)” 

## Guidance 

CFPB Compliance Bulletin and Policy Guidance; “2016-02: Service Providers” (October 2016) 

Federal Deposit Insurance Corporation 

## Regulations 

12 CFR 304.3(d), “Notification of Performance of Bank Services, Form FDIC 6120/06” 12 CFR 326, subpart A, “Minimum Security Procedures” 12 CFR 332, “Privacy of Consumer Financial Information” 

12 CFR 364, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” 

## Guidance 

FIL-103-2020, “Sound Practices to Strengthen Operational Resilience” (November 2, 2020) FIL-52-2020, “FFIEC Joint Statement on Risk Management for Cloud Computing Services” (April 30, 2020) 

FIL-25-2020, “Identification of Essential Critical Infrastructure Workers During the COVID- 19 Response Efforts” (March 26, 2020) 

FIL-14-2020, “Interagency Statement on Pandemic Planning” (March 6, 2020) FIL-19-2019, “Technology Service Provider Contracts” (April 2, 2019) FIL-63-2018, “Cybersecurity Preparedness Resource” (October 19, 2018) FIL-16-2018, “FFIEC Issues Joint Statement: Cyber Insurance and Its Potential Role in Risk Management Programs” (April 10, 2018) 

FIL-68-2016, “FFIEC Cybersecurity Assessment Tool: Frequently Asked Questions” (October 18, 2016) 

FIL-43-2016, “Information Technology Risk Examination (InTREx) Program” (June 30, 2016) 

FIL-37-2016, “FFIEC Joint Statement on Cybersecurity of Interbank Messaging and Wholesale Payment Networks” (June 7, 2016) 

FIL-55-2015, “Cybersecurity Awareness Resources” (November 23, 2015) FIL-28-2015, “Cybersecurity Assessment Tool” (July 2, 2015) FIL-13-2015, “FFIEC Joint Statements on Destructive Malware and Compromised Credentials” (March 30, 2015)` 

FIL-49-2014, “Technology Alert: GNU Bourne-Again Shell (Bash) Vulnerability” (September 29, 2014) 

FIL-16-2014, “Technology Alert: OpenSSL "Heartbleed" Vulnerability” (April 11, 2014) FIL-13-2014, “Technology Outsourcing: Informational Tools for Community Bankers” (April 7, 2014) 

FIL-11-2014, “Distributed Denial of Service (DDoS) Attacks” (April 2, 2014) FIL-44-2008, “Third-Party Risk: Guidance for Managing Third-Party Risk” (June 6, 2008) FIL-77-2006, “Authentication in an Internet Banking Environment: Frequently Asked Questions” (August 21, 2006) 

FIL-103-2005, “FFIEC Guidance: Authentication in an Internet Banking Environment” (October 12, 2005) 

FIL-84-2002, “Financial and Banking Information Infrastructure Committee’s Interim Policy on the Sponsorship of Private Sector Financial Institutions in the GETS Card Program” (August 6, 2002) 

FIL-50-2001, “Bank Technology Bulletin on Outsourcing” (June 4, 2001) 

Federal Reserve 

## Regulations 

Regulation H, 12 CFR 208, appendix D-1, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards” 

Regulation H, 12 CFR 208.61, “Bank security procedures” 

Regulation K, 12 CFR 211.5 and 211.24 (i), “Protection of Customer and Consumer Information” 

Regulation Y, 12 CFR 225, Appendix F, “Interagency Guidelines Establishing Information Security Standards” 

## Guidance 

SR Letter 20-24, “Interagency Paper on Sound Practices to Strengthen Operational Resilience” (November 2, 2020) 

SR Letter 20-6, “Identification of Essential Critical Infrastructure Workers in the Financial Services Sector During the COVID-19 Response” (March 27, 2020) 

SR Letter 20-3/CA Letter 20-2, “Interagency Statement on Pandemic Planning” (March 10, 2020) 

SR Letter 16-11, “Supervisory Guidance for Assessing Risk Management at Supervised Institutions With Total Consolidated Assets Less than $50 Billion” (June 8, 2016) 

SR Letter 15-9, “FFIEC Cybersecurity Assessment Tool for Chief Executive Officers and Boards of Directors” (July 2, 2015) 

SR Letter 13-19/CA Letter 13-21, “Guidance on Managing Outsourcing Risk” (December 5, 2013) 

SR Letter 13-16, “End of Microsoft Support for Windows XP Operating System” (October 7, 2013) 

SR Letter 12-17 / CA 12-14, "Consolidated Supervision Framework for Large Financial Institutions" (December 17, 2012) 

SR Letter 11-9, “Interagency Supplement to Authentication in an Internet Banking Environment” (June 29, 2011) 

SR Letter 06-13, “Questions and Answers Related to Interagency Guidance on Authentication in an Internet Banking Environment” (August 16, 2006) 

SR Letter 05-19, “Interagency Guidance on Authentication in an Internet Banking Environment” (October 13, 2005) 

SR Letter 05-23/ CA 05-10, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” (December 1, 2005) 

SR Letter 04-17, “FFIEC Guidance on the Use of Free and Open Source Software” (December 6, 2004) 

SR Letter 01-15, “Standards for Safeguarding Customer Information” (May 31, 2001) SR Letter 00-17, “Guidance on the Risk Management of Outsourced Technology Services” (November 30, 2000) 

SR Letter 99-8, “Uniform Rating System for Information Technology” (March 31, 1999) SR Letter 98-9, “Assessment of Information Technology in the Risk-Focused Frameworks for the Supervision of Community Banks and Large Complex Banking Organizations” (April 20, 1998) 

SR Letter 96-14, “Risk-focused Safety and Soundness Examinations and Inspections” (May 24, 1996) 

National Credit Union Administration 

## Regulations 

12 CFR 748, “Security Program, Report of Suspected Crimes, Suspicious Transactions, Catastrophic Acts and Bank Secrecy Act Compliance” 12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information” 

12 CFR 749, “Guidelines for Safeguarding Member Information, Records Preservation Program and Appendices—Record Retention Guidelines; Catastrophic Act Preparedness Guidelines” 

12 CFR 749, appendix A, “Record Preservation Program and Record Retention” 

## Guidance 

NCUA Letter to Credit Unions 20-CU-03, “Identification of Essential Critical Infrastructure Workers During COVID-19” (March 2020) 

NCUA Letter to Credit Unions 20-CU-02, “NCUA Actions Related to COVID-19” (March 2020) 

NCUA Letter to Credit Unions 11-CU-09, “Online Member Authentication Guidance Compliance by January 2012” (June 2011) 

NCUA Letter to Credit Unions 07-CU-13, “Evaluating Third-Party Relationships” (December 2007) 

NCUA Letter to Credit Unions 06-CU-10, “NCUAs Information System and Technology IST Program” (June 2006) 

NCUA Letter to Credit Unions 06-CU-07, “IT Security Compliance Guide for Credit Unions” (April 2006) 

NCUA Letter to Credit Unions 06-CU-06, “Influenza Pandemic Preparedness” (March 2006) NCUA Letter to Credit Unions 05-CU-18, “Guidance on Authentication in Internet Banking Environment” (November 2005) 

NCUA Letter to Credit Unions 04-CU-14, “Risk Management of Free and Open Source Software” (November 2004) 

NCUA Letter to Credit Unions 03-CU-03, “Wireless Technology” (February 2003) NCUA Letter to Credit Unions 01-CU-20, “Due Diligence Over Third-Party Service Providers” (November 2001) 

NCUA Letter to Credit Unions 00-CU-11, “Risk Management of Outsourced Technology Services” (December 2000) 

## Risk Alerts 

NCUA Letter to Credit Unions 09-RISK-01, “Information Systems & Technology” (August 2009) 

NCUA Letter to Credit Unions 06-RISK-01, “Disaster Planning and Response” (April 2006) 

Office of the Comptroller of the Currency 

## Regulations 

12 CFR 5.30, “Establishment, Acquisition, and Relocation of a Branch of a National Bank” 12 CFR 5.31, “Establishment, Acquisition, and Relocation of a Branch and Establishment of an Agency Office of a Federal Savings Association” 

12 CFR 30, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 30, appendix D, “OCC Guidelines Establishing Heightened Standards for Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

12 CFR 30, appendix E, “OCC Guidelines Establishing Standards for Recovery Planning by Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

12 CFR 41.83, “Proper Disposal of Records Containing Consumer Information” 

## Guidance 

OCC Bulletin 2020-144, “Sound Practices to Strengthen Operational Resilience” (November 2, 2020) 

OCC Bulletin 2020-23, “Pandemic Planning: Essential Critical Infrastructure Workers in the Financial Services Sector” (March 25, 2020) 

OCC Bulletin 2020-13, “Pandemic Planning: Updated FFIEC Guidance” (March 6, 2020) OCC Bulletin 2020-10, “Third-Party Relationships: Frequently Asked Questions to Supplement OCC Bulletin 2013-29” (March 5, 2020) 

OCC Bulletin 2019-13, “Recovery Planning” (March 15, 2019) 

OCC Bulletin 2018-8, “FFIEC Joint Statement on Cyber Insurance and Its Potential Role in Risk Management Programs” (April 11, 2018) 

OCC Bulletin 2017-7, “Third-Party Relationships: Supplemental Examination Procedures” (January 24, 2017) 

OCC Bulletin 2016-34, “Cybersecurity: Frequently Asked Questions on the FFIEC Cybersecurity Assessment Tool” (October 17, 2016) 

OCC Bulletin 2016-18, “FFIEC Statement: Cybersecurity of Interbank Messaging and Wholesale Payment Networks” (June 7, 2016) 

OCC Bulletin 2015-40, “Cybersecurity: Joint Statement on Cyber Attacks Involving Extortion” (November 3, 2015) 

OCC Bulletin 2015-31, “Cybersecurity: FFIEC Cybersecurity Assessment Tool” (June 30, 2015) 

OCC Bulletin 2015-20, “Cybersecurity: Destructive Malware Joint Statement” (March 30, 2015) 

OCC Bulletin 2015-19, “Cybersecurity: Cyber Attacks Compromising Credentials Joint Statement” (March 30, 2015) 

OCC Bulletin 2014-48, “FFIEC Alert: Bourne-Again Shell (Bash) “Shellshock” Vulnerability” (September 26, 2014) 

OCC Bulletin 2014-17, “Joint Statement: Information Security Vulnerability in OpenSSL Encryption Tool (Heartbleed)” (April 25, 2014) 

OCC Bulletin 2013-29, “Third-Party Relationships: Risk Management Guidance” October 17, 2016 

OCC Bulletin 2011-26, “Authentication in an Internet Banking Environment: Supplement” (June 28, 2011) 

OCC Bulletin 2008-16, “Information Security: Application Security” (May 8, 2008) 

OCC Bulletin 2006-35, “Authentication in an Internet Banking Environment: Frequently Asked Questions” (August 15, 2006) 

OCC Bulletin 2005-35, “Interagency Guidance: Authentication in an Internet Banking Environment” (October 12, 2005) 

OCC Bulletin 2004-47, “FFIEC Guidance: Risk Management for the Use of Free and Open Source Software” (October 27, 2004) 

OCC Bulletin 2003-14, “Interagency White Paper on Sound Practices to Strengthen the Resilience of the U.S. Financial System” (April 8, 2003) 

OCC Bulletin 2003-13, “Telecommunications Service Priority (TSP) Program: FBIIC Policy on Sponsorship of TSP for Private Sector Entities” (March 27, 2003) 

OCC Bulletin 2002-33, “Government Emergency Telecommunications Service (GETS): FBIIC Policy on Sponsorship of GETS Cards for Private Sector Entities” (July 23, 2002) OCC Bulletin 2002-16, “Bank Use of Foreign-Based Third-Party Service Providers: Risk Management Guidance” (May 15, 2002) 

OCC Bulletin 1998-3, “Technology Risk Management: Guidance for Bankers and Examiners” (February 4, 1998) 

Other References 

American Institute of Certified Public Accountants (AICPA), SOC 2 Examinations and SOC for Cybersecurity Examinations: Understanding the Key Distinctions (2017) 

Center for Internet Security (CIS), Control 3: Continuous Vulnerability Management (March 2017) 

Financial Services Information Sharing and Analysis Center, FS-ISAC 

International Organization for Standardization / International Electrotechnical Commission, ISO/IEC 27002:2013, Information Security Management Section 11: Physical and Environmental Security (October 2013) 

Internet Engineering Task Force (IETF), RFC 7591 OAuth 2.0 Dynamic Client Registration Protocol (July 2015) 

Martzloff, François, A New IEC Standard on the Measurement of Power Quality Parameters (2000) 

## National Institute of Standards and Technology (NIST) Resources: 

### National Checklist Program NIST Glossary 

#### SP 800-53 Rev. 5, Security and Privacy Controls for Information Systems and Organizations (September 2020) 

ITL Bulletin, Security Considerations for Exchanging Files Over the Internet (August 2020) SP 800-207, Zero Trust Architecture (August 2020) 

#### SP 800-210, General Access Control Guidance for Cloud Systems (July 2020) 

#### SP 800-204A, Building Secure Microservices-based Applications Using Service-Mesh Architecture (May 2020) 

ITL Bulletin, Security for Enterprise Telework, Remote Access, and Bring Your Own Device (BYOD) Solutions (March 2020) 

SP 800-160 Volume 2, Developing Cyber Resilient Systems: A Systems Security Engineering Approach (November 2019) 

#### NIST Big Data Interoperability Framework: Volume 1, Definitions (October 2019) 

SP 800-204, Security Strategies for Microservices-based Application Systems (August 2019) IR 8228, Considerations for Managing Internet of Things (IoT) Cybersecurity and Privacy Risks (June 2019) 

S 6106.01, Open Source Code (December 2018) SP 1800-5, IT Asset Management (September 2018) 

#### SP 500-316, Framework for Cloud Usability (December 2015) 

#### SP 800-146, Cloud Computing Synopsis and Recommendations (May 2012) 

#### SP 500-292, NIST Cloud Computing Reference Architecture: Recommendations of the National Institute of Standards and Technology (September 2011) 

#### SP 800-145, The NIST Definition of Cloud Computing: Recommendations of the National Institute of Standards and Technology (September 2011) 

SP 800-125, Guide to Security for Full Virtualization Technologies (January 2011) SP 800-28, Guidelines on Active Content and Mobile Code (March 2008) NCSTAR 1-4B, Fire Suppression Systems (September 2005) 

#### SP 800-58, Security Considerations for Voice Over IP Systems (January 2005) 

Open Web Application Security Project (OWASP) Foundation, OWASP API Security Project (2019) 

U.S. Department of Defense (DoD), Summary of the 2018 Department Of Defense Artificial Intelligence Strategy: Harnessing AI to Advance Our Security and Prosperity (2019) 

U.S. Department of the Treasury, Data Governance Board Charter (January 2020) 

Federal Financial Institutions Examination Council 

> FFIEC 

Audit 

AUD 

April 2012 

IT EXAMINATION 

##### HANDBOOK 

Table of Contents 



| Introduction | 1 |
| --- | --- |
| IT Audit Roles and Responsibilities | 2 |
| Board of Directors and Senior Management | 2 |
| Audit Management | 4 |
| Internal IT Audit Staff | 4 |
| Operating Management | 5 |
| External Auditors | 5 |
| Independence and Staffing of Internal IT Audit | 6 |
| Independence | 6 |
| Staffing | 7 |
| Internal Audit Program | 7 |
| Risk Assessment and Risk-Based Auditing | 10 |
| Program Elements | 10 |
| Risk Scoring System | 11 |
| Audit Participation in Application Development, Acquisition, Conversions, and Testing | 13 |
| Outsourcing Internal IT Audit | 14 |
| Independence of the External Auditor Providing Internal Audit Services | 15 |
| Examples of Arrangements | 15 |
| Third-Party Reviews of Technology Service Providers | 17 |
| Appendix A: Examination Procedures | A-1 |
| Appendix B: Glossary | B-1 |
| Appendix C: Laws, Regulations, and Guidance | C-1 |

## Introduction 

This "Audit Booklet" is one of several booklets that comprise the Federal Financial Institutions Examination Council (FFIEC) Information Technology Examination Handbook (IT Handbook) and provides guidance to examiners and financial institutions on the characteristics of an effective information technology (IT) audit function. [1] This booklet replaces and rescinds Chapter 8 of the 1996 FFIEC Information Systems Examination Handbook. It should beused by examiners of the FFIEC member agencies [2] as a foundation from which they can assess the quality and effectiveness of an institution's IT audit program. It describes the roles and responsibilities of the board of directors, management, and internal or external auditors; identifies effective practices for IT audit programs; and details examination objectives and procedures. Agency examiners will use the examination procedures in Appendix A to assess the adequacy of IT audit programs at both financial institutions and technology service providers.The examination guidance and procedures in this booklet focus on IT audit and supplement other, more general, internal and external audit guidance provided by the FFIEC agencies. [3] 

A well-planned, properly structured audit program is essential to evaluate risk management practices, internal control systems,and compliance with corporate policies concerning IT-related risks at institutions of every size and complexity. Effective audit programs are risk-focused, promote sound IT controls, ensure the timely resolution of audit deficiencies, and inform the board of directors of the effectiveness of risk management practices. An effective IT audit function may also reduce the time examiners spend reviewing areas of the institution during examinations. Ideally, the audit program would consist of a full-time, continuous program of internal audit coupled with a well-planned external auditing program. 

The financial industry must plan, manage, and monitor rapidly changing technologies to enable it to deliver and support new products, services, and delivery channels. The rate of these changes and the resulting increased reliance on technology make the inclusion of IT audit coverage essential to an effective over all audit program. The audit program should address IT risk exposures throughout the institution, including the areas of IT management and strategic planning, data center operations, client/server architecture, local and wide-area networks, telecommunications, physical and information security, electronic banking, systems development, and business continuity planning. IT audit should also focus on how management determines the risk exposure from its operations and controls or mitigates that risk. 

To determine what risks exist, management should prepare an independent assessment of the institution's risk exposure and the quality of the internal controls associated with the development, acquisition, implementation, and use of information technology. An institution's IT audit function can provide this independent assessment within the context of the overall audit function and can include work performed by both internal and external auditors and by other independent third parties as appropriate for the institution's complexity and level of internal expertise. The FFIEC member agencies believe that a strong internal auditing function combined with a well-planned external auditing function substantially increase the probability that an institution will detect potentially serious technology-related problems. An effective IT audit program should: 

* • Identify areas of greatest IT risk exposure to the institution in order to focus audit resources;
* • Promote the confidentiality, integrity, and availability of information systems;
* • Determine the effectiveness of management's planning and oversight of IT activities;
* • Evaluate the adequacy of operating processes and internal controls;
* • Determine the adequacy of enterprise-wide compliance efforts related to IT policies and internal control procedures; and
* • Require appropriate corrective action to address deficient internal controls and follow up to ensure management promptly and effectively implements the required actions.

The examiner is responsible for evaluating the effectiveness of the IT audit function in meeting these objectives. The examiner should also consider the institution's ability to promptly detect and report significant risks to the board of directors and senior management. Examiners should take into account the institution's size, complexity, and overall risk profile when performing this and other evaluations. Examiners should consider the following issues when evaluating the IT audit function: 

* • Independence of the audit function and its reporting relationship to the board of directors or its audit committee;
* • Expertise and size of the audit staff relative to the IT environment;
* • Identification of the IT audit universe, risk assessment, scope, and frequency of IT audits;
* • Processes in place to ensure timely tracking and resolution of reported weaknesses; and
* • Documentation of IT audits, including work papers, audit reports, and follow-up.
## IT Audit Roles and Responsibilities 

### Board of Directors and Senior Management 

The board of directors and senior management are responsible for ensuring that the institution's system of internal controls operates effectively. One important element of an effective internal control system is an internal audit function that includes adequate IT coverage. 

To meet its responsibility of providing an independent audit function with sufficient resources to ensure adequate IT coverage, the board of directors or its audit committee should: 

* • Provide an internal audit function capable of evaluating IT controls,
* • Engage outside consultants or auditors to perform the internal audit function, or
* • Use a combination of both methods to ensure that the institution has received adequate IT audit coverage.

An institution's board of directors may establish an "audit committee" to oversee audit functions and to report on audit matters periodically to the full board of directors. For purposes of this booklet, the term "audit committee" means the committee with audit oversight regardless of the type of financial institution. [4] Audit committee members should have a clear understanding of the importance and necessity of an independent audit function. 

To comply with the Sarbanes-Oxley Act of 2002, [5] public stock-issuing institutions are required to appoint outside directors as audit committee members. All members of a stock-issuing institution's audit committee must be members of the board of directors and be independent (i.e., not otherwise compensated by, or affiliated with, the institution). Additionally, 12 CFR 363 (Federal Deposit Insurance Corporation Improvement Act, or FDICIA) requires all depository institutions with total assets greater than $500 million to have independent audit committees. Although not all institutions are subject to these requirements due to their corporate structure (Sarbanes-Oxley) or their size (FDICIA), it is generally considered good practice that they use them as guidelines to ensure the independence of their audit committees. 

The board of directors should ensure that written guidelines for conducting IT audits have been adopted. The board of directors or its audit committee should assign responsibility for the internal audit function to a member of management (hereafter referred to as the "internal audit manager") who has sufficient audit expertise and is independent of the operations of the business. 

The board should give careful thought to the placement of the audit function in relation to the institution's management structure. The board should have confidence that the internal audit staff members will perform their duties with impartiality and not be unduly influenced by senior management and managers of day-to-day operations. Accordingly, the internal audit manager should report directly to the board of directors or its audit committee. 

The board or its audit committee is responsible for reviewing and approving audit strategies (including policies and programs), and monitoring the effectiveness of the audit function. The board or its audit committee should be aware of, and understand, significant risks and control issues associated with the institution's operations, including risks in new products, emerging technologies, information systems, and electronic banking. Control issues and risks associated with reliance on technology can include: 

* • Inappropriate user access to information systems,
* • Unauthorized disclosure of confidential information,
* • Unreliable or costly implementation of IT solutions,
* • Inadequate alignment between IT systems and business objectives,
* • Inadequate systems for monitoring information processing and transactions,
* • Ineffective training programs for employees and system users,
* • Insufficient due diligence in IT vendor selection,
* • Inadequate segregation of duties,
* • Incomplete or inadequate audit trails,
* • Lack of standards and controls for end-user systems,
* • Ineffective or inadequate business continuity plans, and
* • Financial losses and loss of reputation related to systems outages.

The board or its audit committee members should seek training to fill any gaps in their knowledge related to IT risks and controls. The board of directors or its audit committee should periodically meet with both internal and external auditors to discuss audit work performed and conclusions reached on IT systems and controls. 

### Audit Management 

The internal audit manager is responsible for implementing board-approved audit directives. The manager oversees the audit function and provides leadership and direction in communicating and monitoring audit policies, practices, programs, and processes. The internal audit manager should establish clear lines of authority and reporting responsibility for all levels of audit personnel and activities. The internal audit manager also should ensure that members of the audit staff possess the necessary independence, experience, education, training, and skills to properly conduct assigned activities. 

The internal audit manager should be responsible for internal control risk assessments, audit plans, audit programs, and audit reports associated with IT. Audit management should oversee the staff assigned to perform the internal audit work, should establish policies and procedures to guide the audit staff, and should ensure the staff has the expertise and resources to identify inherent risks and assess the effectiveness of internal controls in the institution's IT operations. 

### Internal IT Audit Staff 

The primary role of the internal IT audit staff is to assess independently and objectively the controls, reliability, and integrity of the institution's IT environment. These assessments can help maintain or improve the efficiency and effectiveness of the institution's IT risk management, internal controls, and corporate governance. 

Internal auditors should evaluate IT plans, strategies, policies, and procedures to ensure adequate management oversight. Additionally, they should assess the day-to-day IT controls to ensure that transactions are recorded and processed in compliance with acceptable accounting methods and standards and are in compliance with policies set forth by the board of directors and senior management. Auditors also perform operational audits, including system development audits, to ensure that internal controls are in place, that policies and procedures are effective, and that employees operate in compliance with approved policies. Auditors should identify weaknesses, review management's plans for addressing those weaknesses, monitor their resolution, and report to the board as necessary on material weaknesses. 

Auditors should make recommendations to management about procedures that affect IT controls. In this regard, the board and management should involve the audit department in the development process for major new IT applications. The board and management should develop criteria for determining those projects that need audit involvement. Audit's role generally entails reviewing the control aspects of new applications, products, conversions, or services throughout their development and implementation. Early IT audit involvement can help ensure that proper controls are in place from inception. However, the auditors should be careful not to compromise, or even appear to compromise, their independence when involved in these projects. 

### Operating Management 

Operating management should formally and effectively respond to IT audit or examination findings and recommendations. The audit procedures should clearly identify the methods for following up on noted audit or control exceptions or weaknesses. Operating management is responsible for correcting the root causes of the audit or control exceptions, not just treating the exceptions themselves. Response times for correcting noted deficiencies should be reasonable and may vary depending on the complexity of the corrective action and the risk of inaction. Auditors should document, report, and track recommendations and outstanding deficiencies. Additionally, auditors should conduct timely follow-up audits to verify the effectiveness of management's corrective actions for significant deficiencies. 

### External Auditors 

External auditors typically review IT control procedures as part of their overall evaluation of internal controls when providing an opinion on the adequacy of an institution's financial statements. As a rule, external auditors review the general and application controls affecting the recording and safeguarding of assets and the integrity of controls over financial statement preparation and reporting. General controls include the plan of organization and operation, documentation procedures, access to equipment and data files, and other controls affecting overall information systems operations. Application controls relate to specific information systems tasks and provide reasonable assurance that the recording, processing, and reporting of data are properly performed. 

External auditors may also review the IT control procedures as part of an outsourcing arrangement in which they are engaged to perform all or part of the duties of the internal audit staff. Such arrangements are discussed in more detail in the "Outsourcing Internal IT Audit" section of this booklet. 

The extent of external audit work, including work related to information systems, should be clearly defined in an engagement letter. Such letters should discuss the scope of the audit, the objectives, resource requirements, audit timeframe, and resulting reports. Examiners will typically review the engagement letter, reports, and audit work papers to determine the extent to which they can rely on external audit coverage and reduce their examination scope accordingly. 

## Independence and Staffing of Internal IT Audit 

### Independence 

The ability of the internal audit function to achieve desired objectives depends largely on the independence of audit personnel. Generally, the position of the auditor within the organizational structure of the institution, the reporting authority for audit results, and the auditor's responsibilities indicate the degree of auditor independence. The board should ensure that the audit department does not participate in activities that may compromise, or appear to compromise, its independence. These activities may include preparing reports or records, developing procedures, or performing other operational duties normally reviewed by auditors. 

The auditor's independence is also determined by analyzing the reporting process and verifying that management does not interfere with the candor of the findings and recommendations. For an effective program, the board should give the auditor the authority to: 

* • Access all records and staff necessary to conduct the audit, and
* • Require management to respond formally, and in a timely manner, to significant adverse audit findings by taking appropriate corrective action.

Internal auditors should discuss their findings and recommendations periodically with the audit committee or board of directors. 

Ideally, the internal audit manager should report directly to the board of directors or its audit committee regarding both audit issues and administrative matters. [6] Alternatively, an institution may establish a dual reporting relationship where the internal audit manager reports to the audit committee or board for audit matters and to institution executive management for administrative matters. The objectivity and organizational stature of the internal audit function are best served under such a dual arrangement if the internal audit manager reports administratively to the chief executive office (CEO), and not to the chief financial officer (CFO) or a similar officer who has a direct responsibility for systems being audited. The board or its audit committee should determine the internal audit manager's performance evaluations and compensation. 

The formality and extent of an institution's internal IT audit function depends on the institution's size, complexity, scope of activities, and risk profile. It is the responsibility of the audit committee and management to carefully consider the extent of auditing that will effectively monitor the internal control system subject to consideration of the internal audit function's costs and benefits. For larger institutions or institutions with complex operations, the benefits derived from a full time manager of internal audit or an audit staff will likely outweigh the cost. For small institutions with few employees and/or simple operations, these costs may outweigh the benefits. Nevertheless, an institution without an internal auditor can ensure that it maintains an objective and independent internal function by implementing comprehensive internal reviews of significant internal controls. The key characteristic of such reviews is that the person(s) directing or performing the review is (are) not also responsible for managing or operating those controls. 

### Staffing 

Personnel performing IT audits should have information systems knowledge commensurate with the scope and sophistication of the institution's IT environment and possess sufficient analytical skills to determine and report the root cause of deficiencies. If internal expertise is inadequate, the board should consider using qualified external sources such as management consultants, independent auditors, or other professionals to supplement or perform the institution's internal IT audit function. In some institutions, a person or group that has no other responsibilities outside the IT audit function performs IT audits. Generally, institutions using this approach centralize IT audit coverage and assign one or more IT audit specialists to perform end-user application control reviews as well as technical system audits. A centralized IT audit department can ensure sufficient technical expertise, but can also strain technical resources and require multiple audits in a user department. Additionally, IT auditors in this environment may need to have a greater understanding of financial and business line audit concerns. 

Other institutions may use an integrated audit approach. Using this method, IT audit specialists perform the technology system and other technical reviews, while generalist auditors perform the end-user application control reviews. Institutions should use auditors with technical knowledge appropriate for the areas reviewed. 

An institution's hiring and training practices should ensure that the institution has qualified IT auditors. The auditor's education and experience should be consistent with job responsibilities. Audit management should also provide an effective program of continuing education and development. As the information systems of an institution become more sophisticated or as more complex technologies evolve, the auditor may need additional training. 

## Internal Audit Program 

### Action Summary 

Management should develop and follow a formal internal audit program consisting of policies and procedures that govern the internal audit function, including IT audit. 

An institution's internal audit program consists of the policies and procedures that govern its internal audit functions, including risk-based auditing programs and outsourced internal audit work, if applicable. While smaller institutions' audit programs may not require the formality of those found in larger, more complex institutions, all audit programs should include 

* • A mission statement or audit charter outlining the purpose, objectives, organization, authorities, and responsibilities of the internal auditor, audit staff, audit management, and the audit committee.
* • A risk assessment process to describe and analyze the risks inherent in a given line of business. Auditors should update the risk assessment at least annually, or more frequently if necessary, to reflect changes to internal control or work processes, and to incorporate new lines of business. The level of risk should be one of the most significant factors considered when determining the frequency of audits.
* • An audit plan detailing internal audit's budgeting and planning processes. The plan should describe audit goals, schedules, staffing needs, and reporting. The audit plan should cover at least 12 months and should be defined by combining the results of the risk assessment and the resources required to yield the timing and frequency of planned internal audits. The audit committee should formally approve the audit plan annually, or review it annually in the case of multi-year audit plans. The internal auditors should report the status of planned versus actual audits, and any changes to the annual audit plan, to the audit committee for its approval on a periodic basis.
* • An audit cycle that identifies the frequency of audits. Auditors usually determine the frequency by performing a risk assessment, as noted above, of areas to be audited. While staff and time availability may influence the audit cycle, they should not be overriding factors in reducing the frequency of audits for high-risk areas.
* • Audit work programs that set out for each audit area the required scope and resources, including the selection of audit procedures, the extent of testing, and the basis for conclusions. Well-planned, properly structured audit programs are essential to strong risk management and to the development of comprehensive internal control systems.
* • Written audit reports informing the board and management of individual department or division compliance with policies and procedures. These reports should state whether operating processes and internal controls are effective, and describe deficiencies as well as suggested corrective actions. The audit manager should consider implementing an audit rating system (for example, satisfactory, needs improvement, unsatisfactory) approved by the audit committee. The rating system facilitates conveying to the board a consistent and concise assessment of the net risk posed by the area or function audited. All written audit reports should reflect the assigned rating for the areas audited.
* • Requirements for audit work paper documentation to ensure clear support for all audit findings and work performed, including work paper retention policies.
* • Follow-up processes that require internal auditors to determine the disposition of any agreed-upon actions to correct significant deficiencies.
* • Professional development programs to be in place for the institution's audit staff to maintain the necessary technical expertise.

All institutions are encouraged to implement risk-based IT audit procedures based on a formal risk assessment methodology to determine the appropriate frequency and extent of work. See the "Risk Assessment and Risk-Based Auditing" section of this booklet for more detail. 

IT audit procedures will vary depending upon the philosophy and technical expertise of the audit department and the sophistication of the data center and end-user systems. However, to achieve effective coverage, the audit program and expertise of the staff must be consistent with the complexity of data processing activities reviewed. The audit procedures may include manual testing processes or computer-assisted audit programs (discussed later in this section). 

The audit department should establish standards for audit work papers, related communications, and retention policies. Auditors should ensure that work papers are well organized, clearly written, and address all areas in the scope of the audit. They should contain sufficient evidence of the tasks performed and support the conclusions reached. Formal procedures should exist to ensure that management and the audit committee receive summarized audit findings that effectively communicate the results of the audit. Full audit reports should be available for review by the audit committee. Policies should establish appropriate work paper retention periods. Institutions should consider conducting their internal audit activities in accordance with professional standards, such as the Standards for the Professional Practice of Internal Auditing issued by the Institute for Internal Auditors (IIA), and those issued by the Standards Board of the Information Systems Audit and Control Association (ISACA). These standards address independence, professional proficiency, scope of work, performance of audit work, management of internal audit, and quality assurance reviews. 

IT auditors frequently use computer-assisted audit techniques (CAATs) to improve audit coverage by reducing the cost of testing and sampling procedures that otherwise would be performed manually. CAATs include many types of tools and techniques, such as generalized audit software, utility software, test data, application software tracing and mapping, and audit expert systems. CAATs may be: 

* • Developed by internal programming staff or by outside programmers with audit department supervision;
* • Purchased generalized audit software, e.g., audit packages offered by CPA firms or software vendors;
* • Developed by IT auditors; or
* • Acquired from equipment manufacturers and software houses to analyze machine, programmer, and operations efficiency.

Whatever the source, audit software programs should remain under the strict control of the audit department. For this reason, all documentation, test material, source listings, source and object program modules, and all changes to such programs, should be strictly controlled. In installations using advanced software library control systems, audit object programs may be catalogued with password protection. This is acceptable if the auditors retain control over the documentation and the appropriate job control instructions necessary to retrieve and execute the object program from the libraries where it is stored. If internal control procedures within the computer system do not allow for strict audit control, audit programs should not be catalogued. Computer programs intended for audit use should be documented carefully to define their purpose and to ensure their continued usefulness and reliability. 

CAATs may be used in performing various audit procedures, including the following: 

* • Tests of transactions and balances, such as recalculating interest;
* • Analytical review procedures, such as identifying inconsistencies or significant fluctuations;
* • Compliance tests of general controls, such as testing the set-up or configuration of the operating system or access procedures to the program libraries;
* • Sampling programs to extract data for audit testing;
* • Compliance tests of application controls such as testing the functioning of a programmed control;
* • Recalculating entries performed by the entity's accounting systems; and
* • Penetration testing.

These tools and techniques can also be used effectively to check data integrity by testing the logical processing of data "through" the system, rather than by relying only on validations of input and output controls. 

## Risk Assessment and Risk-Based Auditing 

### Action Summary 

The board of directors should establish an effective risk-based audit function. 

An effective risk-based auditing program will cover all of an institution's major activities. The frequency and depth of each area's audit will vary according to the risk assessment of that area. Examiners should determine whether the audit function is appropriate for the size and complexity of the institution. 

### Program Elements 

Properly designed risk-based audit programs increase audit efficiency and effectiveness. The sophistication and formality of risk-based audits may vary depending on the institution's size and complexity. To determine the appropriate level of audit coverage for the organization's IT environment, management should define an effective risk assessment methodology. This assessment methodology should provide the auditor and the board with objective information to prioritize the allocation of audit resources properly. Risk-based IT audit programs should: 

* • Identify the institution's data, application and operating systems, technology, facilities, and personnel;
* • Identify the business activities and processes within each of those categories;
* • Include profiles of significant business units, departments, and product lines, or systems, and their associated business risks and control features, resulting in a document describing the structure of risk and controls throughout the institution;
* • Use a measurement or scoring system that ranks and evaluates business and control risks for significant business units, departments, and products;
* • Include board or audit committee approval of risk assessments and annual risk- based audit plans that establish audit schedules, audit cycles, work program scope, and resource allocation for each area audited;
* • Implement the audit plan through planning, execution, reporting, and follow-up; and
* • Include a process that regularly monitors the risk assessment and updates it at least annually for all significant business units, departments, and products or systems.
### Risk Scoring System 

A successful risk-based IT audit program can be based on an effective scoring system. [7] In establishing a scoring system, the board of directors and management should ensure the system is understandable, considers all relevant risk factors, and, to the extent possible, avoids subjectivity. Major risk factors commonly used in scoring systems include the following: 

* • The adequacy of internal controls;
* • The nature of transactions (for example, the number and dollar volumes and the complexity);
* • The age of the system or application;
* • The nature of the operating environment (for example, changes in volume, degree of system and reporting centralization, sensitivity of resident or processed data, the impact on critical business processes, potential financial impact, planned conversions, and economic and regulatory environment);
* • The physical and logical security of information, equipment, and premises;
* • The adequacy of operating management oversight and monitoring;
* • Previous regulatory and audit results and management's responsiveness in addressing issues;
* • Human resources, including the experience of management and staff, turnover, technical competence, management's succession plan, and the degree of delegation; and
* • Senior management oversight.

Auditors should develop written guidelines on the use of risk assessment tools and risk factors and review these guidelines with the audit committee or the board of directors. The sophistication and formality of guidelines will vary for individual institutions depending on their size, complexity, scope of activities, geographic diversity, and various technologies used. The institution can rely on standard industry practice or on its own experiences to define risk scoring. Auditors should use the guidelines to grade or assess major risk areas and to define the range of scores or assessments (e.g., groupings such as low, medium, and high risk or a numerical sequence such as 1 through 5). 

The written risk assessment guidelines should specify the following elements: 

* • A maximum length for audit cycles based on the risk scores. (For example, some institutions set audit cycles at 12 months or less for high-risk areas, 24 months or less for medium-risk areas, and up to 36 months for low-risk areas. Audit cycles should not be open-ended.);
* • The timing of risk assessments for each department or activity. (Normally risks are assessed annually, but more frequent assessments may be needed if the institution experiences rapid growth or significant change in operation or activities.);
* • Documentation requirements to support scoring decisions; and
* • Guidelines for overriding risk assessments in special cases and the circumstances under which they can be overridden. (For example, the guidelines should define who can override assessments, and how the override is approved, reported and documented.)

Numerous industry groups offer resources where institutions can obtain matrices, models, or additional information on risk assessments. Among these groups are: ISACA, American Bankers Association (ABA), American Institute of Certified Public Accountants (AICPA), and IIA. Day-to-day management of the risk-based audit program rests with the internal audit manager, who monitors the audit scope and risk assessments to ensure that audit coverage remains adequate. The internal audit manager also prepares reports showing the risk rating, planned scope, and audit cycle for each area. The audit manager should confirm the risk assessment system's reliability at least annually or whenever significant changes occur within a department or function. Operating department managers and auditors should work together in evaluating the risk in all departments and functions by reviewing risk assessments to determine their reasonableness. 

Auditors should periodically review the results of internal control processes and analyze financial or operational data for any impact on a risk assessment or scoring. Accordingly, operating management should be required to keep auditors up to date on all major changes in departments or functions, such as the introduction of a new product, implementation of a new system, application conversions, or significant changes in organization or staff. 

## Audit Participation in Application Development, Acquisition, Conversions, and Testing 

### Action Summary 

Senior management should involve IT audit in major application development, acquisition, conversion, and testing. 

The development, acquisition, or conversion of an automated application is a lengthy and complex process requiring a significant degree of interaction among the programming staff, user departments, and internal audit. This process, known as the system development life cycle or system development methodology, requires detailed developmental stages to ensure that applications meet the needs of the institution. As each stage of the life cycle is reached, the auditor should review the internal controls, testing, and audit trails included in the application. The incorporation of internal controls within a completed application already in production is usually more difficult and expensive. Guidelines should be developed to facilitate the review of new applications during the design phase so that controls can be identified during independent audit review early in the development process. 

The institution's audit policy, as approved by the board of directors, should include guidelines detailing what involvement internal audit will have in the development, acquisition, conversion, and testing of major applications. This includes describing the monitoring, reporting, and escalation processes (when internal controls are found to be insufficient or when testing is found to be inadequate). For acquisitions, this includes describing the phases of the system development life cycle in which IT audit will be involved. For acquisitions with significant IT impacts, participation of IT audit may be necessary early in the due diligence stage. 

It is necessary that audit's participation in the development process be independent and objective. Auditors can determine and should recommend appropriate controls to project management. However, such recommendations do not necessarily "pre-approve" the controls, but instead guide the developers in considering appropriate control standards and structures throughout their project. The auditors are more than just "consultants" on internal controls. While they should not have any direct involvement in management decisions, they should raise objections if they believe the control environment to be inadequate. 

Once a new application system, conversion, or major revision to an existing system is accepted for production processing, the IT auditor should conduct a post-implementation review. This review should occur shortly after the implementation of the new or revised system and should include extensive testing of program logic, calculations, error conditions, edits, and controls. Such testing helps to validate that the software operates as expected. By performing the review soon after migration to the production environment, the auditors can quickly identify processing errors or other unsatisfactory conditions. A prompt post-implementation review should minimize potential losses from processing errors or ineffective software operation or controls and loss of reputation caused by inaccurate information provided to customers. 

In larger IT facilities, formal quality assurance or change management groups may have primary responsibility for post-implementation reviews. In such cases, the IT auditor may choose not to perform a separate review but instead to participate in establishing the test criteria and evaluating results of any other independent reviews. 

## Outsourcing Internal IT Audit 

### Action Summary 

The board of directors of an institution that outsources its internal IT audit function should ensure that the structure, scope, and management of the outsourcing arrangement provides for an adequate evaluation of the system of internal controls. 

In addressing quality and resource issues, many institutions engage independent public accounting firms and other outside professionals to perform work that has been traditionally carried out by internal auditors. These arrangements are often called "internal audit outsourcing," "internal audit assistance," "audit co-sourcing," or "extended audit services." 

Outsourcing such audit services may be beneficial to an institution if it is properly structured, carefully conducted, and prudently managed. To do this, management should ensure that there are no conflicts of interest and that the use of these services does not compromise independence. Potential conflicts of interest may arise if the outsourced auditing firm performs IT audit functions in addition to other audit services, such as providing the independent financial statement, or serving in an IT or management consulting capacity. The board of directors of an institution remains responsible for ensuring that the outsourced internal audit function operates effectively and complies with all regulations governing such arrangements. 

Examiners should assess whether the structure, scope, and management of an internal audit outsourcing arrangement adequately evaluate the institution's system of internal controls. They should also determine whether or not directors and senior managers have fulfilled their responsibilities for maintaining an effective system of internal controls and for overseeing the internal audit function in an outsourced internal audit environment. 

Additional detailed guidance on the structure, independence, and sound practices concerning the use of outsourcing audit providers is available in the "Interagency Policy Statement on the Internal Audit Function and Its Outsourcing." 

### Independence of the External Auditor Providing Internal Audit Services 

It is important that examiners ensure that management has designed any outsourcing arrangements in order to maintain the independence of the audit provider. An accounting firm hired to perform internal audit services for an institution risks compromising its independence when it also performs the external audit for the institution. Concerns arise because, rather than having an independent review, the responsibility of performing outsourced internal audits places the accounting firm in the position of auditing its own work. For example, in designing procedures to audit an institution's financial statements, the accounting firm considers the extent to which it may rely on the institution's internal control system, including the internal audit function. 

The Sarbanes-Oxley Act of 2002 specifically prohibits a registered public accounting firm from performing certain non-audit services for a public company client for whom it performs financial statement audits. Among those prohibited non-audit services are internal audit outsourcing services and financial information system design and implementation. Under rules adopted by the Securities and Exchange Commission, this prohibition generally became effective on May 6, 2003, although a one-year transition period was provided for contractual arrangements in place as of that date. Under Section 36 of the Federal Deposit Insurance Act and its implementing regulation and guidelines, FDIC-insured depository institutions with total assets of $500 million or more are required to be audited annually. The guidelines require these institutions, whether or not they are public companies, and their external auditors to comply with the SEC's auditor independence requirements. Other non-public institutions are encouraged to have their financial statements audited and to follow the Sarbanes-Oxley Act's prohibition on outsourcing internal audit to their external auditor. However, there are circumstances in which these institutions can use the same accounting firm for both external and internal audit work. 

### Examples of Arrangements 

An outsourcing arrangement is a contract between the institution and an audit services firm to provide internal audit services. Outsourcing arrangements take many forms and are used by institutions of all sizes. The services under contract can be as limited as assisting internal audit staff with an assignment in which they lack expertise. This type of arrangement would typically fall under the control of the institution's internal audit manager, to whom the audit provider would typically report. 

Other outsourcing arrangements may call for an audit provider to perform all or several parts of the internal audit work. Under these types of arrangements, the institution should maintain an internal audit manager and, as appropriate, internal audit staff sufficient to oversee vendor activities. The audit provider usually assists the internal audit function in determining the institution's areas of risk and the levels of risk to be reviewed, and recommends and performs audit procedures approved by the institution's internal audit manager. In addition, the outsourced audit provider should work jointly with the internal audit manager in reporting significant findings to the board or its audit committee. 

Before entering into an outsourcing arrangement, the institution should perform due diligence to ensure that the audit provider has a sufficient number of qualified staff members to perform the contracted work. Because the outsourcing arrangement is a professional or personnel services contract, the institution's internal audit manager should have confidence in the competence of the staff assigned by the audit provider and receive timely notice from the vendor of any key staffing changes. Throughout the outsourcing arrangement, management should ensure that the audit provider maintains sufficient expertise to perform effectively and fulfill its contractual obligations. 

When an institution enters into an outsourcing arrangement, or significantly changes the mix of internal and external resources used by internal audit, operational risk may increase. Because the arrangement could be terminated suddenly, the institution should have a contingency plan to mitigate any significant gap in audit coverage, particularly for high-risk areas. In its planning, an institution should consider possible alternatives and determine what it will do if an auditor with specialized knowledge or skills is unable to complete reviews of high risk areas, or if an outsourcing arrangement is terminated. For example, management could maintain information about the services offered and areas of expertise, as well as contact names and phone numbers, of other firms in their geographic area that could provide internal audit assistance in specific areas or a broader range of outsourcing services. 

When negotiating the outsourcing arrangement with a vendor, an institution should carefully consider its current and anticipated business risks in setting each party's internal audit responsibilities. To clearly define the institution's duties and those of the outsourcing vendor, the institution should have a written contract, often referred to as an engagement letter. [8] The contract should: 

* • Define the expectations and responsibilities for both parties;
* • Set the scope, frequency, and cost of work to be performed by the vendor;
* • Set responsibilities for providing and receiving information, such as the manner and frequency of reporting to senior management and the board about the status of contract work;
* • Establish the protocol for changing the terms of the service contract, especially for expansion of audit work if significant issues are found, and stipulations for default and termination of the contract;
* • State that any information pertaining to the institution must be kept confidential;
* • Specify the locations of internal audit reports and the related work papers;
* • Specify the period of time that vendors must maintain the work papers; [9]
* • State that outsourced internal audit services provided by the vendor are subject to regulatory review and that examiners will be granted full and timely access to the internal audit reports and related work papers prepared by the outsourcing vendor;[10]
* • State that internal audit reports are the property of the institution, that the institution will be provided with any copies of the related work papers it deems necessary, and that employees authorized by the institution will have reasonable and timely access to the work papers prepared by the audit provider;
* • Prescribe a process (arbitration, mediation, or other means) for resolving problems and for determining who bears the cost of consequential damages arising from errors, omissions, and negligence; and
* • State that audit providers will not perform management functions, make management decisions, or act or appear to act in a capacity equivalent to that of an employee or a member of management of the institution, and will comply with professional and regulatory independence guidance.

Directors and senior management should ensure that the outsourced internal audit function is competently managed. For example, larger institutions should employ sufficient competent staff members in the internal audit department to assist the internal audit manager in overseeing the outsourcing vendor. Smaller institutions that do not employ a full-time audit manager should appoint a competent institution employee to oversee the outsourcing vendor's performance under the contract. This person should report directly to the audit committee for purposes of communicating audit issues and ideally should have no managerial responsibility for the area being audited. 

Communication among the internal audit function, the audit committee, and senior management should not diminish because the institution engages an outsourcing vendor. The institution's audit manager should be involved with the audit provider in defining the audit universe and setting a risk-based IT audit schedule. The audit provider should appropriately document all work and promptly report all control weaknesses found during the audit to the institution's internal audit manager. 

The outsourcing vendor should work with the internal audit manager to mutually determine what audit findings are significant and should be emphasized when reported to the board and its audit committee. The concept of materiality as the term is used in financial statement audits is not necessarily a good indicator of which control weaknesses to report. For example, reportable weaknesses could affect the institution's reputation or compliance with laws and regulations without a direct impact on the financial statements. 

## Third-Party Reviews of Technology Service Providers 

A technology service provider (TSP) that processes work for financial institutions often is subject to separate audits by internal auditors from each of the serviced institutions. These audits may duplicate each other, creating a hardship on the provider's management and resources. The TSP can reduce that burden by arranging for its own third-party audit to determine the status and reliability of internal controls and by sharing the results of that audit with its client financial institutions. 

A third-party audit or review is performed by independent auditors who are not employees of either the TSP or the serviced institution(s). The TSP, its auditors, or its serviced institutions may engage the third-party auditor. The serviced institutions' auditors may use this third-party review to determine the scope of any additional audit coverage they require to evaluate the system and controls at the TSP. Examiners can also use the third-party review to help scope their supervisory activities. 

Financial institutions are required to effectively manage their relationships with key TSPs. Institution management meets this requirement related to audit controls by: 

* • Directly auditing the TSP's operations and controls
* • Employing the services of external auditors to evaluate the TSP's operations and controls; or
* • Receiving from, and reviewing sufficiently detailed independent audit reports on, the TSP.

Financial institutions using such audits to complement their own coverage should ensure that the independent auditor is qualified to perform the review, that the scope satisfies their own audit objectives, and that any significant deficiencies reported are corrected. It is critically important that the examiner and the institution understand the nature and scope of the engagement and the level of assurance accruing from the work product of the reviewing firm. 

There are two common types of independent third-party reviews: attestation reviews and non-attestation reviews. Attestation reviews [11] are generally conducted by Certified Public Accountants (CPAs) and are based upon Attestation Standards issued by the American Institute of Certified Public Accounts (AICPA). Non-attestation reviews include those performed by IT consultants or others; they may be based upon external standards [12] or industry developed criteria. [13] 

The type of independent third-party review chosen should be based upon the size and complexity of the servicer, the products and services it offers, and its risk profile because the level of assurance provided varies with each type of review. 

Users of audit reports or reviews should not rely solely on the information contained in the report to verify the internal control environment of the TSP. They should use additional verification and monitoring procedures as discussed more fully in the Outsourcing Technology Services Booklet of the FFIEC IT Examination Handbook. Refer to that booklet for additional information on vendor management and to supplement the examination coverage in this booklet. 

### Endnotes 

[1] This booklet uses the terms "institution" and "financial institution" to describe 

[2] Board of Governors of the Federal Reserve System (Federal Reserve Board), 

[3] These include the "Interagency Policy Statement on the Internal Audit Function 

[4] A federal credit union board of directors is required to establish a "supervisory 

[5] Sarbanes-Oxley Act of 2002 (Public Law 107-204) puts into place significant new 

[6] Administrative matters in this context include routine personnel matters such as 

[7] Scoring refers to any consistent means of quantifying and then comparing distinct 

[8] In general, the contract between the institution and the audit provider may or may 

[9] If work papers are in electronic format, contracts often call for the vendor to insured banks, thrifts, and credit unions, as well as technology service providers that provide services to such entities. Federal Deposit Insurance Corporation (FDIC), National Credit Union Administration (NCUA), Office of the Comptroller of the Currency (OCC), and Office of Thrift Supervision (OTS). and Its Outsourcing," March 17, 2003; "Interagency Policy Statement on External Auditing Programs of Banks and Savings Associations," September 22, 1999; and "Interagency Policy Statement on Coordination and Communication Between External Auditors and Examiners," July 23, 1992. committee" with oversight responsibility for audit. A supervisory committee consists of not less than three members, nor more than five members, one of whom may be a director other than the compensated officer of the board. requirements that provide for auditor independence of registered companies that will apply, through FDIC guidelines, (1) to any financial institution that is required under banking laws to have an annual independent audit or (2) to its holding company if the bank satisfies this requirement at the holding company level. All insured depository institutions with $500 million or more in total assets are required under banking laws to have an annual audit by an independent public accountant. If the institution is a subsidiary of a holding company, it can satisfy this requirement by an independent audit of the holding company. Further, the Federal Reserve Board may apply the auditor independence requirements in the Act to all bank holding companies that are required by the Federal Reserve Board to have an annual audit by an independent public accountant even if no subsidiary institution is subject to the requirements. leave and attendance reporting, expense account management, and other departmental matters such as furniture, equipment and supplies. items based on elements that they have in common. All risk-based systems require some means to rank greater or lesser risk, or risk factors. Consequently, many risk-based systems rely on some means of scoring in their implementation. not be the same as the engagement letter. maintain the software that allows the institution and examiners access to electronic work papers during a specified period of time. 

[10] FDICIA Section 112 (12 USC Section 1831m(g)(3)) provides that all auditors are required to make their work papers available to bank examiners. 12 CFR 715.9(c) requires credit unions to obtain a signed audit engagement letter that includes a certification of unconditional access to the complete set of original working papers by credit union examiners. 

[11] For example, AICPA's SSAE-16 Type I and Type II, SOC 2 Type I and Type II, SOC 3 (Web Trust). See http://www.aicpa.org/\_catalogs/masterpage/ Search.aspx?S=soc+1 

[12] ISACA, NIST, IAA, & etc. 

[13] Shared Assessments Program; see http://www.sharedassessments.org/ 

# Appendix A: Examination Procedures 

Examination objectives allow the examiner to determine the quality and effectiveness of the audit function related to IT controls. These procedures will disclose the adequacy of audit coverage and to what extent, if any, the examiner may rely upon the procedures performed by the auditors in determining the scope of the IT examination. 

* • Tier I objectives and procedures relate to the institution's implementation of an effective audit function that may be relied upon to identify and manage risks.
* • Tier II objectives and procedures provide additional validation as warranted by risk to verify the effectiveness of the institution's audit function. Tier II questions correspond to the Uniform Rating System for Information Technology (URSIT) rating areas and can be used to determine where the examiner may rely upon audit work in determining the scope of the IT examination for those areas.

## TIER I OBJECTIVES AND PROCEDURES 

Objective 1: Determine the scope and objectives of the examination of the IT audit function and coordinate with examiners reviewing other programs. 

* 1. Review past reports for outstanding issues, previous problems, or high-risk areas with insufficient coverage related to IT. Consider: 
	+ • Regulatory reports of examination;
	+ • Internal and external audit reports, including correspondence/communication between the institution and auditors;
	+ • Regulatory, audit, and security reports from key service providers;
	+ • Audit information and summary packages submitted to the board or its audit committee;
	+ • Audit plans and scopes, including any external audit or internal audit outsourcing engagement letters; and
	+ • Institution's overall risk assessment.
* 2. Review the most recent IT internal and external audit reports in order to determine: 
	+ • Management's role in IT audit activities;
	+ • Any significant changes in business strategy, activities, or technology that could affect the audit function;
	+ • Any material changes in the audit program, scope, schedule, or staffing related to internal and external audit activities; and
	+ • Any other internal or external factors that could affect the audit function.
* 3. Review management's response to issues raised since the last examination. Consider: 
	+ • Adequacy and timing of corrective action;
	+ • Resolution of root causes rather than just specific issues; and
	+ • Existence of any outstanding issues.
* 4. Assess the quality of the IT audit function. Consider: 
	+ • Audit staff and IT qualifications, and
	+ • IT audit policies, procedures, and processes.Using the results from the preceding procedures and discussions with the EIC, select from the following examination procedures those necessary to meet the examination objectives. Note: examinations do not necessarily require all steps. 

Objective 2: Determine the quality of the oversight and support of the IT audit function provided by the board of directors and senior management. 


	+ 1. Review board resolutions and audit charter to determine the authority and mission of the IT audit function.
	+ 2. Review and summarize the minutes of the board or audit committee for member attendance and supervision of IT audit activities.
	+ 3. Determine if the board reviews and approves IT policies, procedures, and processes.
	+ 4. Determine if the board approves audit plans and schedules, reviews actual performance of plans and schedules, and approves major deviations to the plan.
	+ 5. Determine if the content and timeliness of audit reports and issues presented to and reviewed by the board of directors or audit committee are appropriate.
	+ 6. Determine whether the internal audit manager and the external auditor report directly to the board or to an appropriate audit committee and, if warranted, has the opportunity to escalate issues to the board both through the normal audit committee process and through the more direct communication with outside directors.Objective 3: Determine the credentials of the board of directors or its audit committee related to their ability to oversee the IT audit function. 


	+ 1. Review credentials of board members related to abilities to provide adequate oversight. Examiners should: 
		- • Determine if directors responsible for audit oversight have appropriate level of experience and knowledge of IT and related risks; and
		- • If directors are not qualified in relation to IT risks, determine if they bring in outside independent consultants to support their oversight efforts through education and training.
	+ 2. Determine if the composition of the audit committee is appropriate considering entity type and complies with all applicable laws and regulations. Note - If the institution is a publicly traded company, this is a requirement of Sarbanes-Oxley. Additionally, this is a requirement of FDICIA for institutions with total assets greater than $500 million.Objective 4: Determine the qualifications of the IT audit staff and its continued development through training and continuing education. 


	+ 1. Determine if the IT audit staff is adequate in number and is technically competent to accomplish its mission. Consider: 
		- • IT audit personnel qualifications and compare them to the job descriptions;
		- • Whether staff competency is commensurate with the technology in use at the institution; and
		- • Trends in IT audit staffing to identify any negative trends in the adequacy of staffing.Objective 5: Determine the level of audit independence. 
	
	
		- 1. Determine if the reporting process for the IT audit is independent in fact and in appearance by reviewing the degree of control persons outside of the audit function have on what is reported to the board or audit committee.
		- 2. Review the internal audit organization structure for independence and clarity of the reporting process. Determine whether independence is compromised by: 
			* • The internal audit manager reporting functionally to a senior management official (i.e., CFO, controller, or similar officer);
			* • The internal audit manager's compensation and performance appraisal being done by someone other than the board or audit committee; or
			* • Auditors responsible for operating a system of internal controls or actually performing operational duties or activities. Note that it is recommended that the internal audit manager report directly to the audit committee functionally on audit issues and may also report to senior management for administrative matters.Objective 6: Determine the existence of timely and formal follow-up and reporting on management's resolution of identified IT problems or weaknesses. 
		
		
			* 1. Determine whether management takes appropriate and timely action on IT audit findings and recommendations and whether audit or management reports the action to the board of directors or its audit committee. Also, determine if IT audit reviews or tests management's statements regarding the resolution of findings and recommendations.
			* 2. Obtain a list of outstanding IT audit items and compare the list with audit reports to ascertain completeness.
			* 3. Determine whether management sufficiently corrects the root causes of all significant deficiencies noted in the audit reports and, if not, determine why corrective action is not sufficient.Objective 7: Determine the adequacy of the overall audit plan in providing appropriate coverage of IT risks. 
		
		
			* 1. Interview management and review examination information to identify changes to the institution's risk profile that would affect the scope of the audit function. Consider: 
				+ • Institution's risk assessment,
				+ • Products or services delivered to either internal or external users,
				+ • Loss or addition of key personnel, and
				+ • Technology service providers and software vendor listings.
			* 2. Review the institution's IT audit standards manual and/or IT-related sections of the institution's general audit manual. Assess the adequacy of policies, practices, and procedures covering the format and content of reports, distribution of reports, resolution of audit findings, format and contents of work papers, and security over audit materials.Objective 8: Determine the adequacy of audit's risk analysis methodology in prioritizing the allocation of audit resources and formulating the IT audit schedule. 
		
		
			* 1. Evaluate audit planning and scheduling criteria, including risk analysis, for selection, scope, and frequency of audits. Determine if: 
				+ • The audit universe is well defined; and
				+ • Audit schedules and audit cycles support the entire audit universe, are reasonable, and are being met.
			* 2. Determine whether the institution has appropriate standards and processes for risk- based auditing and internal risk assessments that: 
				+ • Include risk profiles identifying and defining the risk and control factors to assess and the risk management and control structures for each IT product, service, or function; and
				+ • Describe the process for assessing and documenting risk and control factors and its application in the formulation of audit plans, resource allocations, audit scopes, and audit cycle frequencyObjective 9: Determine the adequacy of the scope, frequency, accuracy, and timeliness of IT-related audit reports. 
			
			
				+ 1. Review a sample of the institution's IT-related audit reports and work papers for specific audit ratings, completeness, and compliance with board and audit committee- approved standards.
				+ 2. Analyze the internal auditor's evaluation of IT controls and compare it with any evaluations done by examiners.
				+ 3. Evaluate the scope of the auditor's work as it relates to the institution's size, the nature and extent of its activities, and the institution's risk profile.
				+ 4. Determine if the work papers disclose that specific program steps, calculations, or other evidence support the procedures and conclusions set forth in the reports.
				+ 5. Determine through review of the audit reports and work papers if the auditors accurately identify and consistently report weaknesses and risks.
				+ 6. Determine if audit report content is: 
					- • Timely
					- • Constructive
					- • Accurate
					- • CompleteObjective 10: Determine the extent of audit's participation in application development, acquisition, and testing, as part of the organization's process to ensure the effectiveness of internal controls. 
				
				
					- 1. Discuss with audit management and review audit policies related to audit participation in application development, acquisition, and testing.
					- 2. Review the methodology management employs to notify the IT auditor of proposed new applications, major changes to existing applications, modifications/additions to the operating system, and other changes to the data processing environment.
					- 3. Determine the adequacy and independence of audit in: 
						* • Participating in the systems development life cycle;
						* • Reviewing major changes to applications or the operating system;
						* • Updating audit procedures, software, and documentation for changes in the systems or environment; and
						* • Recommending changes to new proposals or to existing applications and systems to address audit and control issues.Objective 11: If the IT internal audit function, or any portion of it, is outsourced to external vendors, determine its effectiveness and whether the institution can appropriately rely on it. 
					
					
						* 1. Obtain copies of: 
							+ • Outsourcing contracts and engagement letters,
							+ • Outsourced internal audit reports, and
							+ • Policies on outsourced audit.
						* 2. Review the outsourcing contracts/engagement letters and policies to determine whether they adequately: 
							+ • Define the expectations and responsibilities under the contract for both parties.
							+ • Set the scope, frequency, and cost of work to be performed by the vendor.
							+ • Set responsibilities for providing and receiving information, such as the manner and frequency of reporting to senior management and directors about the status of contract work.
							+ • Establish the protocol for changing the terms of the service contract, especially for expansion of audit work if significant issues are found, and stipulations for default and termination of the contract.
							+ • State that internal audit reports are the property of the institution, that the institution will be provided with any copies of the related work papers it deems necessary, and that employees authorized by the institution will have reasonable and timely access to the work papers prepared by the outsourcing vendor.
							+ • State that any information pertaining to the institution must be kept confidential.
							+ • Specify the locations of internal audit reports and the related work papers.
							+ • Specify the period of time that vendors must maintain the work papers. If work papers are in electronic format, contracts often call for vendors to maintain proprietary software that allows the institution and examiners access to electronic work papers during a specified period.
							+ • State that outsourced internal audit services provided by the vendor are subject to regulatory review and that examiners will be granted full and timely access to the internal audit reports and related work papers and other materials prepared by the outsourcing vendor.
							+ • Prescribe a process (arbitration, mediation, or other means) for resolving problems and for determining who bears the cost of consequential damages arising from errors, omissions and negligence.
							+ • State that outsourcing vendors will not perform management functions, make management decisions, or act or appear to act in a capacity equivalent to that of a member of institution management or an employee and, if applicable, they are subject to professional or regulatory independence guidance.
						* 3. Consider arranging a meeting with the IT audit vendor to discuss the vendor's outsourcing internal audit program and determine the auditor's qualifications.
						* 4. Determine whether the outsourcing arrangement maintains or improves the quality of the internal audit function and the institution's internal controls. The examiner should: 
							+ • Review the performance and contractual criteria for the audit vendor and any internal evaluations of the audit vendor;
							+ • Review outsourced internal audit reports and a sample of audit work papers. Determine whether they are adequate and prepared in accordance with the audit program and the outsourcing agreement;
							+ • Determine whether work papers disclose that specific program steps, calculations, or other evidence support the procedures and conclusions set forth in the outsourced reports; and
							+ • Determine whether the scope of the outsourced internal audit procedures is adequate.
						* 5. Determine whether key employees of the institution and the audit vendor clearly understand the lines of communication and how any internal control problems or other matters noted by the audit vendor during internal audits are to be addressed.
						* 6. Determine whether management or the audit vendor revises the scope of outsourced audit work appropriately when the institution's environment, activities, risk exposures, or systems change significantly.
						* 7. Determine whether the directors ensure that the institution effectively manages any outsourced internal audit function.
						* 8. Determine whether the directors perform sufficient due diligence to satisfy themselves of the audit vendor's competence and objectivity before entering the outsourcing arrangement.
						* 9. If the audit vendor also performs the institution's external audit or other consulting services, determine whether the institution and the vendor have discussed, determined, and documented that applicable statutory and regulatory independence standards are being met. Note - If the institution is a publicly traded company, this is a requirement of Sarbanes-Oxley. Additionally, this is a requirement of FDICIA for institutions with total assets greater than $500 million.
						* 10. Determine whether an adequate contingency plan exists to reduce any lapse in audit coverage, particularly coverage of high-risk areas, in the event the outsourced audit relationship is terminated suddenly.Objective 12: Determine the extent of external audit work related to IT controls. 
					
					
						* 1. Review engagement letters and discuss with senior management the external auditor's involvement in assessing IT controls.
						* 2. If examiners rely on external audit work to limit examination procedures, they should ensure audit work is adequate through discussions with external auditors and reviewing work papers if necessary.Objective 13: Determine whether management effectively oversees and monitors any significant data processing services provided by technology service providers: 
					
					
						* 1. Determine whether management directly audits the service provider's operations and controls, employs the services of external auditors to evaluate the servicer's controls, or receives sufficiently detailed copies of audit reports from the technology service provider.
						* 2. Determine whether management requests applicable regulatory agency IT examination reports.
						* 3. Determine whether management adequately reviews all reports to ensure the audit scope was sufficient and that all deficiencies are appropriately addressed.
## CONCLUSIONS 

Objective 14: Discuss corrective actions and communicate findings. 

* 1. Determine the need to perform Tier II procedures for additional validation to support conclusions related to any of the Tier I objectives.
* 2. Using results from the above objectives and/or audit's internally assigned audit rating or audit coverage, determine the need for additional validation of specific audited areas and, if appropriate: 
	+ • Forward audit reports to examiners working on related work programs, and
	+ • Suggest either the examiners or the institution perform additional verification procedures where warranted.
* 3. Using results from the review of the IT audit function, including any necessary Tier II procedures: 
	+ • Document conclusions on the quality and effectiveness of the audit function as related to IT controls; and
	+ • Determine and document to what extent, if any, examiners may rely upon the internal and external auditors' findings in order to determine the scope of the IT examination.
* 4. Review preliminary examination conclusions with the examiner-in-charge (EIC) regarding: 
	+ • Violations of law, rulings, and regulations;
	+ • Significant issues warranting inclusion as matters requiring board attention or recommendations in the report of examination; and
	+ • Potential effect of your conclusions on URSIT composite and component ratings.
* 5. Discuss examination findings with management and obtain proposed corrective action for significant deficiencies.
* 6. Document examination conclusions, including a proposed audit component rating, in a memorandum to the EIC that provides report-ready comments for all relevant sections of the report of examination.
* 7. Document any guidance to future examiners of the IT audit area.
* 8. Organize examination work papers to ensure clear support for significant findings and conclusions.
## TIER II OBJECTIVES AND PROCEDURES 

The Tier II examination procedures for the IT audit process provide additional verification procedures to evaluate the effectiveness of the IT audit function. These procedures are designed to assist in achieving examination objectives and scope and may be used entirely or selectively. 

Tier II questions correspond to URSIT rating areas and can be used to determine where the examiner may rely upon audit work in determining the scope of the IT examination for those areas. 

Examiners should coordinate this coverage with other examiners to avoid duplication of effort with the examination procedures found in other IT Handbook booklets. 

## A. MANAGEMENT 

* 1. Determine whether audit procedures for management adequately consider: 
	+ • The ability of management to plan for and initiate new activities or products in response to information needs and to address risks that may arise from changing business conditions;
	+ • The ability of management to provide reports necessary for informed planning and decision making in an effective and efficient manner;
	+ • The adequacy of, and conformance with, internal policies and controls addressing the IT operations and risks of significant business activities;
	+ • The effectiveness of risk monitoring systems;
	+ • The level of awareness of, and compliance with, laws and regulations;
	+ • The level of planning for management succession;
	+ • The ability of management to monitor the services delivered and to measure the institution's progress toward identified goals in an effective and efficient manner;
	+ • The adequacy of contracts and management's ability to monitor relationships with technology service providers;
	+ • The adequacy of strategic planning and risk management practices to identify, measure, monitor, and control risks, including management's ability to perform self- assessments; and
	+ • The ability of management to identify, measure, monitor, and control risks and to address emerging IT needs and solutions.
## B. SYSTEMS DEVELOPMENT AND ACQUISITION 

* 1. Determine whether audit procedures for systems development and acquisition and related risk management adequately consider: 
	+ • The level and quality of oversight and support of systems development and acquisition activities by senior management and the board of directors;
	+ • The adequacy of the institutional and management structures to establish accountability and responsibility for IT systems and technology initiatives;
	+ • The volume, nature, and extent of risk exposure to the institution in the area of systems development and acquisition;
	+ • The adequacy of the institution's systems development methodology and programming standards;
	+ • The quality of project management programs and practices that are followed by developers, operators, executive management/owners, independent vendors or affiliated servicers, and end-users;
	+ • The independence of the quality assurance function and the adequacy of controls over program changes including the: 
		- - parity of source and object programming code,
		- - independent review of program changes,
		- - comprehensive review of testing results,
		- - management's approval before migration into production, and
		- - timely and accurate update of documentation;
	+ • The quality and thoroughness of system documentation;
	+ • The integrity and security of the network, system, and application software used in the systems development process;
	+ • The development of IT solutions that meet the needs of end-users; and
	+ • The extent of end-user involvement in the systems development process.
## C. OPERATIONS 

* 1. Determine whether audit procedures for operations consider: 
	+ • The adequacy of security policies, procedures, and practices in all units and at all levels of the financial institution and service providers.
	+ • The adequacy of data controls over preparation, input, processing, and output.
	+ • The adequacy of corporate contingency planning and business resumption for data centers, networks, service providers, and business units. Consider the adequacy of offsite data and program backup and the adequacy of business resumption testing.
	+ • The quality of processes or programs that monitor capacity and performance.
	+ • The adequacy of contracts and the ability to monitor relationships with service providers.
	+ • The quality of assistance provided to users, including the ability to handle problems.
	+ • The adequacy of operating policies, procedures, and manuals.
	+ • The quality of physical and logical security, including the privacy of data.
	+ • The adequacy of firewall architectures and the security of connections with public networks.
## D. INFORMATION SECURITY 

* 1. Determine whether audit procedures for information security adequately consider the risks in information security and e-banking. Evaluate whether: 
	+ • A written and adequate data security policy is in effect covering all major operating systems, databases, and applications;
	+ • Existing controls comply with the data security policy, best practices, or regulatory guidance;
	+ • Data security activities are independent from systems and programming, computer operations, data input/output, and audit;
	+ • Some authentication process, such as user names and passwords, that restricts access to systems;
	+ • Access codes used by the authentication process are protected properly and changed with reasonable frequency;
	+ • Transaction files are maintained for all operating and application system messages, including commands entered by users and operators at terminals, or at PCs;
	+ • Unauthorized attempts to gain access to the operating and application systems are recorded, monitored, and responded to by independent parties;
	+ • User manuals and help files adequately describe processing requirements and program usage;
	+ • Controls are maintained over telecommunication(s), including remote access by users, programmers and vendors; and over firewalls and routers to control and monitor access to platforms, systems and applications;
	+ • Access to buildings, computer rooms, and sensitive equipment is controlled adequately;
	+ • Written procedures govern the activities of personnel responsible for maintaining the network and systems;
	+ • The network is fully documented, including remote and public access, with documentation available only to authorized persons;
	+ • Logical controls limit access by authorized persons only to network software, including operating systems, firewalls, and routers;
	+ • Adequate network updating and testing procedures are in place, including configuring, controlling, and monitoring routers and firewalls;
	+ • Adequate approvals are required before deployment of remote, Internet, or VPN access for employees, vendors, and others;
	+ • Alternate network communications procedures are incorporated into the disaster recovery plans;
	+ • Access to networks is restricted using appropriate authentication controls; and
	+ • Unauthorized attempts to gain access to the networks are monitored.
* 2. Determine whether audit procedures for information security adequately consider compliance with the "Interagency Guidelines Establishing Standards for Safeguarding Customer Information," as mandated by Section 501(b) of the Gramm-Leach-Bliley Act of 1999. Consider evaluating whether management has: 
	+ • Identified and assessed risks to customer information;
	+ • Designed and implemented a program to control risks;
	+ • Tested key controls (at least annually);
	+ • Trained personnel; and
	+ • Adjusted the compliance plan on a continuing basis to account for changes in technology, the sensitivity of customer information, and internal/external threats to information security.
## E. PAYMENT SYSTEMS 

* 1. Determine whether audit procedures for payment systems risk adequately consider the risks in wholesale electronic funds transfer (EFT). Evaluate whether: Adequate operating policies and procedures govern all activities, both in the wire transfer department and in the originating department, including authorization, authentication, and notification requirements; 


	+ • Formal contracts with each wire servicer exist (i.e., Federal Reserve Bank (FRB), correspondent financial institutions, and others);
	+ • Separation of duties is sufficient to prevent any one person from initiating, verifying, and executing a transfer of funds;
	+ • Personnel policies and practices are in effect;
	+ • Adequate security policies protect wire transfer equipment, software, communications lines, incoming and outgoing payment orders, test keys, etc.;
	+ • Credit policies and appropriate management approvals have been established to cover overdrafts;
	+ • Activity reporting, monitoring, and reconcilement are conducted daily, or more frequently based upon activity;
	+ • Appropriate insurance riders cover activity;
	+ • Contingency plans are appropriate for the size and complexity of the wire transfer function; and
	+ • Funds transfer terminals are protected by adequate password security.
* 2. Determine whether audit procedures for payment systems risk adequately consider the risks in retail EFT (automatic teller machines, point-of-sale, debit cards, home banking, and other card-based systems including VISA/Master Charge compliance). Evaluate whether: 
	+ • Written procedures are complete and address each EFT activity;
	+ • All EFT functions are documented appropriately;
	+ • Physical controls protect plastic cards, personal identification number (PIN) information, EFT equipment, and communication systems;
	+ • Separation of duties and logical controls protect EFT-related software, customer account, and PIN information;
	+ • All transactions are properly recorded, including exception items, and constitute an acceptable audit trail for each activity;
	+ • Reconcilements and proofs are performed daily by persons with no conflicting duties;
	+ • Contingency planning is adequate;
	+ • Vendor and customer contracts are in effect and detail the responsibilities of all parties to the agreement;
	+ • Insurance coverage is adequate; and
	+ • All EFT activity conforms to applicable provisions of Regulation E.
* 3. Determine whether audit procedures for payment systems risk adequately consider the risks in automated clearing house (ACH). Evaluate whether: 
	+ • Policies and procedures govern all ACH activity;
	+ • Incoming debit and credit totals are verified adequately and items counted prior to posting to customer accounts;
	+ • Controls over rejects, charge backs, unposted and other suspense items are adequate;
	+ • Controls prevent the altering of data between receipt of data and posting to accounts;
	+ • Adequate controls exist over any origination functions, including separation of data preparation, input, transmission, and reconcilement;
	+ • Security and control exist over ACH capture and transmission equipment; and
	+ • Compliance with NACHA, local clearinghouse, and FRB rules and regulations.
## F. OUTSOURCING 

* 1. Determine whether audit procedures for outsourcing activities adequately cover the risks when IT service is provided to external users. Evaluate whether: 
	+ • Formal procedures are in effect and staff is assigned to provide interface with users/ customers to control data center-related issues (i.e., program change requests, record differences, service quality);
	+ • There are contracts with all customers (affiliated and nonaffiliated) and whether the institution's legal staff has approved them;
	+ • Controls exist over billing and income collection;
	+ • Disaster recovery plans interface between the data center, customers, and users;
	+ • Controls exist over on-line terminals employed by users and customers;
	+ • Comprehensive user manuals exist and are distributed; and
	+ • There are procedures for communicating incidents to clients.
* 2. Determine whether audit procedures for outsourced activities are adequate. Evaluate whether: 
	+ • There are contracts in place that have been approved by the institution's legal staff,
	+ • Management monitors vendor performance of contracted services and the financial condition of the vendor,
	+ • Applicable emergency and disaster recovery plans are in place,
	+ • Controls exist over the terminal used by the financial institution to access files at an external servicer's location,
	+ • Internal controls for each significant user application are consistent with those required for in-house systems,
	+ • Management has assessed the impact of external and internal trends and other factors on the ability of the vendor to support continued servicing of client financial institutions,
	+ • The vendor can provide and maintain service level performance that meets the requirements of the client, and
	+ • Management monitors the quality of vendor software releases, documentation, and training provided to clients.
# Appendix B: Glossary 

Application controls - Controls related to transactions and data within application systems. Application controls ensure the completeness and accuracy of the records and the validity of the entries made resulting from both programmed processing and manual data entry. Examples of application controls include data input validation, agreement of batch totals and encryption of data transmitted. 

Application system - An integrated set of computer programs designed to serve a well- defined function and having specific input, processing, and output activities (e.g., general ledger, manufacturing resource planning, human resource management). 

Audit charter - A document approved by the board of directors that defines the IT audit function's responsibility, authority to review records, and accountability. 

Audit plan - A description and schedule of audits to be performed in a certain period of time (ordinarily a year). It includes the areas to be audited, the type of work planned, the high-level objectives and scope of the work and includes other items such as budget, resource allocation, schedule dates, and type of report issued. 

Audit program - The audit policies, procedures, and strategies that govern the audit function, including IT audit. 

Exposure - The potential loss to an area due to the occurrence of an adverse event. 

General controls - Controls, other than application controls, that relate to the environment within which application systems are developed, maintained, and operated, and that are therefore applicable to all the applications at an institution. The objectives of general controls are to ensure the proper development and implementation of systems, and the integrity of program and data files and of computer operations. Like application controls, general controls may be either manual or programmed. Examples of general controls include the development and implementation of an IT strategy and an IT security policy, the organization of IT staff to separate conflicting duties and planning for disaster prevention and recovery. 

Independence - Self-governance, freedom from conflict of interest and undue influence. The IT auditor should be free to make his or her own decisions, not influenced by the organization being audited, or by its managers and employees. 

Outsourcing - The practice of contracting with another entity to perform services that might otherwise be conducted in-house. Contracted relationship with a third party to provide services, systems, or support. 

Risk - The potential that events, expected or unanticipated, may have an adverse effect on a financial institution's earnings, capital, or reputation. 

Risk assessment - A prioritization of potential business disruptions based on severity and likelihood of occurrence. The risk assessment includes an analysis of threats based on the impact to the institution, its customers, and financial markets, rather than the nature of the threat. 

Systems Development Life Cycle (SDLC) - An approach used to plan, design, develop, test, and implement an application system or a major modification to an application system. 

Work program - A series of specific, detailed steps to achieve an audit objective. 

# Appendix C: Laws, Regulations, and Guidance 

## Laws 

* • 12 USC 1761 & 1761d: Supervisory Committee (N/A)
* • Public Law 107-204: Sarbanes-Oxley Act of 2002, Pub (N/A)
## Federal Financial Institutions Examination Council 

* • Interagency Policy Statement on the Internal Audit Function and Its Outsourcing (March 2003)
* • Interagency Policy Statement on External Auditing Programs of Banks and Savings Associations (September 1999)
* • Interagency Policy Statement on Coordination and Communication Between External Auditors and Examiners (July 1992)
## Federal Reserve Board 

* • 12 CFR Part 208, Appendix D-1: Interagency Guidelines Establishing Standards for Safety and Soundness (N/A)
* • SR Letter 03-8; Statement on Application of Recent Corporate Governance Initiatives to Non-Public Banking Organizations (May 5, 2003)
* • SR Letter 03-5: Amended Interagency Guidance on the Internal Audit Function and its Outsourcing (April 22, 2003)
* • SR Letter 02-20: The Sarbanes-Oxley Act of 2002 (October 29, 2002) Federal Deposit Insurance Corporation
* • 12 CFR Part 363: Annual Independent Audits and Reporting Requirements (N/A)
* • FIL 21-2003: Interagency Policy Statement on the Internal Audit Function and Its Outsourcing (March 7, 2003)
* • FIL 96-99: Interagency Policy Statement On External Auditing Programs of Banks and Savings Associations (October 25, 1999)
## National Credit Union Administration 

* • 12 CFR Part 715: Supervisory Committee Audits and Verifications (N/A)
* • NCUA Letter to Credit Unions 02-CU-17: E-Commerce Guide for Credit Unions (December 2002)
* • NCUA Letter to Credit Unions 01-CU-11: Electronic Data Security Overview (August 2001)
* • NCUA Letter to Credit Unions 97-CU-5: Interagency Statement on Retail On-Line PC Banking (April 1997)
## Office of the Comptroller of the Currency 

* • 12 CFR Part 30: Safety and Soundness Standards (N/A)
* • OCC Bulletin 2003-12: Interagency Policy Statement on Internet Audit and Internal Audit Outsourcing (March 17, 2003)
* • OCC Bulletin 99-37: Interagency Policy Statement on External Auditing Programs (July 9, 2003)
* • Comptroller's Handbook: Community Bank Supervision, Booklet (August 2001)
* • Comptroller's Handbook: Community Bank Supervision, Appendix (August 2001)
* • Comptroller's Handbook: Internal and External Audits, Introduction (April 2003)
* • Comptroller's Handbook: Internal and External Audits, Appendixes (April 2003)
* • Comptroller's Handbook: Large Bank Supervision (May 2001)
* • Comptroller's Handbook: Internal and External Audits, Supplemental Examination Procedures (April 2003)
* • The Director's Book: The Role of a National Bank Director (March 1997)
## Office of Thrift Supervision 

* • 12 CFR Part 562.4: Audit of Savings Associations and Savings Association Holding Companies (N/A)
* • 12 CFR Part 570, Appendix A: Interagency Guidelines Establishing Standards for Safety and Soundness (N/A)
* • Thrift Bulletin 81: Interagency Policy Statement on the Internal Audit Function and Its Outsourcing (March17, 2003)
* • CEO LTR 113: Internal Controls (July 14, 1999)
* • Thrift Activities Handbook Section 341: Technology Risk Controls (January 2002)
* • Thrift Activities Handbook Section 350: External Audit (July 2002)
* • Thrift Activities Handbook Section 355: Internal Audit (February 2002)
## FFIEC Information Technology Examination Handbook 

# Business Continuity Management 

NOVEMBER 2019 

Contents 

INTRODUCTION.. 

I.A 

I1.B 

HLA 

H1.A.1 

11.A.2 

11.A.3 

H1.B.1 

Il.B.2 

## HLB 

## IV.A.1 

## IV.A.2 

## IV.A.3 

## IV.A.4 

## IV.A.5 

## IV.A.6 

## IV.A.7 

## IV.A.8 

IV.B 

V.A 

V.B 

V.C 

V.D 

V.E 

V.F 

V.C.1 

V.C.2 

V.F.1 

V 

IV.A 

November 2019 

BUSINESS CONTINUITY MANAGEMENT 

BUSINESS CONTINUITY MANAGEMENT GOVERNANCE. 

Board and Senior Management Responsibilities 

Audit 

RISK MANAGEMENT 

Business Impact Analysis 

Identification of Critical Business Functions 

Interdependency Analysis 

Impact of Disruption 

Risk Assessment.. 

Risk Identification 

Likelihood and impact 

BUSINESS CONTINUITY STRATEGIES 

Resilience 

Physical 

Cyber Resilience 

Data Backup and Replication 

Personnel 

Third-Party Service Providers.. 

Telecommunications 

Power 

Change Management.. 

Communications 

BUSINESS CONTINUITY PLAN 

Event Management.. 

Continuity and Recovery 

Facilities and infrastructure 

Data Center Recovery Alternatives 

Branch Relocation 

Payment Systems.. 

Liquidity Considerations 

Other Components 

Incident Response 

1 

2 

3 

4 

6 

7 

9 

10 

10 

11 

12 

13 

14 

16 

18 

19 

19 

19 

21 

22 

23 

24 

24 

25 

26 

27 

28 

29 

29 

30 

31 

31 

31 

32 

V.F.2 

V.F.3 

VI 

VII 

VII.A 

VII.B 

VII.C 

VII.D 

VII.E 

VII.F 

VII.G 

VILH 

VII.I 

VII.J 

VII.K 

VII.G.1 

VII.G.2 

VII.G.3 

VII.G.4 

VIII 

|X 

# APPENDIX A: 

# APPENDIX B: 

# APPENDIX C: 

APPENDIX D: 

Disaster Recovery 

Crisis or Emergency Management 

TRAINING 

EXERCISES AND TESTS 

Exercise and Test Program 

Exercise and Test Policy 

Exercise and Test Strategies. 

Exercise and Test Objectives 

Exercise and Test Plans 

Exercise and Test Scenarios 

Exercise and Test Methods 

Full-Scale Exercise.. 

Limited-Scale Exercise . 

Tabletop Exercise 

Tests 

Industry Exercises and Resilience 

Third-Party Service Provider Testing 

Testing for Core and Significant Firms 

Post-Exercise and Post-Test Actions 

MAINTENANCE AND IMPROVEMENT 

BOARD REPORTING EXAMINATION PROCEDURES 

GLOSSARY 

ABBREVIATIONS.. 

## REFERENCES . 

33 

34 

35 

37 

38 

39 

39 

40 

40 

41 

42 

42 

43 

43 

44 

44 

45 

45 

46 

47 

49 

50 

70 

77 

78 

November 2019 

# Introduction 

The “Business Continuity Management” (BCM) booklet is one in a series of booklets that comprise the Federal Financial Institutions Examination Council (FFIEC)1 Information Technology Examination Handbook (IT Handbook). The IT Handbook is prepared for use by examiners.2 With the publication of this booklet, the FFIEC member agencies replace the “Business Continuity Planning” booklet issued in February 2015. The change from business continuity planning to business continuity management reflects the changes in customer and industry expectations for the resilience of operations. 

The BCM booklet describes principles and practices for IT and operations for safety and soundness, consumer financial protection, and compliance with applicable laws and regulations. The BCM booklet also outlines BCM principles to help examiners evaluate how management addresses risk related to the availability of critical financial products and services. This booklet discusses BCM governance and its related components, including resilience strategies and plan development; training and awareness; exercises and tests; maintenance and improvement; and reporting for all levels of management, including the board of directors. 

The focus of this revised booklet is on enterprise-wide, process-oriented approaches that consider technology, business operations, testing, and communication strategies critical to the continuity of the entire entity. However, business continuity should not be focused only on the planning process to recover operations after an event, but rather it should include the continued maintenance of systems and controls for the resilience of operations. Business continuity should be incorporated into the risk management life cycle of all systems, processes, and operations of an entity. 

For IT Handbook purposes, the term “entities” includes depository financial institutions,3 nonbank financial institutions,4 bank holding companies,5 and third-party service providers.6 

1 The FFIEC was established on March 10, 1979, pursuant to Title X of the Financial Institutions Regulatory and Interest Rate Control Act of 1978, Pub. L. 95-630. The FFIEC members include the Board of Governors of the Federal Reserve System (FRB), the Consumer Financial Protection Bureau (CFPB), the Federal Deposit Insurance Corporation (FDIC), the National Credit Union Administration (NCUA), the Office of the Comptroller of the Currency (OCC), and the State Liaison Committee (SLC). 

2 Each FFIEC member agency may use the principles outlined in this booklet, consistent with the member agency’s supervisory authority. 

3 The term “depository financial institution” includes national banks, federal savings associations, state savings associations, state member banks, state nonmember banks, and credit unions. 

4 The term “nonbank financial institution” includes non-depository financial institutions under CFPB’s jurisdiction and subject to CFPB supervision and examination. 

5 The term “bank holding company” includes any company which has control over any bank or over any company that is or becomes a bank holding company as defined by the Bank Holding Company Act. 

6 The term “third-party service providers” includes those entities that provide banking services subject to examination under the Bank Service Company Act, the Home Owners Loan Act of 1933, the Dodd-Frank Wall Street Reform and Consumer Protection Act, or other relevant law. 

This booklet does not impose requirements on entities. Instead, this booklet describes practices that examiners may use to assess an entity’s BCM function. 

Appendix A of this booklet provides objectives-based examination procedures. The application of the principles and related examination procedures should vary according to an entity’s complexity and risk profile. Examiners should evaluate entities in accordance with their agency’s regulatory authority. 

# I Business Continuity Management 

BCM is the process for management to oversee and implement resilience, continuity, and response capabilities to safeguard employees, customers, and products and services. Disruptions such as cyber events, natural disasters, or man-made events can interrupt an entity’s operations and can have a broader impact on the financial sector. Resilience incorporates proactive measures to mitigate disruptive events and evaluate an entity’s recovery capabilities. An entity’s BCM program should align with its strategic goals and objectives. Management should consider an entity’s role within and impact on the overall financial services sector when it develops a BCM program. 

Figure 1: Business Continuity Management Cycle 

* 10. Monitor and report

business continuity and 

resilience activities. 

* 1. Oversee and implement resilience, 

continuity and response capabilities. 


	+ 9. Review and update thebusiness continuity program 

to reflect the current 

environment.
* 2. Align business continuity management elements with 

strategic goals and 

objectives. 


	+ 8. Conduct exercises and tests to verify that 
	
	procedures support 
	
	established objectives 
	
	BusinessContinuity 

Management
* 3. Develop a business impact analysis to identify 

critical functions, analyze 

interdependencies, and assess impacts. 


	+ 7. Implement a businesscontinuity training program 

for personnel and other 

stakeholders.
* 4. Conduct a risk assessment to identify risks 

and evaluate likelihood and 

impact of disruptions. 


	+ 6. Establish a business continuity plan that includesincident response, disaster 

recovery, & crisis/ 

emergency mgmt.
* 5. Develop effective

strategies to meet resilience 

and recovery objectives. 

Audit assesses the business continuity program's design effectiveness 

# II Business Continuity Management Governance 

This section provides specific information about BCM governance, including board and senior management responsibilities. General information about governance and risk management is contained in the IT Handbook’s “Management” booklet and the FFIEC members’ examination handbooks. 

BCM governance should include: 

* • Aligning BCM practices with the risk appetite.
* • Identifying the continuity level needed, consistent with the operation’s criticality.
* • Establishing business continuity policy and plans.
* • Allocating resources to BCM activities.
* • Providing competent management to implement the program.
* • Monitoring and assessing business continuity performance relative to these goals.

Figure 1 depicts a typical BCM cycle that entities may follow to manage business continuity risks on an ongoing basis. To manage these risks, the entity may develop a single encompassing BCM policy or individual policies and plans for different functions, depending on the size and complexity of the entity’s operations. An effective practice for business continuity-related policies is to address, at a minimum, the following areas: scope and responsibilities within BCM, accountability, authority, and guidance to develop and maintain effective BCM. 

# II.A Board and Senior Management Responsibilities 

## Action Summary 

The board and senior management govern business continuity through defining responsibilities and accountability, and by allocating adequate resources to business continuity. 

Examiners should review for the following: 

* • Alignment of BCM elements with the entity’s strategic goals and objectives.
* • Board oversight.
* • Management assignment of BCM-related responsibilities.
* • Development of BCM strategies.

The board7 and senior management should set the “tone at the top” and consider the entity’s entire operations, including functions performed by affiliates and third-party service providers, when managing business continuity. Management should evaluate continuity risk, set short- and long-term continuity objectives, adopt policies and procedures to mitigate continuity risk, evaluate continuity performance, and adjust operations in response to test results and actual events. 

Management can strengthen resilience by assessing risk, planning, testing the plans, and incorporating lessons learned from tests and events. Furthermore, management should consider resilience in business functions and the design of new products and services. 

7 Most financial institutions have boards of directors; however, not all third-party service providers do. When an entity does not have a board, the senior leaders may have the responsibilities of the board described in this booklet. 

Board oversight should include: 

* • Assigning BCM responsibility and accountability.
* • Allocating resources to BCM.
* • Aligning BCM with the entity’s business strategy and risk appetite.
* • Understanding business continuity risks and adopting policies and plans to manage events.
* • Reviewing business continuity operating results and performance through management reporting, testing, and auditing.
* • Providing a credible challenge8 to management responsible for the BCM process.

Management oversight should include: 

* • Defining BCM roles, responsibilities, and succession plans.
* • Allocating knowledgeable personnel9 and sufficient financial resources.
* • Validating that personnel understand their business continuity roles and responsibilities.
* • Establishing measurable goals against which business continuity performance is assessed, such as levels of preparedness and resilience targets.
* • Designing and implementing a business continuity exercise strategy.
* • Confirming that exercises, tests, and training are comprehensive and consistent with the BCM strategy.
* • Resolving weaknesses identified in exercises, tests, and training that exceed the entity’s risk appetite.
* • Meeting regularly with a designated coordinator or a business continuity committee to discuss policy changes, exercises, tests, and training plans.
* • Assessing and updating business continuity strategies and plans to reflect the current business conditions and operating environment for continuous improvement.
* • Coordinating plans and responses with external groups (as described in IV.B, “Communications”). 8 A credible challenge involves being actively engaged, asking thoughtful questions, and exercising independent judgment.

9 The term “personnel” includes both permanent and temporary staff. 

# II.B Audit 

## Action Summary 

The board and senior management should engage internal audit or independent personnel to review and validate the design and operating effectiveness of the BCM program. Audit should report to the board and provide an assessment of management’s ability to manage and control risks related to continuity and resilience. 

Examiners should review the following: 

* • Scope of BCM-related audit activities.
* • Audit reporting of BCM-related activities to the board.
* • Board review of audit reports.
* • Tracking and resolution of audit findings.
* • Management’s review of system and organization controls (SOC)10 and third-party service provider audit reports.

The board and senior management should engage internal audit (or an independent review) to assess the BCM design effectiveness, including policies and procedures, and the effectiveness of controls. Audit should report to the board and provide an assessment of management’s ability to oversee and control risks related to continuity and resilience. Auditors should be qualified and independent of BCM processes. Audit scope and frequency depend on the entity’s complexity, risk profile, and changes the entity may be experiencing. Large, complex entities may have multiple audits, covering various departments or aspects of the BCM program. Less complex entities may have their business continuity activities included within an IT general controls audit. 

The internal audit of the BCM program should provide an independent assessment of management’s ability to oversee the entity’s continuity and resilience risk. Auditors should: 

* • Evaluate the business impact analysis (BIA) and risk assessment for reasonableness, identification of critical functions, and the likelihood of different events and the potential impact on operations.
* • Evaluate controls for reliability, adequacy, and effectiveness regarding continuity and resilience.
* • Leverage SOC reports and other external artifacts from third-party service providers, as appropriate. 10 “In 2017, the American Institute of Certified Public Accountants (AICPA) introduced the term “system and organization controls” (SOC) to refer to the suite of services practitioners may provide relating to system-level controls of a service organization and system- or entity-level controls of other organizations. Formerly, SOC referred to service organization controls. By redefining that acronym, the AICPA enables the introduction of new internal control examinations that may be performed (a) for other types of organizations, in addition to service organizations, and (b) on either system-level or entity-level controls of such organizations.” (AICPA, SOC 2 Examinations and SOC for Cybersecurity Examinations: Understanding the Key Distinctions.)
* • Compare the entity’s inherent risk level and the effectiveness of risk mitigation against the entity’s risk appetite.
* • Verify whether test plans achieve the stated objectives.
* • Monitor BCM testing to verify that issues (e.g., deviation from test plans and failed objectives) are appropriately identified and escalated.
* • Assess the BCM program’s effectiveness.

Refer to the IT Handbook’s “Audit” booklet for additional information. 

# III Risk Management 

Business continuity risk management focuses on a subset of operational risk factors, against which capital and reserves alone may not protect an entity, and involves managing the possibility of an event that jeopardizes critical systems.11 The BIA and risk assessment represent the foundation of BCM. As illustrated in figure 2, BCM should integrate with an entity’s enterprise risk management (ERM),12 which allows for the identification and management of risk across the entire entity. BCM allows management to set strategy to effectively mitigate risks posed by disruptive events. The level and formality of BCM and ERM integration should be commensurate with the entity’s complexity and risk profile. 

Figure 2: Business Continuity Management Elements (Relative to Enterprise Risk Management) 

Enterprise Risk Management 

Business Continuity Management 

Incident Response 

Disaster Recovery 

Crisis Management 

Risk 

Management 

Strategies 

& Plan 

Development 

Business 

Continuity 

Plan 

Training 

Exercises & 

Tests 

Maintenance & 

Improvement 

11 Refer to the U.S. Department of the Treasury and the Department of Homeland Security’s (DHS) Financial Services Sector-Specific Plan 2015. 

12 ERM is “[a] process, effected by an entity’s board of directors, management and other personnel, applied in strategy-setting and across the enterprise, designed to identify potential events that may affect the entity, and manage risk to be within the risk appetite, to provide reasonable assurance regarding the achievement of entity objectives.” (Committee of Sponsoring Organizations of the Treadway Commission (COSO), Enterprise Risk Management – Integrated Framework (Executive Summary), September 2004) 

Management should use the BIA and risk management processes to identify and monitor continuity risks for an entity. Once management determines the risk, there are four common strategies to address that risk: risk acceptance, risk mitigation, risk transference, and risk avoidance. Risk transference, such as obtaining insurance, may allow management to recover financial losses or expenses resulting from an event and can be an effective capital management tool; however, insurance should not be a substitute for effective controls or continuity and resilience planning. Management’s continuity and resilience planning efforts should focus on risk mitigation and avoidance strategies, and where appropriate, risk acceptance strategies. These strategies are covered more in depth throughout this booklet. Refer to the IT Handbook’s “Management” booklet for additional information. 

Management at large and systemically important entities whose failure could trigger a broader financial disruption should assess the likelihood and impact of a disruption, both to the entity and the entire financial sector. These entities are a critical component of the broader financial system and should incorporate scenarios of disruptions impacting the financial sector into the entity’s BCM processes. 

The Interagency Paper on Sound Practices to Strengthen the Resilience of the U.S. Financial System (Sound Practices Paper)13 outlines practices for financial industry participants that perform clearing and settlement activities for critical financial markets (core firms) and institutions that process a significant share of transactions in critical financial markets (significant firms). Regulators have notified all participants that meet the definition of a core or significant firm as set forth in the Sound Practices Paper. Because core and significant firms participate in one or more critical financial markets, and their failure to perform critical activities by the end of a business day could present systemic risk to financial systems, their role in financial markets should be addressed as part of the business continuity planning process. 

13 Refer to the Interagency Paper on Sound Practices to Strengthen the Resilience of the U.S. Financial System issued by the SR Letter 03-9 (FRB), Bulletin 2003-14 (OCC), and Release No. 34-47638 (U.S. Securities and Exchange Commission (SEC)). Also refer to 68 Fed. Reg. 17809. 

# III.A Business Impact Analysis 

## Action Summary 

Management should develop a BIA that identifies all business functions and prioritizes them in order of criticality, analyzes related interdependencies among business processes and systems, and assesses a disruption’s impact through established metrics. The BIA should define recovery priorities and resource dependencies for critical processes. 

Examiners should review the following as part of the BIA process: 

* • Identification of critical business functions.
* • Identification of interdependencies across business units.
* • Identification and analysis of disruptive events.
* • Reasonableness of recovery objectives.
* • Communication of BIA results throughout the entity.
* • Comprehensiveness of management’s BIA review.

A BIA is the process of identifying the potential impact of disruptive events to an entity’s functions and processes. A BIA allows management to identify and analyze gaps in critical processes that would prevent the entity from meeting its business requirements. The BIA generally lists recovery priorities and resources on which critical processes depend (e.g., work flow analysis14). Through the BIA process, management should identify interdependencies among critical operations, departments, personnel, services, and the functions with the greatest exposure to interruption. Management should identify resources on which these functions and processes depend and exposures that would warrant further protective measures. Furthermore, the BIA should include financial and other resource costs (e.g., the loss of business, and exposure to legal and regulatory consequences) needed to recover and restore business functions and processes. 

The time and resources to complete the BIA depends on the entity’s size and complexity. Complex entities may have multiple BIAs for various business lines, subsidiaries, or other organizational separations. Information from the ERM, such as business processes and risk appetites, may facilitate the BIA development. 

14 The work flow analysis can assist in documenting interdependencies among critical operations, departments, personnel, and services. 

ILAN 

##  Identification of Critical Business Functions 

Completing the BIA generally involves gathering information regarding business functions, impacts from disruptions, and business interdependencies; analyzing this information; and establishing recovery objectives. Critical business functions,15 including support activities (e.g., help desk, call center, human resources, and payroll), systems, and interrelationships may be analyzed in several ways. Work flows, interviews, organizational charts, network diagrams/topologies, data flow diagrams, succession plans, or delegations of authority for key personnel may help management identify business processes and hierarchies. 

Management should inventory the entity’s critical assets (e.g., people, hardware, software, data, information, and cash) and infrastructure (e.g., network connectivity, communication lines, facilities, and utilities), including those provided by third-party service providers. Furthermore, management should consider supporting activities (e.g., technology support, payroll, contracting) and software (e.g., email, office productivity suites), geographic locations, and unique aspects (e.g., proprietary hardware and software, documentation, or other specialized supplies). Management should also inventory third-party service providers, including specific services they provide. The methodology used should be repeatable, allowing management to reevaluate information after significant changes. 

ILAS 

##  Interdependency Analysis 

The BIA process allows management to identify, analyze, and prioritize interdependencies among business functions and systems for alignment with resilience and recovery objectives. The analysis allows management to evaluate interdependent business functions, systems, and shared resources. 

During its analysis, management should identify single points of failure, which may include telecommunication lines, network connections between branches, backups that become corrupted, reliance on one power source, or data center locations in close geographic proximity. Personnel can be a single point of failure if there are no cross-trained personnel to back up their responsibilities. Important interdependencies that should be considered include the following: 

* • Internal systems and business functions, which could include customer services, production processes, hardware, software, application programming interfaces (i.e., code that allows two programs to communicate with each other), data, and documentation of vital records for legal/statutory or process documentation.
* • Third-party service providers (e.g., core processing, online and mobile banking, settlement activities, and disaster recovery services), key suppliers (e.g., hardware, software, and utility providers), and business partners and their roles and responsibilities for resilience and recovery.

The BIA will assist management in forming contract and service-level agreement (SLA) requirements for availability and reliability of each service. For pre-existing contracts and SLAs, management should confirm that the contract and SLA requirements align with management’s and the customer’s continuity and resilience expectations. 

15 The term “function” can consist of one or more processes. 

ILASS 

##  Impact of Disruption 

Through the BIA process, management should evaluate the potential impact of disruptive events, including operational, financial, and reputational impacts. Management should establish recovery objectives after determining a disruption’s impact. Common measurements include recovery point objective (RPO), recovery time objective (RTO), and maximum tolerable downtime (MTD). Where applicable, these measurements should be evaluated for alignment with third- party service providers’ contracted recovery expectations. 

Figure 3: Recovery Objectives (Relative to an Event) 

Event 

Last Viable 

Restore 

Point 

All 

Functionality 

Recovered 

Critical 

Disruption 

Point 

Data Loss 

(Definite) 

Data Loss 

(Potential) 

Down Time 

(Acceptable) 

Data Loss 

(Potential) 

Down Time 

(Excessive) 

Time 

Line 

Recovery 

Point 

Objective 

Recovery 

Time 

Objective 

Maximum Tolerable Downtime 

As illustrated in figure 3, the RPO represents the point in time, before a disruption, to which data can be recovered (given the most recent backup copy of the data) after an outage. Refer to section IV.A.2, “Cyber Resilience,” for additional information regarding backups. 

As illustrated in figure 3, the RTO defines the maximum amount of time that a system resource can remain unavailable before there is an unacceptable impact on other system resources and business processes. Determining the RTO is important for selecting appropriate technologies and strategies. When it is not feasible to meet an RTO, management should verify whether the RTO is realistic, initiate an action plan and milestone(s) to document the situation, and, when appropriate, plan for its mitigation. Management should consider interrelated RTOs for each business function to determine the total downtime caused by a disruption. Establishing realistic RTOs assists management in determining a critical path and hierarchy for recovery. For example, a process with a shorter RTO that is dependent upon on a process with a longer RTO may indicate a gap that should be analyzed further. 

Whether driven by customer expectations or technological advancement, previously established RTOs that were a few hours in duration may now require near real-time recovery. Therefore, it may be appropriate for management to reevaluate currently acceptable RTOs. 

As illustrated in figure 3, the MTD represents the total amount of time the system owner or authorizing official is willing to accept for a business process disruption and includes all impact considerations. The MTD is important for contingency planners when selecting an appropriate recovery method and developing the scope and depth of recovery procedures. Examiners may encounter other terminology to describe MTD (e.g., maximum allowable downtime). 

Failure to meet established metrics, such as RPO, RTO, and MTD, may have operational impacts, including discontinued or reduced service levels, inability to meet security requirements, workflow disruptions, supply chain disruptions, and delays of business initiatives. The financial impact could include the loss of revenue, increased costs, or fines and penalties. 

# III.B Risk Assessment 

## Action Summary 

Management should evaluate the likelihood and impact of potential disruptions and events. As part of this evaluation, management should consider the geographical area where the entity operates. Additionally, management should consider the risks and threats that could affect the entity’s third-party service providers. Once management identifies scenarios; evaluates specific threats to the controls, strategies, and plans; and understands the entity’s risk exposure, management should develop risk treatment strategies (including risk acceptance or risk transfer) based on the entity’s risk appetite. 

Examiners should review the risk assessment and determine whether it addresses the impact and likelihood of disruptions of the entity’s information services, technology, personnel, facilities, and services provided by third parties. Specifically, examiners should review whether the following types of events are included in the risk assessment: 

* • Natural events such as fires, floods, severe weather, air contaminants, and hazardous spills.
* • Technical events such as communication failure, power failure, equipment and software failure, transportation system disruptions, and water system disruptions.
* • Malicious activity, including fraud, theft, blackmail, sabotage, cyber attacks, and terrorism.
* • International events that may affect services (e.g., political instability and economic disruptions).
* • Low likelihood and high impact events (e.g., terrorist attacks or pandemic events).

Risk assessment is the process of identifying risks to operations, organizational assets, individuals, and other organizations. Risk assessments incorporate threat and vulnerability analyses and address the appropriate mitigations. As part of risk assessment processes, information from the ERM can be leveraged, such as business process documentation, critical risks, impacts, and tolerances. Management should use risk assessments to identify, measure, and mitigate risk exposures to critical functions and processes identified by the BIA. Furthermore, the risk assessment process may result in changes to the BIA. For example, management may prioritize business processes based on their importance to strategic goals and safe and sound practices; however, after developing threat models, results may necessitate prompt alteration of initial priorities or recovery plans. 

ILB. 

##  Risk Identification 

While management performs risk assessments, the focus of business continuity risk identification is on the resilience of the entity. While the causes of events can vary greatly, many of the effects do not. According to the Federal Emergency Management Agency (FEMA), threats and hazards can be categorized as natural, technological, and adversarial or human-caused.16 Each of these threats and hazards can be subcategorized, for example as internal (e.g., malicious insider or human error) or external, systemic or non-systemic, deliberate or inadvertent, and with or without warning. Although the characteristics of each hazard and threat (e.g., speed of onset, size of the affected area) may be different, the general tasks for recovering operations are the same. Management should address common operational functions in the business continuity plan (BCP) instead of having unique plans for every type of hazard or threat. Planning for all threats and hazards ensures that, when addressing emergency functions, planners identify common tasks and the personnel responsible for accomplishing the tasks. 

Management should evaluate potential risks that are in the entity’s geographic area. For example, entities could be located in flood-prone areas, earthquake zones, terrorist targets, or areas affected by tornados or hurricanes. In addition to geographic areas, management should also assess geopolitical risk and the potential for retaliatory cyber attacks. For example, U.S. sanctions against a nation-state could increase the risk of cyber attacks against critical infrastructure(s). 

Management should coordinate business continuity risk identification efforts throughout the entity. Individual business units within larger entities should coordinate risk identification activities to identify systemic threats to the overall entity. Management should identify and inventory the entity’s internal and external assets, types of threats and hazards, and existing controls as an important part of effective risk identification. Refer to the IT Handbook’s “Management” booklet for additional information. 

Furthermore, management should identify cyber security risks (refer to the IT Handbook’s “Information Security” booklet for additional information), which should be gathered as part of the risk assessment process. Cyber security can pose risk to customer information as discussed in the Interagency Guidelines Establishing Information Security Standards17 that implement the Gramm-Leach-Bliley Act (GLBA). 

16 Refer to FEMA’s Comprehensive Preparedness Guide (CPG) 101 Version 2.0. Non-FFIEC agency documents are included for illustrative purposes of common risks and are not supervisory expectations. 

Management should coordinate with external sources to obtain information about hazards and threats. External sources include industry information-sharing groups (e.g., Financial Services Information Sharing and Analysis Center (FS-ISAC)), and local, state, and federal authorities18 that provide timely and actionable information about hazards and threats. In addition, sharing information about events at an entity may help others identify, evaluate, and mitigate cybersecurity threats and vulnerabilities. Information about hazards and threats should be considered in the BIA, risk assessment, and other BCM processes. Refer to the IT Handbook’s “Information Security” booklet for additional information. 

One component in the risk identification process is the gathering and assessment of threat intelligence, which National Institute of Standards and Technology (NIST) defines as “information that has been aggregated, transformed, analyzed, interpreted, or enriched to provide the necessary context for decision-making processes.” Management should integrate its threat- intelligence process with the BCM function. 

Threats are potentially magnified when entities and their third-party service providers are tightly interconnected. An incident affecting one entity or third-party service provider can result in cascading impacts that quickly affect other service providers, institutions, or sectors. The term “supply chain risk” in BCM may be used to represent the risk related to the interconnectivity among the entity and others. A critical failure at a third-party service provider could have large- scale consequences. Management should identify interconnectivity points between the entity and its third-party service providers, as well as between other entities and third-party service providers. Documenting the flow of transactions, such as developing formal process diagrams, may help management identify interdependencies and end-to-end processes. 

ILB.2 

##  Likelihood and Impact 

Management should evaluate the likelihood and impact of disruptive events. Risks may range from those with a high likelihood of occurrence and low impact, such as brief power interruptions, to those with a low probability of occurrence and high impact, such as pandemics. The most difficult risks to address are those that may have a high impact on the entity but a low probability of occurrence. The Department of Homeland Security’s (DHS) National Infrastructure Protection Plan19 provides examples of risk measurement processes and methodologies to help analyze risks. 

17 Refer to the Interagency Guidelines Establishing Information Security Standards issued by 12 CFR 364, Appendix B (FDIC); 12 CFR 208, Appendix D-2 and 12 CFR 225, Appendix F (FRB); and 12 CFR 30, Appendix B (OCC). Also refer to Guidelines for Safeguarding Member Information, 12 CFR 748, Appendix A (NCUA). 

18 Examples include ChicagoFIRST county and state government, the DHS’s National Terrorism Advisory System, FEMA, and the World Health Organization. 

19 Refer to DHS’s National Infrastructure Protection Plan. 

As part of the assessment, management should quantify the impacts and define loss criteria as either quantitative (financial) or qualitative (e.g., impact to customers, reputational impact). The BCM risk assessment should be commensurate with the entity’s risk and complexity and should include reasonably foreseeable events. Worst-case scenarios, such as destruction of the facilities and loss of life, should be addressed. State and local authorities may assist management with identifying specific risks or exposures for geographic locations, and special requirements for accessing emergency zones. 

Management should also assess whether its third-party service providers consider the likelihood of a disruption based on the geographic location of facilities, their susceptibility to threats (e.g., location in a flood plain), and the proximity to critical infrastructure (e.g., power grids, telecommunications, nuclear power plants, airports, major highways, and railroads). 

Management should determine the potential severity of threats and estimate the disruption’s impact under various threat scenarios as it assesses the likelihood and impact of a disruption. The results may be scored quantitatively (e.g., based on a numerical ranking) or qualitatively (e.g., high, medium, and low) and then prioritized. Refer to the IT Handbook’s “Management” booklet for additional information. 

Once management identifies scenarios, it should evaluate specific threats to the entity’s controls, strategies, and plans. The difference, or the gap, between the risks from likely foreseeable threats and the mitigation provided by current controls, represents the risk exposure. Management should develop strategies to manage risk, which could include risk mitigation, avoidance, acceptance, or risk transfer, based on the entity’s risk appetite. 

# IV Business Continuity Strategies 

## Action Summary 

The board and senior management should develop effective strategies to meet resilience and recovery objectives. Effective oversight generally includes guidelines to achieve defined business continuity objectives. 

Examiners should review BCM strategies and determine whether the strategies: 

* • Address personnel, processes, technology, and facility issues.
* • Address critical business risks in the operating environment (e.g., mitigate specific or unique threats, such as cyber threats or loss of critical third-party service providers).
* • Outline a combination of backup, replication, and storage methods for data protection.
* • Provide for high redundancy levels in the telecommunications infrastructure.
* • Detail a consistent change management process throughout the entity.
* • Include alternatives for any proprietary systems.
* • Include provisions for appropriate international business activities, where applicable.

Business continuity strategies are developed after the BIA and risk assessment process. These strategies should be risk-based and address all foreseeable risks, including non-technology risks (e.g., transaction, liquidity, and reputation risks). Strategies should include allocation of resources to meet resilience and recovery objectives. Strategies should be validated to confirm that they are viable and sufficient for peak work volumes. For example, the increased reliance on and interconnectivity of technology makes it less feasible for many entities to operate manually for an extended period, if at all. 

Strategies should include the potential impact to personnel, processes, technology, facilities, and data. Personnel-related strategies may include logistical arrangements to transport or house staff at alternate facilities. In addition, management may establish alternate methods for communicating with employees, customers, and external parties. Process-related strategies may include redundant work sites for business-line operations or manual processes. Technology- related strategies may include fully equipped backup data centers or cloud providers. Backup strategies should include data files, operating systems, and applications and utilities. Facilities- related strategies may include geographic diversity or multiple power sources to reduce single point of failure risk. 

Data protection strategies typically include a combination of backup, replication, and storage to achieve different levels of continuity and resilience. For example, it may be appropriate to deploy more automated, scalable solutions, such as data replication to a cloud. Management should develop comprehensive strategies to protect data, such as: 

* • Integrating operational, continuity, and resilience strategies to protect data based on recovery objectives.
* • Designing a process to preserve the integrity and availability of data from threats.
* • Monitoring the effectiveness and efficiency of data protection solutions.

Strategies should address critical business risks in the operating environment. Management should consider strategies to mitigate specific or unique threats, such as cyber threats or loss of critical third-party service providers. The specific strategy in response to an event may be different based on the entity’s capabilities. Management should determine what alternatives exist for proprietary systems given the significant, unique risks to an entity’s business activities. For example, some entities use internally developed assets (e.g., spreadsheets or other tools) that are critical for certain calculations within a business unit, which are often overlooked, including where and how they are stored, during the risk assessment and BIA processes. Furthermore, management should also consider access capabilities for voice and data, mapping technology infrastructure to employee needs, and internal and external capacity (including remote capacity) to determine whether telecommuting strategies are sufficient. 

Strategies could include cloud architectures, virtualization, and other technologies. Cloud solutions may provide a cost-effective and high-availability environment. Independent of the strategies selected for architecture and data protection, management should still be responsible for data integrity and overall resilience. Cloud-based disaster recovery services20 may be considered as part of resilience programs. Refer to section V.C.1, “Data Center Recovery Alternatives,” for additional information. 

20 Refer to the FFIEC’s statement on Outsourced Cloud Computing. 

# IV.A Resilience 

## Action Summary 

Management should evaluate whether there are appropriate resources to ensure resilience, including an accessible, off-site repository of software, configuration settings, and related documentation, appropriate backups of data, and off-site infrastructure to operate recovery systems. 

Furthermore, management should discuss potential disaster scenarios with the entity’s third- party service providers to prepare for an event. Subsequently, management should assess the entity’s immediate or short-term space requirements, systems, and personnel capacity to assume or transfer failed operations. Additionally, management should assess critical third- party service providers’ susceptibility to simultaneous attacks and verify their resilience capabilities. 

Examiners should review the following: 

* • Appropriateness of resilience practices, including the adequacy of recovery infrastructure and backup processes.
* • Integration with disaster recovery services to protect against data destruction.
* • Assessment of alternate data communications infrastructure between the entity and critical third-party service providers.
* • Evaluation of the entity’s susceptibility to multiple threat scenarios in resilience planning, testing, and recovery strategies.
* • Designation of emergency personnel, including for critical business process-level employees.

Resilience is “the ability to prepare for and adapt to changing conditions and withstand and recover rapidly from disruptions. Resilience includes the ability to withstand and recover from deliberate attacks, accidents, or naturally occurring threats or incidents.”21 The business strategy, not technology solutions, should drive resilience. Resilience extends beyond recovery capabilities to incorporate proactive measures for mitigating the risk of a disruptive event in the overall design of operations and processes. Resilience strategies, including maintaining security standards, should extend across the entire business, including outsourced activities. Management should evaluate whether the entity has appropriate resources (e.g., human, financial, time) for resilience. When developing the entity’s resilience strategies, management should consider lessons learned from previous events. 

21 Refer to the Presidential Policy Directive/PPD-21, Presidential Policy Directive -- Critical Infrastructure Security and Resilience February 12, 2013. 

##  Physical 

Physical resilience is the traditional approach to business continuity and includes IT architecture, infrastructure, facilities, and communications. To avoid the potential for failures after a disruption, management, when possible, should diversify telecommunication lines, establish redundant connections between branches and data centers, create backups, identify multiple power sources, and verify geographic diversity of key entity locations. 

##  Cyber Resilience 

A challenge for cyber resilience is maintaining operations despite ever-changing risks (e.g., malware, data or system destruction and corruption, and communications infrastructure disruption). The sophistication and frequency of cyber attacks increase the potential for disruption and destruction of data and systems. Given the broad and increasing spectrum of cyber threats, resilience measures should be flexible enough to adapt to a diverse range of events. For example, a cyber attack could impact both production and backup facilities simultaneously, potentially rendering both inoperable, whether hosted internally or by a third-party service provider. 

In addition, adversaries may initiate a secondary disruption (e.g., the original disruption could be the impact of a hurricane with the secondary disruption being false transactions or accessing sensitive data). Alternatively, adversaries can launch simultaneous attacks (e.g., a distributed denial of service (DDoS) attack combined with a wire transfer compromise). Therefore, management should adhere to established security and privacy policies and processes to comply with applicable regulations, even during disruptive events. 

##  Data Backup and Replication 

Management should maintain data confidentiality, integrity, and availability for all iterations of data, including data backup and replication, not just focused on the production environment. Data backup and re-creation are important to recovering critical business functions in the event of disruptions. Backup files are commonly created electronically and can be mirrored at an off- site location, backed up on removable media, stored temporarily on network servers until rotated off-site, or backed up to a cloud environment. Backups should be readily accessible and adhere to the entity’s information security policy. 

Management should reassess backup and recovery strategies as the technology and threat environments evolve. For real-time or high-volume systems, it may be appropriate to have advanced duplication and backup methods. These advanced methods, including cloud and mirroring, provide high availability and are detailed in section V.E.1, “Data Center Recovery Alternatives.” 

Management should maintain an accessible, off-site repository of software, configuration settings, and related documentation. Even standard software configurations can vary from one location to another. Differences could include parameter settings and modifications, security profiles, reporting options, account information, customized software changes, or other options. 

Failure to back up software configurations could result in inoperability or could delay recovery. Therefore, a comprehensive backup of critical software is important. Software backups generally consist of the following components: 

* • Operating systems.
* • Applications.
* • Utility programs.
* • Databases.
* • Other critical software identified in the BIA.

Management should establish effective procedures to recover critical networks and systems. Procedures may address the following: 

* • Backup types (physical or virtual).
* • Backup levels (full, incremental, or differential).
* • Updates and retention cycle frequencies.
* • Software and hardware compatibility reviews.
* • Data transmission controls.
* • Data repository maintenance.

Refer to the IT Handbook’s “Operations” booklet for additional information. 

Data replication (also referred to as data synchronization or mirroring) is the process of copying data, usually with the objective of maintaining identical data sets in separate locations. Replication is important in any environment for resilience. Furthermore, management should consider integrity controls during replication so that data changes in production, development, and quality assurance environments are applied throughout the network. 

Two common data replication processes used for information systems are synchronous and asynchronous. Synchronous replication represents the direct application of the data by applying changes at the same time. In practice, synchronous replication allows data to be transmitted in a continuous stream and minimizes data loss; however, it requires significant communication bandwidth and has limitations on the distance data can be transported due to latency issues. Synchronous replication is typically used for critical business functions where little or no data loss can be tolerated. Conversely, asynchronous replication is the indirect application of data through applying changes to a log before transit. In practice, asynchronous replication allows data to be transmitted in intermittent batches. While asynchronous replication increases the potential for data loss related to the fractions of a second required to transmit the data, this process requires less communication bandwidth and is useful for data transport over longer distances, due to reduced latency issues. 

Management should determine the appropriate retention periods for each iteration of data backup. Entities should safeguard against replicating malware and data corruption. This risk is heightened with the use of near real-time data replication systems, as malware can be replicated undetected. Even with diagnostic tools, management could be unaware of an event that causes data integrity issues until well after it happens, as data could appear uncorrupted but later determined to be inaccurate. Management may determine that the backup of critical data files should be subject to longer retention periods to ensure the ability to recover a backup prior to a corruption event. 

Even in situations when the primary and backup facilities are inoperable or corrupted, customers of the entities expect to be able to access their accounts. Entities should develop appropriate cyber resilience processes (e.g., recovery of data and business operations, rebuilding network capabilities and restoring data) that enable restoration of critical services if the institution or its critical service providers fall victim to a destructive cyber attack or similar event. BCM should include the ability to protect offline data backups from destructive malware or other threats that may corrupt production and online backup versions of data. An example of an industry initiative to assist in addressing the resilience of customer account information is Sheltered Harbor.22 

WEA 4 

##  Personnel 

Resilience is dependent upon personnel availability to maintain critical business processes. Personnel could be unavailable or distracted during such events as natural disasters, severe weather events, or pandemics.23 While any one employee’s role may not be designated as mission critical, management should plan for mass absenteeism during an event or disruption. Previous catastrophic events (e.g., Hurricane Katrina24) demonstrate that personnel availability affects timely recovery. 

Management should plan for events during which personnel may not be able to access facilities and critical personnel may not be available immediately after the disruption. Public infrastructure and transportation systems may not be operating, and telecommunication systems may be overburdened and unavailable. Therefore, management should consider: 

* • Staffing and skills needed to operate critical functions related to business continuity.
* • Lodging arrangements for displaced employees and their families.
* • Basic necessities and services for displaced employees, including water, food, clothing, childcare, transportation, and cash.
* • On-site medical support and mobile command centers.
* • Secure telecommunication options if employees work from an alternate location.
* • Designated emergency personnel, including critical business process-level employees. 22 Sheltered Harbor is a voluntary industry initiative launched in 2015 following a series of cybersecurity simulation exercises between public and private sectors, known as the Hamilton Series. The purpose of the proposed Sheltered Harbor standard is to promote the stability and resiliency of the financial sector and to preserve public confidence in the financial system. The Sheltered Harbor standard proposes a combination of secure data vaulting of critical customer account information with a comprehensive resilience plan to provide customers timely access to their account information and underlying funds during a prolonged systems outage or destructive cyber attack. (Sheltered Harbor). 

23 Refer to the FFIEC’s FFIEC Highlights Pandemic Preparedness Guidance. 

24 Refer to the FFIEC’s Lessons Learned From Hurricane Katrina: Preparing Your Institution for a Catastrophic Event.

WEALS 

##  Third-Party Service Providers 

Many entities depend on third-party service providers to perform or support critical operations. A disruption in the delivery of those services can have a direct impact on entities’ resilience. A critical failure at a widely used third-party service provider could have large-scale consequences. Management should assess critical third-party service providers’ susceptibility to multiple event scenarios and verify such third parties’ resilience capabilities. An entity’s third-party service provider can be a single point of failure if management has not considered alternative providers or other contingency plans. If an alternative third-party service provider is not readily available, management should consider options to continue business operations and reevaluate resilience options periodically as conditions may change. Resilience planning should be closely coordinated with third-party service providers. 

Establishing well-defined expectations with third-party service providers is important to business resilience. Contracts and SLAs with third-party service providers should detail roles and responsibilities of each party to promote resilience. Ongoing monitoring of the entity’s third- party service providers helps management identify potential weaknesses in the third-party service provider’s resilience that could affect the entity’s operations. 

Management’s review of an entity’s third-party service provider’s BCM program may include independent audit reports or SOC reports. SOC reports can contain valuable information about the third-party service provider’s products and processes. If management relies on SOC reports, it should verify whether business continuity activities are audited, including whether the scope and depth of review are sufficient to allow management to evaluate the third-party service provider’s control environment.25 Depending on the scope of the audit testing, additional inquiry and activities may be appropriate to understand the resilience of the third-party service provider. 

Management should consider the same risks outlined in their entity’s own internal BCP(s) in relation to third-party service providers, as well as: 

* • Capacity of third-party service provider to meet client recovery objectives in the agreements, relative to other clients’ needs.
* • Ability to participate in recovery testing with third-party service providers and access to testing results.
* • Ability to move outsourced processes either in-house or to another third-party service provider.
* • Alternative resource options (e.g., personnel and systems) for when primary services cannot be delivered.
* • Data confidentiality, integrity, and availability (e.g., transportability and interoperability). 25 SOC 1 reports cover controls at the third-party service provider that affect financial reporting. Business continuity activities are usually reported in unaudited sections of SOC 1 reports because they often do not have a direct correlation to the preparation of the financial statements, unless an event happened during the audit period. SOC 2 reports cover trust services criteria and include activities such as security, confidentiality, availability, privacy, and integrity. Audit firms typically do not opine on the quality of the business continuity activities, because it is difficult to predict what would happen during an actual event. Activities related to business continuity such as replication, plan development, and testing may be included in SOC 2 reports covering availability.
* • Financial capacity to continue meeting contractual obligations.
* • Services concentrated in a limited number of third-party service providers.

Business continuity-related provisions found in contracts and SLAs may include the following: 

* • Time parameter(s) for contracted service(s).
* • Appropriate baseline metrics describing management’s resilience and recovery expectations (e.g., an incident response metric to ensure timely response to events impacting business continuity and resilience).
* • Periodic service reviews to ensure up-to-date agreements with all parties involved.

If operations at a third-party service provider cease, the length of time required to convert to an alternate system would, for most applications, exceed a reasonable RTO. To the extent possible, management should establish plans for the resilience of third-party service providers supporting critical operations. 

VA.6 

##  Telecommunications 

Given the critical nature of telecommunications, management should ensure appropriate redundancy levels in the entity’s telecommunications infrastructure. The entity’s telecommunications infrastructure may contain single points of failure that are outside the control of a single entity. Management should understand the limitations of the entity’s third- party telecommunications providers’ infrastructure. For example, multiple carriers may rely on the same telecommunications backbone. Key aspects management should consider in establishing telecommunication redundancy include: 

* • Identifying and mitigating single points of failure across the entity’s infrastructure.
* • Developing and maintaining a plan to address an outage in the telecommunications lines with the entity’s primary third-party service providers.
* • Establishing redundant telecommunications links with each of the entity’s third-party service providers through a contractual arrangement, which allows either party to switch its connection to an alternate communication path.
* • Reviewing the entity’s third-party service providers’ plans and determining whether critical services can be restored within acceptable time frames.
* • Developing guidelines, commensurate with the entity’s size, complexity, and risk profile, to diversify connections to mitigate the risk of a telecommunications failure.
* • Assessing the communications technology that bridges the transmission distance between the telecommunications service provider and the entity, sometimes referred to as the “last mile,” for single points of failure.
* • Monitoring relationships with telecommunications providers to manage risks.
* • Inquiring about the physical paths used by telecommunications providers and verifying that system redundancies have been properly implemented. Communication is critical to the financial services sector and other industries. Therefore, management should consider the following services provided by the federal government. These services give participants priority access to telecommunications during a wide-spread event.
* • The Telecommunications Service Priority (TSP)26 program.
* • Government Emergency Telecommunications Service (GETS).27
* • Wireless Priority Service (WPS),28 which is the wireless complement to GETS.
##  Power 

The financial industry is dependent on power to run its technology infrastructure and to supply basic necessities to personnel and customers. A long-term power outage can negatively impact an entity’s resilience. Management should implement measures to provide electricity in the event of a short-term power disruption. Furthermore, management should develop plans to provide electricity in the event of a long-term power disruption. As part of its short-term and long-term plans, management should consider the following: 

* • Alternate energy sources (e.g., generators, multiple power grids).
* • Fuel requirements, both for fuel on-hand and contracts with suppliers for deliveries during
* • Load capacity of generators (e.g., length of time, useful life, level of power supplied).
* • Continued maintenance of generators.
* • Testing of generators. events, and any potential impediments to obtaining fuel.

WEA 

##  Change Management 

Management should implement and align a consistent change management process throughout the entity, making sure to include BCM. As changes are made to production systems and business processes during the normal course of business, recovery systems and documentation at alternate locations should similarly be updated to reflect production and primary system changes. 

The change management process should allow for expedient implementation of emergency changes during an event, such as changing an access control list to provide rapid access for troubleshooting and analysis. Change tickets and corresponding activity should be reviewed for appropriateness once the event has been resolved. Even during events, changes should still be properly authorized, monitored, and documented. Poorly administered emergency changes can result in further disruption. Additionally, the interrelated nature of systems can compound disruptions to previously unaffected systems. After an emergency event, systems documentation should be updated for any changes made. Change management elements are addressed in more detail in the IT Handbook’s “Development and Acquisition” and “Operations” booklets. 

26 Refer to the DHS’s “Telecommunications Service Priority” (TSP) webpage. The TSP program provides service vendors a Federal Communications Commission mandate to prioritize requests by identifying those services critical to national security and emergency preparedness. TSP-designated circuits are recovered first in an emergency. Management may contact the entity’s primary federal regulator for information on the TSP program and whether the entity qualifies for a TSP designation. If the entity qualifies, management should integrate the TSP program into the entity’s BCP. 

27 Refer to the DHS’s “Government Emergency Telecommunications Service” (GETS) webpage. GETS provides “priority access and prioritized processing in the local and long distance segments of the landline networks, greatly increasing the probability of call completion.” It is intended to be used in an emergency or crisis situation when the landline network is congested and the probability of completing a normal call is reduced. Management may request GETS cards by submitting an application to the entity’s primary federal regulator. 

28 Refer to the DHS’s “Wireless Priority Service” webpage. 

# IV.B Communications 

Management should consider, plan for, and prepare multiple mechanisms to communicate with others. For example, when traditional voice communications and telecommunications are impaired or inoperable, management may consider alternative communications systems such as text messaging through employer-provided and personal mobile phones, personal email, and instant messaging. Other common solutions include an inbound hotline number, an informational webpage, or a two-way polling phone system. Regardless of the communication device used, appropriate controls to safeguard customer and other sensitive information should be maintained. 

BCM should include communication protocols and contact lists to notify stakeholders. Management should consider the content and process for developing such protocols and templates. Communication protocols should incorporate strategic communications and crisis management approaches in concert with public affairs or external communications (e.g., prepared public/press statements, media response plans, managing social media, etc.). Communication protocols provide customers, third-party service providers, and other external groups a means to communicate when normal channels are inoperable. External groups could include the following: 

* • Regulatory agencies (federal and states).
* • Emergency responders.
* • Law enforcement.
* • Financial sector trade associations.
* • Customers, third-party service providers, and other third parties (e.g., counterparties, clearing and settlement partners, payment system operators).
* • Information-sharing entities (e.g., FS-ISAC).
# V Business Continuity Plan 

## Action Summary 

Management should develop business continuity plan(s) (BCP) with sufficient detail in relation to the entity’s size and complexity. The BCP should address key business needs and incorporate inputs from all business units. 

Examiners should review the plan for the following: 

* • Authorities, responsibilities, and relocation strategies.
* • Communications protocols, event management, business continuity, and disaster recovery.
* • Liquidity concerns before and during an adverse event.29
* • Alternatives for payment systems, facilities and infrastructure, data center(s), and branch relocation during a disaster.

As shown in figure 2, a BCP is an important component of BCM. The BCP documents the practices and procedures for continuing business operations during a disruption. The BCP focuses on critical business functions and varies according to the entity’s size and complexity. The BCP includes specific elements, such as incident response, disaster recovery, and crisis management. Smaller entities may have a single BCP that includes these elements whereas large, complex entities may have multiple plans supported by subsidiary components for business functions, locations, or departments. Furthermore, the BCP should be a living document, regularly updated so that it remains current with system enhancements and organizational changes.30 

A comprehensive plan describes the authorities, responsibilities, procedures, and relocation strategies. Components of the plan should include: 

* • Roles, responsibilities, and required skills for entity personnel and third-party service providers.
* • Solutions to various types of foreseeable disruptions, including those emanating from cyber threats.
* • Escalation thresholds.
* • Immediate steps to protect personnel and customers and minimize damage.
* • Prioritization and procedures to recover functions, services, and processes.
* • Critical information protection (e.g., physical, electronic, hybrid, and use of off-site storage). 29 Refer to NIST SP 800-61, Computer Security Incident Handling Guide. 

30 Refer to “BCP Strategy Concept,” NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems. NOTE: While this document pertains to federal information systems, the principles are relevant for non- federal information systems.
* • Logistical arrangements (e.g., housing, transportation, or food) for personnel at the recovery locations.
* • Network equipment, connectivity, and communication needs, including entity-owned and personal mobile devices.
* • Personnel at alternate sites, including arrangements for those permanently located at the alternate facility.
* • Scope and frequency of testing.
* • Resumption of a normalized state for business processes.

Representatives from all business units should contribute to BCP development and implementation. The BCP may be developed and maintained internally or outsourced. In either case, the entity’s board and senior management should be responsible for the BCP. Management should verify the third-party service provider’s qualifications and expertise when outsourcing BCP development. Management should work with the third-party service provider to design executable and viable strategies. Regardless of its development process, the BCP and supporting documentation should be stored so that it is readily accessible by personnel during adverse events. 

# V.A Event Management 

The BCP may define various situations as events, disruptions, or triggers. An event is an occurrence or change in circumstances that may affect operations. An event can be physical, cyber, or a combination of both. A disruption is either an anticipated or unplanned event that causes operations to degrade or fail for an unacceptable length of time (e.g., a minor or extended power outage, an extended unavailable network, or equipment or facility damage or destruction). A trigger is an event that prompts management’s response. Predefined threshold escalation triggers are a key element of a BCP, and responses should be designed to mitigate the impact from adverse events. 

The BCP should include event management procedures that detail reasonably foreseeable event types and provide thresholds and responses. Procedures should describe how to report an event to management and the situations that warrant notification to those who address events. Management should consider establishing a team(s)31 to address events. Individuals managing the event may change depending on the nature of the event and team member availability. While the team should manage the event and communicate with stakeholders, event monitoring is an entity-wide responsibility (e.g., board, senior management, and other personnel). 

Responses may include activities, programs, or systems that protect life and property, meet basic human needs, and preserve the entity’s operational capability. Examples of event responses include: 

* • Switching operations to a backup facility after a software upgrade and subsequent rollback fail. 31 Depending on the entity’s size and complexity, authority to respond to an event may fall to an individual, a team, or multiple teams. The term “team” is used for purposes of this booklet.
* • Rerouting personnel to a safer location or authorizing telecommuting when the local area becomes unsafe.
* • Authorizing telecommuting when an event causes disruptions to operations.
* • Invoking disaster recovery procedures once management has identified a significant cyber attack.
* • Activating emergency response procedures once a hurricane threatens the local region.
# V.B Continuity and Recovery 

Management should establish protocols for operations continuity and system recovery. The BCP may include: 

* • Addressing customer service requests during downtime.
* • Tracking daily transactions.
* • Reconciling general ledger accounts.
* • Documenting operational tasks.
* • Posting entries after system recovery.
* • Maintaining backup records to provide customer account information (e.g., account numbers,
* • Documenting steps for system hardware and software recovery and restart. customer names, addresses, account status, and account balances).

When appropriate, procedures should address manual steps for critical functions, such as back- office operations, loan operations, and customer support. Business continuity plans and procedures should be clear, concise, and easy to implement in an emergency,32 such as checklists and step-by-step procedures. 

Displaced customers may not have access to their normal identification and personal records. The BCP should include alternate identity verification methods, and management should be alert for fraud or other suspicious activities. Procedures should address fraud identification33 and suspicious activity reporting34 according to protocols and legal requirements.35 

During the recovery phase, management should coordinate access and availability of power and telecommunications systems with various entities. Management should coordinate with the police and fire departments and local and state government agencies to facilitate timely, secure resilience strategies. Management may also coordinate with other federal agencies, such as the Federal Emergency Management Agency, depending on the disaster severity. Refer to the IT Handbook’s “Operations” booklet for additional information. 

32 Refer to NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems. NOTE: While this document pertains to federal information systems, the principles are relevant for non-federal information systems. 

33 Refer to the Financial Crimes Enforcement Network’s (FinCEN) FIN-2006-A001, Guidance to Financial Institutions Regarding Hurricane-Related Benefit Fraud. 

34 Refer to FinCEN’s FIN-2013-G002, Administrative Difficulties in Submitting Electronic Reports to FinCEN. 

35 Refer to 31 CFR 1020.220, Customer Identification Programs for Banks, Savings Associations, Credit Unions, and Certain Non-Federally Regulated Banks. 

# V.C Facilities and Infrastructure 

The BCP should identify alternatives for core operations, facilities, infrastructure systems, suppliers, utilities, interdependent business partners, and key personnel. The backup site may mirror the operational functionality of the primary site. Management should consider site relocation for short-, medium-, and long-term scenarios. When selecting a facility, management should plan for scalability because an event may last for an extended period of time. In addition, management should consider the entity’s proximity to police, fire, and medical facilities, and the expected response time frames should be factored into recovery strategies. Management should enlist the assistance of state and local agencies to expedite building permits and inspections for temporary facilities. Management should verify that recovery alternatives can accommodate the services and processing capabilities affecting critical operations, including: 

* • Core processing.
* • Check processing and imaging.
* • Commercial cash management.
* • Payments.
* • Mailing, faxing, and printing.
* • Customer identification.
* V. C.

##  Data Center Recovery Alternatives 

Data center recovery alternatives vary for infrastructure, configuration, operational state, and data migration. Management should document the reasons (e.g., cost and service level) for choosing an alternative and why it is appropriate based on the entity’s risk profile and complexity. The level of intervention required to activate the alternate sites affects both the cost and duration to resume operations. Recovery alternatives may take several forms, such as fully redundant systems at alternate sites, cloud-based recovery solutions (either internally developed or outsourced), another data center, or a third-party service provider. Data center and alternate site development is complex, and management should consider constraints in the analysis and design process. The primary objectives are for data to be available and remotely accessible. Management should maintain appropriate controls, regardless of solution. Alternative recovery site examples may include: 

* • Cold site: A backup facility that has the necessary electrical and physical components of a computer facility, but does not have the computer equipment in place. The facility is ready to receive computer equipment when personnel move from their main computing location to the backup facility. This facility is usually not considered as the primary recovery option within the financial services industry because of the significant time necessary to install and activate the infrastructure. Comprehensive testing cannot occur until the infrastructure is established.
* • Warm site: An environmentally conditioned work space that is partially equipped with information systems and telecommunications equipment to support relocated operations in the event of a significant disruption. The systems are not loaded with the software or data required to resume operations and typically require manual intervention for failover and system reboots to resume critical processes. Therefore, end users may experience some disruption.
* • Hot site: A fully operational off-site data center equipped with hardware and software used in the event of an information system disruption. Hot site development is complex, and management should consider constraints in the analysis and design process.
* • Mirrored data recovery sites: Two or more separate, active sites that back up one another with each site independently supporting critical business functions. These sites provide almost immediate resumption capacity and are seamless for end users. Physical distance and its related latency present limitations for data centers that use real-time, data mirroring backup technologies. Similar to a hot site, these sites contain all of the equipment and connectivity capabilities; however, they also have a duplicate copy of the data. This method of high availability is commonly referred to as “Active-Active.”
* • Mobile site: A site that possesses capabilities between what a warm and a cold site offer and has portable structures equipped with computing equipment available to customers or personnel. Completely activating a mobile site depends on how quickly it can be delivered and backups restored.
* • Colocation facility: A facility that provides space, power, infrastructure, environmental controls, and telecommunications capabilities for multiple non-related tenants. If management relies on a colocation facility to deliver resources, there is a risk that the capacity at the colocation service provider may not be able to support the entity’s operations during a regional or large-scale event.
* • Reciprocal agreement: An agreement that allows two entities to back up each other. While these agreements may be cost-effective, they are viable only if there is adequate excess capacity at the reciprocal financial institution and both operate on the same version and configuration of core software. Consideration should be given to security and privacy, as sensitive customer information could be exposed to the staff at the reciprocal financial institution. While these arrangements may be acceptable as a short-term solution, management should not rely on them as a long-term recovery solution.
* • Disaster recovery as a service (DRaaS): A cloud-computing solution for replicating and hosting infrastructure, applications, and data that provides failover and recovery services.

V. 

##  Branch Relocation 

An adverse event may lead management to temporarily limit or cease branch operations or temporarily transfer a branch’s operations to alternate locations. An important BCP component is establishing a physical location where personnel and customers can go to conduct business. For financial institutions, approval by the appropriate regulator may be required to close, relocate, or establish additional branch facilities.36 

36 Refer to 12 U.S.C. 1831r-1, “Notice of Branch Closure”; 64 Fed. Reg. 34844, “Policy Statement of the Office of the Comptroller of the Currency, Board of Governors of the Federal Reserve System, Federal Deposit Insurance Corporation, and Office of Thrift Supervision Concerning Branch Closing”; 12 CFR 303, Subpart C, “Establishment and Relocation of Domestic Branches and Offices” (FDIC); 12 CFR 208.6, “Establishment and Maintenance of Branches” (FRB); 12 CFR 5.30, “Establishment, Acquisition, and Relocation of a Branch of a National Bank” 

# V.D Payment Systems 

The BCP should address alternate arrangements if payment systems fail (e.g., automated teller machines (ATM), funds transfers, electronic banking, remote deposit capture, or mobile capabilities). Alternate solutions may include manual procedures for calling in or faxing wire or automated clearing house requests to correspondent financial institutions. In addition, web-based systems or third-party software may be used to perform transactions. Management should verify that redundant electronic payment systems and equipment (e.g., tokens and routers) are included at recovery sites for activation and that documentation is maintained for timely posting of entries when systems are recovered. 

The BCP should also address increased cash demands and moving funds through electronic systems, including internet and mobile banking. Management may consider developing procedures for pre-established withdrawal limits based on the financial institution’s relationships with customers. In addition, management should prepare for a potential increase in branch traffic when ATMs are unavailable. Pre-established agreements with various cash delivery services within and outside of the local area should also be considered so that ATMs can meet customer demand when service returns. 

# V.E Liquidity Considerations 

The BCP should detail processes to address potential cash and liquidity needs during adverse events. During a disaster, power and communications systems may fail (e.g., inoperable ATMs or debit and credit card systems), requiring cash to fulfill customer and business needs. Arrangements to help meet liquidity needs may include: 

* • Emergency borrowing access.
* • Alternative cash delivery.
* • Procedures to secure, deliver, and distribute cash.
* • Temporary purchase authority guidelines.
* • Expense reimbursement options for personnel.
* • Higher-limit credit cards or separate checking accounts, with designated individuals who can sign checks in emergency situations.
# V.F Other Components 

The BCP focuses on sustaining business processes during and after an event. The BCP may incorporate other plans and procedures to minimize a disruption’s impact. Components may include incident response, disaster recovery, and crisis or emergency management. 

(OCC); and 12 CFR 5.31, “Establishment, Acquisition, and Relocation of a Branch and Establishment of an Agency Office of a Federal Savings Association” (OCC). 

VE. 

##  Incident Response 

Incident response helps management minimize the disruption of services or loss of information from an adverse event. Incident response priorities include preservation of life, preservation of property, incident stabilization, and communicating with stakeholders (e.g., impacted personnel, third-party service providers, customers, regulators, law enforcement). As shown in figure 4, the incident response team should coordinate communication with the noted stakeholders. Management should align incident response procedures with other related processes (e.g., cybersecurity, network operations, and physical security), outsourced services (e.g., contracted incident response obligations), and verify that the procedures are considered during planning and BCP development. 

Figure 4: Incident Response Team (Adapted From NIST SP 800-61, Rev. 2) 

Customers 

Media/ 

Other 

Third-Party 

Service 

Providers 

Incident 

Response 

Team 

< 

> 

Board & Senior 

Management 

Law 

Enforcement 

Regulatory 

Agencies 

Management should designate a spokesperson(s) to communicate with the news media. Management should consider various, pre-planned response scenarios approved by the board and senior management. Communication with the news media and via social media may be important for disseminating accurate information. Social media monitoring during an event can help management resolve conflicting messages and proactively respond to issues and concerns. 

Management should train personnel to adhere to the plan when approached by the news media or communicating via social media. 

Furthermore, management should leverage routine processes (e.g., vulnerability management and network monitoring) to anticipate potential incidents, including cyber incidents, and coordinate incident response planning with any third-party service provider plans. Furthermore, management should consider prearranging third-party forensic and incident response services. Management should periodically update and test the entity’s incident response program to verify that it functions as intended, given rapidly changing threats. Refer to the IT Handbook’s “Information Security” booklet for additional information. 

WAE 

##  Disaster Recovery 

Disaster recovery is the restoring of IT infrastructure, data, and systems. Management should identify key business processes and activities to be maintained while IT systems and applications are unavailable and prioritize the order in which these systems are restored, which should be reflected in the BIA. In addition, management should develop a coordinated strategy for the recovery of data centers, networks, servers, storage, service monitoring, user support, and related software. 

Recovery plans should address a broad range of adverse events (e.g., natural disasters, infrastructure failures, technology failures, unavailability of staff, or cyber attacks). Disaster recovery should address guidelines for returning operations back to a normalized state with minimum disruption. 

Disaster recovery should also address the following: 

* • Security controls and protocols, including physical and logical, for implementation and operation of recovery systems.
* • Procedures for restoring backlogged activity or lost transactions to identify how transaction records will be brought current within expected recovery time frames.
* • Instructions to access critical information repositories and other resources when the primary facility is unavailable.

When developing disaster recovery plans, management should exercise caution when identifying critical and non-critical systems. For example, telephone banking, internet banking, or ATMs may not seem critical when systems are operating normally; however, these systems play a critical role in delivering services to customers during a disruption. Similarly, an email system may not appear critical but may be the primary system available for communication during an adverse event. 

VES 

##  Crisis or Emergency Management 

Crisis or emergency management37 is the process that allows the recognition of a crisis, activation of a BCP, and management of emergencies. Crisis or emergency management includes the ability to recover from a major event through predefined leadership and communication. Not every event warrants a crisis or emergency management response. Management should consider the impact of a crisis or emergency on the entity’s reputation and personnel. For example, management may invoke crisis or emergency response procedures during a natural disaster, cyber attack, or other high-profile event. 

The crisis or emergency management portion of the BCP should address coordination with regulatory agencies, local and state officials, law enforcement, and first responders. Scenarios should detail disruptions, and not be confined to a single event, facility, or geographic area. Also, crisis or emergency management plans should address simultaneous disruptions of telecommunications and electronic messaging, including between the entity and third-party service providers. 

Management should designate key personnel from applicable departments to act during a crisis or emergency situation, commensurate with the entity’s size and complexity. Designated personnel should be authorized to make decisions in a timely manner. Key personnel may include: 

* • Senior management for leadership.
* • Facilities management for safety and physical security.
* • Human resources for personnel issues, travel, and relocation.
* • Media relations for managing communications.
* • Finance and accounting for funds disbursement and financial decisions, including unanticipated expenses.
* • Legal and compliance for legal and regulatory concerns.
* • IT, including information security, and operations for specific tactical responses.

Communication protocols for a crisis or emergency event should include contact lists and other viable methods to reach personnel and other stakeholders who may be called upon during a crisis. The contact list should be distributed and accessible to key personnel and should be verified and updated regularly. Management should be able to communicate with personnel located in isolated areas or dispersed across multiple locations. Procedures should enable employees to report their status in a centralized manner and obtain current information. Crisis or emergency management communication protocols should include provisions to contact the entity when normal communication channels are inoperable. 

Notification systems can be manual or automated. In less complex environments, manual communication techniques, such as call trees, are often used; however, information gathering can be time consuming, and responses can be unreliable in a crisis. Maintaining contact information can become unwieldy for large entities; therefore, automated solutions may be used. 

37 The financial services industry uses the terms “crisis management” and “emergency management” interchangeably. 

# VI Training 

## Action Summary 

Management should implement a business continuity training program for all stakeholders. 

Examiners should review for the following: 

* • Objectives of business continuity training.
* • Alignment of business continuity training with strategies.
* • Extent of targeted business continuity training provided to stakeholders, such as personnel, business continuity program staff, and the board.
* • Format of the business continuity training program.
* • Process for reviewing and updating the business continuity training program.

Management should include training as part of an effective business continuity program to educate stakeholders on resilience, business continuity goals, corporate-wide objectives, policies, and individual personnel roles and responsibilities. The board or senior management delegates a committee or individual to oversee the training program; however, the board should be responsible for the training program’s effectiveness. Refer to the IT Handbook’s “Management” booklet for additional information. 

The training program should align with the entity’s strategy and use a comprehensive, risk- based, multi-year approach, including interrelated programs (e.g., disaster recovery and third- party risk management). The frequency of exercises should depend on the size and complexity of the entity and the elements of the training program, risks, and testing program iteration, with all elements covered in a timely manner. Management should take inventory of the current skill sets for business continuity and identify and address any gaps. When appropriate, management should establish goals and objectives for supporting the entity’s business continuity program as part of the performance management process. Some elements of the training program may include: 

* • Exercises.
* • Current risks.
* • Future risks.
* • Recent failures.
* • New programs/technologies.
* • Organizational changes.
* • Previous (exercise) lessons learned.

Training generally involves a conceptual understanding of business continuity, including testing methods, test results, and critical business functions. The training program should include conditions for activating the BCP and what to do when key personnel are unavailable. Training should selectively and purposely seek to validate plans and assumptions by testing the interactions of people, processes, and technology risks and vulnerabilities in a consequence-free exercise environment. 

Training should be tailored to the target audience, addressing the needs of specific groups. Training participants should include the board, senior management, business process owners, and frontline personnel. For example, training for personnel who manage the business continuity program should be different than training for personnel not directly involved in recovery operations. Training should include significant business continuity concepts, interdependencies, disruption impacts, and operational resilience. When applicable, contractors involved with the business continuity program should also receive appropriate training. 

The board should understand the business continuity program, testing initiatives, and key business continuity-related reports. Board training should occur regularly, or more frequently, based on significant changes to business processes, risks, BIA results, or lessons learned from incidents that have impacted the entity. Training methods may involve instructional classes, computer-based training, hands-on experience, lessons learned, and collaborating with other organizations. Role-based training includes cross-training personnel to compensate for significant absenteeism or operational disruptions, which may occur during an event. Training should reflect changes to the business continuity program as they occur. 

# VII Exercises and Tests 

## Action Summary 

The board and senior management should provide for appropriate exercises and tests to verify that business continuity procedures support business continuity objectives. Exercises and tests should be used to validate one or more aspects of the entity’s BCP. 

Examiners should review for the following in exercise and testing plans: 

* • Provisions for exercises and tests occurring at appropriate intervals and when significant changes affect the entity’s operating environment.
* • Comprehensive program objectives and plans of exercises and tests to validate the ability to restore critical business functions in a timely manner.
* • An exercise and test process that provides assurance for the continuity and resilience of critical business functions, without compromising production environments.
* • Authorities and control over exercises and tests.
* • Exercise and test policies, expectations, and strategies that demonstrate the entity’s ability to utilize alternate facilities.
* • Exercise and test objectives for resilience, system monitoring, and the recovery of business processes and critical system components.
* • Exercise and test scenarios, including exercise and test assumptions, objectives, expectations, and assessment metrics.
* • Types of exercises (e.g., full scale, limited scale, or tabletop) and tests.
* • Exercises and tests related to interaction with third parties, industry-wide testing, and core and significant firms.
* • Documentation of issues identified through exercises and tests, and action plans and target dates for resolution.
* • Board expectations for overall business continuity capabilities, including guidelines to achieve defined business continuity objectives.

Exercises and tests38 help ensure that business continuity procedures support business continuity objectives. An exercise is a task or activity involving people and processes that is designed to validate one or more aspects of the BCP or related procedures. There are many different types of exercises, depending on the intended goals and objectives. Exercises may include scenario- driven simulations of BCP elements. For example, exercises may include performing duties in a simulated environment (i.e., functional) or be discussion based (i.e., tabletop). 

A test is a type of exercise intended to verify the quality, performance, or reliability of system resilience in an operational environment. Tests are evaluation tools that use quantifiable metrics to validate the operability of an IT system or system component in an operational environment 

38 For purposes of this booklet, the term “exercise” represents both exercises and tests, unless the term “test” is specifically mentioned. 

(e.g., what happens as a result of removing power from a system or system component). Tests may focus on backup and recovery options of systems. The degree of testing can vary, from individual system components up to comprehensive tests of all system components that support business operations. Effectively, the distinction between the two is that exercises address people, processes, and systems whereas tests address specific aspects of a system. 

# VII.A Exercise and Test Program 

Management should develop a comprehensive exercise and testing program including objectives, and plans to validate the entity’s ability to restore critical business functions. The entity’s risk profile should influence the frequency, objectives, and documentation of the overall exercise schedule. The entity’s consolidated exercise and test schedule should be reflective of exercise and test objectives and the overall exercise and test universe.39 

Management should designate personnel with the authority to control the exercise or test and confirm milestones are met. Business line management should retain ownership and accountability for testing resilience of business operations, including applications and processes (both internal and external). While business line management should be responsible for testing its specific business processes and related interdependencies, managers should coordinate with personnel involved in the enterprise-wide business continuity process and support areas, such as IT and facilities management. Results should be reported to the board and senior management for inclusion in the enterprise-wide business continuity process. 

Exercises and tests should occur either at appropriate intervals, when new risks are identified, or when significant changes affect the entity’s operating environment. Significant changes can render existing test plans obsolete, so BCP(s) should be retested soon after the change. A comprehensive program allows management to evaluate business interdependencies and improve continuity and resilience. 

A key objective for management should be to develop a testing process that validates the effectiveness of the entity’s business continuity program, and identifies any deficiencies that may exist. Therefore, the exercise and test program should incorporate the following: 

* • A policy that includes strategies and expectations for exercise and test planning.
* • Roles and responsibilities for implementation.
* • Sufficient personnel to perform the exercise or test, provide oversight, and document the results.
* • Precautions to safeguard production data, such as performing a backup before performing a test in a test environment, or testing during non-peak hours.
* • Provisions for emergency stops (i.e., management’s authority to stop an exercise if a real-life event occurs) and concluding exercises and tests. 39 Similar to an audit universe, an entity’s exercise and test universe is composed of an inventory of all business processes and system components that are compiled and maintained to identify areas for the exercise and test planning process.
* • Verification of continuity and resilience process assumptions and the ability to process a sufficient volume of work during adverse operating conditions.
* • Activities commensurate with the importance of the business process, as well as to critical financial markets.
* • Result comparison against the BCP to identify gaps between the exercise or test process and recovery guidelines, with revisions incorporated where appropriate.
* • Independent review of business continuity program and exercises and tests (internal and external).
# VII.B Exercise and Test Policy 

The entity’s policies should define exercise and testing expectations and strategies. The policies should: 

* • Identify key roles and responsibilities.
* • Establish minimum frequency, scope, and reporting requirements.
* • Define documentation expectations that are consistent across business processes.
* • Include a process for correcting deficiencies identified during exercises or tests.
* • Address testing of communication and connectivity between the entity and third-party service providers.
* • Detail participation with critical third-party service providers to confirm that entity personnel understand integration with recovery processes.
# VII.C Exercise and Test Strategies 

Management should develop exercise and testing strategies that demonstrate the entity’s ability to support connectivity, functionality, volume, and capacity using alternate facilities. The strategies should include expectations for individual business lines and use of exercise and testing methodologies and scenarios. Testing strategies should encompass internal and external dependencies, including activities outsourced to domestic and foreign-based third-party service providers. Management should test all aspects of the entity’s BCP. Strategies may include: 

* • A multi-year plan to execute the specific depth and breadth of exercises and tests to identify gaps in the program by using different methodologies and scenarios over time.
* • Expectations for testing internal and external recovery dependencies.
* • Assumptions, methodologies, and exercises used to develop the test strategies.

Lessons learned from natural disasters and other events show that for critical business functions, testing strategies should include transaction processing and functional testing to assess the recoverability of infrastructure, capacity, and data integrity. Regardless of the recovery strategy used, management should regularly test recovery provisions commensurate with the risk to the entity and, where applicable, the overall financial service sector. 

# VII.D Exercise and Test Objectives 

The exercise and testing objectives should include resilience, system monitoring, and the recovery of business processes and critical system components. Tests can range from recovering a single file to a full-scale failover to another data center. Tests should include physical security, critical systems, multiple departments, and third-party relationships. Exercises should be sufficiently thorough to test dependencies and interrelationships among systems and third-party service providers. As the exercise and test process matures, it should become increasingly complex up to and including full-scale recovery exercises. Exercises and any associated tests should accomplish the following objectives: 

* • Build confidence that resilience and recovery strategies meet business requirements.
* • Demonstrate that critical services can be recovered within agreed upon recovery objectives (RTOs and RPOs), including customer SLAs, and within MTDs.
* • Establish that critical services can be restored in the event of an incident at the recovery location.
* • Familiarize staff with recovery processes.
* • Verify that personnel are adequately trained and knowledgeable of recovery plans and procedures.
* • Confirm exercise and test plans remain compatible with the BCP and the entity’s infrastructure.
* • Identify gaps and deficiencies.
# VII.E Exercise and Test Plans 

Plans address the objectives and expectations of the exercise or test and outline the scenario and any assumptions or constraints that may exist. Exercises and test plans should include metrics to assess whether objectives are met. Plans should identify roles and responsibilities for participants, support personnel, and observers.40 Exercise and test plans should be commensurate with the nature, scale, and complexity of the recovery objectives. 

Management should receive and review third-party service provider exercise results, regardless of the entity’s extent of participation. Management should consider the scope and results of these exercises in the entity’s BCP. Management should evaluate third-party service providers’ resilience and ability to recover critical services used by the entity if an event occurs. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for additional information. 

Test plans generally include the following: 

* • Roles and responsibilities for all test participants, including support personnel.
* • A consolidated exercise and test schedule that encompasses all objectives.
* • A specific description of objectives and methods.
* • Identification of decision makers and succession plans. 40 For the purposes of this booklet, the term “observers” does not constitute an independent review or audit function.
* • Exercise and test locations.
* • Exercise and test escalation procedures and the ability to adjust for simulated scenarios.
* • Contact information.
* • Metrics to measure the success or failure of the exercise or test.

Management should review the exercise and test results, update the BCP where appropriate, and report the results to the board or board-designated committee. Suggestions for improving test scenarios, plans, or scripts provided by test participants should be incorporated into the testing cycle, where appropriate. 

# VII.F Exercise and Test Scenarios 

Management should develop realistic exercise and test scenarios, based on risks, which simulate disruptions in business functions and help management determine the ability to meet both business requirements and customer expectations. The goal should not be to execute “perfect” exercises without issues; instead, it should be to continuously strengthen the business continuity program and validate the BCP(s). Management should identify and document assumptions used in developing each scenario. The scenarios should include threats that could affect third-party service providers and others, such as significant business partners. Exercises and tests should include communication processes with applicable stakeholders. Exercises demonstrate not only the ability to failover to an alternate site but also validate recovery objectives. Management should consider all reasonably foreseeable risks to connectivity and service-level agreements between the entity’s facility(ies), third-party service provider facilities, and with any applicable counterparties (i.e., entities on the other side of a financial transaction) with whom they transact significant or critical business. 

Scenarios may include: 

* • Simultaneous attacks affecting both the entity and a third-party service provider.
* • Cyber-related events (e.g., isolated malware attack, DDoS attack, data corruption, or a full- scale data center outage).
* • Use of mirrored sites to demonstrate that alternate sites can effectively support customer- specific requirements, work volumes, and site-specific business processes.
* • Processing a full day’s work at peak volumes.

To the extent possible, scenarios should include only resources that would be available during an event (e.g., backup files or equipment at the alternate site). Considering data and systems helps management verify the integrity of data backups (including access to encrypted data) and the adequacy of off-site systems and supplies, such as workstations and procedure manuals. 

Management should develop exercise and test scripts to guide participants and meet objectives. Each script should document the procedures, which may include: 

* • Applications, business processes, systems, or facilities reviewed.
* • Sequential steps for employees or external parties to perform.
* • Procedures to guide manual work-around processes.
* • A detailed schedule for completion.
* • Methods for participants to record results, quantifiable metrics, and any issues.
# VII.G Exercise and Test Methods 

Exercises and tests help management validate continuity and resilience of technology components, including systems, networks, applications, and data, that support critical business functions. The type or combination of methods should be determined by the entity’s size and complexity and the nature of its business. The DHS offers assistance and examples of testing methods,41 which are available to all entities and may be helpful when developing exercises and tests. Rigorous exercise methods and increased frequency help provide greater confidence in the continuity and resilience of business functions. While comprehensive exercises involve greater investments of time, resources, and coordination, the benefit is a more accurate assessment of recovery capabilities if a disaster occurs. This assists management in assessing the resilience of systems and responsiveness of the individuals involved in the recovery process. Comprehensive testing of all critical functions and applications allows management to identify potential problems; therefore, management should use one of the more thorough testing methods discussed in this section to verify the BCP’s viability 

While names for exercises and tests may be different, or used interchangeably, this booklet lists the most commonly encountered elements in the following subsections. 

VILG. 

##  Full-Scale Exercise 

Full-scale exercises (sometimes called a full interruption or comprehensive exercise) help management validate internal and external interdependencies between critical business functions, information systems, and networks (e.g., for critical functions, exercises should include transaction processing and functional testing). Integrated exercises move beyond comprehensive exercises to include testing with internal and external parties and the supporting systems, processes, and resources. Management should periodically reassess and update exercise and test plans to reflect changes in the business and operating environment. 

A full-scale exercise simulates full use of available resources (personnel and systems) prompting a full recovery of business processes. The goal of a full-scale exercise is to determine whether all critical systems can be recovered at the alternate processing site and whether personnel can implement the procedures defined in the BCP. For example, a full-recovery exercise might simulate the complete loss of primary facilities. Features of a full-scale exercise may include the following: 

41 As members of an established sector of critical infrastructure, financial institutions can leverage testing constructs implemented by the DHS. The Homeland Security Exercise and Evaluation Program is the DHS policy and guidance for designing, developing, conducting, and evaluating exercises. The program provides a threat- and performance-based exercise process that includes a mix and range of exercise activities through a series of four reference manuals to establish exercise programs and design, develop, conduct, and evaluate exercises. 

* • Engaging personnel from all business units to participate and interact with internal and external management response teams.
* • Validating the crisis or emergency management process is operating as designed.
* • Verifying personnel knowledge and skills.
* • Validating management response and decision-making capability.
* • Coordinating participants and decision makers.
* • Validating communication protocols.
* • Conducting activities at alternate locations or facilities.
* • Processing data using backup media or alternative methods.
* • Completing actual transactional volumes or an illustrative subset.
* • Performing recovery exercises over a sufficient length of time to allow issues to unfold as they would in a crisis.

VILG. 

##  Limited-Scale Exercise 

A limited-scale exercise is a simulation involving applicable resources (personnel and systems) to recover targeted business processes. The goal of a limited-scale exercise is to determine whether targeted systems can be recovered and whether personnel understand their responsibilities as defined in the plan. Features of a limited-scale exercise may include the following: 

* • Implementing a plan appropriate to the scenario.
* • Verifying personnel knowledge and skills.
* • Validating management response and decision-making capability.
* • Executing on-the-scene coordination and decision-making roles.
* • Verifying whether participants can connect to alternate system(s).
* • Conducting activities at alternate locations or facilities.
* • Testing communication and remote access capability (e.g., switching to alternate equipment or telecommuting).

While limited-scope exercises are important, they often have limited participation (e.g., departmental personnel only) or scope and do not necessarily allow management to gauge interconnectivity and how systems and capacity would support daily activities and workloads. VILG. 

##  Tabletop Exercise 

A tabletop exercise (sometimes referred to as a walk-through) is a discussion during which personnel review their BCP-defined roles and discuss their responses during an adverse event simulation. The goal of a tabletop exercise is to determine whether targeted plans and procedures are reasonable, personnel understand their responsibilities, and different departmental or business unit plans are compatible with each other. By themselves, tabletop exercises are likely insufficient to validate recovery capabilities, because they are limited to a discussion-based analysis of policies and procedures. 

Features of a tabletop exercise may include the following: 

* • Engaging operational and support personnel who are responsible for implementing the BCP.
* • Practicing and validating specific functional response capabilities.
* • Demonstrating knowledge, skills, team interaction, and decision-making capabilities.
* • Role playing with simulated responses, critical steps, recognizing difficulties, and resolving problems.
* • Clarifying critical plan elements, as well as problems noted during exercises.
* • Creating action plans to correct issues.

VILG 4 

##  Tests 

Management uses tests to verify the quantifiable performance and reliability of system resilience. The goal of testing is to determine whether system resilience conforms to the BCP and stated recovery objectives. Test methodologies and frequencies should align with the risk associated with the business function as well as the entity’s testing strategies and objectives. Management should clearly define the characteristics of a successful test, which may include the following: 

* • Validating RPOs, RTOs, and MTDs.
* • Demonstrating recoverability at peak volumes.
* • Confirming that systems can support critical business processes (e.g., transfer to alternate sites, increased workloads, manual workarounds, and communication).
* • Integrating technologies that support critical business activities, including data replication, recovery, and off-site storage.
* • Testing backup data to assess integrity and availability.
* • Certifying facility controls (e.g., environmental, backup power, and physical security).
* • Verifying workspace restoration (e.g., network connectivity and communications).
# VII.H Industry Exercises and Resilience 

Given the potential for and nature of widespread and systemic disruptive events, public and private sector groups42 conduct exercises with their members to verify resilience across the financial industry. These exercises simulate significant regional or industry-wide emergencies, and members are encouraged to use backup sites and test their recovery capabilities. In addition to financial institutions, these coordinated tests often include participation by third-party service providers and government agencies. There are several methods for entities of all sizes to participate, such as through third-party service provider user groups or industry initiatives. For example, industry initiatives include the U.S. Department of the Treasury’s Hamilton Series (national and regional series) and the FS-ISAC’s Cyber-Attack Against Payment Systems (CAPS). The results of these exercises are usually available to members of industry and regulatory groups, and summaries may be available to the public. 

42 Public and private groups include the FS-ISAC, Financial Services Sector Coordinating Council (FSSCC), Financial Systemic Analysis & Resilience Center (FSARC), Financial and Banking Information Infrastructure Committee (FBIIC), and some regional coalitions. 

Examiners should understand that opportunities to participate in such exercises may be limited. The Financial Sector Cyber Exercise Template43 is publicly available from the U.S. Department of the Treasury, and management can use it to help verify the entity’s own response capabilities and evaluate how it would respond during similar situations. Additionally, the template and results may be used as resources to validate exercise and testing assumptions and scenarios. 

# VII.I Third-Party Service Provider Testing 

Third-party service providers deliver critical services to many entities and should be included in the enterprise-wide exercise and testing program. The extent of inclusion in the entity’s program should be based on the criticality of the third-party service provider and the business function. Management should obtain assurance that third-party service providers are resilient and have adequate infrastructure and personnel to restore critical services consistent with business and contractual requirements. The right to perform or participate in testing with third-party service providers should be included in the contract governing the entity’s relationship with the third party. 

Management should actively participate in the entity’s third-party service providers’ testing programs and should verify that testing strategies include likely significant disruptive events. Third-party service providers should be transparent about testing parameters and results because not all clients can participate in every testing activity (e.g., when there is a large client volume) and some exercises and tests may not be relevant to the services provided to a specific customer. Management should request and receive test results and reports, remediation action plans and status reports upon their completion, and related analysis or modeling. Management should track and resolve any issues identified during the exercise in a timely manner, according to the severity of the issues. Any test results that affect the entity should be presented to its board. In most instances, equating one entity’s recovery experience with another’s does not guarantee similar results; therefore, management should perform its own analysis. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for additional information. 

# VII.J Testing for Core and Significant Firms 

Management at core and significant firms should develop verification strategies and execute exercise and testing activities to validate that the entity implemented sound recovery practices consistent with the entity’s role in the industry. Additionally, management should consider the impact of an event at its entity on the entire financial sector. The elements discussed in the Sound Practices Paper supplement the agencies’ respective policies and other guidance on business continuity planning. Entities not designated as core and significant firms may also consider guidance from the Sound Practices Paper as a model for enhancing their testing processes. 

Identification of external interdependencies is important given the sector’s reliance on core and significant firms. Internal testing activities should include systems that support critical market activities in which these firms are core or significant. Exercise and testing activities should confirm that such critical clearing and settlement activities could be recovered within RTOs. 

43 Refer to the U.S. Department of the Treasury’s Financial Sector Cyber Exercise Template. 

Industry standard time frames are continually adjusted based on available technology, pertinent risks, and industry initiatives. Management should adjust its RTOs to be in line with industry standard time frames. Furthermore, management should design testing activities to demonstrate the ability to perform the following activities if a wide-scale disruption affects the accessibility of key personnel: 

* • Complete pending material payments and transactions.
* • Access funding.
* • Manage material open risk positions.
* • Make related entries to books and records.
* • Validate internal and external communication protocols.
* • Ensure connectivity, functionality, and volume capacity.

Management should test with the relevant core firms from their alternate sites and meet testing standards the core firms establish specifically for significant firms and for participants more generally. Management at core and significant firms should perform testing to assess the effectiveness of their recovery strategies. Management is also encouraged, to the extent practical, to participate in pertinent market-wide and cross-market tests44 that validate connectivity from alternate sites and include transaction, settlement, and payment processes. 

Examination and supervisory activities may include evaluations of verification strategies and testing plans to assess whether core and significant firms, which are the focus of the Sound Practices Paper, have achieved the resilience to protect the financial system from a wide-scale disruption. 

# VII.K Post-Exercise and Post-Test Actions 

Management should document issues identified during exercises and tests and create action plans with target dates for resolving issues. Exercise and test results should be analyzed and compared with the objectives and success criteria in the exercise and test plans, and reported to appropriate levels of management. For those items not remediated, management should document decisions to accept risks identified during the exercises. 

Additionally, management should test corrective actions implemented as a result of a failed recovery objective or to address major issues encountered. Management may choose to retest during or before the next regularly scheduled exercise depending on an issue’s severity. Business line management should update the BCP based on test results and adjust the BCM process, including the exercise and testing program. Finally, management should submit regular reports to the board on the exercise and testing activities and whether the BCP meets the entity’s recovery and resilience objectives. 

Exercise and test results may include the following documentation: 

44 Industry and cross-market tests are often conducted by associations such as the Securities Industry Association, Bond Market Association, and Futures Industry Association. These associations are mentioned for illustrative purposes only; this note is not an endorsement of any of these associations. 

* • Dates and locations.
* • An executive summary comparing objectives and results.
* • Material deviations from the plans, including whether intended participation was achieved.
* • Problems identified and lessons learned.
* • Assignment of responsibility for timely resolution of issues identified.

Management should periodically analyze results and issues to determine whether problems can be traced to a common source, such as inadequate change control procedures. Fixing the root cause of the problem may help resolve many underlying issues. 

# VIII Maintenance and Improvement 

Because risks and technology often change, management should regularly review and update the business continuity program to reflect the current environment. Periodic reviews allow management to align the business continuity processes with business objectives. Management should use this information to prioritize and focus on system and process corrections and enhancements. Triggers that prompt maintenance and improvement of the business continuity program may include the following: 

* • Changes in enterprise strategies.
* • New or reconfigured products, services, or infrastructure.
* • Changes in products and services offered by third-party service providers.
* • Deficiencies identified in third-party service provider business continuity processes.
* • New legislation, regulatory requirements, or resilience practices.
* • Results of operational metric analysis (e.g., key risk indications, key performance indicators).
* • Early warning indicators that may identify potential continuity events, crises, or incidents (e.g., frequency and severity of storms, increased cyber attacks, or increases in customer service calls).
* • Variances between budgeted and actual business continuity expenses.
* • Results from exercises and tests, and lessons learned.
* • Changes in the threat landscape (e.g., new capabilities, intent of threat actors).
* • Recommendations (e.g., from audits, vulnerability assessments, and penetration tests).

To determine the extent of changes to the business continuity program, BCM program personnel should contact business unit managers regularly to assess the nature of any changes to the business, structure, systems, software, hardware, personnel, or facilities. Management at smaller, less complex entities may perform this function informally; however, the maintenance and improvement concepts remain valid for those entities. 

The business continuity program should be reviewed for accuracy and completeness at periodic intervals. Likely areas45 that should be adjusted within the BCP may include: 

45 The concept of business continuity program review elements aligns with NIST SP 800-34 Rev. 1, Contingency Planning Guide for Federal Information Systems. While this document pertains to federal information systems, the principles are relevant for non-federal information systems. 

* • Operational requirements.
* • Security requirements.
* • Technical procedures.
* • Hardware, software, and other equipment.
* • Team member contact information.
* • Vendor contact information.
* • Alternate and off-site facility requirements.
* • Vital records.

When updating the business continuity program, management should document, track, and resolve any changes. Management should document, analyze, and review lessons learned from adverse events. Understanding these lessons allows management to prepare for future adverse events. Documented procedures for incorporating lessons learned should include: 

* • Identifying the failure(s).
* • Determining the cause(s).
* • Evaluating potential solutions.
* • Implementing timely corrective actions as appropriate.
* • Recording and reviewing corrective actions taken.

As part of the maintenance and improvement process, management should maintain version control of key business continuity documents and ensure that the latest versions are readily available to appropriate personnel. The level of detail in documentation should be commensurate with the nature of the entity’s operations. This information should be accessible during an event and can be maintained by BCM program management and personnel. The BCM documentation should include evidence substantiating periodic updates of the BIA, risk assessment, and BCP(s). 

Business continuity document management processes may include the following: 

* • Roles and responsibilities.
* • Document control.
* • Version control.
* • Storage and disposal.

Management should follow the entity’s information security standards for confidential or sensitive information contained within business continuity documentation. Additionally, management should maintain backup copies of relevant business continuity documentation in the event that the primary repository becomes inaccessible. 

# IX Board Reporting 

## Action Summary 

The board should establish expectations for management’s business continuity reporting, regularly monitor business continuity and resilience activities, and provide credible challenges to management. 

Examiners should review reports and meeting minutes and conduct discussions with management on the following: 

* • BIA.
* • Risk assessment.
* • BCP.
* • Resilience.
* • Exercise and test results.
* • Identified issues.
* • Strategy updates.
* • Audit results.
* • Metrics, including key risk indicators and key performance indicators for BCM and resilience.

As illustrated in figure 1, management should report on the status of business continuity to the board, completing the BCM cycle. Reports should include a written presentation providing the BIA, risk assessment, BCP, exercise and test results, and identified issues. Additionally, reports should include regular strategy updates based on changes in personnel, roles and responsibilities, and business operations. The board should monitor business continuity and resilience activities regularly to verify that they are implemented as envisioned and reviewed periodically or as changes dictate. The board should be updated in a timely manner based on lessons learned. Board minutes should reflect business continuity discussion (including credible challenges) and approvals. 

# Appendix A: Examination Procedures 

## Examination Objective 

These examination procedures (also known as the work program) are intended to assist examiners in determining the quality and effectiveness of the business continuity process on an enterprise-wide basis or across a particular line of business. Additionally, these procedures assist examiners in evaluating whether business continuity testing demonstrates the entity’s ability to meet its business continuity objectives including management’s ability to recover, resume, and maintain operations after disruptions, ranging from minor outages to full-scale disasters. Examiners are not limited by the examination procedures presented here and may choose to use only certain components of the work program based on the size, complexity, and nature of the entity’s business. Depending on the examination objectives, a line of business can be selected to sample how the entity’s continuity planning or testing processes work individually or for a particular business function or process. 

Objective 1: Determine the appropriate scope and objectives for the examination. 

* 1. Review past reports for outstanding issues or previous problems. Consider the following: 
	+ a. Regulatory reports of examination.
	+ b. Internal and external audit reports.
	+ c. Reports by independent risk management.
	+ d. Business continuity tests.e. Regulatory, audit, and business continuity reports on third-party service providers.
* 2. Review management’s response to issues identified during or subsequent to the last examination. Consider the following: 
	+ a. Adequacy and timing of corrective action.
	+ b. Resolution of root causes rather than symptoms.
	+ c. Status of uncorrected issues.
	+ d. Retesting to validate corrective action.
* 3. Interview management and review responses to pre-examination information requests to identify changes to technology infrastructure or new products and services that could affect business resilience. Consider the following: 
	+ a. Products or services delivered to either internal or external users.
	+ b. Network topology or diagram, including changes to configuration or components and all internal and external connections.
	+ c. Hardware and software inventories.d. Loss, addition, or change in duties of key personnel. 


	+ e. Third-party service providers and software vendor listings.
	+ f. Changes to internal business processes.
	+ g. Changes based on industry changes or threat intelligence.
* 4. Review newly identified threats and vulnerabilities to the continuity of operations. Consider the following: 
	+ a. Technology and security vulnerabilities.
	+ b. Internally identified threats.
	+ c. Externally identified threats (e.g., cybersecurity alerts, pandemic alerts, or emergency warnings published by information-sharing organizations and government agencies).Objective 2: Determine whether the board and senior management promote effective governance of business continuity through defined responsibilities, accountability, and adequate resources to support the program. (II.A, “Board and Senior Management Responsibilities”) 


	+ 1. Determine whether business continuity policies and critical business procedures are: 
		- a. Up-to-date and reflective of the current business environment.
		- b. Communicated effectively throughout the entity.
		- c. Available during adverse events.
		- d. Securely maintained.
	+ 2. Determine whether the board and senior management provide leadership when overseeing business continuity, including: 
		- a. Evaluating continuity risk.
		- b. Setting short- and long-term continuity objectives.
		- c. Adopting appropriate policies and procedures.
		- d. Evaluating continuity performance.
		- e. Adjusting programs and operations in response to test results and actual events.
	+ 3. Determine whether management strengthens resilience through the following: 
		- a. Assessing continuity risk.
		- b. Resilience planning.
		- c. Testing business continuity plans.
		- d. Incorporating lessons learned from testing and events.
		- e. Considering resilience in business functions and the design of existing operations and new products and services.
	+ 4. Determine whether board oversight includes the following: 
		- a. Assigning business continuity responsibility and accountability.
		- b. Allocating resources to business continuity (e.g., personnel, time, budget, and training).
		- c. Aligning BCM with business strategy and risk appetite.
		- d. Understanding business continuity risks and adopting appropriate policies and plans to manage events.
		- e. Understanding business continuity operating results and performance.
		- f. Providing a credible challenge to management responsible for the business continuity process (e.g., the board minutes provide evidence of active discussions).
		- g. Establishing a provision for management intervention if timeliness for corrective action is not met.
	+ 5. Determine whether management oversight of business continuity includes the following: 
		- a. Defining business continuity roles, responsibilities, and succession plans.
		- b. Allocating knowledgeable personnel and sufficient financial resources.
		- c. Validating that personnel understand their business continuity roles.
		- d. Establishing measurable goals against which business continuity performance is assessed.
		- e. Designing and implementing a business continuity exercise strategy.
		- f. Confirming that exercises, tests, and training are comprehensive and consistent with the exercise strategy.
		- g. Resolving weaknesses identified in exercises, tests, and training.
		- h. Meeting regularly to discuss policy changes, testing plans, and training.
		- i. Assessing and updating business continuity strategies and plans to reflect the current business conditions and operating environment for continuous improvement.
		- j. Aligning plans between business units across the enterprise.
		- k. Coordinating plans and responses with external entities.Objective 3: Determine whether the board and senior management engage audit or other independent review functions to review and validate the design and operating effectiveness of the BCM program. (II.B, “Audit”) 


	+ 1. Determine whether the board and senior management have engaged audit (or an independent review) to validate the design effectiveness of the business continuity program and whether controls are operating effectively.
	+ 2. Determine whether audit reports to the board and provides an assessment of management’s ability to manage and control risks related to continuity and resilience.
	+ 3. Determine whether audit leverages SOC reports and other external artifacts from third-party service providers, as appropriate.
	+ 4. Determine whether the board or management validates that the auditor is qualified to carry out the review and is independent of the business continuity or related functions.
	+ 5. Evaluate the audit coverage of business continuity, whether through a general controls audit, during audits of business lines, or as a stand-alone business continuity audit. Audit coverage should include the following: 
		- a. The reasonableness and comprehensiveness of the BIA and business continuity risk assessment(s).
		- b. The reliability, adequacy, and effectiveness of continuity and resilience controls.
		- c. The effectiveness of risk mitigation efforts.
		- d. Whether test plans achieve their stated objectives based on reasonable assumptions.
		- e. Audit monitoring of exercises and tests, reviewing test plans and results, and verifying that any issues are identified and appropriately escalated.
		- f. Assessment of the business continuity program effectiveness.Objective 4: Determine whether management developed an appropriate and repeatable BIA process that identifies all business functions and prioritizes them in order of criticality, analyzes related interdependencies, and assesses a disruption’s impact. (III.A, “Business Impact Analysis”) 
	
	
		- 1. Determine the process through which management inventories business functions. Management may use the following artifacts to identify the functions: 
			* a. Organizational charts.
			* b. Work flows (also called process maps).
			* c. Interview notes.
			* d. Network diagrams/topologies.
			* e. Data flow diagrams.
		- 2. Determine whether management inventoried the critical assets and infrastructure upon which business functions depend, including the identification of single points of failure. Critical assets and infrastructure may include the following: 
			* a. People.
			* b. Hardware.
			* c. Software.
			* d. Cash reserves.
			* e. Supporting activities (e.g., technology support, payroll, contracting).
			* f. Supporting software (e.g., email, office productivity suites).
			* g. Network connectivity.
			* h. Communication lines.
			* i. Facilities.
			* j. Utilities.
			* k. Infrastructure and services provided by third-party service providers.
		- 3. Determine whether the interdependency analysis includes the following: 
			* a. Internal systems and business functions, including services, production processes, hardware, software, and application programming interfaces, data, and vital records.
			* b. Third-party service providers, key suppliers, and business partners.
			* c. Telecommunications single points of failure.
			* d. Power single points of failure.
		- 4. Review the BIA to determine whether the prioritization of business functions is reasonable. Consider management’s ability to do the following: 
			* a. Determine the operational and financial impacts of a disruption.
			* b. Aggregate loss impacts and determine a rating scale to indicate impact severity.
			* c. Reconcile BIA and risk assessment results with prioritization and document whether the reconcilement is adequate.
		- 5. Determine whether the BIA produces sufficient information to estimate the following: 
			* a. Recovery point objectives (RPO).
			* b. Recovery time objectives (RTO).
			* c. Maximum tolerable downtime (MTD).

### Objective 5: Determine whether management conducts a risk assessment sufficient to evaluate the likelihood and impact of potential disruptions and events. (III.B, “Risk Assessment”) 

* 1. Review risk assessment(s) to determine whether management has identified all reasonably foreseeable hazards and threats to the continuity and resilience of the entity. Examples of risks can include: 
	+ a. Natural: 
		- • Flood, earthquake, hurricane, tornado, and other weather events.
	+ b. Technological: 
		- • Technological: Malware, cyberattack, and hardware and software failure.
		- • Operational: Critical infrastructure disruption (e.g., transportation and water systems).
	+ c. Adversarial or human-caused: 
		- • Personnel: Strike, pandemic, and malicious insider.
		- • Social: Terrorism, vandalism, looting, riots, and protests.
	+ d. Combination: 
		- • Facility: Fire, power outage, and loss of access.
		- • Geographic-related: Proximity to railroad or highways used for transport of hazardous materials, proximity to airports, traffic difficulties, and other issues.
		- • Third-party: Services concentrated in a limited number of third-party service providers.
* 2. Determine whether management identifies BCM risks and coordinates risk identification efforts throughout the entity to identify systemic threats. 
	+ a. Determine whether management identifies and inventories the following: 
		- • Internal and external assets.
		- • Types of threats and hazards.
		- • Existing controls.
	+ b. Verify that the risk assessment includes the identification of cybersecurity risks and results of information security risk assessments.
	+ c. Assess whether management obtains information about hazards and threats from external sources.
	+ d. Determine whether management considers threat intelligence in risk identification efforts.
* 3. Ascertain whether management identifies interconnectivity points between the entity and its third-party service providers, as well as interconnectivity between other entities and their third-party service providers (i.e., supply chain).
* 4. Determine whether the risk assessment includes the impact and likelihood of potential disruptive events, including worst-case scenarios.
* 5. Determine whether management identifies and analyzes gaps between the entity’s risk exposure and the risk appetite, and documents any controls implemented to mitigate the residual risk.
### Objective 6: Determine whether the entity’s risk management strategies are designed to achieve resilience. (IV.A, “Resilience”) 

* 1. Verify that management has evaluated strategies and resource needs and allocates appropriate resources to achieve resilience: 
	+ a. Appropriate personnel and skillsets to carry out the functions.
	+ b. Time to identify and implement solutions.
	+ c. Budget to accomplish resilience goals and objectives.
* 2. Determine whether management has implemented physical resilience measures that: 
	+ a. Establish redundant communications between branches and data centers.
	+ b. Identify multiple power sources.
	+ c. Geographically diversify key entity locations.
* 3. Determine whether management has implemented data and cyber resilience measures that: 
	+ a. Maintain confidentiality, integrity, and availability for backup, replication, and production environments.
	+ b. Implement appropriate backups and sufficient documentation and retention periods for each iteration of data backup.
	+ c. Periodically reassess backup and recovery strategies as technology and threats change.
	+ d. Maintain an accessible, off-site repository of software, configuration settings, and related documentation.
	+ e. Establish procedures to recover critical networks and systems, including: 
		- • Backup types (physical or virtual).
		- • Backup levels (full, incremental, or differential).
		- • Update and retention cycle frequencies.
		- • Software and hardware compatibility reviews.
		- • Data transmission controls.
		- • Data repository maintenance.
	+ f. Protect offline data backups from destructive malware that may corrupt production and online backup versions of data.
* 4. Determine whether management documented and implemented, as appropriate, the following resilience measures for personnel: 
	+ a. Staffing and skills needed to operate critical functions related to business continuity.
	+ b. Lodging arrangements for displaced employees and their families.
	+ c. Basic necessities and services for displaced employees, including water, food, clothing, childcare, and transportation.
	+ d. On-site medical support and mobile command centers.
	+ e. Secure telecommunication options if employees work from an alternate location.
	+ f. Designated emergency personnel, including critical business process-level employees (i.e., those necessary to ensure all critical business operations function appropriately).
* 5. Determine whether management documented and implemented, as appropriate, the following resilience measures for third-party service providers: 
	+ a. Considered disruptive events that threaten the operational resilience and viability of the entity’s third-party service provider.
	+ b. Assessed the entity’s immediate or short-term space, systems, and personnel capacity to assume or transfer failed operations.
	+ c. Assessed critical third-party service providers’ susceptibility to multiple event scenarios.
	+ d. Reviewed third-party service provider’s resilience capabilities, including available test and SOC reports.
	+ e. Verified that SLAs with third-party service providers align with the entity’s recovery objectives.
	+ f. Established plans for the resilience of third-party service providers supporting critical operations.
* 6. Determine whether management documented and implemented, as appropriate, the following resilience measures for telecommunications: 
	+ a. Identifying and mitigating single points of failure across the entity’s infrastructure.
	+ b. Developing and maintaining a plan to address an outage in the telecommunications lines with its primary third-party service providers.
	+ c. Establishing redundant telecommunications links with each of the entity’s third-party service providers through a contractual arrangement that allows either party to switch its connection to an alternate communication path.
	+ d. Reviewing the entity’s third-party service providers’ plans and determining whether critical services can be restored within time frames acceptable to the entity.
	+ e. Developing guidelines, commensurate with the entity’s size, complexity, and risk profile, to diversify connections to mitigate the risk of a telecommunications failure.
	+ f. Assessing the communications technology that bridges the transmission distance between the telecommunications service provider and the entity for single points of failure.
	+ g. Monitoring relationships with telecommunications providers to manage risks.
	+ h. Evaluating communications and resilience needs to ensure branch communications.
	+ i. Inquiring about the physical paths used by telecommunications providers and verifying that system redundancies have been properly implemented.
* 7. Determine whether management considers the following as part of the entity’s power resilience strategies: 
	+ a. Alternate energy sources (e.g., generators and multiple power grids).
	+ b. Fuel requirements, both for fuel on-hand and contracts with suppliers for deliveries during events.
	+ c. Continued maintenance of generators.
	+ d. Testing of generators.
* 8. Verify that BCM activities align with the entity’s change management process.
### Objective 7: Determine whether the entity’s BCM includes communication protocols. (IV.B, “Communications”) 

* 1. Determine whether management considers, plans for, and prepares multiple mechanisms to communicate with personnel and other stakeholders while maintaining appropriate controls to safeguard customer information. Other stakeholders could include: 
	+ a. Regulatory agencies (federal and state).
	+ b. Emergency responders.
	+ c. Law enforcement.
	+ d. Financial sector trade associations.
	+ e. Information-sharing entities (e.g., FS-ISAC).
### Objective 8: Assess the appropriateness of the entity’s enterprise-wide BCP. (V, “Business Continuity Plan”) 

* 1. Verify that management implemented a comprehensive BCP that is reflective of the entity’s risk environment. The BCP should outline the following: a. Roles, responsibilities, and required skills for entity personnel and third-party service providers. 


	+ b. Solutions to various types of foreseeable disruptions, including those emanating from cyber threats.
	+ c. Escalation thresholds.
	+ d. Immediate steps to protect personnel and customers and minimize damage.
	+ e. Prioritization and procedures to recover functions, services, and processes.
	+ f. Critical information protection (e.g., physical, electronic, hybrid, and use of off-site storage).
	+ g. Logistical arrangements (e.g., housing, transportation, or food) for personnel at the recovery locations.
	+ h. Network equipment, connectivity, and communication needs, including entity-owned and personal mobile devices.
	+ i. Personnel at alternate sites, including arrangements for those permanently located at the alternate facility.
	+ j. Scope and frequency of testing.
	+ k. Resumption of a normalized state for business processes.
* 2. If management outsources the BCP’s development, verify that management maintains oversight and ownership of the BCP. 
	+ a. Determine whether management verified the third-party service provider’s qualifications and expertise.
	+ b. Verify that entity management worked with the third-party service provider to design executable and viable strategies.
	+ c. Verify that the plan reflects the entity’s current products, business processes, and third- party service providers.
	+ d. Determine whether roles and responsibilities reflect the entity’s current organizational structure.
* 3. Determine whether the BCP includes event management procedures that detail reasonably foreseeable event types, and those procedures include threshold metrics and response methods. 
	+ a. Verify that procedures explain how to report an event to management and the situations that warrant notification.
	+ b. Determine whether management (either an individual or team) has implemented procedures to communicate with both internal and external stakeholders.
	+ c. Verify that event management processes include event response procedures that are appropriate to the event.
* 4. Assess management’s protocols for operations continuity and system recovery. Verify that procedures are clear, concise, accessible, and can be implemented in an emergency. Verify the BCP includes procedures for the following: 
	+ a. Manual steps for critical functions, as applicable.
	+ b. Alternate identity verification methods.
	+ c. Fraud identification and suspicious activity reporting.
	+ d. Other procedures as applicable. Examples may include: 
		- • Addressing customer service requests during downtime.
		- • Tracking daily transactions.
		- • Reconciling general ledger accounts.
		- • Documenting operational tasks.
		- • Posting entries after system recovery.
		- • Maintaining backup records to provide customer account information (account numbers, customer names, addresses, account status, and account balances).
* 5. Verify that the BCP lists alternatives for core operations, facilities, infrastructure systems, suppliers, utilities, interdependent business partners, and key personnel. 
	+ a. Verify that the BCP includes site relocation for short-, medium-, and long-term scenarios.
	+ b. Determine whether management considers scalability.
	+ c. Verify that recovery alternatives can accommodate the services and processing capabilities affecting critical operations, including: 
		- • Core processing.
		- • Check processing and imaging.
		- • Commercial cash management.
		- • Mailing, faxing, and printing.
		- • Customer identification.
		- • Data center activities.
* 6. Verify that the BCP includes procedures for coordination with the first responders and local and state government agencies, when appropriate.
* 7. Verify that the BCP includes procedures to establish an alternate physical location(s) where personnel and customers can go to conduct business, if appropriate.
* 8. Determine whether the BCP addresses alternate arrangements in the event payment systems fail (e.g., ATMs, funds transfers, electronic banking, remote deposit capture, mobile capabilities). 
	+ a. Determine whether the BCP addresses processes for retrieving and transmitting transactions when payment systems are disrupted (e.g., manual procedures for calling in or faxing wire or automated clearing house requests to correspondent banks; mitigating strategies for web-based systems; or third-party software used to perform transactions).
	+ b. Determine whether management verifies that redundant electronic payment systems and equipment (e.g., tokens and routers) are included at recovery sites for activation and that documentation is maintained for timely posting of entries when systems are recovered.
	+ c. Determine whether instant issue cards are utilized and card company security procedures are implemented to limit potential fraud.
* 9. Verify that the BCP addresses the entity's cash management requirements. Procedures may include: 
	+ a. Pre-established cash delivery arrangements.
	+ b. Plans for increases in branch traffic when ATMs are unavailable.
	+ c. Plans for the entity’s operational cash needs.
	+ d. Temporary purchase authority guidelines.
	+ e. Expense reimbursement options for personnel.
	+ f. Higher-limit credit cards or separate checking accounts with designated individuals who can sign checks in emergency situations.
* 10. Determine whether management established an incident response process. As part of incident management planning, determine whether management does the following: 
	+ a. Aligns incident response procedures with other related processes (e.g., cybersecurity, network operations, and physical security).
	+ b. Considers incident response procedures during the development of the business continuity strategy.
	+ c. Leverages routine processes (e.g., vulnerability management and network monitoring) to anticipate potential incidents, including cyber incidents.
* 11. Verify that management developed a coordinated disaster recovery strategy for data centers, networks, servers, storage, service monitoring, user support, and related software. Verify that procedures address the following: 
	+ a. Security controls and protocols, including physical and logical.
	+ b. Procedures for restoring backlogged activity or lost transactions to identify how transaction records will be brought current within expected recovery time frames.
	+ c. Instructions to access the repository of critical information when the primary facility is unavailable.
* 12. Verify whether management designates key personnel from applicable departments to act during a crisis or emergency situation. Key personnel may include: 
	+ a. Senior management for leadership.
	+ b. Facilities management for safety and physical security.
	+ c. Human resources for personnel issues and travel.
	+ d. Media relations for managing communications.
	+ e. Finance and accounting for funds disbursement and financial decisions, including unanticipated expenses.
	+ f. Legal and compliance for legal and regulatory concerns.g. IT, including information security, and operations for specific tactical responses.
* 13. Determine whether management established a crisis or emergency management process. Verify whether the BCP addresses the following: 
	+ a. Coordination with regulatory agencies, local and state officials, law enforcement, and first responders.
	+ b. Disruptions not confined to a single event, facility, or geographic area.
	+ c. Simultaneous disruptions of telecommunications and electronic messaging, including between the entity and third-party service providers.
	+ d. Crisis or emergency management communication protocols, including the designation of a spokesperson(s) to communicate with the news media, as appropriate.
### Objective 9: Determine whether the BCM program includes training and awareness to educate stakeholders about the entity’s continuity objectives and BCM goals. (VI, “Training”) 

* 1. Verify that the training program aligns with the entity’s BCM strategy. Determine whether management does the following: 
	+ a. Inventories the current skillsets for BCM and identifies and addresses any training gaps.
	+ b. Establishes goals and objectives for supporting the BCM program as part of the entity’s performance management process.
	+ c. Implements a training program to educate stakeholders about the BCM goals and objectives. Elements may include: 
		- • Exercises.
		- • Current risks.
		- • Future risks.
		- • Recent failures.
		- • New programs/technologies.
		- • Organizational changes.
		- • Previous (exercise) lessons learned.
* 2. Assess whether management tailors training to the target audience, based on the audience’s needs. The target audience could include: 
	+ a. Board members.
	+ b. Senior management.
	+ c. Business process owners.
	+ d. Frontline personnel.
	+ e. Contract personnel, as applicable.
* 3. Validate that management incorporates significant business continuity concepts, interdependencies, disruption impacts, and operations resilience into the training program.
* 4. Verify that the BCM training program, including board training, is updated as significant changes occur.
### Objective 10: Determine whether the exercise and testing program is sufficient to allow management to assess the entity’s ability to meet its continuity objectives. (VII, “Exercises and Tests”) 

* 1. Determine whether management implemented a comprehensive exercise and testing program, objectives, and plans to validate the entity’s ability to restore critical business functions.
* 2. Verify that the program is appropriate for the entity’s risk profile. Assess whether the entity’s consolidated exercise and test schedule is reflective of exercise and test objectives and the overall exercise and test universe.
* 3. Determine whether management covers all of the functions in the exercise and test universe according to its established timeframes (e.g., all processes are covered annually or every three years).
* 4. Determine whether management has designated personnel with the authority to control the exercise or test and confirm exercise and test milestones are met.
* 5. Verify that business line management retains ownership for testing its specific business processes and coordinates with personnel involved in the enterprise-wide BCM process and support areas.
* 6. Verify that exercises and tests occur at appropriate intervals, or when significant changes affect the entity’s operating environment.
* 7. Verify that management developed a process that is sufficiently robust to confirm the effectiveness of the entity’s business continuity program. Therefore, the exercise program should incorporate the following: 
	+ a. A policy that includes strategies and expectations for exercise and test planning.
	+ b. Roles and responsibilities for implementation.
	+ c. Sufficient personnel to perform the exercise or test, provide oversight, and document the results.
	+ d. Precautions to safeguard production data, such as performing a backup before performing a test in a test environment, or testing during non-peak hours.
	+ e. Provisions for emergency stops and concluding exercises and tests.
	+ f. Verification of continuity and resilience process assumptions and the ability to process a sufficient volume of work during adverse operating conditions.
	+ g. Activities commensurate with the importance of the business process.
	+ h. Entity’s processes commensurate with their significance to critical financial markets.
	+ i. Comparison of exercise and test results against the BCP to identify gaps between the exercise or test process and recovery guidelines, with revisions incorporated where appropriate.
	+ j. Independent review of business continuity program and exercises and tests (internal and external).
* 8. Determine whether the exercise and test policy is appropriate and includes the following: 
	+ a. Key roles and responsibilities.
	+ b. Minimum frequency, scope, and reporting.
	+ c. Documentation expectations.
	+ d. Processes for correcting deficiencies identified during exercises or tests.
	+ e. Communication and connectivity between the entity and third-party service providers.
	+ f. Participation with critical third-party service providers to confirm that entity personnel understand integration with all related recovery processes.
* 9. Determine whether the exercise and test strategies allow management to demonstrate the entity’s ability to support connectivity, functionality, volume, and capacity using alternate facilities. Strategies may include the following: 
	+ a. Expectations for individual business lines and use of exercise and testing methodologies and scenarios.
	+ b. Internal and external dependencies, including activities outsourced to domestic and foreign-based third-party service providers.
	+ c. Multi-year plan(s) to execute the specific depth and breadth of exercises and tests, which use different methodologies and scenarios over time.
	+ d. Expectations for testing internal and external recovery dependencies.e. Assumptions, methodologies, and exercises used to develop the test strategies. 


	+ f. Transaction processing and functional testing to assess the recoverability of infrastructure, capacity, and data integrity.
* 10. Verify that exercise and test objectives include resilience, system monitoring, and the recovery of business processes and critical system components.
* 11. Verify that exercises and associated tests accomplish the following objectives: 
	+ a. Build confidence that resilience and recovery strategies meet business requirements.
	+ b. Demonstrate that critical services can be recovered within agreed upon recovery objectives (RTOs, RPOs, and MTDs) and customer SLAs.
	+ c. Establish that critical services can be restored in the event of an incident at the recovery location.
	+ d. Familiarize staff with recovery processes.
	+ e. Verify that personnel are adequately trained and knowledgeable of recovery plans and procedures.
	+ f. Confirm that exercise and test plans remain compatible with the BCP and the entity’s infrastructure.
	+ g. Identify any gaps between business continuity procedures and objectives.
* 12. Determine whether management established exercise and test plans, commensurate with the nature, scale, and complexity of the recovery objectives that address the objectives and expectations of the exercise or test and outline the scenario and any assumptions or constraints that may exist. Verify whether exercise and test plans include the following: 
	+ a. Identification of roles and responsibilities for participants, support personnel, and observers.
	+ b. Metrics to assess whether objectives are met.
	+ c. A consolidated exercise and test schedule that encompasses all objectives.
	+ d. Specific descriptions of objectives and methods.
	+ e. Roles and responsibilities for all test participants, including support personnel.
	+ f. Identification of decision makers and succession plans.
	+ g. Exercise and test locations to be utilized.
	+ h. Escalation procedures and the ability to adjust for simulated scenarios.
	+ i. Contact information.
* 13. Determine whether management developed reasonably foreseeable threat scenarios that simulate disruptions in business functions and the ability to meet both business requirements and customer expectations. Management should: 
	+ a. Identify and document assumptions used in developing each scenario.
	+ b. Develop scenarios that include threats that could affect third-party service providers, including communication processes with applicable stakeholders.
	+ c. Develop exercises that demonstrate not only the ability to failover to an alternate site but also validate recovery objectives.
	+ d. Create scenarios that include only the data and systems that would be available for recovery.
* 14. Verify that exercise and test scripts document the procedures for executing the exercise or test, which may include: a. Applications, business processes, systems, or facilities reviewed. 


	+ b. Sequential steps for employees or external parties to perform.
	+ c. Procedures to guide manual work-around processes.
	+ d. A detailed schedule for completion.
	+ e. Methods for participants to record results, quantifiable metrics, and any issues.
* 15. Assess whether exercise and test methods are commensurate with the size and complexity of the entity and the criticality of the function to the entity. Verify that exercises and tests are designed to do following: 
	+ a. Validate personnel knowledge and skills, including backup responsibilities.
	+ b. Operate and perform duties (e.g., daily, quarterly, annually) from an alternate site.
	+ c. Process transactions and assess system functionality.
	+ d. Test the viability of both full and incremental backups.
	+ e. Test network connectivity and interdependencies, including those with critical third-party service providers.
* 16. If management performs full-scale exercises, verify whether the exercise includes the following, where appropriate: 
	+ a. Engaging personnel from all business units to participate and interact with internal and external management response teams.
	+ b. Validating that the crisis/emergency management process is operating as designed.
	+ c. Verifying personnel knowledge and skills.
	+ d. Validating management response and decision-making capability.
	+ e. Demonstrating coordination among participants and decision makers.
	+ f. Validating communication protocols.
	+ g. Conducting activities at alternate locations or facilities.
	+ h. Processing data using backup media or alternative methods.
	+ i. Completing actual transactional volumes or an illustrative subset.
	+ j. Performing recovery exercises over a sufficient length of time to allow issues to unfold as they would in a crisis.
* 17. If management performs limited-scale exercises, verify whether the exercise includes the following, where appropriate: 
	+ a. Implementing a plan appropriate to the scenario.
	+ b. Verifying personnel knowledge and skills.
	+ c. Validating management response and decision-making capability.
	+ d. Executing on-the-scene coordination and decision-making roles.
	+ e. Verifying whether participants can connect to alternate system(s).
	+ f. Conducting activities at alternate locations or facilities.
	+ g. Testing communication and remote access capability (e.g., switching to alternate equipment or telecommuting).
* 18. If management performs tabletop exercises, determine whether targeted plans and procedures are reasonable, personnel understand their responsibilities, and different departmental or business unit plans are compatible with each other. (By themselves, tabletop exercises are likely insufficient to validate recovery capabilities because they are limited to a discussion- based analysis of policies and procedures.) Tabletop exercises may include the following: 
	+ a. Engaging operational and support personnel who are responsible for implementing the BCP.
	+ b. Practicing and validating specific functional response capabilities.
	+ c. Demonstrating knowledge and skills, as well as team interaction and decision-making capabilities.
	+ d. Role playing with simulated responses, evaluating critical steps, recognizing difficulties, and resolving problems.
	+ e. Clarifying critical plan elements, as well as problems noted during exercises.
	+ f. Creating action plans to correct issues.
* 19. Verify that management clearly defines the characteristics of a successful test, which may include the following: 
	+ a. Validating RPOs, RTOs, and MTDs.
	+ b. Demonstrating recoverability at peak volumes.
	+ c. Confirming that systems can support critical business processes (e.g., transfer to alternate sites, increased workloads, manual workarounds, and communication).
	+ d. Integrating technologies that support critical business activities, including data replication, recovery, and off-site storage.
	+ e. Testing backup data to assess integrity and availability.
	+ f. Certifying facility controls (e.g., environmental, backup power, and physical security).
	+ g. Verifying workspace restoration (e.g., network connectivity and communications).
	+ h. Ensuring that personnel are familiar with and are able to execute their responsibilities.
* 20. Determine whether the right to perform testing or participate in exercises and tests with third parties is described in the contract governing the entity’s relationship with the third-party service provider.
* 21. Determine whether exercises and tests with third-party service providers are included in the entity’s enterprise exercise and test program based on the risk prioritization of the third-party service provider and the criticality of the services provided to the entity. Assess the following: 
	+ a. The process to rank third-party service providers based on criticality, risk, and testing scope.
	+ b. Coordinated exercises and tests that reasonably validate the abilities of both the entity and the third-party service provider to recover, restore, resume, and maintain operations after disruptions consistent with business and contractual requirements.
	+ c. Evidence that exercises and tests of critical service providers include reasonably foreseeable significant disruptive events.
	+ d. Documentation of the scope, execution, and results of exercises and tests in which the entity is unable to directly participate.
* 22. Determine whether the entity participates in its critical third-party service providers’ exercise and test program(s) at reasonable intervals. Assess the execution of the exercises and tests and whether they included the following: 
	+ a. End-to-end and, when appropriate, full-scale exercises.
	+ b. Transaction processing and functional testing.
	+ c. Network connectivity and interdependencies to include those with critical fourth parties.
	+ d. Bidirectional operations between the entity’s and its third-party service provider’s primary and alternate locations and systems.
	+ e. Supply chain considerations.
* 23. Determine whether testing scenarios with critical third-party service providers consider the following: 
	+ a. An outage or disruption of the service provider.
	+ b. An outage or disruption at the entity.
	+ c. Incident response plans.
	+ d. Crisis management plans.
	+ e. Communication processes with third-party service providers and other stakeholders.
	+ f. Cyber events.
	+ g. Returning to normal operations.
* 24. Determine whether the tests validate the core or significant firm’s backup arrangements to confirm the following: 
	+ a. Backup sites are able to support typical payment and settlement volumes for an extended period.
	+ b. Backup sites are fully independent of the critical infrastructure components that support the primary sites.
	+ c. Trained employees are located at the backup sites at the time of disruption.
	+ d. Backup site employees are independent of the staff located at the primary site at the time of disruption.
	+ e. Backup site employees are able to recover clearing and settlement of open transactions within the time frames addressed in the BCM processes and applicable industry standards.
* 25. Determine whether the exercise and test assumptions are appropriate for core and significant firms and consider the following: 
	+ a. Primary data centers and operations facilities that are completely inoperable without notice.
	+ b. Whether personnel at primary sites, who are located at both data centers and operations facilities, are unavailable for an extended period.
	+ c. Whether other organizations are also affected, causing effects that have the potential to cascade from one organization across to the entire financial services sector.
	+ d. Infrastructure (e.g., power, telecommunications, transportation) that is disrupted.
	+ e. Whether data recovery or reconstruction to restart payment and settlement functions can be completed within the time frames defined by the BCM process and applicable industry standards.
	+ f. Whether continuity arrangements continue to operate until all pending transactions are closed.
* 26. Determine whether the core firm’s testing strategy includes plans to test the ability of significant firms that clear or settle transactions to recover critical clearing and settlement activities from geographically dispersed backup sites within a reasonable time frame.
* 27. Determine whether the significant firm has an external exercise and test strategy that addresses key interdependencies, such as exercises and tests with third-party market providers and key customers, and determine the following: 
	+ a. Whether external exercise and test strategies include the significant firm’s backup sites to the core firm’s backup sites.
	+ b. Whether the significant firm participates in industry (e.g., U.S. Department of the Treasury’s Hamilton Series and FS-ISAC’s CAPS exercises) or cross-market tests sponsored by core firms, markets, or trade associations. Tests should incorporate verifying the connectivity from alternate sites and include transaction, settlement, and payment processes, to the extent practical.
* 28. Determine whether the exercise and test program is sufficient to demonstrate the entity’s ability to meet its continuity objectives and whether the results demonstrate the readiness of personnel to achieve the entity’s recovery and resumption objectives. Determine whether management accomplishes the following: 
	+ a. Coordinate the execution of its exercise and test program to fully exercise its business continuity planning process.
	+ b. Analyze and compare results against stated objectives.
	+ c. Raise issues with appropriate personnel and assign responsibility for resolution.
	+ d. Escalate issues that cannot be resolved in a timely manner to the appropriate level of management.
	+ e. Prioritize and track issues through final resolution.
	+ f. Analyze results and issues to determine whether problems can be traced to a common source.
	+ g. Document recommendations for future exercise and tests.
* 29. Verify that corrective actions have been implemented and that retesting occurs in a timely fashion to address deficiencies in meeting the entity’s objectives.
* 30. Verify that test results are used to update the business continuity processes, enhance future testing, and evaluate whether risk mitigation strategies should be adjusted.

Objective 11: Determine whether management continuously measures the progress and assesses the effectiveness of BCM and uses the information to improve the BCM process. (VIII, “Maintenance and Improvement”) 

* 1. Determine whether management reviews and updates the business continuity program to reflect the current environment. Triggers that prompt maintenance and improvement of the BCM may include the following: 
	+ a. Changes in enterprise strategies.
	+ b. New or reconfigured products, services, or infrastructure.
	+ c. Changes in products and services offered by third-party service providers.
	+ d. Deficiencies identified in third-party service provider BCM processes.
	+ e. New legislation, regulatory requirements, or resilience practices.
	+ f. Results of operational metric analysis (e.g., key risk indications, key performance indicators).
	+ g. Early warning indicators that may identify potential continuity events, crises, or incidents (e.g., frequency and severity of storms, heightened cyber attack activity, or increases in customer service calls).
	+ h. Variances between budgeted and actual BCM expenses.
	+ i. Results from exercises and tests and lessons learned.
	+ j. Changes in the threat landscape (e.g., new capabilities, intent of threat actors).
	+ k. Recommendations (e.g., from audits, vulnerability assessments, and penetration tests, including those involving the use of advanced cybersecurity analysis and assessments).
* 2. Determine whether management has documented, analyzed, and reviewed lessons learned from adverse events. Documented procedures for incorporating lessons learned may include: 
	+ a. Identifying the failure(s).
	+ b. Determining the cause(s).
	+ c. Evaluating potential solutions.
	+ d. Implementing corrective actions as appropriate.
	+ e. Recording and reviewing corrective actions taken.
* 3. Verify that management documents, tracks, and resolves any changes when updating the BCP and the exercise and testing program(s). Furthermore, verify that management maintains appropriate version control of key BCM documents.
* 4. Determine whether management maintains backup copies of relevant BCM documentation in the event that the primary repository becomes inaccessible.
### Objective 12: Determine whether the board has established expectations for BCM reporting. (IX, “Board Reporting”) 

* 1. Review board minutes to determine whether management periodically reports to the board on the status of BCM.
* a. Determine whether reports include a written BCM presentation, including the BIA, risk assessment, BCP, exercise and test results, and identified issues.
* b. Determine whether management provides the board with regular strategy updates based on changes in personnel, roles and responsibilities, and business operations.
* c. Verify that management documents the reasons (e.g., cost and service level) for choosing recovery alternatives and why they are appropriate based on the entity’s risk profile and complexity.
* d. Assess whether the board provides a credible challenge to management, when appropriate.

Objective 13: Discuss corrective action and communicate findings. 

* 1. Review preliminary conclusions with the examiner-in-charge regarding the following: 
	+ a. Apparent violations of laws and regulations.
	+ b. Significant issues warranting inclusion in the report of examination.
	+ c. Proposed Uniform Rating System for IT (URSIT) management component rating and the potential impact of the examiner’s conclusions on composite or other URSIT component ratings.
	+ d. Potential impact of the examiner’s conclusions on the entity’s risk assessment(s).
* 2. Discuss findings with management and obtain proposed corrective action for significant deficiencies.
* 3. Document conclusions in a memorandum to the examiner-in-charge that provides report- ready comments for all relevant sections of the report of examination and clarifying guidance to future examiners.
* 4. Organize work papers to show clear support for significant findings by examination objective.
# Appendix B: Glossary 

The purpose of the glossary is to define technical terms used in the FFIEC IT Examination Handbook booklets in the context of supervisory activities for the entities over which FFIEC members have supervisory authority. The FFIEC members strive to align terminology in the glossary with appropriate authoritative standards, including the NIST Computer Security Resource Center Glossary (NIST Glossary) as the primary source for cyber-related definitions, as appropriate. FFIEC members employed the following process to select, modify, or develop definitions. 

When a NIST definition existed: 

* • If NIST had a defined term and modifications to the definition were unnecessary, the FFIEC members included the NIST definition in this glossary. When multiple NIST definitions were available for the same term, the FFIEC members selected a definition for supervisory purposes.
* • If NIST had a defined term, but the definition needed additional clarity for supervisory purposes to assist with the identification of safety and soundness and enterprise risks related to IT, the FFIEC members included both the NIST definition and the FFIEC-adapted definition. Definitions of this nature are labeled “FFIEC Adapted for Supervisory Purposes” in this glossary’s source column.

When a NIST definition did not exist or the definition was not appropriate for supervisory purposes: 

* • If NIST did not have a defined term, but there was an appropriate authoritative third-party source (e.g., the International Organization for Standardization (ISO) Glossary), the FFIEC members included that authoritative definition.
* • If NIST did not have a defined term and there was not an appropriate authoritative third-party source, the FFIEC members developed a definition for supervisory purposes. Definitions of this nature are labeled “FFIEC Developed for Supervisory Purposes” in this glossary’s source column.

Note: Due to the constantly evolving nature of IT and its associated risks, the FFIEC members may update definitions to maintain alignment with other government agencies and the financial services industry. 



| Term | Definition | Source |
| --- | --- | --- |
|  | A |  |
| Application programming interface (API) | A system access point or library function that has a well-defined syntax and is accessible from application programs or user code to provide well-defined functionality. | NIST Glossary |
|  | Software code that allows two or more programs to communicate with each other. | FFIEC Adapted for Supervisory Purposes |
| Asynchronous replication | Data is first written to the primary storage area (store) and then copied to the secondary storage area (forward) at predefined intervals, which is useful over smaller bandwidth connections and longer distances where latency could occur. | FFIEC Developed for Supervisory Purposes |
| B | | |
| Business continuity | The capability of the organization to continue delivery of products or services at acceptable predefined levels following a disruption. | ISO 22300:2018(en) |
| Business continuity management (BCM) | The process for management to oversee and implement resilience, continuity, and response capabilities to safeguard employees, customers, and products and services. | FFIEC Developed for Supervisory Purposes |
| Business continuity plan (BCP) | The documentation of a predetermined set of instructions or procedures that describe how an organization’s mission/business processes will be sustained during and after a significant disruption. | NIST Glossary |
|  | A comprehensive written plan(s) to maintain or resume business in the event of a disruption. | FFIEC Adapted for Supervisory Purposes |
| Business impact analysis (BIA) | An analysis of an information system’s requirements, functions, and interdependencies used to characterize system contingency requirements and priorities in the event of a significant disruption. | NIST Glossary |
|  | Management’s analysis of an entity’s requirements, functions, and interdependencies used to characterize contingency needs and priorities in the event of a disruption. | FFIEC Adapted for Supervisory Purposes |
| C | | |
| Cold site | A backup facility that has the necessary electrical and physical components of a computer facility, but does not have the computer equipment in place. The site is ready to receive the necessary replacement computer equipment in the event that the user has to move from their main computing location to an alternate site. | NIST Glossary |
| Contingency plan | A plan that is maintained for disaster response, backup operations, and post-disaster recovery to ensure the availability of critical resources and to facilitate the continuity of operations in an emergency situation. | NIST Glossary |
| Crisis | Abnormal and unstable situation that threatens the organization’s strategic objectives, reputation or viability. | Business Continuity Institute Disaster Recovery Journal Glossary |
| Crisis management | The process of managing an entity’s preparedness, mitigation response, continuity, or recovery in the event of an unexpected significant disruption, incident, or emergency. | FFIEC Developed for Supervisory Purposes |
| Critical financial markets | Financial markets whose operations are critical to the economy. Critical financial markets provide the means for financial institutions to adjust their cash and securities positions and those of their customers in order to manage liquidity, market, and other risks to their organizations. Critical financial markets also provide support for the provision of a wide range of financial services to businesses and consumers in the United States and support the implementation of monetary policy. | FFIEC Developed for Supervisory Purposes |


Examples of critical financial markets include federal funds, foreign 



|  | exchange, and commercial paper; U.S. government and agency securities; and corporate debt and equity securities. |  |
| --- | --- | --- |
|  | D | |
| Data | A representation of information as stored or transmitted. | NIST Glossary |
|  | A physical or digital representation of information processed, stored (at rest), or transmitted (in transit). | FFIEC Adapted for Supervisory Purposes |
| Data center | infrastructure(s) (e.g., computer, server, and networking systems and components) designed to store, process, and serve large amounts of data in support of an entity’s strategic and business objectives. A data center may be a dedicated facility or an area or room, that contains computer, server and networking systems and components, and may be private or shared (e.g., a co-location facility). A facility that houses virtual and/or physical information technology | FFIEC Developed for Supervisory Purposes |
| Data mirroring | The act of copying data from a database at a primary location to a database at a secondary location in or near real time. | FFIEC Developed for Supervisory Purposes |
| Data replication | The process of copying data, usually with the objective of maintaining identical sets of data in separate locations. | FFIEC Developed for Supervisory Purposes |
| Data synchronization | The simultaneous comparison and reconciliation of interdependent data files, to ensure that the files contain the same information. | FFIEC Developed for Supervisory Purposes |
| Database | A repository of information or data, which may or may not be a traditional relational database system. | NIST Glossary |
|  | A repository of information or data organized to be accessed, managed, and updated. | FFIEC Adapted for Supervisory Purposes |
| Disaster | Situation where widespread human, material, economic, or environmental losses have occurred, which exceeded the ability of the affected organization, community, or society to respond and recover using its own resources. | ISO 22300:2018(en) |
| Disaster recovery | The process, policies, and procedures related to preparing for recovery or continuation of technology infrastructure, systems, and applications, which are vital to an organization after a disaster or outage. Disaster recovery focuses on the information or technology systems that support business functions, as opposed to business continuity, which involves planning for keeping all aspects of a business functioning in the midst of disruptive events. Disaster recovery is a subset of business continuity. | Business Continuity Institute Disaster Recovery Journal Glossary |
| Disruption | An unplanned event that causes the general system or major application to be inoperable for an unacceptable length of time (e.g., minor or extended power outage, extended unavailable network, or equipment or facility damage or destruction). | NIST Glossary |
|  | An anticipated or unplanned event that causes operations to degrade or fail for an unacceptable length of time | FFIEC Adapted for Supervisory Purposes |

E 



| See Emergency management | crisis management. |  |
| --- | --- | --- |
| Emergency response | Actions taken in response to a disaster warning or alert to minimize or contain the eventual negative effects, and those taken to save and preserve lives and provide basic services in the immediate aftermath of a disaster impact, for as long as an emergency situation prevails. | Business Continuity Institute Disaster Recovery Journal Glossary |
| Event | Occurrence or change of a particular set of circumstances. | NIST Glossary |
|  | An occurrence or change in circumstances that may affect operations. An event can be physical, cyber, or a combination of both | FFIEC Developed for Supervisory Purposes |
| Exercise | A simulation of an emergency designed to validate the viability of one or more aspects of an IT plan. | NIST Glossary |
|  | A task or activity done to practice or test a procedure. There are many different types of exercises, depending on the intended goals and objectives. An exercise may involve performing duties in a simulated environment and can be discussion-based or simulation-based. | FFIEC Adapted for Supervisory Purposes |
|  | F |  |
| Failover | intervention or warning) to a redundant or standby information system upon the failure or abnormal termination of the previously active system. The capability to switch over automatically (typically without human | NIST Glossary |
| Full-scale exercise | software, personnel, communications, utilities, and processing from an alternate site) at the same time. A simulation involving a full use of available resources (e.g., hardware, | FFIEC Developed for Supervisory Purposes |
| Functional testing | correctly. Testing that verifies that an implementation of some function operates | NIST Glossary |
| High availability | A failover feature to ensure availability during device or component interruptions. | NIST Glossary |
|  | Ability of a system to be continuously operational for a desirably long length of time and to maintain a minimum amount of downtime during device or component interruptions. Availability can be measured relative to "100% uptime" or "never failing." | FFIEC Adapted for Supervisory Purposes |
| Hot site | hardware and software, to be used in the event of an information system disruption. A fully operational off-site data processing facility equipped with | NIST Glossary |
| Incident | confidentiality, integrity, or availability of a system or the information the system processes, stores, or transmits or that constitutes a violation or imminent threat of violation of security policies, security procedures, or acceptable use policies. An occurrence that actually or potentially jeopardizes the | NIST Glossary |

H 

I 



| Incident management | The process of identifying, analyzing, and correcting disruptions to operations and preventing future recurrences. The goal of incident management is to limit the disruption and restore operations as quickly as possible. | FFIEC Developed for Supervisory Purposes |
| --- | --- | --- |
| Incident response | The response of an organization to a disaster or other significant event that may significantly impact the organization, its people, or its ability to function productively. An incident response may include evacuation of a facility, initiating a disaster recovery plan, performing damage assessment, and any other measures necessary to bring an organization to a more stable status. | Business Continuity Institute Disaster Recovery Journal Glossary |
| Infrastructure | System of facilities, equipment, and services needed for the operation of an organization. | ISO 22300:2018(en) |
| Integrated exercise | A simulation to test the effectiveness of the continuity plans for a business line or major function that incorporates more than one component or module, including external dependencies. | FFIEC Developed for Supervisory Purposes |
| Interdependencies | When two or more departments, processes, functions, or third-party providers interact to successfully complete a task, business function, or process. | FFIEC Developed for Supervisory Purposes |
|  | L |  |
| Last mile | Communications technology that bridges the transmission distance between the telecommunication service provider and the entity. | FFIEC Developed for Supervisory Purposes |
| Latency | Time delay in processing voice packets. | NIST Glossary |
|  | Time delay in processing voice and data packets. | FFIEC Adapted for Supervisory Purposes |
| Limited-scale exercise | A simulation involving applicable resources (personnel and systems) to recover targeted business processes. | FFIEC Developed for Supervisory Purposes |
|  | M |  |
| Maximum tolerable | The amount of time mission/business process can be disrupted without causing significant harm to the organization’s mission. | NIST Glossary |
| downtime (MTD) | The total amount of time the system owner or authorizing official is willing to accept for a business process disruption, including all impact considerations. | FFIEC Adapted for Supervisory Purposes |
|  | N |  |
| Network backbone | The main communication channel of a network that interconnects one or more network segments and provides a path for the exchange of data between devices. A backbone can span any geographic area. | FFIEC Developed for Supervisory Purposes |
|  | O |  |
| Operational resilience | The ability of systems to resist, absorb, and recover from or adapt to an adverse occurrence during operation that may cause harm, destruction, or loss of ability to perform mission-related functions. | NIST Glossary |
|  | The ability of an entity’s personnel, systems, telecommunications networks, activities, or processes to resist, absorb, and recover from or | FFIEC Adapted for Supervisory Purposes |
|  | adapt to an incident that may cause harm, destruction, or loss of ability to perform mission-related functions. |  |
| Outage | The interruption of systems, infrastructure, support services, or essential business functions, which may result in the entity’s inability to provide services for some period of time. The amount of time lost from an outage may result in downtime. Conversely, downtime may cause an outage. | FFIEC Developed for Supervisory Purposes |
| Outsourcing | The practice of contracting through a formal agreement with a third party(ies) to perform services, functions, or support that might otherwise be conducted in-house. | FFIEC Developed for Supervisory Purposes |
| R | | |
| Reciprocal | An agreement that allows two organizations to back up each other. | NIST Glossary |
| agreement | An agreement that allows two entities (or two internal business groups) with compatible systems and functionality that allows each one to recover at the other’s location. | FFIEC Adapted for Supervisory Purposes |
| Recovery point objective (RPO) | The point in time to which data must be recovered after an outage. | NIST Glossary |
|  | The point in time to which data used by an activity is restored to enable the resumption of business functions. The RPO is expressed backward in time from the point of disruption and can be specified in increments of time (e.g., minutes, hours, or days). | FFIEC Adapted for Supervisory Purposes |
| objective (RTO) Remote access | in the recovery phase before negatively impacting the organization’s mission or mission/business processes. Access to an organizational information system by a user (or an | NIST Glossary |
|  | information system) communicating through an external, non- organization-controlled network (e.g., the Internet). | NIST Glossary |
| Resilience | S withstand and recover rapidly from disruptions. Resilience includes the withstand and recover from deliberate attacks, accidents, or occurring threats or incidents. The ability to prepare for and adapt to changing conditions and | |
| Scenario | A sequential, narrative account of a hypothetical incident that provides the catalyst for the exercise and is intended to introduce situations that will inspire responses and thus allow demonstration of the exercise objectives. | NIST Glossary |
| Service level agreement | Defines the specific responsibilities of the service provider and sets the customer expectations. | NIST Glossary |
|  | A formal agreement between two parties that records: a common understanding about products or services to be delivered, priorities, responsibilities, guarantees, and warranties between the parties. In addition, the agreement describes the nature, quality, security, availability, scope, and timeliness of delivery and response of the parties, the point(s) of contact for end-user problems, and the metrics by which the effectiveness of the process is monitored and approved, and may include other measurable objectives. The agreement should cover not only expected day-to-day situations, but also unexpected or adverse | FFIEC Adapted for Supervisory Purposes |

ability to 


naturally 

Recovery time 

The overall length of time an information system’s components can be 

NIST Glossary 

events, as the need for the service may vary. 



| Supply chain risk management | The implementation of processes, tools, or techniques to minimize the adverse impact of attacks that allow the adversary to utilize implants or other vulnerabilities inserted prior to installation in order to infiltrate data, or manipulate information technology hardware, software, operating systems, peripherals (information technology products) or services at any point during the life cycle. | NIST Glossary |
| --- | --- | --- |
|  | The implementation of processes, tools, or techniques to minimize the adverse impact of attacks that allow the adversary to exploit vulnerabilities inserted prior to installation. This is done in order to infiltrate data, or manipulate information technology hardware, software, operating systems, peripherals (information technology products) or services at any point during the supply chain (e.g., initial production, packaging, handling, storage, transport, mission operation, and disposal). | FFIEC Adapted for Supervisory Purposes |
| Synchronous replication | Data is written to both primary and secondary storage areas at the same time to ensure that multiple copies of the data are current and identical. This method is used for critical business functions where latency is unacceptable, and little or no data loss can be tolerated. | FFIEC Developed for Supervisory Purposes |
|  | T |  |
| Tabletop exercise | A discussion-based exercise where personnel with roles and responsibilities in a particular IT plan meet in a classroom setting or in breakout groups to validate the content of the plan by discussing their roles during an emergency and their responses to a particular emergency situation. A facilitator initiates the discussion by presenting a scenario and asking questions based on the scenario. | NIST Glossary |
|  | A discussion-based exercise where personnel meet in a classroom setting or in breakout groups to validate a component(s) of the business continuity plan(s) by discussing their roles and responsibilities. A facilitator initiates the discussion by presenting a scenario and asking questions based on the scenario. | FFIEC Adapted for Supervisory Purposes |
| Test | An evaluation tool that uses quantifiable metrics to validate the operability of a system or system component in an operational environment specified in an IT plan. | NIST Glossary |
|  | A type of exercise intended to verify the quality, performance, or reliability of system resilience in an operational environment. | FFIEC Adapted for Supervisory Purposes |
| Threat intelligence | Threat information that has been aggregated, transformed, analyzed, interpreted, or enriched to provide the necessary context for decision- making processes. | NIST Glossary |
| Trigger | known as a triggering event. An event that causes the system to initiate a response. Note: Also | NIST Glossary |
|  | An event that prompts a response from management or an automated system. Also known as a triggering event. | FFIEC Adapted for Supervisory Purposes |
|  | W |  |
| Warm site | An environmentally conditioned work space that is partially equipped with information systems and telecommunications equipment to support relocated operations in the event of a significant disruption. | NIST Glossary |

# Appendix C: Abbreviations 

ATM automated teller machine 

BCM business continuity management 

BCP business continuity plan 

BIA business impact analysis 

CA Letter Consumer Affairs Letter 

CAPS Cyber-Attack Against Payment Systems 

CDC Centers for Disease Control and Prevention 

CFPB Consumer Financial Protection Bureau 

CFR Code of Federal Regulations 

COSO Committee of Sponsoring Organizations of the Treadway Commission 

DDoS distributed denial of service 

DHS U.S. Department of Homeland Security 

DRaaS disaster recovery as a service 

ERM enterprise risk management 

FBIIC Financial and Banking Information Infrastructure Committee 

FDIC Federal Deposit Insurance Corporation 

FFIEC Federal Financial Institutions Examination Council 

FIL Financial Institution Letter 

FRB Board of Governors of the Federal Reserve System 

FS-ISAC Financial Services Information Sharing and Analysis Center 

FSARC Financial Systemic Analysis & Resilience Center 

FSSCC Financial Services Sector Coordinating Council 

GETS Government Emergency Telecommunications Service 

IIA Institute of Internal Auditors 

ISO International Organization for Standards 

IT information technology 

## IT Handbook FFIEC Information Technology Examination Handbook 

MTD maximum tolerable downtime 

NCUA National Credit Union Administration 

NIST National Institute of Standards and Technology 

OCC Office of the Comptroller of the Currency 

ODNI Office of the Director of National Intelligence 

RPO recovery point objective 

RTO recovery time objective 

SLA service-level agreement 

SLC State Liaison Committee 

SOC systems and organization control 

SR Letter Supervision and Regulation Letter 

SSAE Statement on Standards for Attestation Engagement 

TSP Telecommunications Service Priority 

URSIT Uniform Rating System for Information Technology 

USC United States Code 

WPS Wireless Priority Service Program 

# Appendix D: References 

## Laws 

12 U.S.C. 95(b) / 1463(a) / 3102(b), “Comptroller Authority to Declare a Legal Holiday” 12 U.S.C. 1464, “Home Owners’ Loan Act” 12 U.S.C. 1831r-1, “Notice of Branch Closure” 

12 U.S.C. 1861–1867, “Bank Service Company Act” 12 U.S.C. 1882, “Bank Protection Act” 

12 U.S.C. 3352, “Emergency Exceptions for Disaster Areas” 15 U.S.C. 6801 and 6805(b), “Gramm–Leach–Bliley Act” 

18 U.S.C. 1030, “Fraud and Related Activity in Connection With Computers” 

Consumer Financial Protection Bureau 

### Guidance 

CFPB Statement on Supervisory Practices Regarding Financial Institutions and Consumers Affected by a Major Disaster or Emergency (September 2018) 

CFPB Compliance Bulletin and Policy Guidance; 2016-02, Service Providers (October 2016) 

Federal Reserve 

### Regulations 

12 CFR 208, Appendix D-1, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 208, Appendix D-2, “Interagency Guidelines Establishing Information Security Standards (State Member Banks)” 

12 CFR 225, Appendix F, “Interagency Guidelines Establishing Information Security Standards” 

### Guidance 

SR Letter 20-3 / CA Letter 20-2, “Interagency Statement on Pandemic Planning” (March 2020) 

SR Letter 16-11, “Supervisory Guidance for Assessing Risk Management at Supervised Institutions with Total Consolidated Assets Less than $50 Billion” (June 2016) 

SR Letter 15-10 / CA Letter 15-8, “Expansion of the Federal Reserve’s Emergency Communications System” (October 2015) 

SR Letter 15-9, “FFIEC Cybersecurity Assessment Tool for Chief Executive Officers and Boards of Directors” (July 2, 2015) 

SR Letter 13-19 / CA Letter 13-21, “Guidance on Managing Outsourcing Risk” (December 2013) 

SR Letter 13-16, “End of Microsoft Support for Windows XP Operating System” (October 2013) 

SR Letter 13-6 / CA Letter 13-3, “Supervisory Practices Regarding Banking Organizations and Their Borrowers and Other Customers Affected by a Major Disaster or Emergency” (March 2013) 

SR Letter 12-14, “Revised Guidance on Supervision of Technology Service Providers” (October 2012) 

SR Letter 10-13, “Interagency Supervisory Guidance for Institutions Affected by the Deepwater Horizon Oil Spill” (October 2010) 

SR Letter 06-3, “Interagency Supervisory Guidance for Institutions Affected by Hurricane Katrina” (February 3, 2006) 

SR Letter 05-24, “Interagency Questions and Answers for Financial Institutions in Response to Hurricanes Katrina and Rita” (December 2, 2005) 

SR Letter 05-17, “Katrina Related Marketing Practices Invoking the Name of the Federal Reserve” (September 22, 2005) 

SR Letter 05-16, “Supervisory Practices Regarding Banking Organizations and Consumers Affected by Hurricane Katrina” (September 15, 2005) 

SR Letter 03-9, “Interagency Paper on Sound Practices to Strengthen the Resilience of the U.S. Financial System” (May 28, 2003) 

Federal Deposit Insurance Corporation 

### Regulations 

12 CFR 304.3(d), “Notification of Performance of Bank Services, Form FDIC 6120/06” 12 CFR 364, Appendix A “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 364, Appendix B “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 364, Supplement A to Appendix B “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” 

### Guidance 

FIL-25-2020 “Identification of Essential Critical Infrastructure Workers During the COVID- 19 Response Efforts” (March 26, 2020) 

FIL-14-2020 “Interagency Statement on Pandemic Planning” (March 6, 2020) FIL-19-2019, “Technology Service Provider Contracts” (April 2, 2019) FIL-63-2018, “Cybersecurity Preparedness Resource” (October 19, 2018) FIL-62-2017, “Major Disaster Examiner Guidance” (December 15, 2017) FIL-68-2016, “FFIEC Cybersecurity Assessment Tool: Frequently Asked Questions” (October 18, 2016) 

FIL-43-2016, “Information Technology Risk Examination (InTREx) Program” (June 30, 2016) 

FIL-37-2016, “FFIEC Joint Statement on Cybersecurity of Interbank Messaging and Wholesale Payment Networks” (June 7, 2016) 

FIL-55-2015, “Cybersecurity Awareness Resources” (November 23, 2015) FIL-28-2015, “Cybersecurity Assessment Tool” (July 2, 2015) 

FIL-13-2015, “FFIEC Joint Statements on Destructive Malware and Compromised Credentials” (March 30, 2015) 

FIL-13-2014, “Technology Outsourcing: Informational Tools for Community Bankers” (April 7, 2014) 

FIL-11-2014, “Distributed Denial of Service (DDoS) Attacks” (April 2, 2014) FIL-44-2008, “Third-Party Risk: Guidance for Managing Third-Party Risk” (June 6, 2008) FIL-6-2008, “Interagency Statement on Pandemic Planning: Guidance for Minimizing a Pandemic’s Potential Adverse Effects” (February 6, 2008) 

FIL-49-2006, “Lessons Learned from Hurricane Katrina: Preparing Your Institution for a Catastrophic Event” (June 15, 2006) 

FIL-27-2005, “Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” (April 1, 2005) 

FIL-84-2002, “Financial and Banking Information Infrastructure Committee’s Interim Policy on the Sponsorship of Private Sector Financial Institutions in the GETS Card Program” (August 6, 2002) 

FIL-50-2001, “Bank Technology Bulletin on Outsourcing” (June 4, 2001) 

National Credit Union Administration 

### Regulations 

12 CFR 748, "Security Program, Report of Suspected Crimes, Suspicious Transactions, Catastrophic Acts and Bank Secrecy Act Compliance" 12 CFR 748, Appendix A, “Guidelines for Safeguarding Member Information” 

12 CFR 749, "Guidelines for Safeguarding Member Information", Records Preservation Program and Appendices – Record Retention Guidelines; Catastrophic Act Preparedness Guidelines" 

12 CFR 749, Appendix A, “Record Preservation Program and Record Retention” 12 CFR 749, Appendix B, “Catastrophic Act Preparedness Guidelines” 

### Guidance 

NCUA Letter to Credit Unions 20-CU-03, "Identification of Essential Critical Infrastructure Workers" (March 2020) 

NCUA Letter to Credit Unions 20-CU-02, "NCUA Actions Related to COVID-19" (March 2020) 

NCUA Letter to Credit Unions 10-CU-10, "2010 Hurricane Season and Ongoing Disaster, Emergency, and Pandemic Preparedness and Planning" (June 2010) 

NCUA Letter to Credit Unions 09-CU-13, "Hurricane Preparedness and Pandemic Planning" (June 2009) 

NCUA Letter to Credit Unions 08-CU-01, “Guidance on Pandemic” (January 2008) NCUA Letter to Credit Unions 07-CU-13, “Evaluating Third-Party Relationships” (December 2007) 

NCUA Letters to Credit Unions (06-CU-11), "Interagency Guidance Lessons Learned by Institutions Affected by Hurricane Katrina" (June 2006) 

NCUA Risk Alert 06-Risk-01, “Disaster Planning and Response” (April 2006) 

NCUA Letter to Credit Unions 06-CU-06, “Influenza Pandemic Preparedness” (March 2006) NCUA Letter to Credit Unions 02-CU-17, “e-Commerce Guide for Credit Unions” (December 2002) 

NCUA Letter to Credit Unions 01-CU-21, “Disaster Recovery and Business Resumption Contingency Plans” (December 2001) 

NCUA Letter to Credit Unions 01-CU-20, “Due Diligence Over Third-Party Service Providers” (November 2001) 

Office of the Comptroller of the Currency 

### Regulations 

12 CFR 5.30, “Establishment, Acquisition, and Relocation of a Branch of a National Bank” 12 CFR 5.31, “Establishment, Acquisition, and Relocation of a Branch and Establishment of an Agency Office of a Federal Savings Association” 

12 CFR 30, Appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 30, Appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 30, Appendix D, “OCC Guidelines Establishing Heightened Standards for Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

12 CFR 30, Appendix E, “OCC Guidelines Establishing Standards for Recovery Planning by Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

### Guidance 

OCC Bulletin 2020-23, “Essential Critical Infrastructure Workers in the Financial Services Sector” 

OCC Bulletin 2020-13, "Pandemic Planning: Updated FFIEC Guidance" OCC Bulletin 2019-13, “Recovery Planning” 

OCC Bulletin 2019-8, “Loans in Areas Having Special Flood Hazards – Private Flood Insurance: Final Rule” 

OCC Bulletin 2018-47, “Recovery Planning Guideline: Final Revised Guidelines” OCC Bulletin 2018-14, “Installment Lending: Core Lending Principles for Short-Term, Small-Dollar Installment Lending” 

OCC Bulletin 2018-8, “Cyber Insurance: FFIEC Joint Statement on Cyber Insurance and Its Potential Role in Risk Management Programs” 

OCC Bulletin 2017-61, “Major Disasters: Interagency Examiner Guidance for Institutions Affected by Major Disasters” 

OCC Bulletin 2017-54, “Branches and Relocations: Revised Comptroller’s Licensing Manual Booklet” 

OCC Bulletin 2017-35, “Flood Disaster Protection Act: Revised Comptroller’s Handbook Booklet” 

OCC Bulletin 2017-24, “Branch Closings: Revised Comptroller’s Licensing Manual Booklet” 

OCC Bulletin 2017-21, “Third-Party Relationships: Frequently Asked Questions to Supplement OCC Bulletin 2013-29” 

OCC Bulletin 2017-7, “Third-Party Relationships: Supplemental Examination Procedures” OCC Bulletin 2016-34, “Cybersecurity: Frequently Asked Questions on the FFIEC Cybersecurity Assessment Tool” 

OCC Bulletin 2016-30, “Enforceable Guidelines for Recovery Planning: Final Guidelines” OCC Bulletin 2015-31, “Cybersecurity: FFIEC Cybersecurity Assessment Tool” 

OCC Bulletin 2013-29, “Third-Party Relationships: Risk Management Guidance” 

OCC Bulletin 2012-28, “Supervisory Guidance on Natural Disasters and Other Emergency Conditions” 

OCC Bulletin 2006-26, “Disaster Planning: Hurricane Katrina – Lessons Learned” OCC Bulletin 2006-12, “Influenza Pandemic Preparedness: Interagency Advisory” OCC Bulletin 2006-6, “Community Reinvestment Act: Hurricanes Katrina and Rita” OCC Bulletin 2003-14, “Interagency White Paper on Sound Practices to Strengthen the Resilience of the U.S. Financial System” 

OCC Bulletin 2003-13, “Telecommunications Service Priority (TSP) Program: Policy on Sponsorship of TSP for Private Sector Entities” 

OCC Bulletin 2002-33, “Government Emergency Telecommunications Service (GETS): FBIIC Policy on Sponsorship of GETS Cards for Private Sector Entities” 

OCC Bulletin 2002-16, “Bank Use of Foreign-Based Third-Party Service Providers: Risk Management Guidance” 

OCC Bulletin 1998-3, “Technology Risk Management: Guidance for Bankers and Examiners” 

Other References 

U.S. Department of Health & Human Services, Centers for Disease Control and Prevention, Pandemic Influenza (January 2019) 

Communications, Security, Reliability, and Interoperability Council, Infrastructure Sharing During Emergencies (December 2014) 

National Infrastructure Protection Plan, NIPP 2013: Partnering for Critical Infrastructure and Resilience (November 2013) 

NIST SP 800-34 Rev. 1, Contingency Planning Guide for Information Technology Systems (May 2010) 

BITS Financial Services Roundtable, BITS Framework for Managing Technology Risk for Service Provider Relationships (May 2008) 

Basel Committee on Banking Supervision, The Joint Forum: High-level Principles for Business Continuity (August 2006) 

U.S. Department of Homeland Security, Pandemic Influenza Preparedness, Response, and Recovery Guide for Critical Infrastructure and Key Resources (September 2006) Department of Health and Human Services, Centers for Disease Control and Prevention Business Pandemic Influenza Planning Checklist (December 2005) 

Homeland Security Council National Strategy for Pandemic Influenza (November 2005) 

Federal Reserve Bank of New York, Best Practices to Assure Telecommunications Continuity for Financial Institutions and the Payment and Settlement Utilities: Report by the Assuring Telecommunications Continuity Task Force (September 2004) 

The President’s National Security Telecommunications Advisory Committee, Financial Services Task Report (April 2004) 

| 

## FFIEC Information Technology Examination Handbook 

# Development, Acquisition, and Maintenance 

AUGUST 2024 

& 

INTRODUCTION ........................................................................................ 1 

I ........................... OVERVIEW OF DEVELOPMENT, ACQUISITION, AND 

MAINTENANCE ......................................................................................... 3 

II .......................... GOVERNANCE OF DEVELOPMENT, ACQUISITION, AND 

MAINTENANCE ......................................................................................... 5 

II.A Policies, Standards, and Procedures .................................................. 6 

II.B Roles and Responsibilities................................................................... 6 

II.B.1 Board, Senior Management, and Other Common Roles ......................... 7 

II.B.2 IT Project Management Roles ................................................................. 8 

II.B.3 Development Roles ............................................................................... 10 

II.B.4 Acquisition Roles ................................................................................... 12 

II.B.5 Maintenance Roles ............................................................................... 14 

II.B.6 Other Common Development, Acquisition, and Maintenance Roles ..... 14 

II.B.7 Supply Chain Roles ............................................................................... 15 

II.B.8 Other Support Functions ....................................................................... 15 

II.B.9 Audit’s Role ........................................................................................... 16 

III ........................ RISK MANAGEMENT OF DEVELOPMENT, ACQUISITION, AND MAINTENANCE ............................................................................... 18 

III.A Risk Identification ............................................................................... 19 

III.B Risk Measurement .............................................................................. 20 

III.C Risk Monitoring and Reporting .......................................................... 20 

III.D Controlling or Mitigating Risk ............................................................ 21 

IV ........................ COMMON DEVELOPMENT, ACQUISITION, AND 

MAINTENANCE RISK TOPICS ................................................................ 22 

IV.A Open-Source ........................................................................................ 23 

IV.B Commercial-off-the-Shelf ................................................................... 25 

IV.C Licenses, Agreements, and Copyright Protection ........................... 26 

IV.C.1 Software Licenses ................................................................................. 27 

IV.C.1(a) Free and Open-Source Software Licenses ............................ 28 

IV.C.1(b) Proprietary Software Licenses ............................................... 28 

IV.C.2 Hardware Licenses ............................................................................... 29 

IV.C.3 Copyright Protection .............................................................................. 29 

IV.D Secure Development ........................................................................... 30 

& 

## IV.E 

## IV.F 

## IV.G 

## IV.H 

## IV.I 

### IV.I.1 

### IV.I.2 

### IV.J.1 

### IV.J.2 

## IV.J 

## IV.K 

## IV.L 

## IV.M 

## IV.N 

Data ...................................................................................................... 32 

Secure Operating Environments ....................................................... 32 

Microservices ...................................................................................... 33 

Containers ........................................................................................... 37 

Application Programming Interfaces ................................................ 43 

API Gateway ......................................................................................... 44 

API Risk Mitigation ................................................................................ 46 

Methodologies ..................................................................................... 48 

Waterfall ................................................................................................ 49 

Agile ...................................................................................................... 49 

Quality Management ........................................................................... 52 

Documentation Standards .................................................................. 53 

Post-Implementation Review ............................................................. 54 

IT Project Management ....................................................................... 55 

IT Project Phases .................................................................................. 56 

### IV.N.1 

#### IV.N.1(a) 

Initiation .................................................................................. 57 

IV.N.1(b) 

Planning ................................................................................. 58 

IV.N.1(c) 

Execution ................................................................................ 59 

IV.N.1(d) Closeout ................................................................................. 59 

Monitoring and Controlling .................................................................... 60 

IT Project Documentation ...................................................................... 61 

### IV.N.2 

### IV.N.3 

#### IV.N.3(a) 

IT Project Request.................................................................. 61 

IV.N.3(b) 

Business Case ....................................................................... 62 

IV.N.3(c) 

Feasibility Study ..................................................................... 62 

IV.N.3(d) 

IT Project Plans ...................................................................... 63 

IV.N.3(e) Closeout Documentation ........................................................ 63 

System Development Life Cycle ........................................................ 64 

SDLC Phases ........................................................................................ 65 

## IV.O 

### IV.O.1 

#### IV.O.1(a) 

Initiation .................................................................................. 66 

IV.O.1(b) 

Development or Acquisition ................................................... 68 

IV.O.1(c) 

Implementation and Assessment ........................................... 69 

IV.O.1(d) 

Operations and Maintenance ................................................. 71 

IV.O.1(e) 

Sunset and Disposal .............................................................. 72 

IV.P 

Third-Party Relationship Risk Management ..................................... 74 

Planning ................................................................................................ 74 

### IV.P.1 

& 

IV.P.2 Due Diligence and Third-Party Selection .............................................. 74 

IV.P.3 Contract Negotiation ............................................................................. 75 

IV.Q Supply Chain Considerations ............................................................ 75 

IV.Q.1 Supply Chain Risk Management ........................................................... 77 

IV.Q.2 Software Bill of Material ........................................................................ 89 

IV.Q.3 Enterprise Risk Management and Supply Chain Risks ......................... 90 

V ......................... DEVELOPMENT .................................................................. 91 

V.A Development Standards and Controls .............................................. 93 

V.B Testing ................................................................................................. 96 

V.C DevOps and DevSecOps .................................................................... 99 

V.C.1 DevOps ............................................................................................... 100 

V.C.2 DevSecOps ......................................................................................... 100 

V.D.1 Model Development ............................................................................ 106 

V.D.2 Database Development ....................................................................... 107 

V.D Functional Development Types ....................................................... 105 

VI ........................ ACQUISITION .................................................................... 109 

VI.A Acquisition Policies, Standards, and Procedures .......................... 111 

VI.B Acquisition Projects ......................................................................... 113 

VI.C Solicitation ......................................................................................... 113 

VI.D Evaluation .......................................................................................... 116 

VI.E Contracts and Other Agreements .................................................... 117 

VI.E.1 Statement of Work .............................................................................. 117 

VI.E.2 Master Services Agreement ................................................................ 119 

VI.E.3 Service Level Agreement .................................................................... 120 

VI.E.4 Contracts ............................................................................................. 120 

VI.E.5 Escrowed Source Code Agreements and Documentation .................. 124 

VI.E.6 Exit Strategy ........................................................................................ 125 

VII ...................... MAINTENANCE ................................................................. 126 

VII.A Preventive Maintenance ................................................................... 127 

VII.B Change Management ........................................................................ 127 

VII.B.1 Implementing Changes ....................................................................... 129 

VII.B.2 Additional Control Considerations in Change Management ................ 132 

VII.B.2(a) Data Controls in the Testing Environment ........................... 132 

VII.B.2(b) Library Controls ................................................................... 132 

& 

VII.B.2(c) Code Repository Controls .................................................... 133 

VII.B.3 Change Types ..................................................................................... 135 

VII.B.3(a) 

Routine Modifications .......................................................... 135 

VII.B.3(b) 

Major Modifications .............................................................. 136 

VII.B.3(c) Emergency Modifications ..................................................... 137 

VII.B.4 Change Management Documentation ................................................. 139 

VII.B.4(a) 

Change Request Form ........................................................ 140 

VII.B.4(b) 

Impact Analysis ................................................................... 140 

VII.B.4(c) 

Rollback or Back-Out Plan ................................................... 141 

## VII.C 

## VII.D 

## VII.E 

End-of-Life ......................................................................................... 142 

Termination and Disposal ................................................................ 144 

Maintenance Documentation ........................................................... 145 

APPENDIX A: EXAMINATION PROCEDURES ..................................... 146 

APPENDIX B: GLOSSARY .................................................................... 182 

APPENDIX C: ABBREVIATIONS .......................................................... 202 

APPENDIX D: REFERENCES ............................................................... 204 

& 

## INTRODUCTION 

The “Development, Acquisition, and Maintenance” booklet is one in a series of booklets that compose the Federal Financial Institutions Examination Council (FFIEC)1 Information Technology Examination Handbook (IT Handbook). The FFIEC IT Handbook is prepared for use by examiners.2 With the publication of this booklet, the FFIEC members replace the “Development and Acquisition” booklet issued in April 2004. The revised title now reflects the importance of maintenance in the life of a system or component.3 This booklet 

* • Describes system and component development, acquisition, and maintenance.
* • Highlights key risk management practices when developing, acquiring, or maintaining systems and components.
* • Provides an overview of and discusses information technology (IT) project management, the system development life cycle (SDLC), and supply chain risk management (SCRM).
* • Addresses the importance of system and software maintenance to an entity’s resilience.

For FFIEC IT Handbook purposes, the term “entity” includes depository financial institutions,4 nonbank financial institutions,5 bank holding companies,6 savings and loan holding companies,7 and third-party service providers.8 

1 The FFIEC was established on March 10, 1979, pursuant to Title X of the Financial Institutions Regulatory and Interest Rate Control Act of 1978, Pub. L. 95-630. The FFIEC comprises the principals of the Board of Governors of the Federal Reserve System (FRB), the Consumer Financial Protection Bureau (CFPB), the Federal Deposit Insurance Corporation (FDIC), the National Credit Union Administration (NCUA), the Office of the Comptroller of the Currency (OCC), and the State Liaison Committee (SLC). 

2 Each FFIEC member uses the principles outlined in this booklet consistent with the member’s supervisory authority. 

3 Examples of systems and components include hardware, firmware, software, peripherals, and network components. 

4 The term “depository financial institution” includes national banks, federal savings associations, state savings associations, state member banks, state nonmember banks, and credit unions. 

5 The term “nonbank financial institution” includes nondepository financial institutions under the jurisdiction of either state banking departments or the CFPB. 

6 The term “bank holding company” includes any company that has control over any bank or over any company that is or becomes a bank holding company as defined by the Bank Holding Company Act. 

7 The term “savings and loan holding company” includes any company that directly or indirectly controls a savings association or controls any other company that is a savings and loan holding company as defined by the Home Owners’ Loan Act. 

8 The term “third-party service provider” means third parties that provide services, the provision of which is subject to examination under the Bank Service Company Act, the Home Owners’ Loan Act, the Dodd–Frank Wall Street Reform and Consumer Protection Act, or other relevant law. 

& 

This booklet does not impose new requirements on entities. Instead, this booklet describes the principles and practices that examiners can use when assessing an entity’s system development, acquisition, and maintenance activities. 

Appendix A of this booklet provides objectives-based examination procedures. Application of principles and related examination procedures will vary consistent with the examined entity’s complexity and risk profile (including the size of the entity or the nature of the systems and components). 

## I OVERVIEW OF DEVELOPMENT, ACQUISITION, AND MAINTENANCE 

Development, acquisition, and maintenance activities are integral to an entity’s operations. This booklet discusses how weaknesses in IT development, acquisition, and maintenance processes may lead to issues with confidentiality, integrity, availability, and resilience of the entity’s systems, components, and data. Management determines the systems, products, and services that the entity will provide, whether to develop or acquire them, and how to maintain and service those systems, products, and services. Generally, whether developing or acquiring systems, products, and services, management performs some form of acquisition activity, including procurement. Management also oversees maintenance activities to prolong the life of systems and components (i.e., IT assets) and support continuity of operations. Management should plan for maintenance activities from the outset of acquisition or development to ensure secure continuity of operations. The following definitions and explanations provide an overview of IT development, acquisition, and maintenance. 

Development: Systematic application of knowledge toward the production of useful materials, devices, and systems, or processes of defining, designing, testing, and implementing systems or components. Development includes validation and demonstration of a chosen technology, use of test and production environments, improvement of developed prototypes, integration into systems and subsystems, and inclusion of hardware builds. Development activities may be performed by the entity’s personnel or third parties who develop systems and components on the entity’s behalf. Management may choose to acquire systems and components from third parties and may customize them to meet the entity’s needs. 

Acquisition: All stages for acquiring products or services, beginning with determining the need for the product or service and ending with contract completion and closeout. Acquisition generally involves creating a relationship with a third party in the supply chain; therefore, effective SCRM is integral to the acquisition process. Acquisition activities include procurement processes that help ensure that management receives the contracted products or services. Acquisition activities, including procurement processes, help management achieve and maintain confidentiality, integrity, availability, as well as resilience, including supply chain resilience, throughout the life of systems and components. 

Maintenance: Any act that either prevents the failure or malfunction of equipment or restores its operating capability. This includes incremental changes to improve performance. Maintenance activities include the processes to monitor systems and components and make changes (e.g., install patches and add new functions) to prevent their failure or malfunction and continue to meet user and customer needs. Management should perform preventive maintenance throughout the IT asset’s useful life to prevent or minimize catastrophic failure and promote confidentiality, integrity, availability, and resilience. Maintenance may be performed by the entity’s personnel or third parties. Maintenance activities should be performed regardless of the origin or location (e.g., geographic or virtual) of the systems or components. 

The next section of this booklet addresses governance and risk management elements. Also addressed are common risk topics related to development, acquisition, and maintenance. The 

& 

booklet explains key topics, such as IT project management, SDLC, and supply chain risk management considerations, which are integral to development, acquisition, and maintenance activities to provide for ongoing operations. Appendices provide examination procedures, agency and industry references, and a glossary. 

## II GOVERNANCE OF DEVELOPMENT, ACQUISITION, AND MAINTENANCE 

### Action Summary 

Management should establish, and the board of directors (board) should oversee, an effective governance framework for development, acquisition, and maintenance activities. Additionally, the board should oversee related IT project management processes to manage projects related to those activities. 

Examiners should review the following: 

* • Enterprise-wide IT policies, procedures, and standards describing the entity’s requirements throughout the development, acquisition, and maintenance life cycle.
* • Charters (e.g., board, management, or committee), organizational charts, relevant
* • Project plans and meeting minutes of the board and committees to ensure that activities documentation, and practices to determine whether appropriate roles and responsibilities are identified and assigned with suitable decision-making authority. and projects align with the entity’s strategic objectives and the board’s risk appetite.
* • Project audit reports to determine whether the audit function provides independent, objective assurance of the effectiveness of an entity’s development, acquisition, and maintenance activities.
* • Documentation of controls for personnel with access to program code to limit placement
* • Quality assurance (QA) reports to evaluate processes for the detection of potential coding into the production environment. errors.

The board9 should oversee and management should establish an effective governance structure that allows for the effective oversight and management of the development, acquisition, and maintenance of the entity’s systems and components. Additionally, the board should oversee related IT project management processes and projects related to those activities. The board should oversee significant projects to ensure that they align with an entity’s strategic plans. Projects that do not align may cause lost revenue or diminished economies of scale resulting in budget shortfalls. Misalignment may cause unexpected harm to the entity or its reputation (e.g., customer dissatisfaction, user frustration, noncompliance with laws and regulations, and IT or operational performance issues). Ineffective communication or coordination by the board with appropriate stakeholders can lead to problems (e.g., scope creep on projects and cost overruns) and processes that do not facilitate appropriate communication across business departments. When IT activities are siloed away from business departments or other business line IT departments (i.e., when an entity has multiple lines of business that have their own IT departments), it may result in management establishing counterproductive objectives. 

9 Most financial institutions have boards; however, not all third-party service providers do. When an entity does not have a board, senior leaders may have the responsibilities of a board as described in this booklet. 

Management should consider the needs of internal and external stakeholders10 when making decisions regarding IT development, acquisition, and maintenance activities. Effective communication helps stakeholders carry out their roles and responsibilities and supports entity- wide alignment of these IT activities with an entity’s strategic plans. Effective communication also helps stakeholders appropriately identify, assess, and mitigate risks and their potential impacts. Additionally, when contemplating IT projects and activities, management should consider business strategies and objectives, resilience needs, information security requirements, legal and regulatory requirements, and allocation of resources (e.g., personnel, budget, and time). 

### II.A Policies, Standards, and Procedures 

Effective management develops and implements comprehensive, entity-wide IT policies, standards, and procedures covering the development, acquisition, and maintenance life cycle. Large or complex entities may have multiple policies for different business line functions and their underlying systems and components. The board and designated owners or committees should regularly review and approve IT policies. Policies should clearly delineate development, acquisition, and maintenance responsibilities and provide for communication to all personnel, stakeholders, and appropriate third parties. Standards, on the other hand, may be used to define the processes and rules to support IT policies. For example, software developers often use coding standards in their work. Procedures are often developed to provide instructions to perform a function or task to align with IT policies and standards and may be adjusted to meet changes in the entity’s IT environment. Periodic adjustments to standards and procedures may be needed to continue to align with the board-defined risk appetite, threat environment, and risks to the entity and its customers. Management should review and approve deviations from policies, standards, and procedures related to development, acquisition, and maintenance. For example, if the entity’s policy prohibits the use of open-source software, management should approve any exceptions when developers use open-source software. 

### II.B Roles and Responsibilities 

The board should oversee and management should implement the entity’s development, acquisition, and maintenance activities by identifying and assigning appropriate roles and responsibilities. Assigning roles and responsibilities helps management to assign decision- making authority to an appropriate individual or team. Designated roles and responsibilities allow management and stakeholders to identify relevant lines of communication. Additionally, management may specify qualifications, competence, skills, and expertise needed in various roles. Examples of common roles related to development, acquisition, and maintenance activities are described in the following sections of this booklet. In smaller or less complex entities, formal roles may not be established; however, management should identify and assign the responsibilities described in these sections. As appropriate for the needs of the entity, it is important to consider training needs to support development, acquisition, and maintenance responsibilities. For more information about IT roles and responsibilities in general, refer to the FFIEC IT Handbook’s “Management” booklet. 

10 For purposes of this booklet, stakeholders may include management or designated individuals from all departments affected by the proposed project (e.g., information technology [IT], legal, compliance, independent risk management, business process owners, and audit), and board members. At times, stakeholders can also include external entities (e.g., clients, consumers, customers, or customers of financial institution clients of a third-party service provider). 

#### II.B.1 Board, Senior Management, and Other Common Roles 

Primary roles and responsibilities for the board and senior management for development, acquisition, and maintenance activities should include the following: 

* • Board: The board, or board-designated committee,11 typically confirms that IT-related development, acquisition, and maintenance activities align with entity strategic objectives and the board’s risk appetite. The audit committee of the board is involved with reviewing and validating the entity’s audit-related activities, including development, acquisition, and maintenance.12 Additionally, the board generally approves 


	+ o Significant IT investments.
	+ o Policies and standards.
	+ o Significant IT projects that may affect the entity’s strategic direction.13Board members should have appropriate knowledge of risks to provide a credible challenge14 to management responsible for development, acquisition, and maintenance functions.
* • Senior management: Senior management approves and champions development,
* • Chief information officer (CIO): The CIO leads day-to-day IT system and component acquisition, and maintenance projects within its authority, ensures that project execution is in alignment with entity objectives and risk appetite, and ensures that adequate resources, including qualified staff, are available to complete IT projects. development, acquisition, and maintenance in accordance with the entity’s policies and business strategy. Prudent practices include the CIO consulting with the entity’s risk management function and legal counsel to ensure that development, acquisition, and maintenance decisions are consistent with sound risk management principles and applicable laws and regulations. Additionally, the CIO facilitates the integration of any new projects, systems, and components into the entity’s operations to ensure that they align with strategic objectives and IT strategies. The CIO helps determine the feasibility of proposed projects or changes. 11 For purposes of this booklet, when the role of the board is mentioned, it can be inferred that this role may be fulfilled by a board-designated committee, as appropriate, unless otherwise stated. An example of a board- designated committee is the architectural review board, which is common in larger or more complex entities. 

12 For more on the general role of audit and its responsibilities, refer to the FFIEC IT Handbook’s “Audit” booklet. 

13 Generally, the board approves critical operations and core business functions. For more information, refer to the following guidance: FDIC Financial Institution Letter (FIL) 103-2020, “The FDIC Publishes Sound Practices to Strengthen Operational Resilience”; FRB Supervision and Regulation (SR) Letter 20-24, “Interagency Paper on Sound Practices to Strengthen Operational Resilience”; and OCC Bulletin 2020-94, “Operational Risk: Sound Practices to Strengthen Operational Risk.” 

14 A credible challenge involves being actively engaged, asking thoughtful questions, and exercising independent judgment.
* • Chief information security officer (CISO): The CISO typically develops enterprise-wide cybersecurity and information security policies and standards, including procedures promoting secure development, acquisition, and maintenance practices, and provides input for the consideration and inclusion of security and resilience in IT projects. The CISO is responsible for validating that security and resilience are maintained throughout the life of a project, system, or component.
* • IT steering committee: An IT steering committee typically reviews and approves major development, acquisition, and maintenance proposals. Additionally, the committee provides a credible challenge to IT project managers and management responsible for development, acquisition, and maintenance activities. The credible challenge allows management to verify that projects adhere to entity policies, standards, and procedures; that project managers identify and appropriately mitigate risks; and that project costs stay within the allocated budget. The IT steering committee is responsible for reporting to the board and overseeing any issues (e.g., project issues or failure to meet standards) or additional project needs (e.g., additional funds and resources) by translating technical concepts in a way that is clear and understandable to relevant stakeholders.
#### II.B.2 IT Project Management Roles 

There are multiple IT project management roles that, when performed effectively, can play a significant part in a project’s success. A project can be part of larger programs, which may include multiple related projects. Roles may overlap in smaller or less complex entities or projects, which is acceptable if mitigating controls are in place. Segregation of duties and dual controls or other compensating controls are important for development, acquisition, and maintenance projects. For example, segregation of duties helps ensure that one person cannot use projects to misappropriate entity funds; purchase substandard software, hardware, or components; or initiate inappropriate contracts. Additionally, a key concern is that seemingly small problems in IT projects can quickly escalate in scale. Dual control may be used to mitigate this risk because it allows for problems to be identified and addressed earlier since no single person or group can make final decisions without agreement from others. For example, during development, code review involves a second individual to review code before it is released to test environments. Segregation of duties and dual control help foster security and resilience. For more information, refer to the “IT Project Management” section of this booklet. Common IT project management roles and responsibilities include the following: 

* • Sponsor: A project’s sponsor is the most senior role in the project or program, which may contain multiple projects. Depending on the project’s size and complexity, there may be more than one sponsor. Responsibilities include obtaining stakeholder endorsement for the project based on its objectives and business case,15 providing resources, and appointing the project owner. The sponsor represents the project in discussions with senior management, provides both formal and informal support to project teams, and promotes the positive aspects of the changes resulting from the project. The sponsor works with senior stakeholders to resolve strategic issues across projects in a program or among projects. Additionally, the sponsor approves milestones and confirms the project’s successful delivery. 

15 A business case provides justification to undertake a project, and the business case identifies the benefit, costs, and provides a rationale for the preferred solution. For more information, refer to the Project Management Institute (PMI), “Is This Really Worth the Effort? The Need for a Business Case.”
* • Project owners: A project owner typically helps determine a project’s vision and guides
* • Product owner: A product owner represents the business line stakeholders (e.g., team, progress toward the objectives to meet that vision throughout the project life cycle. The project owner manages key project risks to maintain alignment between the entity’s objectives and those of the project. Additionally, the project owner obtains resources from the sponsor, serves as the primary communication link with management and other stakeholders, and is responsible for the successful completion of the project. department, or customer) for the team that undertakes the project. The product owner ensures that the project team delivers the most value by helping to prioritize deliverables. The product owner is responsible for communicating project status with the business line stakeholders.
* • Project or program managers: Project or program managers are responsible for working with the business change manager to plan and monitor the project or program tasks. Additionally, they verify that tasks align with the objectives throughout the project’s or program’s life cycle. They are responsible for defining success and providing oversight for the completion of tasks and successful delivery of the project’s or program’s objectives. Project or program managers tend to have practical project management experience rather than specific business line expertise. They monitor and manage resources to stay within timelines and budget, including coordinating between projects and managing project interdependencies. Additionally, project or program managers manage issues and direct corrective action when necessary. They monitor, report, and communicate a project’s or program’s status to management and other stakeholders. Lastly, project or program managers maintain all project documentation.
* • Business change manager: A business change manager represents the business line for projects or programs in discussions with others. The role includes highlighting and focusing on benefits and risks for the business line and identifying the appropriate timing (for example, during periods of lower volumes) of implementation and releases. The business change manager plans and manages the integration of the changes in business line systems or processes, including identifying new business processes, to meet strategic objectives. A project or program may have multiple business change managers representing their respective lines of business. The business change manager defines and monitors key performance indicators to objectively measure the project’s or program’s success. The business change manager translates the technical aspects and benefits of a project or program into a format that is understandable to and executable by business line management and staff. Business change managers plan and manage business continuity during and immediately after the change takes place.
* • Project or program management office or organization (PMO) personnel: Traditional project management methodologies, such as waterfall, typically centralize project governance through the PMO. The entity’s size, complexity, and project types determine the number and qualifications of PMO personnel. Larger or more complex entities often have numerous PMO personnel to coordinate the projects and programs undertaken by an entity. Smaller or less complex entities often do not have designated PMOs or dedicated project personnel. The IT project’s size and complexity determine the PMO’s extent of engagement. Beyond keeping projects on track and identifying and removing obstacles, PMO activities generally involve analyzing the project’s feasibility and risk; determining whether to develop, acquire, or outsource systems and components; ensuring quality of deliverables; and verifying that the project delivers value to the entity and affected business units.
* • Stakeholders: Stakeholders should be involved early in the planning process to provide input before finalizing project requirements. In addition, regular communication between project managers and stakeholders helps to ensure that stakeholders agree with the project’s proposed direction. The list of potential stakeholders can be internal or external and may include the following individuals:16 



| Internal stakeholders | External stakeholders |
| --- | --- |
| Board of directors | Customers, consumers of critical services, or financial institution clients of a third party |
| Senior management | Third parties (e.g., service providers, suppliers, or partners) |
| Heads of business lines, especially critical service owners | User groups |
| Relevant internal business unit personnel (e.g., IT, human resources, compliance, and legal) | Shareholders |
#### II.B.3 Development Roles 

Development personnel typically encompass the technology professionals charged with designing, building, and maintaining solutions to solve a business problem or fulfill technology needs identified by business strategy. Development personnel may create solutions to support new products offered to customers, expand existing system capacity to support growth, or integrate systems after a merger. Larger or more complex entities may have separate personnel or departments to fulfill development roles, or varying development roles may have more granular responsibilities (e.g., user interface developers, software engineers, or mobile application developers). In smaller or less complex entities, roles may overlap, which may be acceptable if appropriate mitigating controls are in place. Third parties may help the entity with or serve in development roles. 

Segregation of duties and dual controls or other compensating controls are important for development, acquisition, and maintenance activities because they help foster security and resilience. For example, segregation of development and implementation duties helps ensure that developers cannot directly alter the production environment. Inappropriate developer access may adversely affect the production environment’s confidentiality, integrity, availability, or resilience. Effective dual control allows management and other personnel to identify and address problems earlier since no single person or group can make changes or modifications without appropriate approval. Without dual control, seemingly small coding, building, and patching problems can quickly escalate in scale. 

16 Refer to Cybersecurity and Infrastructure Security Agency (CISA), CRR Supplemental Resource Guide, Vol. 3: Configuration and Change Management, Version 1.1. Also refer to CISA, CRR Supplemental Resource Guide, Vol. 5: Incident Management, Version 1.1. 

Typically, development deliverables are software applications or smaller modules of a larger application or system. Some larger or more complex entities, however, employ software engineering specialists to modify firmware, customize third-party-developed in-house applications, or adapt hardware products, such as automated teller machines (ATM), cash dispensers, and passbook or receipt printers to fit the entity’s specific needs. Larger or more complex entities, especially those providing cloud, managed security, and payments services, often build proprietary hardware (e.g., servers or point-of-sale terminals) used in-house and by customers they service. 

Staff roles that support development include the following: 

* • Network architects: Network architects generally design, select, and implement the appropriate system architecture to satisfy stakeholder requirements and achieve the desired results under given constraints. Network architects often have extensive knowledge of the entity’s business plan to design a network to help the entity achieve its strategic objectives. They create plans and layouts for data communication networks and present those plans to management; explain risks; and justify recommended designs, changes, and consequences of inaction. They consider security when designing networks and systems. Once network architects define the appropriate architecture, they generally document and communicate it to the developers. Network architects upgrade hardware and software as needed to support solutions. After deployment, they may support those networks and troubleshoot any issues. When needed, network architects research new or emerging technologies to determine whether they are appropriate to implement for the entity. They evaluate network traffic to estimate growth and determine capacity management needs. Network architects may work with other IT personnel, such as network or system administrators and information systems managers, to ensure that networking needs are met. They work with third parties to manage upgrades and support the networks. Larger or more complex entities may define additional roles for enterprise architecture, including software and hardware architecture.
* • Developers: Developers create software and the underlying systems and components to support an entity’s business lines and strategic objectives, including security and resilience. They analyze users’ needs and design and develop software to meet those needs, including how the systems or components will work together. Developers should have a clear understanding of user requirements and needs to ensure that deliverables meet user expectations. Developers document every aspect of a system or component as a reference for future maintenance and upgrades. They help ensure that a program continues to function normally through regular maintenance and, when necessary, recommend upgrades to keep pace with technology and security needs. They communicate with quality management personnel and testers to ensure that the system or component operates as envisioned. Developers may specialize in a particular language, platform, or business sector and may work individually in small or large teams.
* • Software engineers: A software engineer is a type of developer who has a broad view of a project’s system and software requirements and plans its scope and order of work. Software engineers may direct software developers, QA analysts, and testers.17
* • Hardware engineers: Hardware engineers typically design new hardware. As part of the design process, hardware engineers create schematics of equipment to be built and test the hardware. They analyze test results and modify the design as needed. Hardware engineers often work with developers to ensure that hardware components work together with the latest software. Additionally, hardware engineers oversee the manufacturing process for hardware. Many hardware engineers design devices used in manufactured products that incorporate processors and other computer components and that connect to the internet (e.g., point-of- sale terminals, card readers, and ATMs). 17 Refer to the U.S. Bureau of Labor Statistics’ Occupational Outlook Handbook, “Software Developers, Quality Assurance Analysts, and Testers.”
* • Information security analysts: Information security analysts plan and carry out security measures to protect an entity’s networks and systems. They work with developers to build security into systems and components and maintain the security aspects once developed. The role specializes in building and performing security assessments, identifying threats to systems, and ensuring that the software complies with the entity’s security standards and policies. Information security analysts should have an enterprise-wide understanding of the entity’s security architecture and interoperability of systems and components.
* • Systems analysts: Systems analysts can also be referred to as systems architects. Systems analysts use their knowledge of the entity’s systems, procedures, and technology needs to help IT personnel design systems that operate more efficiently and support the enterprise- wide business and strategic objectives. Systems analysts work with other IT personnel to help an entity’s business leaders understand how systems and components support the entity’s strategic and business line goals and objectives. Systems analysts devise ways to add functionality to systems by researching different technologies and analyzing costs and benefits of changing, upgrading, or implementing new IT systems to help managers decide which, if any, to install. Systems analysts validate the communication and interface between systems to ensure that they continue to function. They work with other IT personnel to evaluate system capacity needs. They work with business personnel to write instruction manuals and train the systems’ end users. Additionally, systems analysts may work with other IT personnel to solve problems that arise after the initial system setup.
#### II.B.4 Acquisition Roles 

Acquisition personnel typically procure systems or components. Larger or more complex entities may have separate individuals, teams, or departments responsible for acquisition. Acquisition personnel are often assisted by representatives from several departments, such as project management, IT, contracting, finance, information security, legal, and third-party risk management. Acquisition-related roles may be broken down further into the product or service type purchased (e.g., technology component). At smaller or less complex entities, the acquisition role often is one of multiple duties assigned to an individual (e.g., IT manager or president), which is acceptable if mitigating controls are in place. Additionally, third parties may perform the entity’s acquisition activities (e.g., cloud access security broker). Segregation of duties, dual controls, and other compensating controls are important in acquisition activities to avoid conflicts of interest (e.g., choosing third parties based on relationships versus whether the third party provides the appropriate product, best service, or most advantageous price). Depending on whether the entity chooses to develop IT solutions or procure them from third parties, acquisition roles may vary. 

General responsibilities include specifying what is required, requesting proposals, receiving bids from third parties, evaluating bids and bidders, initiating contracts, and managing contractual relationships. Responsibilities also include evaluating supply chain risks related to third parties (e.g., geopolitical risk for third parties outside the United States). These responsibilities may require specialized knowledge to evaluate pricing and other aspects (e.g., contract terms or support services) of the relationship. Responsibilities are carried out throughout the entire life cycle of the third-party relationship.18 For more information, refer to the “Acquisition” section of this booklet. 

Roles that support acquisitions include the following: 

* • Procurement manager: A procurement manager can also be referred to as a third-party risk manager or business relationship manager. The procurement manager is responsible for the procurement strategy being consistent with the entity’s overall strategy and risk appetite. Procurement managers are responsible for developing the entity’s procurement policies, standards, and procedures to help ensure that procurement personnel avoid potential conflicts of interest or inappropriate third-party relationships. Procurement managers evaluate third parties based on the price, quality, functionality, and delivery speed of products and services. They verify that vendor processes align with the entity’s requirements (e.g., security and resilience) by interviewing vendors and visiting third-party facilities. They analyze proposals, financial reports, and other information to determine reasonable costs, negotiate contracts on the entity’s behalf, and arrange agreements with third parties (e.g., service-level agreements [SLA] or product delivery time frames). Procurement managers evaluate and monitor contracts to ensure that third-party management complies with the contract’s terms and conditions (including compliance with applicable laws and regulations) and determine the need for changes. When necessary, procurement managers meet with entity and third-party management to discuss defective or unacceptable products or services and determine corrective action. Procurement managers maintain and review records of items bought, costs, deliveries, product performance, and inventories. They may attend meetings, trade shows, and conferences to learn about new industry trends and make contacts with potential third- party partners. Procurement managers may work with other personnel, including those in program management, IT, information security, or business lines involved in the project.
* • Third-party risk manager: This role can also be referred to as third-party relationship manager and may also be the same person as the procurement manager. This role involves performing due diligence on third parties before procuring systems, components, or contracting for services (e.g., development or information security activities). When appropriate, the third-party risk manager performs ongoing oversight over third parties throughout the relationship’s life cycle. 18 The term ‘‘business arrangement’’ may also be used and is meant to be interpreted broadly; it is synonymous with the term ‘‘third-party relationship.’’ A third-party relationship may exist despite a lack of a contract or remuneration. Third-party relationships can include outsourced services, use of independent consultants, referral arrangements, merchant payment processing services, services provided by affiliates and subsidiaries, and joint ventures.

& 

#### II.B.5 Maintenance Roles 

Appropriate personnel should perform maintenance throughout the life cycle of systems and components. Some responsibilities assigned as part of maintenance include asset management (including end-of-life [EOL] and end-of-support [EOS] management), patch management, vulnerability management, and performance and capacity management. Management should understand maintenance roles and related responsibilities. Maintenance personnel should have knowledge and understanding of all relevant systems and components they are expected to operate and maintain. Both maintenance personnel and management should analyze, document, and understand the costs of maintenance (e.g., budget, time, or personnel) versus the costs of not performing maintenance (e.g., system failures, data breaches, and customer dissatisfaction). Larger or more complex entities may have separate individuals, teams, or departments charged with maintenance. At smaller or less complex entities, maintenance roles may be part of other roles or duties that an individual may have, which is acceptable if mitigating controls are in place (e.g., segregation of duties and dual controls). Additionally, third parties may perform responsibilities related to maintenance for the entity, according to contractual agreements. 

IT staff are generally responsible for maintaining an entity’s systems and components to ensure that they continue to operate as expected. Maintenance generally includes performing updates and applying patches, monitoring the systems’ or components’ status, and monitoring the servers and infrastructure that support the entity’s systems and components. Maintenance roles may have more granular responsibilities (e.g., network support) depending on the complexity of the entity’s IT environment. Maintenance roles should be independent from development roles to prevent developers from accessing production environments. For more information, refer to the “Maintenance” section of this booklet. 

#### II.B.6 Other Common Development, Acquisition, and Maintenance Roles 

Depending on the entity’s size and complexity, the following roles are common to development, acquisition, and maintenance activities: 

* • Configuration or change control board (CCB): The CCB is “a group of qualified people with responsibility for the process of regulating and approving changes to hardware, firmware, software, and documentation throughout the development and operational life cycle of an information system.”19 The CCB typically is part of an entity’s change management process, and it reviews and prioritizes change requests related to a project or production environment.
* • Testers and quality assurance analysts: During development, acquisition, and maintenance, testers and quality assurance analysts create test plans, scenarios, and procedures for new or changed systems and components to confirm that they function as intended. Testers are responsible for testing systems, components, and controls regardless of whether they are developed internally or procured from a third party. Testers design and conduct tests to check systems and components for problems. They identify, document, and 19 Refer to NIST Glossary.

& 

report risks from test results and recommend steps to minimize or resolve risks or defects. They assess the usability and functionality of systems and components to identify issues, including difficulties a user might have. They can use manual or automated processes, with additional testing as necessary, and evaluate results. Testers document the results of testing and report defects or problems to developers, project teams, and other stakeholders. Once the system or component is released to production, testers run additional tests to look for errors and usability problems. They perform tests after any upgrades, maintenance, or implementation of patches and fixes on a system or component to validate the changes made. Depending on the types of tests performed (e.g., unit, security, regression, and integration), other testers may be involved at various SDLC phases, based on the testers’ roles and knowledge of the system or component and its use. For more information, see the “Testing” section in this booklet. 

#### II.B.7 Supply Chain Roles 

Typically, supply chain personnel are responsible for implementing and managing systems and components throughout the entity’s supply chain. Larger or more complex entities may have separate individuals, teams, or departments charged with supply chain roles and responsibilities. These personnel may include representatives from several key departments, such as development, procurement (including logistics and product delivery), maintenance, project management, IT, contracting, finance, information security, and third-party risk management. 

Common internal roles may be the chief risk officer, CIO, CISO, program executive, program manager, system engineers or system security engineers, and other personnel. Common external supply chain roles may be suppliers, developers, system integrators, third-party system service providers, and other external personnel responsible for supply chain activities as noted in agreements (e.g., contracts) between the entity, third parties, and their subcontractors.20 

#### II.B.8 Other Support Functions 

Several lines of business and other support functions should be involved in overseeing or validating development, acquisition, and maintenance activities early in the process. One of those functions may be end-user and customer support, often referred to as the IT help desk. The end-user and customer support role works with development, acquisition, and maintenance personnel to respond to user or customer concerns. This role may also assist with resolving problems that cannot be corrected quickly. Moreover, this role provides feedback to development, acquisition, and maintenance personnel about the functionality of products and services. This role records the details of customer or user interactions and the resolution of problems. End-user and customer support staff should understand the escalation process and the personnel who can address more complex problems. 

20 For more information on common external supply chain roles, refer to NIST Special Publication (SP) 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

& 

#### II.B.9 Audit’s Role 

An effective audit function provides independent, objective validation of controls and statements of assurance on the effectiveness of an entity’s development, acquisition, and maintenance activities. Although auditors should not have any direct involvement in management decisions, they should raise objections if they believe the control environment is inadequate. Auditors may plan for their advisory capacity in development, acquisition, and maintenance activities by developing an understanding of the proposed system or changes. Auditors may require specialized knowledge of IT to advise on or review these activities. They should validate schedule adherence and management. Auditors should determine the effectiveness of controls in the entity’s development, acquisition, and maintenance activities and recommend appropriate mitigation. They may communicate with developers regarding appropriate control standards and frameworks throughout IT projects. 

Auditors do more than consult when reviewing controls in new or modified systems or components. In smaller or less complex entities, auditors typically assess an entity’s development, acquisition, and maintenance activities during an “IT general controls”21 audit. Larger or more complex entities may have a dedicated IT audit function, which generally follows a risk-based approach to prioritize the review of numerous IT processes and controls. These entities may have separate audits to assess general processes, such as development, acquisition, or maintenance, or may review these activities as part of business line, project, or other technology audits. During each SDLC phase, auditors review the internal controls, testing, and audit trails included in systems and components. 

Auditors may participate in an advisory capacity in IT projects and may perform pre- and post- implementation reviews. Post-implementation reviews should occur shortly after implementing the new or revised system or components. These reviews help validate that the system or component operates as expected and provide financial statement users with relevant information in ways that justify the cost of providing it. 

In larger or more complex entities with numerous IT systems and components, formal quality management or change management groups may have primary responsibility for post- implementation reviews. In such cases, auditors may choose not to perform a separate review; however, they may participate in validating minimum test criteria and evaluating the results of reviews. 

Auditors’ validation activities regarding IT projects or change management may include reviews for the following: 

* • Project or changes were authorized.
* • Project or changes were subjected to a risk-impact assessment.
* • Project or changes were handled effectively and formally documented, especially when it was an emergency change. 21 While “IT general controls” is a typical name for all-encompassing IT audits, entities may use various names for these reviews. 

&
* • Project or changes were prioritized among all other IT projects or changes in a manner that is effective for the entity.
* • Project or changes were tracked by a formal process.

For more information, refer to the FFIEC IT Handbook’s “Audit” booklet. 

& 

## III RISK MANAGEMENT OF DEVELOPMENT, ACQUISITION, AND MAINTENANCE 

### Action Summary 

Management should implement continual risk management processes within the entity’s development, acquisition, and maintenance activities to identify, measure, monitor, and control reasonably foreseeable internal and external risks and threats, including those that could result in unauthorized disclosure, misuse, alteration, or destruction of customer information or customer information systems. 

Examiners should review the following: 

* • Policies, standards, and procedures for identifying, measuring, mitigating, monitoring, and
* • Documented processes and metrics used to measure the level of risk.
* • Detailed documentation of processes used to review, accept, and document risks that
* • Documentation of risk assessment processes to identify key risks at the onset of IT projects
* • Risk assessments that highlight internal and external risks related to development, reporting risks related to development, acquisition, and maintenance activities. management cannot mitigate or transfer. and throughout their life cycles. acquisition, and maintenance activities.
* • Documentation of ongoing processes and reports to monitor and communicate risk, including emerging risks related to development, acquisition, and maintenance activities.
* • Reports to stakeholders that are timely, accurate, and include clear, relevant metrics.

Management should identify, measure, monitor, and control reasonably foreseeable internal and external risks and threats, including those that could result in unauthorized disclosure, misuse, alteration, or destruction of customer information or customer information systems.22 While the requirement is relative to risks to sensitive customer information, it is a prudent practice relative to any sensitive information type. Additionally, management should consider risks that could result in a severe disruption or material compromise to critical service delivery. It is also important to consider known risks related to developed or acquired products and systems,23 and any known potential misuses. IT risk management activities should include policies, standards, and procedures for identifying, measuring, mitigating, monitoring, and reporting risks related to development, acquisition, and maintenance activities. Additionally, management should consider using threat models to assess security policies, standards, and procedures. While there are many widely used threat modeling methodologies, it is important for entity personnel to consider implementing a model commensurate with the threats in the entity’s overall environment. 

22 Refer to 15 USC 6801 and 6805(b), “Financial Services Modernization Act of 1999” (Gramm‒Leach‒Bliley Act or GLBA), further implemented by FFIEC members as follows: FDIC: 12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards”; FRB: Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards”; and Regulation Y, 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards”; NCUA: 12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information”; and OCC: 12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards.” Additionally, refer to Federal Trade Commission (FTC) 16 CFR 314, “Standards for Safeguarding Customer Information.” 

23 Developed or acquired products and services may include hardware (e.g., servers, laptops), software (e.g., application programming interfaces), or services (e.g., banking-as-a-service). 

Risk management activities include identification of risks associated with development, acquisition, maintenance, and associated IT projects, including the risks associated with not initiating a project.24 Examples of risk management activities to consider include the following: 

* • Measuring each activity’s level of risk.
* • Mitigating risks to an acceptable, board-approved level of residual risk.
* • Monitoring risks related to development, acquisition, and maintenance activities.
* • Reporting updates to senior management and the board, as necessary.

At times, management may choose to transfer some of the risk, such as by purchasing insurance (e.g., errors and omissions or cyber) to address the potential for unknown errors in source code. When management cannot mitigate or transfer risk, there should be a process to review, accept, and document the risk and its acceptance by the board. For an acquisition, management and the board may decline to move forward if the risk level exceeds the board’s risk appetite (e.g., purchase of a product that uses an amount of open-source code above approved levels). Management and the board should regularly review and approve risk acceptance decisions consistent with the entity’s governance structure. For more information about risk management, refer to the FFIEC IT Handbook’s “Management” booklet. 

### III.A Risk Identification 

Risk identification involves identifying and documenting risks that may affect development, acquisition, and maintenance activities. Effective risk identification is a continuous process that includes iterative reassessment of risks. Identifying key risks related to development, acquisition, and maintenance activities gives management opportunities to implement appropriate controls and mitigate risks. Identifying key risks at the onset of an IT project allows for early assessment of risks, risk effects, and risk mitigation options. For example, a code review helps developers find errors before migrating code between the test and the production environments. Ideally, risk identification and assessments involve stakeholders with business process knowledge who may be affected by the development, acquisition, or maintenance activities or the related IT projects. As always, information security concerns should also be considered. 

Risk identification highlights internal and external risks related to development, acquisition, and maintenance activities. Examples of internal risks include insider threats (e.g., trusted employees who use authorized access in an unauthorized manner for personal gain, entity harm, or errors and omissions) and scheduling difficulties (e.g., loss of knowledgeable personnel or 

24 There is a strong relationship between the phases in the SDLC, the SCRM life cycle (both discussed in this booklet), and the third-party risk management life cycle, referenced in the Interagency Guidance on Third-Party Relationships: Risk Management. 

& 

unavailability of skilled personnel). Examples of external risks include those arising from third- party relationships, industry threats and changes (e.g., new products or services, regulatory changes, or new cyber threats), and natural disasters. Additionally, financial technology (fintech)25 firms and other third-party relationships may not be subject to the same regulatory requirements as the entity. Management is responsible for holding the third party accountable to the entity’s standards (e.g., compliance with regulations and adherence to security and resilience standards) and the board’s risk appetite. 

### III.B Risk Measurement 

Management should implement effective standards to measure risk in the entity’s development, acquisition, and maintenance activities. Risk measurement should be an ongoing process and commensurate with the size and complexity of an entity’s activities. As the complexity of an entity’s activities and processes increases, management may benefit from using automated tools to help measure risk. Effective risk measurement processes include management setting and monitoring objective standards for performance. Examples of risk measurement related to development, acquisition, and maintenance include the following: 

* • Comparisons of estimated versus actual completion dates for IT project deliverables.
* • Number of open issues related to projects and the length of time issues remain open.
* • Percentage of occasions when management needed to back code out of production.
* • Cost overruns greater than the entity’s established limits.
* • Service levels below those defined in contracts and agreements.
* • Number of unapplied patches or patches applied beyond the policy time frames.
* • Policy exceptions.
### III.C Risk Monitoring and Reporting 

Effective management monitors and reports risks related to development, acquisition, and maintenance activities. Examples of risks monitored by management include project management (e.g., milestone date shifts, negative test results, and major requirements changes), cybersecurity, supply chain, and emerging technology. Reports of these risks should be timely and accurate; include clear, relevant metrics (e.g., trends related to the number of open issues or code back-outs); and note deviations from policies, standards, and procedures. Reports should be distributed to appropriate stakeholders, including the board when necessary. Management should communicate technical aspects that are easily understood (e.g., explaining acronyms or technical jargon) when reporting to the entity’s board and relate the IT issues to the entity’s business concerns. Effective monitoring and reporting inform management about problems and performance issues in a timely manner, so that management can minimize the potential for an increase in the levels of risk associated with identified issues. Monitoring and reporting should enable all stakeholders to understand the risks and agree with the proposed courses of action. 

25 For purposes of this booklet, “fintech” refers to using technology in novel ways to provide financial services. 

& 

### III.D Controlling or Mitigating Risk 

Risk mitigation relies on identification and monitoring of risk in conjunction with the board’s risk appetite. These limits should assist in limiting exposure to the various risks associated with the entity’s IT-related activities. Implementation of effective operational controls to address these risks are described throughout this booklet. One example of risk mitigation is implementing code reviews during development to detect and correct errors earlier in the development process that might cause the system or component to fail. Effective management adopts repeatable control processes to ensure that risks are consistently addressed across the entity over time. 

& 

IV 

## COMMON DEVELOPMENT, ACQUISITION, AND MAINTENANCE RISK TOPICS 

### Action Summary 

Management should implement effective risk mitigation throughout development, acquisition, and maintenance activities regardless of the phase of the project in the life cycle and agnostic as to the type of technology. Specific risks and controls should be considered depending on management’s chosen solution. 

Examiners should review the following: 

* • Systems, components, and services, including related contracts and licenses, throughout the supply chain for appropriate risk identification and mitigation.
* •
* • Inventory of all systems and components (e.g., open-source, proprietary, application programming interfaces [API], and container images and registries), including related licenses, and data as part of IT asset management (ITAM).
* • Access, authentication, and authorization controls for systems, components, data, and 

Security controls (e.g., secure coding requirements and baseline configuration use) used to harden systems and components. related documentation throughout the supply chain to ensure appropriate security.
* •
* • Segregation of duties in development, acquisition, and maintenance activities. 

Process of selecting and implementing methodologies to enable effective management and control of development, acquisition, or maintenance projects and alignment with entity objectives. 

Operating parameters (e.g., timing, speed, throughput, and data validation) for systems and components to determine performance. 

Activity logs related to systems, components, and data to identify operating risks. 

Monitoring processes of development and maintenance activity for identification of anomalies and unauthorized access or modification to systems, components, and data. 

Reporting processes for decision-making and measuring the level of project success. 

Training on development, acquisition, and maintenance concepts (e.g., methodologies); effectiveness of training; and capability of personnel to implement concepts learned.
* • Documentation of internally developed systems and components and externally procured
* •
* •
* •
* •
* • products and services to effectively operate and maintain the systems and components.
* • Evaluation process (e.g., post-implementation review, stakeholder interview, problem documentation and resolution, cost-benefit analysis, and reports to senior management) for development, acquisition, and maintenance projects.

IT systems are designed, built, and implemented to achieve strategic goals and business objectives. While there are risks specific to each of the development, acquisition, and maintenance activities, certain risk considerations are common to all three. Common development, acquisition, and maintenance risk topics are discussed in the following subsections of this booklet: 

* • “Open-Source”
* • “Commercial-off-the-Shelf”
* • “Licenses, Agreements, and Copyright Protection”
* • “Secure Development”
* • “Data”
* • “Secure Operating Environments”
* • “Microservices”
* • “Containers”
* • “Application Programming Interfaces”
* • “Quality Management”
* • “Documentation Standards”
* • “Post-Implementation Review”
* • “IT Project Management”
* • “System Development Life Cycle”
* • “Supply Chain Considerations”
### IV.A Open-Source 

Open-source software is software released under a license that allows the software and its source code to be accessed, used, modified, and shared by anyone.26 Effective management identifies and mitigates risks related to the use of open-source components (e.g., open-source software components and hardware components). For example, components may be based on poorly written code, or the developer may not have properly addressed security concerns. Open-source vulnerabilities may be more common depending on the underlying code’s quality because the overall review process for open-source is less transparent and more difficult to validate. If the original developer makes updates, they may not be pushed to the entity. In that case, effective management would request updates from the original open-source developer to address vulnerabilities and manually deploy updates. Alternatively, when the original developer does not make updates to open-source systems and components, effective management may engage in- house or third-party software development personnel to update the software. 

The Open Worldwide Application Security Project (OWASP) recommends the following component analysis27 strategies to reduce risks associated with the use of open-source components:28 

26 For more information, refer to NIST Directive S 6106.01, “Open Source Code.” 

27 OWASP defines “component analysis” as “the process of identifying potential areas of risk from the use of third- party and open-source software and hardware components.” 

28 For more information, refer to OWASP, Component Analysis. 

& 

* • Evaluating the type of framework and libraries to reduce architectural changes, regressions (or defects), and code rewrites.
* • Identifying and analyzing the purpose of each component to reveal the existence of components with duplicate or similar functionality.
* • Evaluating the number of third-party and open-source components in a project because the higher the number, the more difficult it is for development teams to maintain large sets of components over time.
* • Using private central repositories29 or public repositories’ code-signing and verification tools
* • Identifying a component’s provenance31 to help ensure knowledge of authorship of software to minimize risk of threats30 related to public repositories. components, manufacturers, suppliers, software repositories, and country of origin.
* • Maintaining accurate formulation32 and pedigree33 information for source code that is readily available, modifiable, and redistributable.
* • Identifying the license for a given component and whether it allows certain types of usage, contains distribution requirements or limitations, or requires specific actions if the component is modified.
* • Aggregating the risk of all direct, transitive, runtime, and environmental dependencies providing a holistic view of inherited risk.34 29 A “repository” is defined as “a place, room, or container where something is deposited or stored.” For purposes of IT, repositories may store requirements, policies, processes, data, software libraries, projects, configurations, performance goals, and applications, with the potential of supporting both software development and operations management. 

30 Some of the threats against public repositories include typosquatting (i.e., naming a component to take advantage of common misspelling); organization/group abuse (i.e., pretending to be a public person or entity and abusing the perceived trust); malware through transfer (i.e., leveraging weak or absent code-signing requirements to spread malware through the transfer of an open-source project from one maintainer to another); and cross-build injection (i.e., abusing dependency resolution schemes and weak infrastructure controls to inject malicious components in place of safe ones). 

31 For purposes of this discussion, the identification of a component’s provenance refers to the chronology of the origin, development, ownership, location, and changes to a system or system component and associated data. It can include personnel and processes used to interact with or make modifications to the system, component, or associated data. 

32 OWASP describes “formulation” as “how components were built…and a comprehensive list of parallel and sequential steps that were taken to build, test, and deliver a component.” 

33 NIST Glossary defines “pedigree” as “the validation of the composition and provenance of technologies, products, and services is referred to as the pedigree. For microelectronics, this includes material composition of components. For software this includes the composition of open source and proprietary code, including the version of the component at a given point in time. Pedigrees increase the assurance that the claims suppliers assert about the internal composition and provenance of the products, services, and technologies they provide are valid.” 

34 Inherited risks are derived from an application’s transitive dependency (i.e., when an application or component has a direct dependency on another component and that component then has a dependency on another component) or direct dependency on every component. Transitive dependencies have their own risk that is inherited by every component and application that relies on them. Refer to OWASP, Component Analysis. 

&
* • Evaluating the health of an open-source project through quality controls and metrics (e.g.,
* • Including external services (such as those relied on for functionality) in the overall inventory FFIEC IT Examination Handbook Development, Acquisition, and Maintenance frequency of code changes and patches), community engagement (e.g., user base and involvement), and vulnerability analysis. of components.

During software evaluation, a review of the open-source developer’s formal documentation helps management determine potential software maintenance risks after software selection. Open- source documentation may be less comprehensive when compared with documentation for proprietary systems and components. Effective management proactively maintains updated application and user documentation, especially when code changes are made. 

For more information, refer to the FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets. 

### IV.B Commercial-off-the-Shelf 

Commercial off-the-shelf (COTS) systems are systems, components, or solutions that are ready- made and available for sale, lease, or license to the general public. COTS is also referred to as off-the-shelf. Entities typically use COTS for operating systems (OS), applications, network infrastructure, servers, desktops, laptops, and mobile devices. Entities often choose to use COTS because it generally is less costly than developing systems and components in-house and requires fewer resources to maintain. COTS solutions generally provide a default set functionality. For example, a default installation of a server OS may include mail, web, and file-sharing services whether or not the solution requires those functions. This is because COTS providers may be developing their products to serve a wide variety of customers, not just those in the financial industry. Therefore, unnecessary services may be present in COTS and represent potential security weaknesses (e.g., unnecessary services creating a wider attack surface), which should be mitigated (e.g., turned off or patched). Protection against those risks begins when the systems or components are constructed and installed through a process referred to as “hardening.” Management should consult third-party providers and vendors regarding recommended security controls to harden the COTS solution. Hardening can involve employing recommendations in a documented installation procedure and generally includes the following: 

* • Changing default passwords.
* • Installing the most secure, up-to-date versions of applications.
* • Configuring security settings as appropriate.
* • Enabling logging.
* • Configuring backups to increase resilience.

A COTS solution may be integrated with existing systems and components to provide additional or enhanced business services to internal and external customers. Management should mitigate any risks related to integration (e.g., lack of interoperability or integration between systems and components). If modifications are made, the process to develop and implement them may be time-consuming and challenging. These modifications may result in additional configuration changes for COTS, or interface changes between COTS and other systems and components (e.g., 

& 

APIs, middleware, and cloud). These changes may then require additional resources and personnel to perform. For more information, refer to the FFIEC IT Handbook’s “Information Security” and “Outsourcing Technology Services” booklets. 

### IV.C Licenses, Agreements, and Copyright Protection 

Systems and components are often licensed, not purchased. Typically, licenses do not give a client (sometimes referred to as a licensee) ownership rights over the licensed product. The licensor35 provides licenses to clients that grant certain rights to use the system or components. The licensor typically grants rights to a client for a specific duration and may charge annual and other fees for system or component use. An effective license and agreement review process at the entity is important to ensure that terms are clearly defined and understood prior to engagement. Before negotiating licenses, management should accurately assess current and future needs and ensure that licenses will continue to meet the entity’s needs. 

The defined scope of a license is a key issue in evaluating and, when feasible, negotiating the terms of a licensing agreement. When reviewing a license, management should confirm that it clearly states whether system or component usage is exclusive, the number of user licenses, and whether there are any time, place, manner, or other types of limitations with the system or component’s use. Effective management reviews licenses to determine whether they allow backup copies related to mission-critical systems or components on which the entity may need to rely for disaster recovery or business continuity purposes. The entity may need to negotiate with licensors to ensure the ability to backup hardware and software if backups are not provided for in the license. In difficult license agreement negotiations, including when an entity has limited negotiating power, management should understand any resulting limitations and consequent risks. Possible actions that an entity might take in such circumstances include determining whether the product or service can still meet the entity’s needs, whether the product or service would result in increased risk to the entity, and whether residual risks are acceptable. If the license agreement is unacceptable for the entity, management may consider other approaches, such as employing other third parties or conducting the activity in-house. In certain circumstances, entities may gain an advantage by negotiating license agreements as a group with other entities (e.g., user groups and banking associations).36 

If the entity plans to provide the systems or components to other related entities (e.g., subsidiaries or contractors), management should include those entities as users in the licenses. If management is responsible for developing systems and components and providing them to other entities or its subsidiaries, management should implement appropriate licenses for the systems or components developed. 

Knowledge of license expiration dates is crucial for the planning and management of license renewal. If there is no license expiration or the license renews automatically (i.e., a perpetual license), the license agreement should explicitly outline those terms. Failure to specify a fixed term or termination date does not automatically provide the entity with a perpetual license. Management should specify in its agreement the appropriate time periods for all licenses and the minimum amount of notice required for license termination. Effective licensing and ITAM processes include tracking license time frames. 

35 A “licensor” is defined as “the person who gives or grants a license.” 

36 For more information, refer to Interagency Guidance on Third-Party Relationships: Risk Management. Specific agency references to this document include (FDIC) FIL 29-2023, (FRB) SR Letter 23-4, and (OCC) Bulletin 2023- 17. 

Effective management periodically reviews system and component licenses to compare all installed licensed systems and components with the respective license terms. This allows management to detect unauthorized installations and validate appropriate license use. If there is a discrepancy between the total number of licenses allowed by the agreement and the installed software, management should address the inappropriate usage. Audit personnel should consider this when developing the scope of their reviews. 

There are several other types of agreements management should consider and review in addition to licenses. For example, a third party may offer maintenance agreements, which outline available maintenance services (e.g., provision of new versions, releases, or updates). Another type of agreement is a development agreement, which outlines terms for the development of systems or components. This agreement may be internal or with a third party. If the agreement involves a third party, the entity may not retain ownership rights even if the entity paid to have the system or component developed. 

A license or agreement should address the availability and cost of system and component updates and modifications (i.e., maintenance). When drafting agreements, effective management determines whether a third-party vendor provides access to source or object code (“code”). Management should have the vendor’s permission and participation for modifications to the code for systems and components. Unauthorized modifications to the code may void maintenance agreements. 

A license or agreement should direct third-party vendors to deliver appropriate documentation. This should include application and user documentation. Management should ensure that the agreement specifies that updated application and user documentation will be provided when any changes are made to procured systems or components. 

#### IV.C.1 Software Licenses 

Effective ITAM includes software license oversight. Software licenses have varying provisions and requirements for ownership and usage. It is important to consider license provisions and all consequences for violating provisions. In more critical instances (i.e., critical to providing business services), entities may engage specialized legal expertise to understand and mitigate software license risks. If an entity develops software and licenses that software to others, management should be aware of the liabilities that come with licensing activities, including considerations related to software maintenance, integration, compatibility, and fraud. Tracking and managing the usage and implementation of different types of licenses for which an entity paid helps ensure that the entity is operating within the licenses’ specific requirements. There are several types of software licenses, including free and open-source software licenses and proprietary licenses. 

& 

#### IV.C.1(a) Free and Open-Source Software Licenses 

There are two types of free and open-source software (FOSS) licenses: 

* • Public domain (and equivalent) license: Public domain software is software not protected by copyright laws of any nation that may be freely used without permission of or payment to the creator and that carries no creator warranties.37 This reduces creator liability relative to the software’s use. Software creators may renounce software ownership and any usage limitations to ensure that the software is able to be used by anyone regardless of jurisdiction license requirements and to limit their liability.38
* • Open-source license: Typically, open-source software used by entities has some type of attached license. Companies often license open-source software through a third party that makes software use and maintenance easier. Just as with proprietary software licenses, it is important to understand the license provisions such as who owns the software source code, and any restrictions on what can be done with the software. Examples of open-source software license subtypes are lesser general public licenses, permissive licenses, general public licenses, and copyleft licenses.39

FOSS is typically acquired and used in an as-is manner. An entity may not be aware of the developer(s) in public domain FOSS. There may or may not be updates made available for the software, and changes made to the software may be made by other individuals besides the developer. Risks associated with FOSS include the potential for unidentified or unpatched vulnerabilities and development changes by unknown parties. An accurate inventory of FOSS should be maintained as part of an effective ITAM process, and management should understand and abide by the requirements of FOSS licenses. Additionally, some licenses require users to contribute software additions or enhancements, or they may prohibit the use for commercial purpose or profit. Management should be aware of what information is shared when contributing an enhancement to the FOSS development community. 

#### IV.C.1(b) Proprietary Software Licenses 

In proprietary software licenses, the software publisher retains software ownership, and the entity and end users agree to accept and abide by the terms of the software licenses. A licensee and its employees may only use the software as allowed by the license and typically cannot copy, modify, or distribute the software and its underlying code. An end user license agreement (EULA) provides specifics regarding provisions or restrictions. EULAs typically apply to for- profit open-source software and non-open-source software, and they are often used for commercial purposes. Some examples of proprietary licenses include noncommercial use-only licenses, proprietary licenses, and trade secret licenses. Regardless of the types of licenses encountered, they often cover the following: 

37 Refer to NIST Glossary. 

38 For more information, refer to public-domain equivalent licenses, such as Creative Commons’ CC0. 

39 Copyleft is a general licensing method for making a program free while requiring all modified and extended versions of the program to be free as well. There are strong and weak copyleft licenses. Refer to Department of Defense (DOD), DoD Open Source Software FAQ. 

* • Ownership rights of the software.
* • Permission to use the software and usage rights.
* • Number of users allowed to use the software.
* • Inclusions or add-ons (e.g., support, maintenance, and software upgrades).
* • Warranty terms.
* • Installation location and frequency.
* • Permissions and limitations regarding copying, modifying, and distributing software and the
* • Copyrights.
* • Terms for license termination.
* • Software performance guarantees.
* • Penalties and fees for noncompliance.
* • Length of the agreement and its terms. underlying code.

For more information on ITAM, which includes management of software licenses, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

#### IV.C.2 Hardware Licenses 

Entities identify and manage hardware licenses in ITAM programs to ensure that their hardware use is consistent with agreements between the manufacturer, any third party, and the entity. Entities may access components (e.g., circuit boards, servers, switches, tokens, universal serial buses, mobile devices, service ports, and cameras) in solution development. Hardware licenses, like software licenses, should identify any limitations on hardware use. 

If an entity licenses COTS hardware, the hardware may come as is and any alterations or modifications may void the warranty in the license. If the hardware is proprietary, items such as warranties, modifications, and maintenance should be included in the license agreement. If an entity builds hardware and then licenses that hardware to other entities, effective management maintains awareness of the liabilities that come with licensing activities, including considerations related to hardware maintenance, integration, compatibility, and fraud. 

For more information on ITAM, which includes management of hardware and software licenses, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

#### IV.C.3 Copyright Protection 

Copyright laws40 protect proprietary as well as open-source software. Examples of elements covered by copyright protections generally include the following: 

40 Refer to U.S. Copyright Office, Copyright Law of the United States (Title 17). 

* • Reproduction:
* • Adaptation:
* • Publication:
* • Performance:
* • Display: The copyright owner maintains rights in any reproduction of the original work. 

The copyright owner has rights to adaptations based on the original work. 

The copyright owner has the right to distribute the work to the public. 

The copyright owner has the right to perform the work publicly. 

The copyright owner has the right to display the work publicly.

Unlicensed system or component use or licensing agreement violations expose entities to litigation. Common challenges in deploying software, consistent with licenses and copyrights, include keeping track of deployed instances when the entity is large and decentralized, keeping track of deployed instances when deployments are made to virtual environments and are not automatically tracked, instances being shared when the license does not provide for sharing, and license limits on concurrent system or component use. 

Measures that management may employ to protect against copyright violations include obtaining a site license that authorizes system or component use at all of the entity’s locations, informing users of the rules governing site licenses, and acquiring an automated program that scans for unauthorized system or component use or copyright violations. While these measures may help identify copyright violations, the best control mechanism is a well-communicated corporate policy that management enforces and auditors validate for compliance. 

### IV.D Secure Development 

Secure development is an approach to creating products and services that incorporates security into every phase of the product’s or service’s development and use. Secure software development includes practices “to reduce the number of vulnerabilities in released software, to reduce the potential impact of the exploitation of undetected or unaddressed vulnerabilities, and to address the root causes of vulnerabilities to prevent recurrences.”41 While this booklet primarily focuses on the secure development of software, there are also techniques for securely developing hardware.42 System, component, and service development, acquisition, and maintenance inherently presents security risks. This is true whether the system, component, or service is developed internally or acquired. 

When management outsources development to third parties, it should monitor the third parties’ conformance to contract requirements, Information Security Standards,43 and other legal and regulatory requirements. A third party providing development services should maintain policies, standards, and procedures that promote secure development consistent with the entity’s requirements and the board’s risk appetite. When acquiring systems and components, management should evaluate the third party’s secure coding standards (e.g., through independent certification or audit) and consider related supply chain risks.44 It is also important that third- party system or component developers use secure coding standards, that its use is independently verified, and that management reviews the verification. This is important to verify when products are initially purchased and to review periodically as products are updated and patched. Furthermore, system maintenance should consider security impacts of integration with legacy systems and components. For more information, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services” and “Information Security” booklets. 

41 Refer to NIST SP 800-218, Secure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software Vulnerabilities. 

42 For more information on mitigation of hardware development risks, refer to DOD’s Securing Defense-Critical Supply Chains. 

43 Refer to 15 USC 6801 and 6805(b), GLBA, further implemented by FFIEC members as follows: FDIC: 12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards,” and 12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice”; FRB: Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards,” and Regulation Y, 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards”; NCUA: 12 CFR 748, appendix A, “Guidelines for Safeguarding 

General software quality management practices contribute to secure systems and components. For example, when thorough testing results in functional flaws being corrected, security vulnerabilities can also be identified and corrected. There are quality assurance tests that can specifically identify security flaws such as fuzz testing45 and penetration testing. There are also quality management tools such as secure code reviews and source code security analyzers46 that can systematically and efficiently identify security vulnerabilities and other flaws for remediation. Entities that use these practices and tools are more likely to produce secure systems and components than those that do not. 

Manual or automated code reviews help identify vulnerabilities. Manual code reviews47 are performed by entity personnel or a third party and may be less costly than an automated code review.48 However, limitations on reviewers’ knowledge or experience may result in unidentified issues, such as syntax errors and code vulnerabilities due to human error. Additionally, manual reviews may not be effective for extensive volumes of testing. Automated code reviews, on the other hand, may be more sophisticated, can reduce human error, and generally provide more timely identification of weaknesses. These tools are scalable and can be continuously updated as technology and vulnerabilities evolve. Entities review software code that has been implemented to mitigate the risk that vulnerabilities may be introduced through routine updates and patches. If 

Member Information”; and OCC: 12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards.” 

44 For more information on supply chain risks affecting development, refer to the “Development” and “Supply Chain Considerations” sections of this booklet. 

45 Fuzz testing refers to a black box software testing technique, which basically consists of finding implementation bugs using malformed or semi-malformed data injection in an automated fashion by tools referred to as “fuzzers,” which are programs or scripts that submit some combination of inputs to the test target to reveal how it responds. For more information, refer to OWASP’s Fuzzing. 

46 According to NIST, “Source code security analyzers examine source code to detect and report weaknesses that can lead to security vulnerabilities.” 

47 Manual code review is the process of personnel reviewing the source code line by line to identify possible vulnerabilities. 

48 Refer to NIST Internal Report (IR) 8397, Guidelines on Minimum Standards for Developer Verification of Software. 

& 

an automated code review process is implemented, management should ensure that the embedded rules of the code review tools are appropriately configured and used. Management selects code review types that are effective for the entity’s project and available resources, and management validates that the code review process meets its needs. 

System vulnerability scanning is another tool for mitigating security risks during development.49 Scanning software is implemented in development environments so that vulnerabilities are identified and remediated before they are exposed to users and exploited by malicious actors. Requirements for system vulnerability scanning can be included in contracts and ancillary agreements if the underlying system is critical enough. Entities also continue to scan systems for vulnerabilities once systems are deployed and being maintained to mitigate the risk that vulnerabilities are introduced as the system is upgraded. Refer to FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets. 

### IV.E Data 

Mitigating the risk of data compromise is important in addition to controlling software and system development. To mitigate the risk of data compromise, entity personnel establish and maintain data inventories that include data characteristics such as storage location, criticality, and sensitivity. They also implement and maintain controls that protect the data consistent with their characteristics. For example, an entity may implement a policy that highly sensitive data will not be used in development and test environments. Instead, an entity may create synthetic data to use in development and testing that is a proxy for the actual, highly sensitive data. Another control example is documenting system data use so that security engineers can implement controls that protect data throughout process execution.50 For more information, refer to the FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets. 

### IV.F Secure Operating Environments 

Management should maintain a secure operating environment throughout development, acquisition, and maintenance activities whether entity employees are operating the system or a third party’s employees are operating the system. Entities use various controls to secure operating environments, such as configuration management, access control, and business continuity planning and testing. Effective application of formal policies addressing the least privilege principle help control access to systems, components, and data. An effective entity establishes documented policies to communicate and implement operating environment controls and provides for periodic audits for validation of the controls to determine whether systems and components are functioning as intended. Additional operating environment control examples are listed below: 

49 Like network port and service identification, vulnerability scanning identifies hosts and host attributes (e.g., operating systems, applications, or open ports), but it also attempts to identify vulnerabilities rather than relying on human interpretation of the scanning results. Refer to NIST SP 800-115, Technical Guide to Information Security Testing and Assessment. 

50 NIST states in SP 800-37, rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy, that “such documentation includes, for example, data flow diagrams, entity relationship diagrams, database schemas, and data dictionaries.” 

* • Identifying personnel allowed to access development, test, and production environments.
* • Determining under which conditions they may access systems, components, and data within
* • Maintaining authorization procedures for granting and verifying access.
* • Determining how long users require access.
* • Segregating operating environments (e.g., development, test, QA, and production) and production environments. specifying access controls for each operating environment, while accounting for new business functions.
* • Ensuring resilience when developing, acquiring, or maintaining systems, components,
* • Maintaining control over remote access (e.g., timing, location, personnel, and multifactor
* • Providing appropriate controls over access to and by specific devices.
* • Maintaining business line and IT representation when determining security and resilience services, and data. authentication [MFA]). measures.
* • Maintaining ITAM processes for current and planned assets.

For more information, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations,” “Outsourcing Technology Services,” and “Information Security” booklets. 

### IV.G Microservices 

Microservices refers to an architectural and organizational approach to building systems that involves much smaller components than historical approaches and requires attention to mitigate risks that could be material. NIST defines “microservices” as “a set of containers that work together to compose an application.” This includes a series of interconnected containers or applications working in coordination (referred to as “orchestration”). Microservices-based architectures and applications are prevalent in cloud-based systems but can also be run in non- cloud-based virtualized environments. 

Traditionally developed, or monolithic,51 applications comprise multiple lines of code developed as a single application. To work properly, these applications reside on a single server or virtual machine. Any updates rely on an update to the entire application. By contrast, microservices- based applications consist of small, self-contained (i.e., containers), independent services that use APIs to communicate and work together. Each microservice has a singular purpose (e.g., messaging, calculations, or database access). Microservices are generally technologically heterogeneous and can be written in different languages, use different development platforms, and be spread across multiple servers or virtual machines. Because microservices architecture has independent containers working together to create an application, updates can be applied to any one independent container without having to update the entire application. Additionally, each microservice can be reused to create new applications. These properties of microservices facilitate scalability and a faster, more agile application development process. 

51 A monolithic application (or monolith) refers to a single unit, as opposed to a microservice architecture, which comprises smaller, independently deployable services. 

During acquisition or development of systems using microservices, effective control practices are used to mitigate the risk of systems malfunctioning and risk of security incidents. An example of an effective control is deploying and using highly secure and stable service registries for tracking the services included in a system. A microservice has two broad functions:52 

* • Business logic, which implements the business functionalities, computations, and service composition or integration logic.
* • Network processes, which manage the interservice communication mechanisms and are built on top of the underlying OS-level network stack. 

NIST provides four drivers underlying the design principles of microservices:53
* • Each microservice must be managed, replicated, scaled, upgraded, and deployed independently of other microservices.
* •
* • Each microservice must have a single function and operate in a bounded context (i.e., have limited responsibility and dependence on other services).
* • All microservices should be designed for constant failure and recovery, and therefore must be as stateless54 as possible. 

One should reuse existing trusted services (e.g., databases, caches, and directories) for state management.

Additionally, NIST provides a list of the following design principles for microservices: 

* •
* •
* •
* •
* •
* •
* •

#### Autonomy: 

Ability to operate independently as a self-contained entity that delivers all of the functions of an operations stack. 

Loose coupling: Minimal dependency between services so the change in one service does not require a change in another service. 

#### Reusability: 

Use of a service in different ways for different purposes. 

#### Composability: 

Ability to be assembled easily and configured to meet specific needs. 

Fault tolerance: Property of a system that allows proper operation even if components fail. 

#### Discoverability: 

Ability to be located and identified using discovery services. 

Alignment of APIs with business processes: Aligning microservices, APIs, and business processes during the design phase allows for easier changes to the services when business processes change. 

52 Refer to NIST SP 800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture. 

53 

54 

Refer to NIST Glossary. 

Refer to NIST SP 800-204, Security Strategies for Microservices-Based Application Systems. 

Because microservices can be replicated or deployed across servers, a microservice architecture generally has a directory for microservices to publish their locations, also referred to as a service registry. NIST provides the following strategies for service registry configuration:55 

* • Service registry capabilities should be provided through servers that are either dedicated or part of a service mesh56 architecture.
* • Service registry services should be in a network that has been configured with certain quality of service parameters to ensure its availability and resilience.
* • Communication between an application service and a service registry should occur through a secure communication protocol (e.g., hypertext transfer protocol secure or transport layer security).57
* • Service registries should be validated to ensure that only legitimate services perform the registration, refresh operations, and query the database to discover services.
* • Service registration and service deregistration functions should follow the principles of bounded context and loose coupling. Management should set parameters for the processes of registration to and deregistration from the service registry.58 only take place after the performance of a health check60 on the application service.
* • If a third-party registration pattern59 is implemented, registration and deregistration should
* • A distributed service registry should be deployed for large microservices applications, and data consistency should be maintained among multiple service registry instances.61 55 Ibid. 

56 NIST SP 800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture, defines “service mesh” as “a distributed computing middleware that optimizes communications between application services.” 

57 NIST defines “transport layer security” as “an authentication and security protocol widely implemented in browsers and web servers.” For more information, refer to NIST SP 800-63-3, Digital Identity Guidelines. 

58 As noted in NIST SP 800-204, Security Strategies for Microservices-Based Application Systems, the application service should not have tight coupling with an infrastructure service, such as a service registry service, and service self-registration and deregistration patterns should be avoided. When an application service crashes or is running but unable to handle requests, its inability to perform deregistration affects the integrity of the whole process. Therefore, registration and deregistration of an application service should be enabled using a third-party registration pattern, and the application service should be restricted to querying the service registry for service location information as described under the client-side discovery pattern. 

59 For purposes of this discussion, a pattern refers to repeatable processes to assist in the standardized design, monitoring, and maintenance of microservices. 

60 A health check or health testing is testing in an implementation immediately before or during normal operation to determine that the implementation continues to perform as implemented and as validated. Refer to Law Insider’s Dictionary. 

61 Refer to NIST SP 800-204, Security Strategies for Microservices-Based Application Systems, for more information on distributed service registry, which involves several service registry agents cooperating to provide controlled access to resources. Distribution of the registry agents results in improved availability, higher concurrency, better response times to user queries, and enhanced flexibility.

Microservices are exposed to similar threats as web-based applications (e.g., cross-site scripting or injection attacks). Controls to prevent or mitigate these attacks should be included in the microservices code.62 Microservices can have security, reliability, and latency issues. Having multiple microservices can increase the entity’s attack surface. Effective management evaluates implementation options that meet the entity’s security requirements. Management of microservices-based architectures should include monitoring services, which may be running on different servers or written in different languages. Management should consider the following monitoring controls: 

* •
* • Monitoring at the gateway and service level. 

Implementing a centralized dashboard to display the status of multiple services and network segments. the baseline.
* • Creating a baseline and implementing intrusion detection to provide alerts on deviations from 

To preserve resilience when developing and using microservices, NIST recommends the following control examples:63
* • Load balancing by having multiple instances of the same service and evenly distributing the load of those instances.
* • Implementing circuit breaking by setting a threshold for failed responses from a microservice. When the threshold is exceeded (i.e., the circuit breaker is tripped), requests should not be forwarded to that microservice. The goal is to prevent cascading failures and allow time to investigate and address the issue. 

Throttling or limiting the rate of requests to a microservice. 

Redirecting requests to new versions of the microservice.64
* •
* •
* • Limiting traffic to new versions of a microservice until management can validate the correctness of a response and understand the performance.65

For more information on the development and use of microservices, refer to the “Development” section of this booklet. 

62 

For more information on specific controls, refer to “OWASP API Security Project.” 

63 Refer to NIST SP 800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture. 

64 This is referred to as blue/green deployments. When a new version of a microservice is deployed, requests from customers using the old version can be redirected to the new version using the API gateway that can be programmed to maintain awareness of the locations of both versions. For more information, refer to NIST SP800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture. 

65 This process is referred to as “canary releases,” in which only a limited amount of traffic is initially sent to a new version of a microservice because the correctness of its response or performance metric under all operating scenarios is not fully known. Once sufficient data are gathered about its operating characteristics, the requests can be proxied to the new version of the microservice. For more information, refer to NIST SP 800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture. 

& 

### IV.H Containers 

A container is a method for packaging and securely running an application in a virtualized environment. Containers enable applications to be portable, reusable, and automatable in terms of their creation, use, and destruction. Containers provide software developers the ability to segment applications in separate environments to support well-defined functionality. This allows the entity to coordinate the development, testing, implementation, and operation of applications in a more consistent, precise, and efficient manner. Containers enable virtualized segmentation, which allows for increased security and transparency but may require additional configuration to support effective integration. In addition to the use of containers in the production environment, it is beneficial to leverage containers in the development and test environments, which helps to promote consistency. 

Figure 1 depicts the following five foundational architectural tiers and components and the three life cycle phases for container development and technology architecture.66 The foundational architectural tiers and components are as follows: 

* • Developer systems, in the image creation, testing, and accreditation phase, generate container images and send them for testing and accreditation.
* • Testing and accreditation systems, in the image creation, testing, and accreditation phase,
* • Orchestrators facilitate the conversion of container images into containers during the image
* • Hosts run and stop containers as directed by the orchestrator in the container deployment and validate and verify the contents of container images, sign container images, and send container images to the registry.
* • Registries (internal and external), in the image storage and retrieval phase, store images and distribute container images to the orchestrator on request. storage and retrieval phase and deploy containers to hosts in the container deployment and management phase. management phase.

The three phases noted in figure 1 are (1) image creation, testing, and accreditation; (2) image storage and retrieval; and (3) container deployment and management for container development and technology architecture. 

66 For more information, refer to NIST SP 800-190, Application Container Security Guide. 

& 

Figure 1: Container Technology Architecture Tiers and Components and Life Cycle Phases 

DEVELOPER 

#### SYSTEMS 

TESTING AND ACCREDITATION 

#### SYSTEMS 

REGISTRIES 

ORCHESTRATORS 

#### HOSTS 

&- 

&- 

Admin 

Admin 

Testing and 

Accreditation 

Internal 

Registry 

External 

Registry 

Orchestrator 

Host With Containers 

Host With 

Containers 

Host With 

Containers 

Host With Containers 

IMAGE CREATION, TESTING, 

AND ACCREDITATION PHASE 

#### IMAGE STORAGE 

AND RETRIEVAL PHASE 

#### CONTAINER 

#### DEPLOYMENT AND 

MANAGEMENT PHASE 

When setting up containers, it is important to consider data isolation. Data may be stored separately from configuration information and software (i.e., as separate building blocks). When data and configuration information are stored separately from the containerized software, the software, data, or configuration information can be created, used, and destroyed without consequence to the other building blocks in the container. Management may use persistent storage67 for ongoing access to containerized applications, data, and configuration information. The aspects of isolation and persistent storage allow for new versions of containers to be created and used efficiently, without losing previously used data. When a new version of the software or containerized image is executed or initialized, connections to the persistent storage need to be restored along with any authorization and access rights considerations. 

Container images are typically designed to be portable across machines and environments so that an image created in a development lab can be easily moved to a test lab for evaluation, then copied into a production environment to run without needing to make any modifications.68 This deployment process (i.e., copying the image into production) results in a version of the application that is running and available to respond to requests. According to NIST, “When an image is deployed into a container, the image itself is not changed, but instead a copy of it is 

67 Merriam-Webster defines “persistent” as “continuing without change in function or structure.” For purposes of this discussion regarding storage in containers, “persistent storage” refers to the long-term access to application information beyond the container’s lifetime. 

68 Refer to NIST SP 800-190, Application Container Security Guide. 

& 

placed in the container and transitioned from being a dormant set of [application] code to a running instance of the [application].”69 

The use of containers is not without risks; therefore, during container development, management should consider the risks and countermeasures provided in NIST 800-190,70 such as those in table 1. 

Table 1: Container Risks and Countermeasures 



| Risks | Countermeasures |
| --- | --- |
| Image risks |  |
| Image vulnerabilities71 | Consider containers and images when selecting or using vulnerability management tools. |
| Image configuration defects | Adopt tools and processes to validate and enforce compliance with secure configuration best practices, such as implementing privileged user controls and validation of image configuration settings.72 |
| Embedded malware | Monitor images for embedded malware by monitoring for malware signature sets and detecting behavioral patterns and anomalies. |
| Clear text secrets73 | Use orchestrators and APIs to manage security of access to and provision of secrets to specific containers that require them based on predefined settings. |
| Untrusted images | Maintain a set of trusted images and registries. Only use images from this set to run in the environment, thus mitigating the risk of untrusted or malicious components being deployed. Consider processes to ensure that images and registries are secure, trusted, and periodically validated and that the hosts they reside on are from these approved lists.74 |
| Registry risks |  |
| Insecure connections to registries | Configure development tools, orchestrators, and container runtimes to connect only to registries over encrypted channels. The goal is to ensure that all data pushed to and pulled from a registry occur between trusted end points and are encrypted in transit. |
| Stale images in registries | Reduce registries to minimize unsafe and vulnerable images that should no longer be used. Access images using unchanging names that specify discrete versions of images to be used to ensure that specific and uncorrupted images are deployed as part of each job.75 |

69 

Ibid. 

70 

Ibid. 

71 

72 

73 

Container image vulnerabilities may not be detected by traditional vulnerability management tools. 

For more information, refer to NIST SP 800-190, Application Container Security Guide. 

Many apps require secrets to enable secure communication between components. The risk is that if someone steals the image, that person can learn the secrets, such as username and password, to connect to a backend database, connection strings, and private keys. Refer to NIST SP 800-190, Application Container Security Guide. 

74 

75 

For more information, refer to NIST SP 800-190, Application Container Security Guide. 

Another option is using a “latest” tag for images and referencing this tag in deployment automation, but this may not always be effective. Regardless of whether an organization chooses to use discrete names or to use a “latest” tag, it is critical that processes exist to ensure that the most recent unique name or the images tagged “latest” represent 

& 



| Risks | Countermeasures |
| --- | --- |
| Insufficient authentication and authorization restrictions | Any access to registries that contain proprietary or sensitive images should involve authentication. Gaining write-access privileges to a registry should entail appropriate authentication to ensure that only images from trusted entities can be added to the registry. Audit all write-access privileges to registries and log any read actions for sensitive images.76 |
| Orchestrator Risks |  |
| Access considerations, such as unbounded administrator access77 | Orchestrators should use a least-privilege access model in which users are only granted the ability to perform the specific actions on the specific hosts, containers, and images that their job roles require. Test team members should have limited or no access to containers used in production.78 |
| Unauthorized access | Tightly control access to cluster-wide administrative accounts, as these accounts provide the ability to affect all resources in the environment. Use appropriate authentication methods (e.g., MFA and single sign-on when applicable). Use tools for encrypting data used with containers that allow the data to be accessed properly from containers regardless of the node on which they are running.79 |
| Orchestrator node trust80 | Configure orchestration platforms to provide features that create a secure environment for all the applications they run. Maintaining a secure-by-default posture is particularly important with third-party deployments of the entity’s containers. Orchestrators should be able to perform the following: introduce nodes securely to the cluster,81 maintain a persistent identity for the nodes throughout their life cycle, and maintain an accurate inventory of nodes and their connectivity states. Orchestration platforms should be resilient (i.e., a compromise of one node should not compromise the overall security of the cluster).82 |
| Poorly separated inter- container network traffic83 | Configure orchestrators to separate network traffic into discrete (e.g., internal versus external applications) virtual networks by sensitivity level, and |

the most up-to-date versions. For more information, refer to NIST SP 800-190, Application Container Security Guide. 

76 For more information, refer to NIST SP 800-190, Application Container Security Guide. 

77 A single orchestrator having administrator access. Access should be limited according to need. For example, applications may be managed by different teams with differing sensitivity levels. As many orchestrators were designed with the assumption that user interaction would be with administrators, there is the potential for unauthorized access; therefore, authorization and access concerns are relevant. Refer to NIST SP 800-190, Application Container Security Guide. 

78 For more information, refer to NIST SP 800-190, Application Container Security Guide. 

79 For more information, refer to NIST SP 800-190, Application Container Security Guide, and the FFIEC IT 

80 The orchestrator is the most foundational node. Weak orchestrator configurations can expose the orchestrator and Handbook’s “Information Security” booklet. other container technology components to increased risk. Refer to SP NIST 800-190, Application Container Security Guide. 

81 An example of a cluster is a set of nodes that run containerized. 

82 A compromised node should have the ability to be isolated and removed from the cluster without disrupting or degrading overall cluster operations. For more information, refer to NIST SP 800-190, Application Container Security Guide. 

83 If a virtual overlay network is used to manage container traffic, security and management tools may not have clear visibility into the traffic. If traffic has varying sensitivity levels on the same network, more sensitive data may be susceptible to attack due to expanded access to the network users with lesser privileges. For example, if the public- 

& 



| Risks | Countermeasures |
| --- | --- |
|  | communication between the two should occur through a small number of well- defined interfaces.84 |
| Mixing of workload sensitivity levels on the same host85 | Configure orchestrators to isolate deployments to specific sets of hosts by sensitivity levels. Implement rules that prevent high-sensitivity workloads from being placed on the same host as those running lower-sensitivity workloads. Segmenting containers by purpose, sensitivity, and threat posture provides additional defense-in-depth.86 |
| Container Risks |  |
| General container runtime- related risks87 | Use tools or processes that continuously assess configuration settings across the environment and actively enforce them. Use segmentation to provide control and isolation over containers to minimize unauthorized access and loss of data. Run containers with the default secure computing profiles88 provided by their runtime. Consider using additional profiles for higher risk applications. Use tools to identify vulnerabilities in the container runtimes deployed to upgrade any instances at risk and to ensure that orchestrators only allow deployments to properly maintained container runtimes. |
| Unbounded network access from containers89 | Employ a combination of network monitoring and filtering tools (e.g., application- aware tools)90 to mitigate the risk from inter-container traffic across networks of differing sensitivity levels. |

facing website is compromised, attackers may be able to use shared networks to attack an internal app using sensitive information. Refer to NIST SP 800-190, Application Container Security Guide. 

84 For more information, refer to NIST SP 800-190, Application Container Security Guide. 

85 An orchestrator may place a container running a public-facing web server on the same host as one processing sensitive data, because that host happens to have available resources at the time of deployment, as the orchestrator manages scale and density of traffic. In the case of a critical vulnerability in the web server, a container processing sensitive data may be at greater risk of compromise due to the greater access to the host of the container. Refer to NIST SP 800-190, Application Container Security Guide. 

86 Concepts such as application tiering and network and host segmentation should be taken into consideration when planning app deployments. By segmenting containers in this manner, it is much more difficult for an attacker who compromises one of the segments to expand that compromise to other segments. In larger-scale environments with hundreds of hosts and thousands of containers, this segmentation is automated to be practical. Common orchestration tools can help management in the segmentation process. For more information, refer to NIST SP 800- 190, Application Container Security Guide. 

87 Container runtimes include such risks as (1) insecure container runtime configurations and (2) capability for containers running in privileged mode to access host configurations, potentially compromising the host and all other containers on it. 

88 Secure computing profiles can be used to limit the system-level capabilities allocated to containers at runtime. For more information, refer to NIST SP 800-190, Application Container Security Guide. 

89 By default, in most container runtimes, individual containers can access each other and the host OS over the network. If a container is compromised and acting maliciously, allowing this network traffic may expose other resources in the environment to risk. Tools and operational processes that are not container-aware are not able to inspect this traffic or determine whether it represents a threat. Refer to NIST SP 800-190, Application Container Security Guide. 

90 Application-aware tools provide the ability of a system to recognize and classify applications passing through it. These tools allow systems to make decisions based on an application, its features, and the content it’s carrying. These tools should be able to not just see the inter-container traffic but also dynamically generate the rules used to 

& 



| Risks | Countermeasures |
| --- | --- |
| Rogue containers91 | Maintain separate environments for development, test, and production with specific controls (e.g., role-based access control) for container deployment to mitigate the potential for rogue containers. There should be a clear audit trail process during container development to give management information that associates any container build or modification to specific users. |
| Application vulnerabilities, such as risks inherent in the general use of applications | Implement additional container-aware tools92 using behavioral learning (i.e., heuristics) and appropriate security profiles to detect anomalies and events, such as writing to unexpected locations and file types, sending traffic to unexpected network destinations, and storing or executing malware. Additionally, containers should be run with their root file systems in read-only mode to monitor for compromise, to isolate tampering to these specific locations, and separate them |
| Host OS Risks |  |
| Large attack surface93 | Minimize unnecessary functionality by using OSs designed to host only containers and have other services and functionality disabled to reduce the attack surface. Additionally, host OSs should have read-only file systems and have hardening practices implemented by default. Regularly scan and update the container runtime and lower-level components (e.g., kernel) in a timely manner. |
| Shared kernel94 | Use separate, dedicated hosts for containerized and noncontainerized workloads. Isolating the workloads enables the application of appropriate safeguards to containers and avoids affecting noncontainerized workloads. |
| Improper user access rights, such as allowing users to log on directly95 to hosts to manage containers | Employ least privilege access. Audit all authentication to the OS, monitor all login anomalies, and log any privileged user activities to identify anomalous (and potentially unauthorized) access patterns. |


from the rest of the application. 

filter this traffic based on the specific characteristics of the apps running in the containers. For more information, refer to NIST SP 800-190, Application Container Security Guide. 

91 Rogue containers are unplanned or unsanctioned containers in an environment. They may be used in development builds or test images and may pose additional risk to the organization, especially when they persist in the environment without the awareness of development teams and security administrators. Refer to NIST SP 800-190, Application Container Security Guide. 

92 Container-aware tools provide the ability to monitor the container environment and provide precise detection of anomalous and malicious activity within it. For more information, refer to NIST SP 800-190, Application Container Security Guide. 

93 The larger the attack surface is, the better the odds are that an attacker can find and access a vulnerability, leading to a compromise of the host OS and the containers running on top of it. Refer to NIST SP 800-190, Application Container Security Guide. 

94 The use of a shared kernel results in a larger attack surface as the level of isolation provided by container runtimes is not as high as that provided by hypervisors. Runtime container security means vetting all activities in the container application environment, from analysis of container and host activity to monitoring the protocols and payloads of network connections. Refer to NIST SP 800-190, Application Container Security Guide. 

95 When users log on directly to the host with elevated privileges to manage specific containers, there is the possibility of accessing and affecting other containers on that host. Refer to NIST SP 800-190, Application Container Security Guide. 

& 



| Risks | Countermeasures |
| --- | --- |
| Host OS component vulnerabilities96 | Use appropriate tools provided either by the OS vendor or other trusted organizations to regularly check for and apply updates to all software components used in the OS to mitigate potential vulnerabilities. This is particularly important for the kernel and container runtime components as newer releases of these components often add additional security protections and capabilities beyond simply correcting vulnerabilities. Deploy application components and their dependencies97 in a container to identify or prevent anomalies and configuration changes, promote resilience, and allow management to reduce its attack surface, prevent persistent storage of data on the host, promote statelessness98 on the |
| Host OS file system tampering99 | Run containers with the minimal set of file system permissions required. NIST recommends that containers should not be able to make sensitive directories available on a host’s file system, especially those directories containing configuration settings for the OS. Monitor what directories are placed, made available, and accessed on the file system. |

host, and reduce application-level host dependencies. 

### IV.I Application Programming Interfaces 

An API is software code that allows two or more different programs to communicate with each other. APIs are an important part of various applications, including web, mobile, and software- as-a-service (SaaS) applications. APIs often link microservices and may be public, private, or a collaboration between customers, partners, and unaffiliated third parties to share information and allow their software to function together. Another function of APIs is to facilitate communication between containers. For more information on APIs and how they fit with other elements of an entity’s IT environment, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

When developing, acquiring, and maintaining APIs and related services, there are several considerations.100 Examples include the following: 

* • Aligning the API with business processes, particularly when designing a microservice.
* • Iterating the interface definition with developers before the service is used so that the • Inappropriate access controls. 96 All host Oss, even container-specific ones, provide foundational system elements, such as access and resulting API serves as a contract between clients and services. authentication. As a foundational element in container technology, host OS vulnerabilities can affect everything running on the host, including containers and apps. Refer to NIST SP 800-190, Application Container Security Guide. 

97 In IT infrastructure, dependencies are relationships of reliance in and among infrastructure assets and systems that must be maintained for those systems to operate and provide services. For more information, refer to CISA’s “Infrastructure Dependency Primer.” 

98 According to NIST Glossary, statelessness or quality of being “stateless” refers to “a data representation or a process that is self-contained and does not depend on any external data store.” 

99 A change to a sensitive system file on the host OS could affect the stability and security of the host and all other containers running on it. Refer to NIST SP 800-190, Application Container Security Guide. 

100 For more information on developing, acquiring, and maintaining APIs, refer to NIST SP 800-204, Security Strategies for Microservices-Based Application Systems.
* • Inadequate user authentication.
* • Excessive data exposure.
* • Lack of resources for processing access requests, including rate limiting problems.
* • Allowing modification of object properties.102
* • Misconfigured security.
* • Injection flaws.
* • Lack of appropriate ITAM and documentation leading to maintenance weaknesses and
* • Lack of appropriate logging and monitoring.
* • Lack of integration with the entity’s incident response program.
* • Determining and implementing appropriate security related to APIs.101

Risks related to APIs include the following: exposed end points. 

#### IV.I.1 API Gateway 

Understanding how APIs can act as a gateway to microservices is important. Unlike a legacy application where the endpoint may be only a single server, a microservices-based application consists of multiple endpoints. Therefore, a single-entry point (i.e., gateway) for all clients to access multiple component microservices of the application would allow for improved access. Another situation in which an API gateway may be deployed is as a front-end-to-backend103 connector, as in the case of legacy enterprise software. This occurs when an entity migrates from a legacy enterprise application by gradually replacing its components with independent microservices over time. Direct communication between clients and multiple end points often results in excessive point-to-point connections; therefore, the API gateway’s primary function is to route inbound requests to the correct downstream services to minimize the number of connections. All client requests first go through the API gateway, which then routes requests to the appropriate microservice. The API gateway often handles a request by invoking multiple microservices and aggregating the results. In some instances, the API gateway may be used as part of a back end for front-end services, which enables support for clients with different communication vectors (e.g., browser or mobile device), and then requests are divided into multiple gateways. Many API gateway use cases can support APIs written in different languages.104 

101 For more information on API security, refer to the FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets. “OWASP API Security Project” also discusses API security issues and controls. 

102 Object properties provide a simple association between name and value. All properties have a name, and value is one of the attributes linked with the property, which defines the access granted to the property. 

103 The front end of a system involves the parts that users see and interact with, whereas the system’s back end includes the logic, data, and structure. 

104 Examples of different languages include Java, JavaScript, and Jolie. 

Because the API gateway is the entry point for microservices, management should configure it with the necessary infrastructure services.105 In addition to its main service of handling requests, an API gateway also helps with the following infrastructure services: 

* •
* •
* •
* •
* •
* •
* •
* •
* •
* •
* •

Service discovery. 

Authentication and access control. 

Load balancing. 

Caching. 

Providing custom APIs for each type of client. 

Performing application-aware health checks. 

Service monitoring. 

Attack detection. 

Attack response. 

Security logging and monitoring. 

Circuit breaking. 

These additional infrastructure services can be created or implemented in the code that uses the API gateway. Figure 2 provides a simple illustration of the API gateway location during a request. It shows that the API gateway routes requests from various sources (e.g., laptops, mobile devices, and users) to the various infrastructure services. 

Figure 2: Location and Interaction of API Gateway 

\ 

A 

/ API Gateway 

Infrastructure 

Service 

Infrastructure 

Service 

Infrastructure 

Service 

Infrastructure 

Service 

Microgateways are API gateways used to define and enforce customized policies for microservices-based applications. If used, they should be protected through service-specific security policies. Microgateways are usually implemented as containers and should contain policies for application requests and responses. When policies and their enforcement are implemented as a container, they are unchanging; therefore, they provide a degree of protection 

105 

Refer to NIST SP 800-204, Security Strategies for Microservices-Based Application Systems. 

against accidental and unintended modifications. Modifications could result in security breaches or conflicts. In other words, microgateways implemented as containers may help prevent breaches and conflicts because any security policy updates require the microgateway’s redeployment. It is essential that the microgateway deployed for a microservice instance communicate with service registry and monitoring modules, allowing them to keep track of the operational status of the microservice that the microgateway is designed to protect. 

When used with microservices, an API gateway or microgateway may serve to implement the following core features and functions: 

* • Optimized end point: The API gateway simplifies the process by providing aggregation, which results in fewer requests and responses. The API gateway can serve as a public interface for multiple individual APIs and their requests. Additionally, it performs the necessary protocol translation for client requests.
* • Circuit breaker: Developers can set a threshold in the API gateway for microservice failed responses to requests and cut off requests when the failure is above the threshold. This avoids the possibility of a cascaded failure and allows management time to analyze logs, implement necessary fixes, and push necessary updates to address the failing instance of the microservice.
* • Load balancing: When there are multiple instances of the same service, the load can be evenly distributed across the instances to avoid delayed responses or service crashes due to overload on any one instance.
* • Rate limiting (throttling): The rate of requests going into a microservice should be limited to ensure continued availability of service for all clients.
* • Blue/green deployments:106 When a new version of a microservice is deployed, requests from customers using the old version can be redirected to the new version because the API gateway can be programmed to be aware of the locations of both versions.
* • Canary releases: Only a limited amount of traffic is initially sent to a new version of a microservice to verify the accuracy of its response and performance. Once sufficient data demonstrate that the microservice is operating as designed, then the API gateway can direct the requests to the new version of the microservice.
#### IV.I.2 API Risk Mitigation 

Mitigation strategies for common API risks include the following:107 

* • Inappropriate access controls: API endpoints are vulnerable to unauthorized access as attackers can manipulate the specific object ID or other identifier that is sent with the request. Management should apply extra layers of security, such as for broken object-level authorization,108 beyond those for standard end-point security, and implement appropriate authorization checks at the object level. 106 This type of deployment provides an application release model when user traffic is progressively transferred from a prior version (i.e., old or blue) of an app or microservice to a nearly identical new (i.e., green) release. Both the blue and green versions are running in production at the same time. 

107 For more information, refer to “OWASP API Security Project.”
* • Inadequate user authentication: Authentication processes are not functioning correctly or are inappropriate for the way the API is used (e.g., designed for internet of things [IoT] versus a web application) or without considering potential vectors of attack. Management should validate the user authentication process for the use of the API and consider MFA.109
* • Security misconfiguration: Security settings may be missing or inappropriate for the current expected functionality of the API, giving an attacker the opportunity to gain unauthorized access or knowledge of the system. Attackers may use automated tools to detect and exploit these flaws, leading to data or device compromise. Management should implement appropriate security, patch and update APIs, and disable unnecessary functions.
* • Excessive data exposure: Developers try to implement APIs generically without addressing the sensitivity of the exposed data. Automated tools can have difficulty detecting this type of vulnerability because they cannot differentiate between legitimate data provided from the API and inappropriately provided sensitive data. This problem creates the potential for unauthorized data access. Developers should review the responses from the API to ensure that a request contains only legitimate data and to understand how the requestor will use the data. Developers should consider creating and implementing a scenario-based response process (including error codes) to validate that data returned by the APIs are appropriate for the scenario.
* • Lack of resources and data limiting: API requests consume resources such as network, central processing unit (CPU), memory, and storage. When APIs do not implement rate limiting or limits are not set properly, it may lead to an API being unresponsive or unavailable (i.e., denial of service). Management should appropriately set all API processing parameters (e.g., execution timeouts, maximum allocatable memory, number of file descriptors, number of processes, request size, number of requests per client or resource, and number of records per page to return in a single request response). If even one of the limits is missing or set inappropriately, an API may be vulnerable.
* • Broken function level authorization: Implementing proper authorization checks can be difficult because applications can contain many types of roles or groups and complex user hierarchy (e.g., subusers and users with more than one role). Because these checks are difficult to implement, what appears to be a legitimate API call or request may not be authorized, allowing unauthorized access to functionality, particularly administrative functions. Management should ensure that all access is denied by default and employ specific role-based permissions for users to gain access to functions. Appropriate personnel should review API end point security.
* • Mass assignment:110 Users can update multiple object properties without appropriate authorization. The design of APIs provides for easier exploitation of mass assignment because they expose the underlying implementation of the application along with the properties’ names. Management should deny access to properties unnecessary for the user’s role and only allow access when necessary. 108 Object-level authorization involves access-control tools applied at the code level to validate appropriate access to objects (e.g., fields such as names or values) by only authorized users. 

109 For more information, refer to FFIEC’s Authentication and Access to Financial Institution Services and Systems on multifactor authentication. 

110 The MITRE Corporation defines “mass assignment” as “a feature that allows simultaneous modification of multiple object attributes.”
* • Injection:
* • Improper asset management: Management may not properly maintain API and related Client and external system data may not be validated and filtered appropriately, allowing malicious data to be introduced into systems and components via the API. Injection can lead to information disclosure, data loss, denial of service, or complete host takeover. Management should validate and filter all data coming to an API with appropriate parameters. asset inventories or may not update and patch API security in a timely manner. This may either allow unauthorized access to sensitive data or compromise the server through older, unpatched API versions connected to the same database. Management should maintain current, accurate inventories of APIs and related assets, including services,111 and regularly review them. Management should maintain logging of API activity (e.g., authentication, errors, redirects, rate limiting, and end points, including their parameters, requests, and responses). Management should consider security measures, such as API security firewalls, segregation of production and nonproduction data, and timely removal of older API versions.
* • Insufficient logging and monitoring: Without sufficient, timely logging and monitoring, including API activity, it is difficult to identify patterns of potential malicious activity (e.g., threats and potential security weaknesses), which may lead to compromise of systems, components, and data. Management should perform continuous logging and monitoring of relevant API activity (e.g., failed authentication attempts, denied access, and input validation errors). Automated security information and event management tools with appropriately configured dashboards may help management monitor and manage API-related logging. To maintain confidentiality and integrity of sensitive data in activity logs, effective management secures logs and ensures only appropriate access to them.

With the volume and potential significance of API-related vulnerabilities, it is critical to incorporate planning for the exploitation of these vulnerabilities during API development and the entity’s incident response plan. Neglecting to do so can result in the compromise of confidentiality, integrity, availability, and resilience as well as inadequate or untimely response during an incident. For more information on security and other topics related to APIs, refer to the FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets. 

### IV.J Methodologies 

A methodology112 is used to facilitate the development, acquisition, or maintenance of a system or component project. Management should establish appropriate methodologies to enable effective management and control of system and component development, acquisition, and maintenance activities. Management can apply various methodologies, or a hybrid, to different projects based on stakeholder needs and project objectives. Methodologies can be a combination of strategies, design philosophies, and accepted practices designed as a structured, organized set of rules that allow a project team to work together effectively. If the entity employs multiple methodologies, the chosen methodology should be defined for each IT project. 

111 For more information, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

112 Merriam-Webster defines “methodology” as “a particular procedure or set of procedures.” 

Effective management aligns implementation of any methodology with the overall strategic and business objectives. Planning, education, and communication are important elements to help ensure that critical resources are available when needed for IT projects. Management should promote effective planning through IT project management and support training for developers, quality management members, testers, and maintenance personnel. Entity staff should be proficient and qualified in the selected methodologies. Common examples used in the financial industry include waterfall and agile; however, examiners may encounter others. 

#### IV.J.1 Waterfall 

The waterfall methodology was the first widely used model. It is considered a traditional model for development, acquisition, and maintenance projects. This methodology provides a logical, rigid approach to managing a sequential series of tasks or steps in which each phase is completed before the next phase of the project can begin. This methodology may be useful for stable, less complex projects with well-defined objectives and requirements that are not prone to change. A primary benefit of this methodology is its ease of use and implementation. Additionally, because of the sequential progression of the project, coding issues are identified earlier, and project status is more easily measured than in other methodologies. However, it may be difficult or cost- prohibitive to return to a previous project phase to make corrections or changes in requirements requested by stakeholders. Other drawbacks include excessive time to produce a product, stakeholder difficulty in defining the desired end product, and difficulty making changes once started. 

The waterfall methodology is a multiphase approach that begins with a requirements phase when stakeholders define the project requirements and most of the communication between stakeholders occurs. Once the first phase is completed, a product or service can then be designed, developed, tested, and implemented. This methodology allows only minimal stakeholder changes or iterations, and a final product is not provided until the implementation. Moreover, this methodology progresses through other phases until the final phase, which is the maintenance phase, during which any issues are corrected. 

#### IV.J.2 Agile 

An alternative to traditional project management methods (also known as predictive or waterfall management) is the use of adaptive or agile management methods. Incremental and iterative development principles form the foundation of agile methodologies.113 Such principles involve breaking down a project into smaller, manageable modules that can be designed, developed, vetted, and installed in repeated cycles allowing for additional features, adjustments, and corrections with each iteration. With incremental and iterative development, management does not need to identify all requirements at the beginning of the project, as changes may be added during later iterations. Agile projects are different from waterfall projects because they rely on (1) defining requirements before and during execution; (2) delivering frequent, iterative, and incremental products (i.e., not always fully completed); and (3) welcoming changes at any point in the process.114 Incremental and iterative development may be used for larger projects in which the final product’s requirements are well-defined, but details may change or need enhancement during the process. 

113 The agile development methodologies represent a family of development types rather than a single methodology. Organizations exploring agile methodologies are working to define core values and guiding principles for enabling high-performing teams in implementing and executing with agility. These methodologies emphasize close communication and collaboration between the project team and stakeholders. 

There are different models of incremental and iterative development (e.g., iterative, spiral,115 and prototyping modeling116), but they follow the main principle of a defined repetitive process. An agile methodology is an incremental and iterative development methodology that relies heavily on stakeholder interaction throughout the development process. During each phase, a deliverable is produced for the stakeholders, who provide feedback. The benefits of an agile methodology include earlier availability of a version of the deliverable and improved stakeholder satisfaction due to the regular feedback. A primary drawback of an agile methodology is the additional resource requirements (e.g., time, personnel, and funding) needed to implement the additional iterations. 

Generally, an agile methodology involves dividing a project into smaller modules or “sprints.” Each sprint represents an independent project, with phases (e.g., planning, requirements, design, coding, testing, and documentation) similar to those of other development methodologies. In some cases, sprints may become part of a larger project. The project is evaluated at the end of each sprint, and adjustments are implemented as appropriate. An agile methodology is designed to anticipate change at regular intervals based on feedback from stakeholders, such as customers and business analysts, and derive business value from the feedback. 

When applied effectively, the overall business goal of an agile methodology is to minimize risk of introducing defects, prevent cost overruns, and quickly resolve changes in scope before there is a significant impact to the project. An agile methodology aims to satisfy stakeholder requirements by providing rapid, continuous deliveries of useful systems and components, delivered in short intervals. It aims to release working elements of the systems and components at the end of each iteration, even if the overall product is incomplete. The feedback is used to make changes to the existing deliverable and the overall project plan. 

Cross-functional teams representing various business lines are created to facilitate development. The diverse representation of these teams promotes consideration of multiple perspectives, improving visibility during the development process. The result of each iteration should be a functional deliverable for the customer. Real-time feedback117 from customers or stakeholders is a key aspect of an agile methodology. 

114 NIST Advanced Manufacturing Series 100-40, Agile for Model-Based-Standards Development. 

115 In the spiral model, the project iteratively goes through specific development phases (e.g., identify, design, build, and evaluate) with refinement in each iteration (or spiral) until development is complete. For more information, refer to National Aeronautics and Space Administration, A Software Development Simulation Model of a Spiral Process. 

116 Prototyping modeling involves developing a product with the look, feel, and limited functionality of the product under development. It can be used in conjunction with other models allowing developers to build prototypes during development. The prototype is built, tested, and adjusted until a working model is developed and can be produced as a final product or deployed throughout a system. 

An agile methodology employs a flatter organizational structure to allow iterative delivery of systems or components. A common role supporting an agile methodology is the scrum master,118 which is similar to the traditional project manager role. However, unlike the project manager, a scrum master supports and serves the product owner and the development team by helping to remove obstacles to project deliverables. 

An agile methodology may create unique challenges in documentation of development; therefore, the entity’s documentation requirements should be clearly defined in the entity’s project management requirements. Effective documentation relies on real-time communication between the development team and stakeholders, including end users. In any methodology, a lack of clarity or poor communication can negatively affect project deliverables and timelines (e.g., delays, scope creep, costs, and quality). This may have increased significance in an agile methodology because multiple parts of the overall project in process may be affected, leading to a greater impact than if only one segment of a project in process is affected. 

Individual agile methodologies119 may differ in their specific processes; however, they are based on some common principles.120 However, agile principles could be at odds with security principles. For example, the agile principle of speed to delivery could cause developers to leave out important security controls that would take longer to include but be invisible to the end user. To mitigate the risk of security flaws in an agile project, leaders can establish security standards that must be met before a solution is deployed for production use. 

In prototyping models of systems and components (e.g., rapid application development), developers could bypass established change controls, leading to security and integrity risks. Following established control procedures when using these models is as important as when using any other development methodology type. 

117 Feedback loops from customers and stakeholders may take several forms (e.g., emails, meetings) for communicating expectations and needed changes. 

118 NIST defines a “scrum master” as “the role performing the management of the iteration and increments.” A scrum is an agile project management approach that helps teams structure and manage their work through a set of values, principles, and practices toward a common goal. 

119 Examples of agile methodologies include Extreme Programming, Scrum, Lean Software Development, Crystal Methodologies, Adaptive Software Development, Feature Driven Development, and Dynamic Systems Development Methodology. 

120 Common principles include short development iterations, minimal design upfront, emergent design and architecture, collective code ownership and ability for anyone to change any part of the code, direct communication and minimal or no documentation (i.e., the code is the documentation), and gradual building of test cases. Refer to Noopur Davis, Secure Software Development Life Cycle Processes: A Technology Scouting Report, and related guidance, such as CISA, Securing the Software Supply Chain: Recommended Practices Guide for Developers, and Shifting the Balance of Cybersecurity Risk: Principles and Approaches for Security-by-Design and -Default. 

& 

### IV.K Quality Management 

Quality management refers to coordinated activities to direct and control an organization regarding quality. It helps management assess whether newly developed, procured, or modified systems and components are operating as envisioned, and are designed and comply with an entity’s policies, standards, and procedures. Entities assess quality through manual, automated, or hybrid methods throughout the SDLC. Quality management should be an independent function from development, and prudent practices typically include implementing compensating controls when segregation of duties cannot be fully achieved. For example, developers should not test and validate systems and components that they developed. 

Quality management comprises the functions of QA and quality control (QC), which together focus on providing confidence that quality requirements will be fulfilled. Although the goal is similar, QA and QC differ somewhat. QA refers to a planned, systematic pattern of all actions necessary to provide adequate confidence that a system, component, or facility conforms to established requirements. QC refers to the operational techniques and procedures (such as design analysis and inspection for defects) used to achieve quality requirements. QA and QC may be implemented separately or together, depending on the size and complexity of the entity and its development, acquisition, and maintenance activities. 

Quality management is a critical part of well-managed development, acquisition, and maintenance activities. Comprehensive quality management, risk management, and testing standards provide a means to manage project risks and promote expected functionality, security, and interoperability in systems and components in a secure, resilient manner. Quality management policies, standards, and procedures should be applied to internally and externally developed programs and should address the following: 

#### • Commitment: 

Successful projects generally include commitment from all involved parties. Senior management should adequately support and promote projects throughout an entity to promote success of a project. Failure by management to implement or support quality management programs hinders its ability to quickly detect project weaknesses and programming errors. Correcting weaknesses and errors detected late in a project life cycle is often more difficult and costly and may be less effective. 

#### • Expectations: 

To improve quality management and minimize deficiencies, stakeholders should clearly define their expectations and effectively communicate their requirements initially and throughout a project. For example, expectations and requirements could include reliability, resilience, performance, simplicity, usability, interpretation of error messages, accessibility, interoperability, and robustness. 

#### • Completeness: 

Each phase of a project life cycle should include procedures to follow and expected deliverables. Quality management personnel should verify the business case for a project, required functional features, and appropriateness of project considerations to determine completeness in each project phase before moving to the next phase. Audit and compliance personnel should verify that quality management includes quality standards to validate that the project meets internal and external requirements. 

#### • Scalability: 

Projects vary in size and complexity. Quality management standards should match project characteristics and risks and may differ by project size and type. Quality reviews may consider whether the entity’s systems and components can scale, as necessary. 

#### • Measurability: 

To accurately evaluate a project’s success, management should assess results against defined expectations and requirements to determine project success. Quality management personnel should assess the quality of products and processes against measurable standards, metrics, and expectations. 

#### • Tracking: 

Quality management personnel should validate that project personnel properly document a project’s progress; record, report, and monitor problems to resolution; and communicate progress and concerns to management. 

Quality management personnel should be independent of the project they are reviewing to objectively assess elements, such as progress, problem resolution, documentation, and adequacy of the project. 

Information security personnel perform a critical function in ensuring the confidentiality, integrity, availability, and resilience of internally developed and procured systems.121 Quality management personnel should validate the existence and effectiveness of 

#### • 

Independence: 

#### • 

Security: information security considerations. The extent of security validation should be commensurate with risks associated with the project. 

#### • 

Legal and regulatory: Legal and compliance personnel provide guidance throughout a project to ensure that it conforms with applicable statutory and regulatory requirements to mitigate project risks. Quality management personnel should assess statutory and regulatory requirements for deliverables (e.g., digital accessibility)122 and determine whether the systems and components can meet those requirements. 

### IV.L Documentation Standards 

Thorough documentation allows stakeholders to clearly understand system and component functionality, security, control features, and resilience. Documentation conveys how a system or component was developed, how it functions, and where appropriate security and resilience points are included. Entity personnel can refer to documentation to effectively operate and maintain the systems and components. Additionally, well-prepared and maintained documentation reduces resilience risks, such as the loss of institutional knowledge common with personnel turnover. Documentation helps transfer key information (e.g., narratives, flowcharts, and any special system coding or file layouts) over time and across groups. Management should maintain documentation for both internally developed systems and components and externally procured products and services. Due to the sensitive nature of system and component documentation (e.g., internet protocol addresses, server names, and security controls), management should restrict access to sensitive documentation based on job description and need. 

Examples of items that documentation may contain include feature and function descriptions, design specifications, programming descriptions, build procedures, and operating instructions. Also, documentation should be updated as systems and components are updated to ensure that the benefits described above continue. 

121 For more information, refer to NIST SP 800-53, rev. 5, Security and Privacy Controls for Information Systems and Organizations. 

122 For more information, refer to Section 508 of the Rehabilitation Act of 1973. 

For acquired systems and components, management should obtain documentation from the third party and incorporate it into the entity’s own stored documentation. Before purchase, effective management ensures (through an internal review or a third-party certification) that a procured system’s documentation meets the entity’s documentation needs and standards. 

System documentation that includes current build and configuration instructions allows administrators to recover the system after a disruptive event. For a recovery process to be effective, these build and configuration instructions should be kept current as the system is maintained and changed. There are many build and configuration processes that are automated, and the scripts that automate those processes should be documented appropriately for future reference. However, in those cases it may be the manual action (unautomated) documentation that is at the highest risk of becoming stale. 

Common documentation examples include the following: 

* • System or component descriptions and topologies that provide functional purposes, narrative explanations, and pictorial depictions of operating environments and the interrelated input, processing, and output functions of integrated systems and components.
* • System and program flowcharts and models that identify the source and type of input information, processing, and control actions (automated and manual), and the nature and location of output information for a system or component. Additionally, program flowcharts present graphical views of the procedural program sequencing and provide a practical way to illustrate complex programs and routines. Administrators can use these flowcharts to view a system holistically or drill down to specific functions or interrelated components of a system or program.
* • System file and information layouts provide specification useful in information collection, storage, and display.
* • Program documentation details specific data input, processing, and output instructions, and should include documentation about system security. Examples of program documentation include program listings, source code, narrative comments, technical programming scripts,123 and nontechnical descriptions of the scripts.
* • Manuals and procedures inform IT personnel and end users on the operation of systems and components.
### IV.M Post-Implementation Review 

Organizations formally perform a post-implementation review (PIR) for system development and implementation projects to continuously improve. Processes and techniques that were effective are passed to future projects as effective practices. Problems and their solutions are also passed along to help future projects avoid pitfalls. In agile projects when there are multiple implementations, smaller reviews are completed after each task or deliverable is implemented. Typical PIR steps are 

123 Merriam-Webster defines a “script” in computing as “a sequence of instructions or commands for a computer to execute.” 

* •
* •
* •
* •
* •
* •
* •
* •

Gathering data including project initiation documents, post-implementation metrics, and post-implementation stakeholder interview results. 

Analyzing any gaps between project initiation goals and objectives and actual outcomes, including the reasons for any gaps. 

Summarizing the analysis and any recommendations in a report to management.124 

Common project aspects analyzed in a PIR include the following: 

User satisfaction. 

Actual benefits compared to projected benefits. 

System or component defect level when implemented, which helps measure system testing effectiveness. 

Project management effectiveness. 

Actual costs and timeline versus business case projections. 

When entities analyze project aspects like those above and pass the results to management and future project teams, they raise future project success probability and mitigate the risk of future project failure. 

## IV.N 

### IT Project Management 

#### Action Summary 

Consistent use of appropriate project management policies, standards, and procedures can help personnel be effective in identifying and mitigating project risks before they materialize. 

Examiners should review the following: 

* • Project plans, proposals, and status reports to determine the effectiveness of IT project manager collaboration with stakeholders (e.g., through the PMO) for oversight and completion of IT projects.
* • Board and committee minutes to evaluate how the entity prioritizes projects relative to business goals and objectives, evaluates the project’s effect on operations, and monitors and supports projects during execution.
* •
* •
* •
* •

Project plans and proposals to determine how well they identify the project purpose, the requirements to address business needs, and the deliverables for each project phase. 

Change management documentation to determine the appropriateness of change decision- making levels and the consistency of approved changes with the project charter and plan. 

Testing and quality management plans to determine the adequacy of quality controls. 

Project closeout documentation to evaluate the entity’s ability to inform future projects. 

124 

Refer to U.S. Government Accountability Office’s The Post-Implementation Review. 

Project management is the use of specific knowledge, skills, tools, and techniques to deliver something of value to people.125 Effective project management includes established policies, standards, and procedures that project personnel apply enterprise-wide. Examples of projects include developing a new product or service, expanding into a new geographic market, and investing in a new system. When reviewing and prioritizing projects, effective management considers the project’s effect on operations and the entity’s needs (e.g., IT, information security, lines of business, customer needs, and regulatory and legal compliance). Entity projects often include a supporting IT project due to the underlying systems and components in business operations. For instance, when management considers offering a new product or service or expanding into a new geographic market, there are often IT implications. Effective IT project management processes, which are a subset of and align with the enterprise project management policies, standards, and procedures, should address issues specific to IT projects. Effective management develops and follows consistent processes to identify risks and oversee IT projects to address any risks identified. IT projects generally include IT system development, acquisition of a new IT system or component, or significant maintenance of or change to an IT product or service. If the entity has a PMO, IT project managers should work with the PMO to oversee and carry out IT projects. 

An IT project should be managed in relation to the entity’s size and complexity and consistent with the project’s criticality and risks. An ineffectively managed IT project may result in late deliveries, cost overruns, or systems or components that do not meet entity, user, customer, or regulatory requirements. Systems or components that do not meet entity minimum standards or customer requirements can result in underused, insecure, or unreliable products or services. Adding functions, security, or automated controls into systems or components late in the initial development or after implementation to address missed requirements may incur substantial costs (e.g., personnel, time, and money), resulting in less effective systems or components. Furthermore, poor project management can lead to legal issues, such as violations of law and regulation and monetary penalties. 

The project management discipline discussed in this section and the SDLC discipline discussed in the next section overlap significantly. In practice, effective system and component development teams integrate discipline use without duplicating effort. 

#### IV.N.1 IT Project Phases 

A general project management life cycle is shown in figure 3. The type of IT project (e.g., development, acquisition, or maintenance) will affect the project management life cycle chosen. For example, when an SDLC is chosen for a development project (e.g., adaptive versus predictive), the procurement processes chosen for an acquisition project, and the change control practices chosen for a maintenance project will affect how the project is managed. Furthermore, the activities completed within a project’s life cycle are based on the characteristics of a project and the employed project management methodology. 

125 Refer to PMI’s “What Is Project Management?” 

& 

Figure 3: Project Management Life Cycle 

Enter Phase/Start Project 

Project Concept 

| 

MONITORING AND CONTROLLING PROCESSES 

INITIATING PROCESSES 

V 

INITIATION 

##### PLANNING PROCESSES 

V 

##### PLANNING 

CLOSING PROCESSES 

V 

CLOSEOUT 

G 

IT 

##### EXECUTION PROCESSES 

V 

##### EXECUTION 

Exit Phase/End Project 

Project Completion 

A project team often begins a project by creating a proposal to management that explains the business case including the desired system and component features and project scope, the planned benefits, the estimated time required, and the estimated cost.126 Management reviews the proposal and determines whether the project is feasible and makes sense for the entity. If management approves the proposal and initiates the project, the business case serves as the basis for developing a detailed project plan. 

The four main phases shown in figure 3 (Initiation, Planning, Execution, and Closeout) are described further in the following subsections. 

#### IV.N.1(a) Initiation 

The project’s initiation phase begins with identifying stakeholders who determine the project’s purpose, scope, and final deliverables. The following would typically be completed during this phase: 

126 PMI, A Guide to the Project Management Body of Knowledge, fifth edition, p. 50. 

* • A project request that provides the business case including a description of the work, the
* • A project charter that identifies the project owner (i.e., the responsible party), and defines the
* • Initial business and technical requirements.127 FFIEC IT Examination Handbook Development, Acquisition, and Maintenance benefits, alternatives considered, the impact of not doing the work, initial estimates of resources and schedule, and strategic match. mission and main goals of the project.

When the project involves developing a new system or component or making significant changes to an existing system or component, management analyzes and determines whether to develop or acquire (referred to as “build or buy”) the solution. A feasibility study128 helps in the process of making this determination. Considerations in the feasibility study include availability of internal expertise, cost of building the solution compared with procuring it, availability of an external product that meets the entity’s requirements, solution implementation timeline, and the project’s complexity. Refer to table 2 in the “Feasibility Study” section of this document for additional feasibility considerations. Regardless of whether the decision is to build or buy, the feasibility analysis helps management to verify the reasonableness of the preliminary assumptions and to identify resource requirements in greater detail. 

#### IV.N.1(b) Planning 

In the planning phase, management forms a project team129 that defines and refines project deliverables to achieve the objective and develops the project plan. Project plan common elements are tasks and milestones, task timelines, and names of those who are responsible for completing each task. Project teams engage stakeholders to define deliverables that achieve objectives and meet the entity’s functional, IT, information security, and legal and regulatory requirements. Requirements include systems, components, and resources that will support and interact with any new product or service. Clearly defined deliverables (including documentation deliverables) help stakeholders understand expectations. The project team should also define testing requirements and objective acceptance criteria, which are unbiased and predefined criteria for determining whether the project meets the stated objectives through milestones and project completion. Additionally, security and resilience design should be included from the beginning of the project to be most effective. Information regarding project management governance is in the FFIEC IT Handbook’s “Management” booklet. 

127 The NIST Glossary defines “requirement” as “a statement that translates or expresses a need and its associated constraints and conditions.” 

128 A feasibility study considers the critical aspects of a proposed project; assesses the degree to which the requirements, designs, or plans can be implemented; and helps determine the likelihood of the project’s success. A formal feasibility study may not be performed at smaller, less complex entities; however, management should perform some analysis of system or component needs for a given project. 

129 Depending on the IT project type and complexity, the project team may include multidisciplinary stakeholders from varying lines of business. An effective project team’s roles and responsibilities are clearly defined and communicated so everyone involved is aware of their responsibilities. 

#### IV.N.1(c) Execution 

During the project’s execution phase, the project team completes the project plan tasks. The team tracks and compares actual task execution with the project plan, maintains a log of problems (e.g., inability to meet milestones, resource changes, and unanticipated risks), tracks problem resolution, reports on effects to the project timeline, and monitors interdependency issues. During the execution phase, scope creep is a common problem that can occur as developers address issues or receive subsequent requests to add or modify a system’s features. It may result from inadequately defined requirements, a lack of a project change control process, inaccurate time and budget analysis, or a weak project manager or executive sponsor. Establishing change approval procedures during development and cutoff dates (after which time requested changes are deferred to subsequent versions) helps mitigate scope creep. 

Strong change approval procedures enforced by management can mitigate the risks that come with scope creep. Procedures can include independent project monitoring for additions or modifications of functional and nonfunctional features to help enforce management review and approval. Procedures can also include project plan variance management reporting that could indicate scope creep (e.g., delays in completion of tasks or cost overruns). Significant project plan variances may require the entity to reassess and re-baseline project plans. Project managers regularly report the project’s status to stakeholders, senior management, and, when appropriate, the board in order to inform of changes and issues. 

Strong testing and other QC procedures can mitigate the risk that the entity’s project goals and stakeholder requirements are not met during the execution phase. Testing helps find deficiencies or defects and helps ensure that the system or components operate as intended. Depending on the project type, testing may be scheduled throughout the project during any phase. For example, testing may not always occur during every sprint when using an agile development methodology. Users, designers,130 developers, and IT staff may be involved in testing. Throughout the testing process, management should maintain comprehensive and accurate documentation reflecting the testing methodology employed, tests performed, and test results. 

#### IV.N.1(d) Closeout 

During the project’s closeout phase, the project team delivers the agreed-upon scope items as outlined in the project plan. For example, in a systems development or acquisition project, project closeout is when the project team transitions the systems to the operations staff (i.e., moves application from a staging to a production environment). Often during the project closeout, project teams analyze the project (i.e., post-implementation review) to identify effective project practices and discuss issues encountered and how they were resolved. This information is used to inform and improve project management practices. Project teams review project documentation in the closeout phase to ensure that it is complete, supports maintenance, and can be used by future teams to identify effective practices. 

130 Designers may include personnel engaged in creation and execution of plans for a project or structure (e.g., graphic designers, web developers and digital designers, web and digital interface designers, computer programmers). See Bureau of Labor Statistics, Occupational Outlook Handbook, for more information on job descriptions. 

& 

#### IV.N.2 Monitoring and Controlling 

Monitoring and controlling are important parts of the processes of IT project management. This takes place throughout all phases of IT project development (refer to figure 3). Monitoring and controlling are helpful for tracking, reviewing, and evaluating the progress of an IT project. Monitoring and controlling helps management identify IT project management risks (e.g., errors, cost overrun, scope creep, and missing milestones). A combination of management and the project manager or sponsor are responsible for monitoring and controlling the entire project throughout all phases. 

During the initiation phase, monitoring and controlling activities include the following: 

* • Validating that relevant stakeholders are identified and all stakeholders’ project requirements
* • Coordinating the project phases, including tasks and activities, sufficiency of resources, and
* • Validating that the project scope is sufficiently identified and refined to minimize scope
* • Evaluating the application of project management policy, standards, and procedures.
* • Validating that appropriate success criteria are identified and the project is feasible.
* • Determining effective establishment of reporting lines, reporting processes, and reports. are well-defined. process steps and timing for each phase. creep.

During the planning phase, monitoring and controlling activities include the following: 

* • Validating the appropriateness of the project plan’s tasks and time frames as well as resource
* • Reviewing the project plan iteratively and validating any approvals for any updates.
* • Validating stakeholder support and engagement.
* • Verifying that the project plan and associated project documents are appropriate, sufficiency. comprehensive, and approved.

During the execution phase, monitoring and controlling activities include the following: 

* • Meeting regularly with the project team to track progress, address impediments or issues, and
* • Monitoring, measuring, and analyzing project performance compared to the project plan and
* • Validating that any changes are authorized, quality is maintained, scope creep is mitigated,
* • Recommending corrective or preventive action.
* • Verifying that configuration management policies and procedures are followed.
* • Monitoring expenditures compared to the project budget and addressing any cost overruns. track task and milestone completion. identifying any variance. and stakeholders are informed.

During the closeout phase, monitoring and controlling activities include the following: 

* • Validating that the project team follows closeout processes when the project is complete.
* • If a project is discontinued before implementation, determining and documenting the reasons
* • Verifying that project deliverables were accepted.
* • Overseeing a post-implementation review.
* • Confirming that the system or components have been added to inventories that support for the abnormal project closure for use by future project teams. routine maintenance, such as patching.
#### IV.N.3 IT Project Documentation 

IT project documentation helps ensure clear communication among the project team, management, and other stakeholders. For example, strong written documentation provides a record of key decisions (e.g., project approvals, timeline, and scope changes) that the project team can refer to throughout the project. 

Types of IT project documentation range from simple documents, such as meeting minutes and project status reports, to more complex documents such as feasibility studies, project plans, requirements, and PIRs. Project documentation allows management to track and monitor security, resilience, and compliance concerns throughout the project and after its completion. Entities establish documentation standards and procedures to mitigate the risk of inconsistent or incomplete documentation. When determining the amount of project documentation needed, various factors to consider include an entity’s size and complexity, the project type (e.g., development, acquisition, or maintenance), and the project’s complexity. The following subsections describe common examples of project documentation. 

#### IV.N.3(a) IT Project Request 

IT project requests outline proposed projects including the reason for initiating the project. Effective project requests convey proposed business objectives and project requirements between the project team, management, and other stakeholders. Project requests also identify project responsibility and accountability, including identifying the project sponsor. Project requests often include the following: 

* • Project sponsor.
* • Customer or user.
* • Other stakeholders.
* • Purpose and proposed scope of the project.
* • Project deliverables.
* • Project constraints (e.g., time, budget, and technology).
* • Business case.131 131 A business case generally accompanies the project request and provides additional information to help set appropriate parameters for the project.

& 

#### IV.N.3(b) Business Case 

A business case conveys business related information to help management determine whether to fund a project. The goal is to justify the project resources (e.g., budget and staffing) to address a business need. Typically, the project’s sponsor helps to develop and owns the resulting business case.132 Business cases often include the following: 

* • The need or problem the project will address (e.g., systems not meeting operational requirements or loss of market share).
* • Alternative solutions including estimated staffing, timeline, costs, benefits, and risks.
* • The proposed solution with rationale (e.g., buy a new system or develop a new component).

Effective business cases address both the parameters for implementing and maintaining the solution. For example, both the costs to build and maintain various system options are analyzed before a proposed solution is presented. 

#### IV.N.3(c) Feasibility Study 

A feasibility study is an analysis of a known problem or need and the proposed solution conducted independent of the project request team. It helps stakeholders evaluate a proposed solution considering relevant factors—including economic, technical, legal, and scheduling considerations—to determine a project’s probability of success. Table 2 outlines feasibility study considerations. 



| Business | • | Entity objectives. |
| --- | --- | --- |
| considerations Functional | * • * • * • * • * • * • * • * • * • * • * • * • | Effect on existing operations. IT security risk assessment Entity’s IT and information security Expected benefits. Potential entity changes regarding Budget, scheduling, training, Licensing needs. Potential legal or regulatory Estimated completion dates Expected benefits and risks Third party’s due diligence throughout End user needs. availability, and resilience. key security roles, or managers. relationships). |

Table 2: Feasibility Study Considerations 

to determine security risks and mitigation needs. 

requirements addressing data confidentiality, integrity, 

facilities or the addition or reduction of users, IT staff, 

or personnel constraints (including for oversight of third-party 

issues that could affect the project’s feasibility. 

of IT projects and major project milestones. 

for consumers relative to the new product or service. 

the supply chain. 

* • Internal control and information security requirements.
* • Operating, database, and backup system requirements (e.g., type, capacity, performance,
* • Hardware requirements (e.g., infrastructure needs, processing chips, and credit card or
* • Facility needs (e.g., raised floor, cabling, and heating, ventilation, and air conditioning  scalability, and resiliency). point-of-sale components). [HVAC]).

requirements 

132 Refer to PMI, “Is This Really Worth the Effort? The Need for a Business Case.” 



| * • Network requirements (e.g., physical, virtual, software-defined, and hyper-converged * • Connectivity and interface requirements with internal or external applications, third-party networks; types of storage; number of users; and type, volume, and frequency of data transmission). service providers, internal or external users, and customers. |
| --- |
| Expected useful life of the proposed product or application. Alternative solutions (e.g., build or buy). |
| • Third-party hardware and software vendor requirements related to entity functional requirements. |
| * • Estimated costs of projects (e.g., overall and by project phase). * o Nonrecurring project costs (e.g., hardware, software, and overhead). |
| o Recurring operational costs (e.g., personnel, maintenance, telecommunications, and overhead). |
| • Entity’s requirements compared to third-party products, services, and activities implemented in the supply chain. |
| * • Soft (or intangible) costs.133 * • Tangible benefits (e.g., increased revenues, decreased costs, and return on investment). |

* • Product development, design, and testing standards throughout the supply chain.
* • Supply chain considerations related to entity business considerations and functional
* •
* •
* • Intangible benefits (e.g., improved public opinion or more useful information). requirements.

Cost-benefit 

analysis 

#### IV.N.3(d) IT Project Plans 

IT project plans describe how a project will be executed, monitored and controlled, and closed. Entities use project plans to communicate tasks, time frames, and responsible parties to project stakeholders throughout a project. The details in an IT project plan identify necessary technical steps in sequence and help the team identify any missing tasks that are needed to achieve the project’s objectives. The project plan also identifies interconnectivities and interdependencies throughout the project—how segments of the project are interrelated. Generally, IT project plans consider the following: 

* • Approved project scope.
* • Roles and responsibilities.
* • Communication among the project team, stakeholders, and management.
* • Schedule, including completion of key tasks and achieving milestones.
* • Quality management tasks (e.g., testing both developed systems and patches for procured
* • Risk management tasks (e.g., periodic risk reviews).
* • Task budgets.
* • Implementation tasks (e.g., training and deployment). systems).
#### IV.N.3(e) Closeout Documentation 

Entities use closeout documentation to apply lessons learned from past projects to future projects. These lessons can include practices and techniques that were effective, problems that could be avoided if particular processes are used, and how high-performing project teams were 

133 Soft costs generally include indirect dollars spent in other areas (e.g., sales, general, and administrative expenses) to support a change in business model, equipment, or practices. 

& 

formed. Many lessons can be memorialized by updating existing policies, procedures, and standards. Several documents can be used to improve future projects, such as the following: 

* •
* •
* •

##### PIR. 

Project plans with projected and final task completion dates. 

Risk reviews including suggested changes to project management-related policies, standards, and procedures. 

##### Action Summary 

## IV.O 

### System Development Life Cycle 

Management should implement an SDLC to manage systems and system components throughout their life cycle and achieve the objectives of confidentiality, integrity, availability, and resilience to achieve the entity’s business objectives. 

Examiners should review the following: 

* •
* •
* •
* • Responsibility and accountability assignment. 

Key stakeholder involvement level. 

Stakeholder communication and tracking of all SDLC phases and actions. 

The documented management and control processes, including for supply chain partners.

One NIST SDLC definition is that it is “the scope of activities associated with a system, encompassing the system’s initiation, development and acquisition, implementation, ongoing operation and maintenance, and ultimately its disposal that instigates another system initiation.”134 The acronym SDLC is also used to refer only to software development and implementation (standing for the software development life cycle). However, this booklet uses the acronym SDLC to refer to the broader concept encompassing the entire system and its components. If an entity engages in internal development activities, management should have a documented process (e.g., SDLC) that management and personnel use to manage and control development activities. Effective SDLC processes are well-documented by organizations such as NIST.135 Using proven processes helps to mitigate the various risks of building, maintaining, and retiring systems. Implementing the SDLC allows management to organize these activities into smaller, more manageable segments or phases. Data security should be considered throughout all phases of the SDLC to maintain confidentiality, integrity, availability, and resilience. 

The SDLC discipline discussed in this section and the project management discipline discussed in the last section overlap significantly. In practice, effective system and component development teams integrate discipline use without duplicating effort. 

134 

135 

Refer to NIST Glossary. 

Refer to NIST SP 800-160, vol. 1, rev. 1, Engineering Trustworthy Secure Systems. 

#### IV.O.1 SDLC Phases 

##### Action Summary 

During the SDLC phases, system development project teams work to achieve project objectives, mitigate the risk of lower quality development projects, and address security. These considerations are considered throughout all phases. 

Examiners should review elements of each phase such as the following: 

###### Initiation Phase 

* • The system’s purpose, expected benefits, how it supports business objectives, and any legal and regulatory requirements.
* • Initial security impact analysis and validation of the appropriate project specifications.
* • Extent to which the project request is communicated to stakeholders in the supply chain.
###### Development or Acquisition Phase 

* • Design specifications, including security control design.
* • Risk assessments, including using the results of security risk assessment, to supplement the baseline security controls.
* • Risk mitigation strategies.
* • Test, conversion, implementation, and training plans, accounting for confirmation of the
* • Change management documentation.
* • Draft user, operator,136 and maintenance manuals. functionality and controls.
###### Implementation and Assessment Phase 

* • Design reviews and system tests, including any new specification testing.
* • Deployment approach (e.g., phased-in, simultaneous).
* • Training, including user and system support documentation.
* • PIR.
###### Operations and Maintenance Phase 

* • Performance and controls monitoring.
* • Change management controls, including as used to control configurations.
* • ITAM inventory and associated audits.
###### Sunset and Disposal Phase 

* • Plans and validation measures for accessing and retrieving data from archives.
* • Off-boarding procedures, including for third-party providers.
* • The entity’s post-disposal review, including any lessons learned documentation. 136 Refer to NIST Glossary.

& 

Effective management understands the SDLC phases and the actions needed in each phase. The phases may be divided differently depending on the entity, the project type and characteristics, and the SDLC used. Management should identify the actions and assign responsibility and accountability for completing those actions. Key stakeholders of the system or component being developed or modified should monitor progress in each phase including the output of each phase. This involvement mitigates the risk that the system or component does not deliver the requested functionality. Management should maintain confidentiality, integrity, availability, and resilience throughout all phases of the SDLC. 

An entity that defines its SDLC phases helps ensure transparency and accountability to, and agreement and system or component acceptance by, the stakeholders. Figure 4 illustrates the five general SDLC phases (Initiation, Development or Acquisition, Implementation and Assessment, Operations and Maintenance, and Sunset and Disposal) identified by NIST.137 

Figure 4: NIST Example of a System Development Life Cycle 

O 

On 

O 

3 

K 

#### IV.O.1(a) Initiation 

* 1. INITIATION The need for a system is expressed, and its purpose and high-level requirements are documented.
* 2. DEVELOPMENT OR ACQUISITION The system is designed, purchased, programmed, developed, or otherwise constructed. This phase often consists of other defined phases, such as the system development phase of the acquisition phase.

®) 

* I3. IMPLEMENTATION AND ASSESSMENT After initial testing, the system is installed or fielded.

| 4, OPERATIONAL AND MAINTENANCE The system performs the work it was developed for. 

* 5. SUNSET AND DISPOSAL The system is disposed of once the transition to a new computer system is completed.

The initiation phase begins when entity personnel identify an opportunity to build, buy, or modify a system or component and formally seek approval with an IT project request. The project team should describe the IT project’s purpose, identify expected benefits, and explain how the proposed system or component supports the entity’s objectives. The project team should summarize the confidentiality, integrity, availability, resilience, and legal and regulatory requirements. They should identify alternative solutions and justify their recommended solution. Through IT project request development, stakeholders should gain a common understanding of the project’s objectives, security considerations, and risk management planning to mitigate the risk of project failure. 

137 Refer to NIST Information Technology Laboratory (ITL) Bulletin, “The System Development Life Cycle (SDLC).” 

During the IT project request review, management can accept, reject, or request changes before it allocates resources. Management can also commission a formal feasibility study to inform its decision. If the IT project request is to modify an existing system, management should consider performing a security impact analysis138 to identify any negative impact to existing security controls. Such a security impact analysis may be performed as part of the feasibility study. 

Planning, particularly in the project’s early stages, should help the project team and management coordinate development activities and manage risks effectively. Planning helps the project team and management add or clarify the project’s specific activities, resources, costs, and benefits. A critical part of planning is to coordinate stakeholder discussions to identify and document as many of the entity’s functional, security, and network requirements as possible. 

Primary items entity personnel typically include in planning consist of the following: 

* • Responsibilities of third-party service providers, internal audit, information security, and IT
* • Entity SDLC processes.
* • SDLC phase acceptance criteria including review and approval procedures to help ensure that staff. development teams complete all SDLC phase or independent sprint requirements before moving into subsequent phases.
* • Control and security features to be designed and built, or acquired, and implemented.
* • Change management processes to minimize disruption to the project plan.
* • Risk management processes, including project methodology selection.
* • Cost tracking mechanisms, including to track overhead (e.g., office space, hardware, and software used during the project) as well as other related costs (e.g., budgeting personnel expenses, outsourced activities).

When evaluating IT project requests, effective management considers input from all stakeholders. For example, management evaluates the appropriateness of the requested functional requirements. Each function has design and development implications. Each function requires testing, documentation, and ongoing support. Therefore, the exclusion of unnecessary functions can significantly reduce the resources required to support a request. Management considers and analyzes all requests to determine whether to develop or acquire the system or component. 

138 For more information on conducting a security impact analysis, refer to NIST SP 800-128, Guide for Security- Focused Configuration Management of Information Systems. 

& 

#### IV.O.1(b) Development or Acquisition 

During the development or acquisition phase, the system or component is designed and developed or acquired. Key system or component designs are created or reviewed before development begins or the acquisition is completed. When a project is initially proposed and reviewed, the decision to develop or acquire may be uncertain. Early stakeholder involvement in design creation or acquisition specification review mitigates the risk that the system design does not support the functional requirements. The more predictive the SDLC is, the more design work will occur earlier in the SDLC. The more adaptive the SDLC is, the more design work will be spread throughout the SDLC phases. 

When an entity acquires a system or component, important design considerations include how much configuration is possible, whether the system or component can be restored to a secure configuration, and whether there are restrictions on users or services that can make configuration changes. Entity personnel can configure systems and components to avoid specific known threats and risks based on the entity’s risk appetite. For example, if a product or service is used by bank customers, it may be important that the product or service’s security and functionality allows the capability for the customer to change some configurations (e.g., change location restrictions, adjust monetary limits, and allow use of physical access controls). 

System and component security should be a high priority throughout this phase. If an IT security risk assessment was conducted as part of the feasibility study, it can be used early in this phase to design baseline controls to address risks identified. If an IT security risk assessment was not completed as part of the feasibility study, it can be completed early in this phase. Designing security controls early in the development and acquisition phase is important to system or component confidentiality, integrity, availability, and resilience. If the system or component is being developed or acquired, it is important to address security concerns, such as those for customer information, and personnel should “identify reasonably foreseeable internal and external threats that could result in unauthorized disclosure, misuse, alteration, or destruction of customer information or customer information systems.”139 Therefore, it is important to identify security controls requirements and consider appropriate controls that might affect the entire supply chain. It is typical for system and component functionality and design to change throughout the phase, which can change security effectiveness. The security impact analysis performed during the SDLC initiation phase can be helpful to evaluate security adequacy before, during, and after system and component changes are made in this phase.140 Early implementation of security controls can minimize their cost, allow for efficient deployment, and reduce integration issues. 

139 Refer to GLBA and 15 USC 6801 and 6805(b), further implemented by FFIEC members as follows: FDIC: 12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards,” and 12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice;” FRB: Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards,” and Regulation Y, 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards”; NCUA: 12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information”; OCC: 12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards.” Additionally, refer to FTC 16 CFR 314, “Standards for Safeguarding Customer Information,” for similar provisions for service providers. 

140 For more information on conducting a security impact analysis, refer to NIST SP 800-128, Guide for Security- Focused Configuration Management of Information Systems. 

Appropriate personnel should define and create initial testing, conversion, implementation, and training plans and obtain management approval during the development or acquisition phase. Development personnel should initially test the design during development to confirm that the system’s or component’s functionality is meeting requirements and controls, including security controls, are functioning as intended. Testing early and throughout this phase helps a team identify functional or security flaws when remediation can be less expensive. 

The potential for scope creep increases during this phase, and project stakeholders monitor and mitigate this risk. Effective entities have a process to review the appropriateness of new or modified requirements and development changes to minimize scope creep, as discussed in the “IT Project Management” section of this booklet. 

Designers should document completed designs and functions, including information security designs. Design documents may include system architecture, software architecture, and data structure design. Detailed documentation enhances a developer’s ability to modify systems and components after they are placed into production. The documentation should include appropriate information such as all related systems and components (including IoT product components and devices), any accreditation, certification, or evaluation results. Documentation can be used by management to compare original objectives and specifications with systems and components ready for implementation. The development team typically drafts user, operator, and maintenance manuals during this phase. 

#### IV.O.1(c) Implementation and Assessment 

The objective of the implementation and assessment phase is to prepare the system, operational environment, entity, and end users for system or component use, and to assess whether the system or component meets business needs and operational requirements. In this phase, the team configures and enables system or component features, tests the features’ functionality, and installs or implements the system or component after obtaining appropriate approvals. 

It is important to thoroughly test before implementation to help ensure that the system or component meets all entity specifications. These tests should be documented so that as the system or component is changed, previous tests are used and adjusted to validate rather than creating new tests. Building on original testing documentation also may result in subsequent tests being more comprehensive than if they were not leveraged. 

The more complex and critical the development or acquisition, the more important it is to rigorously assess the product before implementation. For example, conversions of core banking systems require more detailed reviews and higher levels of approvals from management given their significance to delivery of business services, as opposed to a lower level of oversight for routine maintenance of a less critical system. These reviews would occur before implementation. In the more complex and critical implementations, approval from many stakeholders such as business continuity management, information security, and third-party risk management may be 

& 

necessary. For more information on routine changes and conversions, refer to the “Implementing Changes” section of this booklet. 

Primary implementation phase tasks include communicating the implementation schedule to internal and external stakeholders, training users, and installing the system or component. To be most effective, the implementation schedule takes into account the business impact (e.g., conversions are scheduled on long weekends to allow additional time before affecting weekday business). Management and other appropriate personnel perform tasks such as the following during the implementation phase: 

* • Execute the implementation plan, including the following: 
	+ o Assessing risk for issues that may occur during implementation activities (e.g., rollout, conversion, or update).
	+ o Conducting user acceptance testing (UAT).
	+ o Updating the asset inventory.
	+ o Training (internal and external).
* • Input, import, or convert data and validate the functionality of the system or component using
* • Confirm the confidentiality, integrity, availability, and resilience of systems and data.
* • Confirm the interoperability of systems and components.
* • Configure and test system and component security controls.
* • Validate performance parameters (e.g., throughput, capacity, error rates, and memory usage)
* • Conduct a final audit of information security and adherence to policies and procedures, as
* • Create and test back-out or rollback plans to prepare for unforeseen and unrecoverable
* • Conduct PIRs (e.g., survey users, review complaints, plan future functionality, and identify those data. and ensure that the system or component operates as expected. well as risk tolerance levels. Determine whether the findings of the audit meet the entity’s predetermined requirements for system deployment. problems that may occur during implementation. Entity personnel may accomplish this by various back-out or rollback methods (e.g., using one or more restart points or reverting to the legacy system or prior version). other improvements). Additionally, the reviews may identify lessons learned and process improvement information.

Implementation strategies vary and are designed to mitigate different types of implementation risk. Examples of implementation types may include the following: 

* • Parallel implementation consists of running the old and new system or component simultaneously until the new system or component is evaluated and approved. If the new system fails, operations can continue using the old system while issues are corrected. Running two systems or components simultaneously requires additional resources (e.g., costs, personnel, and time), but is a logical strategy if no system downtime is tolerable.
* • Pilot implementation involves releasing the complete, new system or component to a limited (i.e., pilot) group of users. After successful rollout to that pilot group, management decides how to proceed with the rollout process. Advantages of using a piloting strategy include minimizing the risks of a comprehensive rollout to the entire user population, as well as opportunities to test the system with the initial rollout and any additional rollouts. However, this strategy may also be time-consuming and expensive. A risk to this strategy is that it may allow for large numbers of insignificant enhancements instead of focusing on critical system issues.
* • Phased implementation involves deploying a new system or component in phases (i.e., rolling out modules, features, or functionality incrementally over time) generally according to a predetermined schedule. This strategy helps mitigate the risk that a foundational flaw is discovered at the end of the project rather than earlier when it would be easier to correct. This strategy potentially requires less training and fewer resources spent at one time, and potentially fewer errors on which to focus during each phase. This strategy may lengthen the implementation time frame. In addition, there may be integration and interoperability concerns, such as reverse compatibility issues with legacy components while the old system is being replaced in phases.

Training is critical to the success of the implementation and assessment phase as are training plans and supporting materials for operating, using, and maintaining the system. Training is often the first exposure to the system for most users and should be provided before system or component deployment to the production environment. Training enables users to familiarize themselves with the new or updated system or component. A positive training experience typically improves user acceptance. During this phase, appropriate personnel should coordinate training logistics, including who should be trained, what the training involves, and when training should be conducted. Effective management organizes a training and awareness campaign and notifies users of any implementation and training responsibilities. This helps establish user expectations regarding system and component capabilities. Those responsible for supporting the system or component in the entity should have a combination of technical documentation, training, and hands-on assistance enabling support personnel to provide operational support to the users. Once the product is implemented, management should perform a PIR (see the “Post- Implementation Review” section of this booklet for more information). 

#### IV.O.1(d) Operations and Maintenance 

In the operations and maintenance phase, systems and components are in production and operating; enhancements and other modifications are developed and tested; and hardware and software components are changed. Entity personnel should continuously monitor system and component performance and adjust the system or component so that it operates consistent with pre-established user, security, and other entity requirements. Entity personnel should manage and document configuration changes whether baseline or unique. Documenting system and component changes and assessing the potential impact of these changes on a system’s or component’s security, functionality, performance, and resilience are essential activities in this phase. 

Maintenance can occur periodically or regularly, such as annually, semiannually, quarterly, or weekly. In agile-based methodologies, maintenance may occur continuously. The maintenance frequency varies across systems and components, and the timing is prompted by business and operational need. 

An entity’s change control processes play an important role in the operations and maintenance phase. Changes to a system or component can affect baseline configurations and controls, and this impact should be analyzed. To mitigate the risk of an enhancement or other modification disrupting or degrading operations, effective entities follow established change management policies, standards, and procedures. For more information, refer to the “Maintenance” section of this booklet and the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” and “Information Security” booklets. 

Examples of commonly performed tasks in this phase are the following: 

* • Ensuring that systems and components are operational and available during the defined hours
* • Implementing nonemergency change requests during scheduled outages.
* • Ensuring that all processes, manual and automated, are documented.
* • Ensuring adequate resource availability for operations, maintenance, and resilience.
* • Performing and testing system, component, and data backups.
* • Validating the entity’s physical security measures.
* • Ensuring that contingency plans for resilience are updated, tested, and funded.
* • Ensuring that all operations and maintenance personnel take appropriate, ongoing training.
* • Maintaining and monitoring system and component performance measurements, statistics,
* • Ensuring that third-party SLAs are being monitored and met.
* • Performing configuration, security, and design assessments to ensure that system and
* • Patching software for systems and components.
* • Managing and controlling configurations and changes to the system. This includes installing, of operation. and system logs. component parameters and configurations are correct. configuring, upgrading, and maintaining systems, components, and data, as well as related documentation.

Management is responsible for operations and maintenance phase task performance regardless of whether tasks are performed by entity or third-party personnel. For more information, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services,” “Business Continuity Management,” “Architecture, Infrastructure, and Operations,” and “Information Security” booklets. 

#### IV.O.1(e) Sunset and Disposal 

In the sunset and disposal phase, plans are developed for the orderly termination of systems or components and the preservation of data that reside in them during the transition to a new system or component. Data to be preserved include entity data and client and consumer data. The systems, components, and data may be migrated to another system, archived, reassigned, or destroyed. There are several risks in the disposal phase such as the risk of sensitive data disclosure to unauthorized individuals, business functionality impairment, intellectual property loss, and reputation damage. Archive solutions may address the frequency and speed of any future data retrieval. Additionally, effective entities have a process in place to periodically validate the accessibility of archived data. 

Specific tasks and activities occurring during this phase depend on the risk and complexity of the systems, components, or services. Considerations in system retirement and disposal include the following: 

* • Disposal or transition plan involving all applicable parties that identifies critical steps,
* • Hardware and software components to preserve, including for archive use.
* • Data archive and migration—data could be migrated to the new system, archived, or a
* • System and component documentation preservation.
* • Advanced notification to all end users and stakeholders of the system or component sunset
* • Plans for end-user migration to a replacement system or component.
* • Plans for permanently erasing (i.e., sanitizing) data from the terminated system or decisions, and milestones to properly terminate, transition, and dispose of a system, component, service, and data. combination of the two. plan and the planned termination date. component. Methods for sanitization include deleting, overwriting, and destroying data.141

If the system or component requiring disposal is managed by or the related data are stored by a third party, comprehensive off-boarding procedures help mitigate risks related to unauthorized access to sensitive information. Procedures should address items such as access, security, data governance and storage, and recordkeeping requirements (e.g., legal, regulatory, compliance, and audit). Effective management has a process to validate that its third party appropriately performs all necessary steps associated with system, component, data, and service sunset and disposal. The third party should maintain and make available to management evidence (e.g., certification) of disposal and archival activities to demonstrate completion. 

Effective entities perform a post-sunset and disposal review that confirms the necessary processes were completed and documents lessons learned from shutting down and archiving the terminated system or component. The review should identify archived data and documentation locations. The review may be conducted again within six months of system or component disposal to identify any missed issues that only surface after an extended period of the system or component not being available. 

For more information on sunset and disposal, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations,” “Information Security,” and “Outsourcing Technology Services” booklets. 

141 For more information on data sanitization processes, refer to the FFIEC IT Handbook’s “Information Security” booklet. 

### IV.P Third-Party Relationship Risk Management 

Entities can realize significant benefits from working with third parties such as gaining access to new technologies, human capital, delivery channels, products, services, and markets. However, the use of third parties can reduce an entity’s direct control over activities and may introduce new risks or increase existing risks142 in development, acquisition, and maintenance activities. Increased risk often arises from greater operational or technological complexity, newer or different types of relationships, or potentially inferior performance by the third party. As part of sound risk management, entities engage in more comprehensive and rigorous planning, due diligence, oversight, and management of third-party relationships that support higher-risk development, acquisition, and maintenance activities, including critical activities. Considerations discussed are relevant to each entity’s development, acquisition, and maintenance activities, based on specific facts and circumstances, but may not apply to all of an entity’s third-party relationships. 

#### IV.P.1 Planning 

As part of sound risk management, effective planning allows an entity to evaluate and consider how to manage risks before entering into a third-party relationship. Higher risk and greater complexity development, acquisition, and maintenance services warrant more careful planning and other considerations to mitigate the risk that the relationship will result in material negative impacts on the entity. Refer to the Interagency Guidance on Third-Party Relationships: Risk Management and FFIEC IT Handbook’s “Outsourcing Technology Services” booklet for more information on planning concepts. 

#### IV.P.2 Due Diligence and Third-Party Selection 

Conducting third-party due diligence143 before selecting and entering into relationships is an important part of sound risk management when engaging third parties in development, acquisition, and maintenance activities. Due diligence gives management the information needed to determine whether a relationship would help achieve a banking organization’s strategic and financial goals. Third parties that would support an entity’s higher risk or more complex development, acquisition, and maintenance activities typically warrant a greater degree of due diligence. 

In some instances, the appropriate entity personnel may not be able to obtain the desired initial due diligence information from a third party. For example, the third party may not have a long operational history, may not allow onsite visits, or may not share (or be permitted to share) information that is requested. While the methods and scope of due diligence may differ, the entity’s project management process should identify and document any limitations, understand the risks of such limitations, and consider potential alternatives.144 Management should evaluate the conclusions from such supplemental efforts based on the entity’s own specific circumstances and performance criteria for the activity. Refer to the Interagency Guidance on Third-Party Relationships: Risk Management and FFIEC IT Handbook’s “Outsourcing Technology Services” booklet for more information on due diligence concepts. 

142 Refer to the Interagency Guidance on Third-Party Relationships: Risk Management. 

143 Merriam-Webster defines “due diligence” as “the care that a prudent person might be expected to exercise in the examination and evaluation of risks affecting a business transaction.” Due diligence includes assessing the third party’s ability to perform the activity as expected, adhere to an entity’s policies related to the activity, comply with all applicable laws and regulations, and conduct the activity appropriately. 

#### IV.P.3 Contract Negotiation 

When evaluating whether to enter into a relationship with a third party, an entity’s management typically determines whether a written contract is needed; and, if the proposed contract can meet the entity’s business goals and risk management needs, then entity management typically negotiates appropriate contract provisions145 for development, acquisition, and maintenance activities. In certain circumstances, it may be advantageous to negotiate initial development, acquisition, and maintenance contracts with other organizations (e.g., banking associations or user groups). As part of its oversight responsibilities, the board should be aware of—and, as appropriate, may approve or delegate approval of—contracts involving higher-risk development, acquisition, and maintenance activities. Refer to the Interagency Guidance on Third-Party Relationships: Risk Management and FFIEC IT Handbook’s “Outsourcing Technology Services” booklet for more information on contract negotiation concepts. 

### IV.Q Supply Chain Considerations 

#### Action Summary 

Management should implement SCRM policies and procedures consistent with the entity’s size, criticality to the financial system, and complexity. 

Examiners should review the following: 

* • Relevant policies, standards, procedures, project plans, and any SDLC documentation to determine how the examined entity has incorporated SCRM into its enterprise-wide risk management practices.
* • System and component control configurations and reports used by management to monitor, control, and protect communications at the key access points of information systems that inform SCRM activities.
* • Entity’s architectural designs, system and component development techniques, and systems engineering principles as well as those applicable to the entity’s third parties to maintain effective information security throughout the supply chain. 144 Refer to the Interagency Guidance on Third-Party Relationships: Risk Management. 

145 Ibid.
* • System and service inventories to determine how well the inventories identify all systems and services, how well they categorize each system and service’s criticality, and how well they identify the entire supply chain needed to provide the system or service.
* • Entity’s methods for initially assessing and monitoring after implementation for
* • Entity management’s assessment of supply chain partners’ programs to address inauthentic provenance of systems, components, and data.
* • Communication processes and documented communication of threat intelligence and vulnerability identification with supply chain partners. or unapproved systems or components (e.g., counterfeit or shadow IT).
* • SCRM controls in maintenance-related situations including monitoring for unauthorized modifications, communicating changes, and monitoring for EOL.

NIST defines “supply chain” as “a system of organizations, people, activities, information, and resources, possibly international in scope, which provides products or services to consumers.”146 Supply chains evolve continuously through mergers and acquisitions, joint ventures, and other partnership agreements. Supply chains can be dispersed around the world. 

Entities interact with a supply chain when they develop, acquire, and maintain logical or physical systems or components (e.g., computers, servers, and other hardware components, software, or services), and when they engage with a third party for a service. Even when an entity develops its own systems and components and manages its own infrastructure, it will still periodically interact with one or more supply chains when purchasing additional external hardware, software, raw materials, and services. As entities increase their reliance on third parties for systems, components, and services, supply chains are more complex, diverse, and interconnected. 

If the entity incorporates systems and components from third parties in their development and maintenance activities, consideration of SCRM in the SDLC is appropriate. Awareness of risks arising from integration with suppliers’ systems and components helps with management of associated risks such as compatibility issues, backdoors, or unauthorized access points. Whether developed in-house or by a supply chain partner, additional scrutiny should be applied when custom development of systems and components occurs to ensure proper configuration to meet business and information security needs. 

Supply chain risk is defined as “the potential for harm or compromise that arises as a result of security risks from suppliers, their supply chains, and their products or services. Supply chain risks include exposures, threats, and vulnerabilities associated with the products and services traversing the supply chain as well as the exposures, threats, and vulnerabilities to the supply chain.”147 Examples of supply chain risks include counterfeit goods (e.g., unauthorized systems or components sold as authentic goods), substandard materials, loss of functionality, theft of data or intellectual property (e.g., customer data and logos), and malware inserted into authentic systems and components. 

146 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

147 Refer to NIST Glossary. 

Another supply chain risk is the potential to contract with a third party on the U.S. Department of the Treasury’s Office of Foreign Assets Control (OFAC) Sanctions List or located in countries that are on the list. Management should ensure that the entity’s supply chain partners are not on the OFAC list.148 This may include evaluating the third party’s ownership structure (including identifying any beneficial ownership whether public or private, foreign or domestic).149 To accurately determine whether a third party is on the list or affiliated with companies on the list, it is important to consider any nested relationships through common ownership or any subsidiary or affiliate relationships. It is important to understand risks related to supply chains by tracking interdependencies between all parties involved (e.g., owners and third-party service providers, including vendors) in the supply chain. 

Supply chain risks increase when supply chain partners are unstable financially or during times of economic, cyber, or logistical disruption to the operations and continuity of key supply chain elements.150 These partners include third parties and their supply chain partners (also referred to as fourth parties). Some supply chain attackers use indirect paths and trusted relationships to gain access to the entity for disruptive purposes, financial gain, or to obtain intelligence. Attackers often exploit a third-party service provider’s supply chain to access multiple other victim businesses (i.e., the service provider’s customers) for subsequent attacks. 

#### IV.Q.1 Supply Chain Risk Management 

SCRM is the systematic process for managing supply chain risk by identifying susceptibilities, vulnerabilities, and threats throughout the supply chain and developing mitigation strategies to combat those threats whether presented by the supplier, the supplier’s product and its subcomponents, or the supply chain (e.g., initial production, packaging, handling, storage, transport, mission operation, and disposal).151 SCRM builds on traditional acquisition and procurement practices by adding processes to identify, measure, monitor, and control risks throughout the supply chain. SCRM processes provide entity management with information to help supplement third-party risk management activities (e.g., due diligence and contract negotiation) and procurement of systems or components by presenting all elements in the supply chain for evaluation. 

148 Per the U.S. Department of the Treasury’s Office of Foreign Assets Control’s (OFAC) “Basic Information on OFAC and Sanctions,” “U.S. persons must comply with OFAC regulations, including all U.S. citizens and permanent resident aliens regardless of where they are located, all persons and entities within the United States, all U.S. incorporated entities and their foreign branches. In the cases of certain programs, foreign subsidiaries owned or controlled by U.S. companies also must comply. Certain programs also require foreign persons in possession of U.S.-origin goods to comply.” 

149 Refer to Interagency Guidance on Third-Party Relationships: Risk Management. 

150 Refer to NIST IR 8419, Blockchain and Related Technologies to Support Manufacturing Supply Chain Traceability: Needs and Industry Perspectives. 

151 Refer to NIST Glossary. 

Management should monitor, control, and protect communications (i.e., information transmitted or received) applicable to supply chain-related activities at key access points (e.g., external boundaries and key internal boundaries). Effective management uses architectural designs, software development techniques, and systems engineering principles to promote effective information security in the supply chain by identifying and mitigating potential SCRM-related risk. 

An attempt should be made to identify potential single points of failure among all entities in the entity’s supply chain due to the numerous interconnectivities and risks from all partners. Review of documents, such as system and network topologies and process flow diagrams, may help with identification of these single points of failure. 

NIST identifies SCRM high-level controls in various documents.152 Management should consider the following controls in all development, acquisition, and maintenance activities. 

* • SCRM policies, standards, and procedures that 
	+ o Align with other internal and external policies, standards, and procedures (e.g., information security and business continuity management).
	+ o Instruct staff on how to choose hardware, software, and third-party service providers
	+ o Address system and component supply chain traceability.
	+ o Specify supply chain due diligence for new vendors, third-party service providers, and
	+ o Identify security standards (e.g., percentage of open-source components allowed and
	+ o Specify information protection processes including what data may be shared, the from an SCRM perspective. ongoing supply chain monitoring. The initial assessment should occur during the initiation phase of a project, before new products or services are provided, or new contracts are signed. Due diligence activities should include at least identification and understanding of the criticality of supported function(s), its critical components, and the sensitivity of the information that may be accessible by the supplied system, component, or third party. access requirements) for purchased products and supply chain partners. It is important for management to consider starting with applicable, established national and international standards as a baseline for security requirements for the entity’s supply chain. sharing method, and to whom information is shared (the specific roles). Processes should account for appropriate privacy protections and any dissemination prohibitions, safekeeping, and clearance (e.g., security and access control) requirements.
	+ o Detail information retention and disposal requirements, especially when sensitive and proprietary information of a supply chain partner is concerned.
* • SCRM plan contains steps to assess, monitor, and respond to risks associated with supply chain interaction and procurement activities. The plan describes entity and supply chain implementations, requirements, constraints, and implications at the system level. The SCRM 152 Refer to NIST SP 800-53, rev. 5, Security and Privacy Controls for Information Systems and Organizations, and NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations.
* • General controls and processes are based on the SCRM plan and entity risk assessments. plan can be stand-alone but is often part of an entity’s information security program and third-party risk management program. The plan should address supply chain risks associated with geographic location (e.g., defining acceptable locations). The entity should define roles and responsibilities for personnel (e.g., development, acquisition, and maintenance) to address various risks associated with supply chain activities. Management analyzes the risks and designs controls to mitigate risks to an acceptable level as defined by entity senior management and the board. To promote confidentiality, integrity, availability, and resilience throughout the supply chain, controls and processes should include development, information security (e.g., access control and other relevant laws and regulations),153 procurement, supplier diversity,154 and contractual provisions (e.g., clauses stating that contractual requirements apply to any subcontractors). Management should provide the following: 


	+ o Appropriate protections in the information systems, components, and networks for data
	+ o Tamper-resistance and detection controls for critical components.155 in transit and at rest for the supply chain partners’ information, such as source code testing data, blueprints, and intellectual property.
	+ o Appropriate logging, disparate data correlation, and alerting controls (e.g., access logs, usage pattern reports, and time of day access reports) to obtain evidence in the event of a supply chain compromise.
	+ o Appropriately segregated and isolated environments between the entity and its supply chain partners to minimize the effect of information leakage across IT environments (e.g., development, testing, and production). IT environments. out-of-band validation) for user access to systems and components throughout the supply chain, providing for timely update and periodic review.
	+ o Controls over the use of security assessment and monitoring tools within and between
	+ o Logical and physical access controls, such as identification and authentication (e.g.,
	+ o Current access and authentication lists and appropriate controls to minimize the potential for insider threats as entities develop and acquire systems and components.
	+ o Formal process for assigning identifiers (e.g., names, numbers, and blockchain) to systems and components (e.g., digital and physical) for management and control throughout the supply chain. controls in the entity’s agreements with supply chain partners. systems and supply chain partners’ systems.
	+ o Provisions for physical and logical resilience and appropriate implementation of
	+ o Appropriate monitoring tools and processes at the boundaries between the entity’s 153 Refer to FTC 16 CFR 314, “Standards for Safeguarding Customer Information.” 
	
	154 Management should consider supplier diversity for resilience purposes. If only one supplier is relied upon for products or services and is unable to provide them, business could be interrupted; therefore, additional suppliers should be considered. Conversely, too many suppliers may be difficult to manage, and confidentiality, availability, and integrity or quality of service may be compromised. 
	
	155 Criticality analysis can help determine which components are critical.
	+ • Inventory is a foundational building block for supply chain management. The entity may rely on third parties to support its strategy and operational functions. Management should develop, document, and maintain an accurate inventory of third parties that reflects the entity’s key supply chain partners. Management determines the third party’s criticality based on the systems and components the supplier’s products and services support and the entity’s level of dependency on the supplier for business function. The inventory should be detailed enough for identifying criticality and supply chain risk for tracking and reporting. The inventory should be periodically reviewed and updated, including 
		- o Description of the supplied products and services (e.g., model or software version).
		- o Programs, projects, systems, and components that use the supplier’s products and services (i.e., interconnectivities). component, or service.
		- o Assigned criticality level that aligns to the criticality of the program, project, system,
	+ • Configuration management allows management to track changes made throughout the SDLC to systems, components, and documentation, which is important for tracking details of changes made (e.g., what changes were made, who made them, and who authorized them). Configuration management processes help identify evidence (e.g., baselines and authorizations) used for investigations of potential supply chain cybersecurity compromise. Configuration management is critical to the entity’s ability to establish the provenance of components, including tracking and tracing them through the SDLC and the supply chain. It is important to consider configuration management minimum security requirements for the supply chain. Management should apply appropriate configuration management controls to its own systems and encourage or require the use of comparable controls by all parties in the entity’s supply chain through contracts. For more information, refer to the FFIEC IT Handbook’s “Information Security” booklet.
	+ • Resilience should be considered from the beginning of the SDLC and maintained throughout the useful life of the system or component. This aids in cost reduction and efficiency of implementation and includes planning for alternative third-party service providers and vendors of systems, components, and services. Another resilience consideration is alternative delivery routes if the primary one is unavailable, especially when it applies to a critical provider. Management can improve resilience by using platform-agnostic systems and components that allow for portability that will improve resilience throughout the supply chain. Having multiple third-party sources (i.e., heterogeneity)156 for supply of systems and components can result in alternatives for availability and reduce the potential impact of a supply chain compromise. In those situations, an alternative source of supply allows an entity to more rapidly switch to an alternative system or component that may not be affected. Additionally, having heterogeneous components may help decrease the attack surface and impact of a compromise. This is because all systems and components are not alike; therefore, while they may be exposed to similar risks, they may not be exposed to identical vulnerabilities. Additionally, many risk mitigation solutions used for contingency planning (e.g., alternative storage and processing sites and telecommunication pathways) may have their own supply chains with additional risks. Entity management should understand and mitigate all relevant risks associated with interdependencies throughout the various supply chains potentially affecting the entity. Management should plan for certain scenarios, including 156 Heterogeneity techniques include the use of distributed storage and processing, different Oss, virtualization techniques, and multiple sources of supply. 
	
	
		- o Unplanned system or component failure and subsequent replacement.
		- o Planned replacement related to feature improvements, maintenance, upgrades, and modernization.
		- o Product or service disruption (e.g., loss or degradation of data or operations).Potential supply chain disruptions affect the entity’s operations (e.g., transportation issues, system and component availability problems, or financial difficulties of entities in the supply chain). Management should consider provisions for excess capacity, bandwidth, and redundancy in agreements with supply chain partners and take appropriate mitigation steps, as necessary. For more information, refer to the FFIEC IT Handbook’s “Business Continuity Management” booklet.
	+ • Provenance involves the chronology of the origin, development, ownership, location, and changes to a system or system component and associated data. Provenance may include personnel and processes used to interact with or make modifications to the system, component, or associated data.157 Effective management documents provenance for systems, components, and data, and monitors for changes in the chain of custody that may increase risk to the entity throughout the SDLC. Management should consider producing software bills of material (SBOM)158 for applicable and appropriate classes of software (e.g., purchased, open-source, and in-house developed software). SBOMs should be digitally signed using a verifiable and trusted key, enabling entities to establish provenance. For more information on SBOMs, refer to the “Software Bill of Material” section of this booklet.
	+ • Supply chain partner assessments and reviews should be part of the entity’s third-party and supply chain risk management processes, as appropriate. SCRM assessments should include the supply chain infrastructure (e.g., development and testing environments and delivery systems) and the information systems or components traversing the supply chain and should align with enterprise risk management processes and governance. As part of the risk assessment, the entity should have an accurate inventory of suppliers that identifies their criticality to the business. It is important for entity personnel to consider any information pertinent to the security, integrity, resilience, quality, trustworthiness (e.g., not on the OFAC list), or authenticity of their supply chain partners and products. Management should consistently evaluate supply chain partners consistent with the specific context and purpose for which the assessment is being conducted, selecting additional factors for consideration based on supply chain risk. The quality of information (e.g., its relevance, completeness, and accuracy) relied on for an assessment is an important consideration; therefore, management should document the reference sources. If an entity has a PMO, it can help define requirements, methods, and tools for supply chain partner assessments. Irrespective of the entity’s project management methodology, effective project management processes can help identify critical components, especially those that are used by multiple business lines, functions, systems, and components. For example, effective management considers the following practices: 
	
	157 Refer to NIST Glossary. 
	
	158 NIST Glossary defines “SBOM” as a “formal record containing the details and supply chain relationships of various components used in building software. Software developers and vendors often create products by assembling existing open-source and commercial software components. The SBOM [lists] these components [for a given] product.” 
	
	
		- o Determine whether there is potential foreign ownership or influence and whether the supply chain partner may have relationships with OFAC-sanctioned individuals,
		- o Evaluate supply chain partner oversight of its subcontractors (i.e., fourth parties) or
		- o Identify the level of open-source systems and components used by the entity, and
		- o Conduct research on COTS systems and components (e.g., via publicly available organizations, or countries. developers. determine how the supply chain partner demonstrates its compliance with applicable open-source licensing agreements. resources) or request proof to determine whether the supply chain partner (e.g., original equipment manufacturer [OEM]) has performed testing as part of their quality or security processes.
		- o Use authorized resellers or distributors with an ongoing relationship with the supply
		- o Acquire directly from vetted OEMs or their authorized distributors and resellers when
		- o Track chain of custody of systems, components, and underlying code as they move chain partner for systems and components not directly acquired from an OEM entity. obtaining alternative sources for continued support. Decisions about using alternative sources (i.e., other than OEMs or authorized resellers and servicers) should consider input from all stakeholders (e.g., business lines, IT, CISO, and compliance). throughout the supply chain to minimize the potential for counterfeit or altered products. Use of mechanisms, such as radio frequency identification (RFID), digital signatures, bar code scanning, or blockchain to employ supply chain protection techniques in the acquisition, development, and use of code may be deployed throughout the entity to facilitate tracking chain of custody. These techniques include ensuring that159
			* • Code (including mobile code) originates from vetted sources when acquired.
			* • Vetted system and component integrators are used for the development of custom code before installing.
			* • Verification processes are in place for acceptance criteria before installation to verify the source and integrity of code. chain, including activities to assess an entity’s supply chain partners. Internal audit and assurance activities may include the following: 
				+ o Review of system or component documentation.
				+ o Review of processes for tracking reports to measure adherence to SLAs.
				+ o Use of service provider system and organization control (SOC) reports and other independent review reports to validate that supply chain partners meet the entity’s minimum standards and implement timely corrective actions for identified deficiencies.
		- • Audit and assurance (internal) to validate management’s assessment of risks in the supply 159 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 
		
		
			* o Verification of suppliers’ claims of conformance to contractual security and compliance
			* o Validation of system or component integrity. requirements.
			* o Use of validation tools and techniques (e.g., scanning) for detecting malware or counterfeit goods (e.g., unauthorized systems or components sold as authentic goods). Additionally, management may use manual inspection techniques for identifying genuine components.
			* o Verification of ongoing training to ensure that appropriate personnel are aware of emerging supply chain risks.
		- • Supply chain operational security is important because of the interconnectedness of numerous relationships with supply chain partners and the difficulty in coordinating multiple operational security efforts, which creates the opportunity for a potential breach. Effective management communicates with its supply chain partners to promote awareness of threat intelligence and relevant vulnerabilities in the entity’s supply chain to inform operational security processes. In some situations, entity management may choose to withhold information from supply chain partners to prevent parties with malicious intent from using the information to compromise the entity. To protect against compromise, 
			* o Management should consider employing techniques to introduce randomness160 into entity operations and assets in the entity’s systems or networks. may be accessible in downloads or deliveries of systems and components, whether developed or acquired.
			* o Management should consider concealment techniques, such as masking metadata that
			* o If management considers advanced security protection techniques (e.g., misdirection, honeypots) beyond standard industry techniques (e.g., basic randomness and concealment), it should discuss these techniques with the entity’s legal counsel and board, as appropriate, before implementation, as they may present liability and additional risk to the entity.
		- • Agreements161 between the entity and its supply chain partners should include provisions addressing common supply chain risks, including their applicability to any subcontractors. Agreements should address risks, including the following: 
			* o Personnel162 security controls (e.g., background checks and screening, termination and transfer procedures, and consequences of insider threats) for individuals with access to the entity’s supply chain. 160 For purposes of this discussion, randomness includes randomly switching among several delivery enterprises or routes or changing the time and date of receiving supplier software updates if previously predictably scheduled. For more information, refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 
			
			161 Agreements may include contracts, contract addendums, service level agreements (SLA), and operating agreements. 
			
			162 Supply chain-related personnel, whether internal or third-party, may include acquisition and contracting professionals, program managers, supply chain and logistics professionals, shipping and receiving staff, IT professionals, business owners, system owners, and information security engineers.
			* o Off-boarding procedures to maintain security of entity or supply chain partner information at the close of a contract or end of service to prevent the misuse of sensitive entity or customer information. Agreements should address relationship termination to facilitate a secure off-boarding process (e.g., removing data from cloud environments).
			* o Most recent set of applicable security and functionality requirements as a baseline, with provisions for future enhancement as risk mitigation needs dictate.
			* o Processes to monitor and track the vulnerability of the supply chain, based on the criticality or risk profile of the supply chain partner, system, component, or service. A system, component, and service inventory may help management to identify assets that may be subject to known vulnerabilities. This may provide a starting point for determining the level of vulnerability monitoring needed for systems, components, and services throughout the entity’s supply chain.
			* o Information sharing (e.g., collection, analysis, and distribution) of threat intelligence, incidents, and other key risk indicators throughout the supply chain. The intelligence gathered enables management to proactively identify and respond to threats in the entity’s supply chain. Therefore, management should consider information-sharing clauses in agreements and contracts. management needs to take action to mitigate the risk in some way) information is learned, indicating that a supply chain partner or a system, component, or service is a target of a specific threat.
			* o Procedures and responsibilities of supply chain partners when actionable (i.e.,
			* o Provisions for boundary (e.g., network perimeters) protections, which should be incorporated into agreements with supply chain partners, when applicable. This should address initial implementation of boundary control requirements for interconnected networks in the supply chain. applicable throughout the supply chain. This is a consideration for assessing compliance with Gramm–Leach–Bliley Act (GLBA) provisions.
			* o Inclusion of protections (e.g., encryption) for sensitive information at rest or in transit,
		- • Incident response agreements should include the entity’s notification requirements for imminent threats (e.g., system, component, service, or supply chain partner may be the target of an attack), incidents, and compromises that may affect the entity.163 It is important for management to consider addressing the following incident response-related information in its agreements with its supply chain partners: 
			* o Definition and triggers of an incident. 163 Refer to Computer-Security Incident Notification Requirements for Banking Organizations and Their Bank Service Providers, referenced in agency guidance FDIC FIL-74-2021, “Computer-Security Incident Notification Final Rule,” and OCC Bulletin 2021-55, “Computer-Security Incident Notification: Final Rule.” Implementation is further discussed in FDIC FIL-12-2022, “Computer-Security Incident Notification Implementation”; FRB SR Letter 22-4/Consumer Affairs (CA) 22-3, “Contact Information in Relation to Computer-Security Incident Notification Requirements”; and OCC Bulletin 2022-8, “Information Technology: OCC Points of Contact for Banks’ Computer- Security Incident Notifications.”
			* o Roles and responsibilities, including clear boundaries of responsibility, for incident response processes, including third-party expertise.164
			* o Methods and timing of incident communication with regulators and supply chain partners. These should be defined in agreements with supply chain partners to ensure an efficient, coordinated incident response effort (e.g., speed of communication, response, corrective actions, and other related activities).
			* o Incident response training (e.g., threat briefing or incident response exercises) when appropriate.
			* o Incident response testing with critical supply chain partners, as appropriate.
			* o Review of the agreement based on lessons learned after incidents and any new intelligence.
		- • Tamper resistance and detection processes allow entity management to recognize when unauthorized changes to systems and components are made in transit between the supply chain partner and the entity. Entity or supply chain partner personnel should inspect critical systems and components to ensure that tamper-resistant controls are in place and to determine whether there is evidence of tampering. Systems and components should be reviewed for tampering before use and periodically thereafter. Provisions for this type of review should be included in contracts with supply chain partners.
		- • System or component authenticity and integrity is critical for managing cybersecurity risks throughout the supply chain. Without effective SCRM and ITAM processes, it may be possible for entity personnel or third parties to use counterfeit systems and components. This may allow for potential security, functionality, quality, and legal weaknesses (e.g., counterfeit components may void contracts, warranties, or insurance coverage), leading to compromise of confidentiality, integrity, and availability of systems, components, services, and data throughout the supply chain. By deploying effective system and component integrity controls, management can mitigate cybersecurity risks, such as insertion of malicious code and use of counterfeits, throughout the supply chain. Effective controls include anti-counterfeit policies and procedures that protect against introducing counterfeit systems and components into the entity’s infrastructure (e.g., ATM processor boards with extra communication chips built into the circuitry, noncertified hardware developers). System and component integrity controls may include the following: 
			* o System and component integrity policy and procedures, including the use of various integrity verification tools and techniques. These tools and techniques may include the following: sandboxes. 
				+ • Digital signature or checksum verification.
				+ • Acceptance testing for physical systems and components.
				+ • Verification testing confined to limited-privilege environments, such as
				+ • Code execution restrictions in limited-privilege environments before
				+ • Validation that binary or machine-executable code is obtained directly from the implementation in production. OEM or a verified supplier or distributor. 164 Roles and responsibilities include identification, determination, escalation, notification, handling, analysis, monitoring and tracking, and provisions for third-party expertise (e.g., forensics).
			* o Process to communicate with supply chain partners to identify, report, and correct
			* o Protection from code threats originating from an unauthorized or malicious source in system and component flaws in a timely manner. the supply chain. These protections should be applied throughout the supply chain.
			* o Monitoring for supply chain system and component security and threat intelligence alerts and advisories from supply chain partners. Effective management takes appropriate actions in response. Monitoring processes should include monitoring that lessons learned from prior compromises are appropriately acted upon. For example, if malicious code implanted during software development leads to a compromise, effective controls are implemented to further ensure code legitimacy in the future. It is important for management to consider 
				+ • Correlation of available threat intelligence information (e.g., internally produced and from supply chain partners) to identify potential threats or vulnerabilities requiring mitigation.
				+ • Employment of enhanced monitoring over activities performed by higher-risk personnel (e.g., users with elevated authority or privileges). components exist in the supply chain. Typically, management addresses this issue
			* o Determining periodically whether any counterfeit or shadow IT systems and through contractual provisions with supply chain partners regarding their mitigation program for shadow IT risk. If any are discovered, management should assess the impact of removal, then remove any suspect systems or components from the entity’s infrastructure as appropriate.165
		- • Maintenance includes performing system and component updates and replacements and may be performed by a third party. When performed by a third party, maintenance becomes part of the supply chain and SCRM principles should be applied. Management should perform the following when implementing maintenance processes throughout the supply chain: 
			* o Define agreements that identify roles, responsibilities, and practices that may be used for maintenance activities, especially when third parties are responsible for maintaining the entity’s systems or components.
			* o Monitor for unauthorized modification or removal of the entity’s systems or components (e.g., use of counterfeit systems, counterfeit components, and malware) in the supply chain. Agreements with supply chain partners should address monitoring and communication to affected parties throughout the supply chain.
			* o Monitor systems and components for planning for EOL to prepare for replacement or upgrade to the systems and components. Effective management considers any potential availability issues in the supply chain for systems and components or has agreements to continue support for legacy systems or components until a change can be made without significant disruption to operations.
		- • System or component EOL and disposal processes outline the steps personnel should take when components are nearing EOL and need to be decommissioned and removed from the entity’s infrastructure. Standard EOL processes should be followed. Additional processes related to supply chain activities may involve the following: 165 For more information on shadow IT and IT asset management, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet.
* o Inclusion of data disposal processes to allow entity management to mitigate the risk that entity data maintained by supply chain partners may be retained or compromised.
* o Consideration of supply chain partner interdependencies associated with the removal of a system or component from the entity’s environment, as well as throughout the supply chain. For example, the removal of a supply chain partner’s system or component that may disrupt the entity’s ability to provide continuous service to customers.
* o Sanitization or destruction of information from supply chain partner systems, components, and media before disposal or release for reuse. Agreements should address this for all locations and providers in the supply chain. Off-boarding procedures should be addressed in agreements to maintain data confidentiality, integrity, and availability until the relationship with that supply chain partner is officially terminated.
* o Application of data protection controls (e.g., tracking chain of custody) throughout off- boarding processes for an entity’s data and for the data received from supply chain partners.

Additionally, as a part of SCRM, entity management should consider interconnectivity risks throughout the supply chain. What may initially be assessed as a low-risk activity or asset may be considered a high-risk activity or asset based on the interconnectivity or reliance on that system or component. For example, a system or component (e.g., HVAC, smart TVs, and IoT devices) may not appear high-risk, yet the system or component may be connected to critical systems and components throughout the supply chain, and subject to remote access risks. Therefore, management should have a process to validate the effectiveness of the security of systems and components throughout the supply chain when performing development, acquisition, and maintenance activities, and make appropriate adjustments to risk assessments to account for interconnectivity risk. 

To effectively manage supply chain risks, management should have a clear understanding of interconnectivity in the entity’s supply chain. To facilitate this understanding, management should consider using available information, such as that provided by third-party user groups and associations,166 which can augment ongoing monitoring and due diligence, threat intelligence, and security throughout the supply chain. A vulnerability to one system, component, or supply chain partner may pose a vulnerability to the entire supply chain. Figure 5 depicts diverse supply chain relationships that affect an entity’s visibility and control of the supply chain. Entities depend on the supply chain to provide a variety of products and services to enable the enterprise to achieve its strategic and operational objectives. As NIST states, acquirers often lack visibility and understanding of how acquired technology is developed, integrated, and deployed and how the services that they acquire are delivered. Additionally, acquirers with inadequate or absent SCRM processes and practices may experience increased exposure to cybersecurity risks throughout the supply chain. The level of exposure to cybersecurity risks throughout the supply chain depends largely on the relationship between the products and services provided and the criticality of the missions, business processes, and systems they support.167 Entities have a variety of relationships with their suppliers, developers, system integrators, external system service providers, and other information communication and technology/operational technology- related168 service providers.169 

166 Associations may include standards-setting organizations, such as the National Automated Clearinghouse Association (Nacha), and PCI Security Standards Council (for the payment card industry) and information-sharing organizations (e.g., Financial Services Information Sharing and Analysis Center [FS-ISAC], and other information- sharing and analysis centers [ISAC]). 

Effective management considers risk management factors over the entire life cycle of a third- party relationship, including planning, due diligence, contract negotiation, ongoing monitoring, and termination. For more information on these factors, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services” and “Management” booklets. Additionally, for more information on supply chain relationships, refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

Figure 5: Supply Chain Relationships 

Supplier 

External Service 

Provider 

System integrator 

External Service 

Provider 

Supplier 

External Service 

Provider 

ICT/OT Supplier 

ICT/OT Supplier 

Acquiring 

Enterprise 

REDUCED VISABILITY, UNDERSTANDING, AND CONTROL 

Supplier 

Developer 

Supplier 

External Service 

Provider 

ICT/OT Supplier 

Developers 

Supplier 

External Service Provider 

Supplier 

+ 

167 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations, for more information. 

168 NIST Glossary defines “information and communication technology” as “encompassing the capture, storage, retrieval, processing, display, representation, presentation, organization, management, security, transfer, and interchange of data and information.” It defines “operational technology” as “programmable systems or devices that interact with the physical environment (or manage devices that interact with the physical environment).” 

169 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

& 

##### IV.Q.2 

#### Software Bill of Material 

An SBOM is a formal record containing the details and supply chain relationships of various components used in building software.170 “A primary purpose of an SBOM is to identify components and their relationships to one another, using some combination of baseline component information.”171 There are benefits to supply chain partners including developers, purchasers, and operators of software. An SBOM can help developers of systems and components be aware of any software they might use in development of entity solutions. For purchasers, an SBOM helps identify software supporting a product potentially subject to compatibility issues. An SBOM enables an entity and its operators to determine in a relatively short time whether the entity is affected by a vulnerability and where in the supply chain the entity may have been affected172 because management can match vulnerabilities to elements in the SBOM. 

Management may use an SBOM to identify what systems and components fall outside the entity’s risk tolerance thresholds (e.g., has a significant vulnerability, inappropriate use of open- source components, or is linked to an untrusted provider). An SBOM may help with the management of OEM licensing and compliance and enable management to quickly identify interdependencies and other supply chain risks. An SBOM gives management visibility into systems and components used in the entity’s infrastructure, including open-source systems and components and IoT products.173 This visibility allows management to perform activities such as the following: 

* • Determine whether any of the software or components used in the entity’s infrastructure are subject to specific vulnerabilities or potential risks associated with publicized breaches, as determined through entity threat intelligence processes.
* •
* • Uniquely identify systems and components used by customers and authorized entities. 

Trace users and the use of licenses, allowing management to determine whether access control information is accurate and whether its use is appropriate.

Tools used to read an SBOM should “uniquely identify individual components in a standard format,”174 so that all references are uniform throughout the supply chain. Additionally, an SBOM should be updated whenever software elements are changed or software is updated. 

170 

171 Organizations. 

Refer to NIST Glossary. 

Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and 

172 Refer to National Telecommunications and Information Administration (NTIA), Framing Software Component Transparency: Establishing a Common Software Bill of Materials (SBOM) and “SBOM Myths vs. Facts.” 

173 For more information, refer to NIST IR 8425, Profile of the IoT Core Baseline for Consumer IoT Products, and NIST IR 8259A, IoT Device Cybersecurity Capability Core Baseline. 

174 Refer to NTIA’s Framing Software Component Transparency: Establishing a Common Software Bill of Materials (SBOM) and “SBOM at a Glance.” 

& 

SBOMs typically do not identify intellectual property, patents, algorithms, or code; if they do, management should implement appropriate security for this proprietary information. 

NIST states that as SBOMs mature, management should help ensure that they do not deprioritize existing SCRM capabilities (e.g., vulnerability management practices and vendor risk assessments) under the mistaken assumption that SBOMs replace these activities. Accurate SBOMs are meant to provide improved transparency, which is complementary to an entity’s risk management practices, not a substitute for them. “Entities that are unable to appropriately ingest (i.e., recognize and understand), analyze, and act on the data that SBOMs provide likely will not improve their overall SCRM posture.”175 

#### IV.Q.3 Enterprise Risk Management and Supply Chain Risks 

SCRM touches on risk management activities across the entity and should be incorporated into enterprise and technology risk management activities. A few examples of security elements tied to SCRM include the following: 

* • Confidentiality: Supply chain partners may receive sensitive entity and customer information.
* • Integrity:
* • Availability and resilience: Systems, components, or services may not be available or Systems or components may not operate as designed, leading to a data integrity issue, or third parties may intentionally or unintentionally change entity, partner, customer, or consumer data. recoverable when needed.

According to NIST, “Managing supply chain risk is a complex, multifaceted undertaking that requires a coordinated effort across an organization to build trust relationships and communicate with internal and external stakeholders.”176 Supply chain activities occur throughout the SDLC; therefore, SCRM should be embedded throughout the SDLC.177 Additionally, when applicable, management should incorporate third parties into business continuity and resilience activities throughout the supply chain. 

175 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

176 Refer to NIST 800-53, rev. 5, Security and Privacy Controls for Information Systems and Operations. 

177 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations. 

& 

## V DEVELOPMENT 

### Action Summary 

Implementation of sound processes for the development of systems and components supporting the entity’s business needs and operations is important. 

Examiners should review the following: 

* • Documentation of training in secure design and coding techniques for those entity
* • Development standards, including procedures for managing changes and a back-out plan.
* • Evidence of communication throughout the supply chain regarding identification of critical personnel who are responsible for development. systems and components, potential threats and vulnerabilities, configurations, and responsibilities for selection and maintenance of system and network components.
* • Entity coding standards and list of entity-approved software development languages.
* • Documentation of security certification for completed systems and component-related
* • Development designs used to validate security and functionality throughout the supply
* • Risk assessment documentation related to the use of or switch to a development operations code. chain. (DevOps) approach, or extending to a development security operations (DevSecOps) approach, and effectiveness of controls.

Development is the systematic application of knowledge toward the production of useful materials, devices, and systems. In this context, it involves the processes of defining, designing, developing, testing, and implementing systems or components. Development includes validation and demonstration of a chosen technology, use of test and production environments, improvement of developed prototypes, integration into systems and subsystems, and hardware builds. Understanding development concepts is important to all entities whether development is performed in-house or by a third party on the entity’s behalf. Additionally, development can be a complex topic, which requires the entity’s board, senior management, and business line management to understand risks and communicate effectively. For entities that develop or modify their own systems and software, effective management requires training in secure design and coding techniques of those responsible for development. If formal standards are not in place and development processes are not controlled, the following can occur, affecting confidentiality, integrity, availability, and resilience: 

* • Corruption (e.g., malware or sabotage) of the development process.
* • Unintentional creation of vulnerabilities (e.g., backdoors or open ports).
* • Omission or errors in process or code (e.g., intended processes that were forgotten or calculations that are incorrect) resulting in production issues (e.g., disruptions or delays). Entity personnel should maintain and follow documented development policies, standards, and procedures that result in systems and components that meet the entity’s requirements for confidentiality, integrity, availability, and resilience. Standards and procedures should identify approved development tools and tool configurations in the development process or in a specific development methodology. 

When engaged in development, management may consider using design and coding techniques, appropriate tools (e.g., computer-aided design), and prototypes. When development personnel use design and coding techniques, they should appropriately manage risks (e.g., eliminating inaccurate techniques or outdated tools and prototypes). Prototypes may help illustrate a system’s or component’s functionality to stakeholders and help management identify, evaluate, and highlight design risks not apparent during the impact analysis or before production. Then the design risks may be resolved more efficiently. There are alternatives to prototyping, such as defining and building a system or component with only enough features to accomplish the essential user objectives of the system. 

As part of the SDLC, effective management works toward developing a trustworthy system. From a security perspective, a trustworthy system178 meets specific security requirements and other critical requirements defined and set by entity management. To help develop a trustworthy system, management should employ secure program coding practices. Secure coding practices help developers minimize the potential for known source code-related vulnerabilities in the development phase. 

Examples of secure coding practices include the following:179
* • Validate all inputs and validate and properly encode all outputs.
* • Avoid using unsafe functions.
* • Detect and correct errors effectively.
* • Provide logging and tracing capabilities.
* • Consider use of automated features that encourage secure coding practices in development
* • Establish procedures for manually applying secure coding practices when automated methods
* • Use tools (e.g., linters180 or formatters) to analyze code, identify common mistakes and bad
* • Check for common system, code, and development environment vulnerabilities.
* • Assign developers to review code to complement (not replace) independent code review and environments, when appropriate. are insufficient or unavailable. coding style, and standardize the style and formatting of the source code. verify compliance with security requirements. 178 Refer to NIST SP 800-160, vo1. 1, rev. 1, Engineering Trustworthy Secure Systems. 

179 Refer to NIST SP 800-218, Secure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software Vulnerabilities. 

180 For purposes of this booklet, a “linter” is a type of tool used to perform code analysis to flag issues, such as programming errors, bugs, and stylistic errors.
* • Identify and correct vulnerabilities before release of software to production to prevent exploitation.

Developers should communicate throughout the supply chain to ensure that partners are aware of potential threats and vulnerabilities when developing, testing, and maintaining systems and components. Additionally, the individuals responsible for selecting system and network components should incorporate supply chain processes when choosing such components. Developer training should include secure coding and the use of tools to find vulnerabilities in systems and components across the supply chain. For more information, refer to the “Supply Chain Considerations” section of this booklet. 

### V.A Development Standards and Controls 

Management should establish development standards, including procedures for controlling changes during the development process that address the following: 

* • System controls, including a system’s or component’s functionality, security, automated
* • Quality management (also referred to as quality assurance and quality control [QA/QC]), control features, and coding standards. including the development and implementation of a system or component so it meets predefined specifications and management’s expectations.
* • Release management, including migration of the final release of systems or components from a development or development testing environment into the production environment for deployment. This may include multiple steps. A release can be completed manually, or the release process could be automated. Established rollback instructions, or back-out plans, should be developed and available in the event of unforeseen deployment problems.
* • Documentation to facilitate stakeholders’ understanding of the following: 
	+ o Development process.
	+ o Error correction and program modification processes.
	+ o System or component business functionality.
* • Reporting, including processes for generating and managing reports (e.g., types of reports, timing, and stakeholders who should receive them) during development to help management make important budgeting and other data-driven decisions. Reports could include project updates, technical issue logs, and change management logs.

Development standards should articulate the entity’s minimum development requirements. For example, development standards may address the selection of programming styles, languages, and tools; layout or format of scripted code; naming conventions; and program library requirements. Effective management communicates in policy its reasons for using specific programming styles and languages on a project or service in project documentation. This is done to identify decisions made by management so developers can understand the reasons certain programming styles and languages were used and whether they remain appropriate for current functionality and stakeholder needs. Examples are included in table 3. 

& 

Table 3: Descriptions and Reasons for Using Programming Styles and Example Languages 



| Programming style | Description | Why | Example languages181 |
| --- | --- | --- | --- |
| Compiled | Source code converted into machine language before the code can operate | and execution speed (for transactions) is essential. * • Useful when resources are limited * • Less portable than hybrid or | C, C++, GO, Swift, Objective-C, Visual Basic |
| Hybrid (compiled and interpreted) | Uses a combination of compiled and interpreted languages programming style | and random access memory [RAM]) * • Portable and slower than compiled. * • Requires more resources (e.g., CPU than compiled, but less than | Java, C#, Clojure, Scala, Spark, Prolog |
| Interpreted182 | Lines of code that can operate without first being compiled | * • Less complex than compiled or * • Easier to find trained developers, as hybrid programming styles, but requires more resources (e.g., CPU and RAM). less technical knowledge is needed | Python, JavaScript, PowerShell, PHP, Structured Query Language (SQL), Ruby, Perl, Lua, Delphi |
| Assembler | Converts assembly instructions into machine language | * • Useful when you need to minimize * • Often used for firmware. resources (e.g., CPU and RAM) needed to implement the code. | Assembly |
| Markup language | Language with rules and instructions accompanying the code, which facilitates use by humans and programs | * • Useful when text needs to be formatted in a specific way (e.g., font, color, and size). | HTML, XML, SGML |
| Legacy | Older programming languages that potentially are unsupported, general use is declining | * • Personnel with knowledge of code development and use is declining, making it difficult to maintain and upgrade. * • Concerns related to programming style in sunset phase of SDLC. | FORTRAN, COBOL, APL, ALGOL, LISP, PASCAL, Assembly, REXX, JCL |


interpreted languages due to the need to recompile for each new system. 


interpreted language. 

to implement the code. 

The use of naming conventions183 for a software program’s modules and any related subroutines, databases, or programs that interact with an application help a team of developers work more efficiently together. For example, naming convention use promotes consistency so programmers can link subroutines into a unified program more efficiently. Naming conventions also facilitate understanding so IT staff not involved in the original development can later modify systems efficiently. Finally, use of naming conventions often facilitates software code reuse and repurposing. 

181 Languages may be applicable in several different language styles; these are just examples. 

182 An interpreted programming style refers to processing a script or other program expressions line by line and in accordance with the language requirements, without first compiling a program into machine instructions. 

183 NIST defines a “naming convention” as “a collection of rules, which when applied to data, results in a set of data elements named in a logical and standardized way. These names inform the user about the contents of the data value domain, and the usage of the data element, in a concise manner.” 

To establish development standards and controls, prudent practices include thorough development testing and validation of systems and component-related code. Effective management keeps completed systems and component-related code that have passed security certification in program libraries as discussed in the “Additional Control Considerations in Change Management” section of this booklet. 

Due to supply chain risk in development, for both in-house and supply chain partners, it is important to consider using the following standards and controls when developing information systems and components: 

* • Design security controls to be difficult to disable (e.g., tamper-proofing techniques), and, if they are disabled, trigger notification methods such as audit trails, tamper evidence, or alarms.
* • Design delivery mechanisms (e.g., downloads for software) to avoid unnecessary exposure or access to the supply chain and systems or components traversing the supply chain.
* • Design relevant validation mechanisms to be used during implementation and operation.

Developer configuration management is critical for reducing cybersecurity risks, both in-house and throughout the supply chain. Developers should manage the configurations of the development environments in which they are working. They should create configuration guides for the systems and components they are developing for distribution with the system or component. By implementing configuration management standards and controls, developers reduce the occurrence and likelihood of flaws while increasing accountability and ownership for the changes. Developer configuration management should be performed by developers, including any third parties involved in the process. 

If management decides, based on assessments of risk throughout the supply chain, that customized development of certain critical systems and components is necessary, then it should have agreement on standards and controls used in customized system and component development throughout the supply chain. Whether developed in-house or by a supply chain partner, additional scrutiny should be applied when custom development of systems and components occurs to ensure proper configuration to meet business and information security needs. Management should work with suppliers and partners to ensure that critical systems and components are identified. Effective management helps ensure that suppliers or the entity itself has a continued ability to maintain customized systems and components that are critical to the entity’s operations. For example, having the source code, build scripts, and tests for a software component could enable an entity to have a third party maintain the system or component if necessary. For more information, refer to the “Escrowed Source Code Agreements and Documentation” section of this booklet. 

### V.B Testing 

#### Action Summary 

Management should maintain testing policies, standards, procedures, as well as other process controls that are effectively used to mitigate risks in internally and externally developed systems and components. 

Examiners should review the following: 

* • Testing policies, standards, and procedures, as well as other process controls, to evaluate
* • Testing scope documentation, including for application interoperability and vulnerability
* • Documentation regarding controls over the use of production data in testing.
* • Documentation of the type of testing, testing results, corrective actions, and testing
* • Documentation of testing for any new controls added to systems and components to avoid how well entity personnel use testing to confirm that systems and components meet the entity’s requirements. discovery. completion. conflicts (e.g., integration and interface, security) resulting in failed business processes.
* • Any updates to manuals and training plans after testing.

Testing is essential to the development process to promote confidentiality, integrity, availability, and resilience. Whether developed internally or by a third party, appropriate personnel should test systems and components to identify and correct defects before deployment, including security-related defects. 

Testing should be sufficient to confirm that systems and components meet the entity’s architectural, functional, information security, and legal/regulatory requirements. To help mitigate the risk that an integration point contains an undiscovered defect, entities test the system or component being developed, including how well that system or component interoperates with other systems and components. This scope is commonly achieved through a combination of code-level, system-level, and code vulnerability testing. 

Starting test plans no later than the development and acquisition phase helps teams test more comprehensively than if they wait to create test plans later in the SDLC. Additionally, the level of detail in the test plan and script should match the level of risk the system or component presents to the examined entity’s business. The more detailed test plans and scripts are, the higher the likelihood that testers will identify defects before system or component implementation. 

Using production data in testing may provide assurance that the system or component functions as expected; however, there are significant risks (e.g., unauthorized access to or modification of sensitive entity or customer information). Management should determine the need for using production data in testing and employ appropriate controls if its use is deemed necessary. When possible, testers should use simulated synthetic data or sanitized184 production data during system or component development and testing185 to protect sensitive customer and entity data. Data used for testing should not include sensitive customer information unless the data are sanitized186 before testing, and this should be addressed in policy. Due to the risks involved with actual customer data, when sanitizing data is not feasible, management should document an exception to board-approved policy for its use. Implementation and maintenance of controls similar to those used in the production environment should be used to appropriately protect the data for compliance with legal and regulatory requirements. The Information Security Standards require safeguarding of sensitive customer information regardless of the environment (e.g., testing, QA, or production) where the information resides.187 For more information, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” and “Information Security” booklets. 

The types of testing188 performed should be appropriate for the development activity’s inherent risk. Effective management has a methodical process to define and conduct testing necessary to demonstrate the effectiveness of a developed system or component. Typically, testing is performed in stages, and knowledgeable testing specialists and relevant stakeholders should be involved in testing. Regardless of the process, various tests may be used individually or in combination at different points in the development and testing phases. During system or component development, developers perform code reviews, which typically occur as part of the testing process. Appropriate personnel can perform testing manually, with automated tools, or a combination of both. 

184 Data sanitization disguises (i.e., anonymizes) sensitive information in test and development databases by overwriting the information with realistic looking but false data of a similar type. Some forms of sanitization include NULLing out, masking data, substitution, shuffling records, and encryption. For more information, refer to NIST SP 800-160, vol. 1, rev. 1, Engineering Trustworthy Secure Systems. 

185 Refer to NIST SP 800-160, vol. 1, rev. 1, Engineering Trustworthy Secure Systems. 

186 Data sanitization can help minimize risks related to unauthorized access of that data. Unsanitized data passed to other systems or subsystems (e.g., command shells, relational databases, and commercial off-the-shelf [COTS] components) may be vulnerable. Attackers may be able to exploit unused functionality to access, manipulate, or exfiltrate the data causing legal, reputation, and operational risk to the entity. Additionally, that data may provide information to attackers, allowing for unauthorized lateral movement throughout the network, systems, and components. 

187 Refer to GLBA, further implemented by FFIEC members as follows: FDIC: 12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards,” and 12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice”; FRB: Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards,” and Regulation Y, 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards”; NCUA: 12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information;” OCC: 12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards.” Additionally, refer to FTC 16 CFR 314, “Standards for Safeguarding Customer Information,” for similar provisions for service providers. 

188 For purposes of this section, NIST IR 8397, Guidelines on Minimum Standards for Developer Verification of Software, defines “testing” as “any technique or procedure performed on the software itself to gain assurance that the software will perform as desired, has the necessary properties, and has no important vulnerabilities.” 

While the testing types, such as dynamic testing, may be performed during multiple phases, commonly performed testing in the development and acquisition phase includes the following: 

* • Static analysis: Personnel detect software vulnerabilities by examining the application
* • Unit testing:191 Developers perform unit tests to assess the functionality of small modules of source code and binary code and attempting to analyze and identify all possible behaviors that might arise at runtime.189 An example of static analysis is software application security testing, which analyzes the quality of the code.190 code.
* • Security testing: Developmental testing helps ensure that the technical and security features and functions of the system perform as intended.192 This may include initial penetration testing of the code.
* • Dynamic analysis: Personnel use testing that operates by executing a program using a set of input use cases and analyzing the program’s runtime behavior. Testing may be extensive (i.e., time-consuming) depending on the number of scenarios analyzed. An example of dynamic, execution-based scans is dynamic application security testing, which is intended to simulate real-world attacks.193

The development team should document the results of testing performed. Documentation should include the type of testing performed, scope of the testing, test results, further action based on results of the test (e.g., error correction, patch, or retest), and whether the testing is considered complete. Appropriate personnel can provide a report communicating the test results to management as appropriate. 

Commonly performed testing in the implementation and assessment phase includes the following: 

* • System testing: Testing is performed on a complete system to evaluate its compliance with
* • Additional security testing: If new controls are added to the system, additional acceptance specified requirements. tests of those new controls should be performed to help ensure that new controls meet security specifications and do not conflict with or invalidate existing controls or functionality.
* • Integration testing: Personnel perform an orderly progression of testing in which software elements, hardware elements, or both are combined and tested to evaluate their interactions, until the entire system has been integrated.194 A primary goal of integration testing is to ensure that systems and components function appropriately together. This is especially difficult when software uses components developed by different vendors, in different languages, and the implementation sources are not all available.195 189 Refer to NIST 800-163, rev. 1, Vetting the Security of Mobile Applications. 

190 For more information, refer to OWASP Vulnerability Management Guide (OVMG). 

191 Information Systems Audit and Control Association (ISACA) Glossary defines “unit testing” as “a testing technique that is used to test program logic in a particular program or module. The purpose of the test is to ensure that the internal operation of the program performs according to specification. It uses a set of test cases that focus on the control structure of the procedural design.” 

192 Refer to NIST ITL Bulletin, “The System Development Life Cycle.” 

193 For more information, refer to OWASP Vulnerability Management Guide (OVMG).
* • UAT: Personnel perform testing that involves taking use cases or procedures for how the system was designed to perform and ensuring that someone who follows the procedure gets the intended result; however, it does not necessarily demonstrate how well the system supports users in performing those functions.196 Therefore, UAT is not used to determine usability. UAT generally occurs toward the end of development testing activities. UAT may be useful for validating procedures and user training on the operation of new or significantly changed systems and components.
* • Regression testing: Personnel execute testing that involves the performance of the same tests many times to determine whether to return to the prior state. A retest of a system or component helps to assess functionality after programmers make code changes following previous tests. Regression testing generally includes systems that may not have changed but may be affected by a new or changed system or component.
* • Stress testing: For purposes of this discussion, this refers to testing performed to determine the limitations of a system or component. IT personnel periodically test to determine whether the entity’s system or component can handle the anticipated maximum volume or duration of activity while maintaining required functionality. This may be performed using automated testing tools that generate simulated scenarios.

Regardless of the testing methods used, management should implement practices to document, report, and address identified issues, including security-related issues, in a timely manner. Tracking corrections and modifications resulting from testing facilitates the completeness of the overall program documentation. During the implementation and assessment phase, effective management reviews and finalizes all supporting documentation, such as user, operator, and maintenance manuals as well as any conversion, implementation, and training plans associated with a new release or significant update. 

### V.C DevOps and DevSecOps 

DevOps builds on agile principles and is a software engineering culture and set of practices designed to unify software development and operations. DevSecOps takes DevOps one step further by integrating security (“Sec” stands for “security”). The following subsections of this booklet provide more information on DevOps and DevSecOps. 

194 Refer to ISACA Glossary. 

195 For more information, refer to Leonard J. Gallagher and Jeff Offutt, Test Sequence Generation for Integration Testing of Component Software. 

196 Refer to NIST IR 7741, NIST Guide to the Processes Approach for Improving the Usability of Electronic Health Records. 

& 

#### V.C.1 DevOps 

DevOps is a “set of practices for automating the processes between software development and information technology operations teams so that they can build, test, and release software faster and more reliably. The goal is to shorten the SDLC and improve reliability while delivering features, fixes, and updates frequently in close alignment with business objectives.”197 DevOps is used to promote coordination and communication between development and operations teams (e.g., developers, testers, or operations personnel). For example, a group of developers can be embedded with the operations team to acquire domain-specific expertise, allowing them to better understand applicable business processes in a given area of the entity’s systems. The operations team benefits from having developers readily accessible to help operations personnel better understand the entity’s developed applications and IT infrastructure. 

Using DevOps practices, personnel can automate tasks that were previously performed manually. For example, a DevOps team can automate configuration management processes (e.g., firewall rules, server hardening, and mobile device management). DevOps practices often include containerization, which allows applications to be implemented as microservices. For more information on containers and microservices, refer to the “Common Development, Acquisition, and Maintenance Risk Topics” section of this booklet. 

Automation and orchestration give the DevOps approach several benefits including shorter development cycles, increased deployment frequency, faster time to market, and more stable operating environments. In the past, entities may have had changes that took place on a weekly basis; however, in a DevOps environment, the same number and type of changes can be made daily or even hourly. However, automation of previously manual activities, combined with frequent and rapid release cycles, may result in perpetuation of errors or invalid code. Management should assess the risks involved in using a DevOps approach and implement appropriate controls. Potential risks include the following: 

* • Misconfigured process automation (e.g., quality and release management).
* • Unclear governance practices, such as inadequate development standards and procedures and
* • Inappropriate metrics or tracking measures.
* • Unauthorized code access and modification via unsecured code repositories (e.g., GitHub).
* • Lack of cyber hygiene (e.g., inappropriate configurations or unscanned and vulnerable
* • Developers being able to use uncontrolled and insecure system images.
* • Inadequate controls over code implemented in production (e.g., bypassing the entity’s coding a lack of validation of effectiveness. systems are released). standards).
#### V.C.2 DevSecOps 

DevSecOps is the evolutionary progression from DevOps that integrates security objectives and controls (e.g., metrics and compliance reports) into the development process. The main characteristics of this practice are to automate, monitor, and apply security at all phases of the SDLC. Automation of the workflows and integrated security testing is a key attribute of DevSecOps. Additionally, automation of testing (e.g., unit testing, code analysis, and image scanning) provides timely feedback to DevSecOps teams while not obstructing productivity. Cybersecurity and design have the same priority as they would in traditional system and component development. Security resources are integrated at the outset of the development process. DevSecOps is a key approach used in cloud development environments. Cloud-native applications require updates and deployment techniques to be flexible and secure for business reasons, as well as resilient to respond to cybersecurity events.198 

197 Refer to NIST SP 1800-16, Securing Web Transactions: TLS Server Certificate Management. 

Coding services and tools can be used to automate and implement security faster in the development process, allowing for quicker implementation. NIST notes that DevSecOps can be used with the following types of coding and coding services:199 

* • Application code: Code used for one or more business functions, made up of code describing the business transactions and any database access.
* • Application services code (e.g., service mesh code): Provides various services for the application, such as service discovery, establishing network routes, network resiliency services (e.g., load balancing, retries), and security services (e.g., enforcing authentication and authorization based on policies).
* • Infrastructure as code: Expresses the computing, networking, and storage resources needed to run the application in the form of declarative code. parameters for realizing security objectives through security controls (e.g., authentication and
* • Policy as code: Contains declarative code for generating the rules and configuration
* • Observability as code: Code that triggers automation of software related to logging all authorization) during runtime. transactions, tracing communication pathways involved in executing application requests, and monitoring applications during runtime.

As infrastructure and development activities have moved to a cloud-based environment, the use of the term “as code” is often added to the type of technique. Further, “when using ‘as code’ techniques, the code that is written (e.g., for provisioning a resource) is managed like application source code. This implies that it is versioned, documented, and has access controls defined similarly to what is done for an application source code repository.”200 In addition, some on- premises hardware components may be replaced and deployed as software in cloud-based environments. 

198 Refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

199 Ibid. 

200 Ibid. 

& 

DevSecOps makes use of the continuous integration (CI)201 and continuous delivery (CD)202 or continuous deployment203 pipeline (see figure 6) during the SDLC, depending on whether the entity uses automation to move code into production. The U.S. Department of Defense (DOD) defines this CI/CD pipeline as “the set of tools and the associated process workflows to achieve CI/CD or continuous deployment with build, test, security, and release delivery activities, which are steered by a CI/CD orchestrator and automated as much as practice allows.”204 

Developers digitally sign code in the CI/CD pipeline process. This helps with determining code integrity. For example, downstream evaluations can compare the expected code author’s name to the name of the person who last changed the code and take appropriate action if they do not match. 

Figure 6: CI/CD Pipeline Process Workflow 

</> 

Commit 

Code 

-(C 

T 

- 

A 

Unit and 

Integration 

Tests 

Deploy to 

Testing 

Environment 

Acceptance 

Tests 

Deploy to 

Production 

Environment 

CONTINUOUS INTEGRATION (C1) 

CONTINUOUS DELIVERY (CD) CONTINUOUS DEPLOYMENT 

During CI (as illustrated above), developers frequently merge code changes into a central repository where automated builds and tests run.205 CI activities include committing code (i.e., establishing 

201 Continuous integration (CI) involves developers frequently merging code changes into a central repository where automated builds and tests run. Build is the process of converting the source code to executable code for the platform on which it is intended to run. When developers use CI to deploy new software, the developer’s changes are validated by creating a build and running automated tests against the build. This process avoids the integration challenges that can happen when waiting for release day to merge changes into the release branch. For more information, refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

202 NIST defines “continuous delivery” as “the stage after CI when code changes are deployed to a testing or staging environment after the build stage.” For more information, refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

203 NIST defines “continuous deployment” as “similar to continuous delivery except that the releases happen automatically, and changes to code are available to customers immediately after they are made.” For more information, refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

204 Refer to DOD’s DoD Enterprise DevSecOps Reference Design: Version 1.0. 

205 For a definition of CI, refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

& 

version control, in which a snapshot is taken of the current code changes and saved to a repository), developers packaging up code (i.e., bundling of related code) or revisions to code, and automated initial code testing (such as unit and integration testing). 

Management often uses CI processes to put the entity’s apps into containers directly in the build process itself. Also, during CI, code is uploaded into a central repository where automated tools validate and initially test the code. The purpose is to avoid inconsistency from the very beginning of an app’s life cycle to help ensure consistency in the app’s runtime environment (i.e., the environment in which a program is executed). Many organizations may see developers build in one environment, test in another, and deploy in a third, so having consistency in assessment and enforcement across these environments is key.206 

Once the code is initially validated and tested, CD automatically deploys code to the formal testing environment for acceptance testing. Within the CD segment illustrated above, code is deployed to production manually, using scripts to assist in the configuration. In continuous deployment, rather than manually, deployment occurs when the entity automates the deployment process, and code is available to users immediately. 

NIST documents the following resources and tools used in the CI/CD pipeline process: 

207 

* • Pipeline software. 

o 

CI software: Pulls code from a code repository for building the software, facilitates initial testing tools, and saves tested artifacts to an image registry (i.e., repository for copies of code to maintain coding integrity). 

o 

CD or continuous deployment software: Pulls artifacts from the repository and deploys the package.
* • Development software. environments). 

o 

Build tools: Used for constructing software (e.g., for integrated development 

o 

Testing tools (e.g., software application security testing, dynamic application security testing, or software composition analysis).
* • Repositories. 

o 

Source code repositories (e.g., GitHub). 

o 

Container image repositories or registries.
* • Observability or monitoring tools. 


	+ o Logging and log aggregation tools.o 

o 

Tools that generate metrics. 

Tracing tools (e.g., sequence of application calls). 

206 Refer to NIST SP 800-190, Application Container Security Guide. 

207 For more information, refer to NIST 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

o 

Visualization tools (e.g., used to combine data from all development activities to generate dashboard/alerts). 

NIST recommends the following controls to secure the CI/CD pipeline process:208
* •
* •
* • Harden servers hosting code and artifact repositories. 

Secure credentials (e.g., authorization tokens) used for accessing repositories. 

Implement controls on who can check in and check out artifacts in container image registries. These registries store artifacts produced by the CI pipeline and serve as bridges between the CI and CD pipelines.
* •
* • Log all code and build update activities. 

Send build reports to developers and stop further pipeline tasks when a build or test fails in the CI pipeline. Code repositories should be configured to automatically block all subsequent pull requests from the continuous deployment stage of the pipeline until issues are resolved.
* •
* •
* • Digitally sign (preferably multiparty digital signing) the release artifact during each required CI/CD stage during the build and release process.
* • Verify that all required digital signatures are present during production release to ensure that

Send build reports to the security team and stop further pipeline tasks when an audit fails. 

Ensure that developers can only access the application code. no one bypasses the pipeline. 

Figure 7 provides an overview of the CI/CD pipeline. Automated security testing is performed throughout development phases and throughout production. 

Figure 7: CI/CD Pipeline Architecture209 

DEVELOP 

BUILD 

DEV 

TEST 

SEC 

DEPLOY 

##### OPS 

MONITOR 

Elvaedo 

208 Refer to NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh. 

209 

Refer to DOD’s DoD Enterprise DevSecOps Reference Design: Version 1.0. 

### V.D Functional Development Types 

Functional development types include hardware, software, front end, and backend. Examples of hardware developed for the financial sector are point-of-sale terminals, mobile card readers, credit cards, and managed security devices. Examples of software developed for the financial sector are mobile banking apps, online banking systems, loan estimators, core banking systems, transaction monitoring systems, and imaging systems. Development of either hardware or software may include a combination of backend and front-end development types. Backend refers to the parts of systems that are not seen by the end user. Front end refers to the parts of systems that the end user sees and uses. Understanding that there are different functional development types is important for development teams as each development type may have unique procedures (e.g., steps and timing), include various reporting lines (e.g., internal and external stakeholders, including management), and address different risks (e.g., physical and virtual) depending on the project. 

Functional development types can include the following: 

* • Hardware development: Hardware development includes integrating hardware with software to provide a user experience that supports the business use cases. This includes designing and building the physical aspects of a hardware component. Hardware may include servers, circuit boards, credit cards, ATMs, point-of-sale terminals, and mobile reader devices. The hardware developer designs the system, selects components, builds prototypes, and coordinates testing. The developer generally has in-depth knowledge of software development because developing hardware requires using complex design tools and programming skills. Hardware development includes incorporating firmware and producing circuitry concepts and circuit diagrams, which are then put into operation. The developer designs circuit board layouts and programs microchips and microcontrollers. They develop and simulate digital signal and image processing. They are responsible for maintenance and testing as well as preparing manufacturing documents and product documentation. Hardware developers are sometimes referred to as electronics developers or hardware designers.
* • Front-end (or client-side) development: Front-end210 development can be facilitated through hardware or software-based solutions. A front-end developer works toward providing an effective end-user experience. This includes anything (e.g., text and layout, touchscreen, and icons) the user interacts with on their devices (e.g., PCs, tablets, mobile phones, and ATMs). Developers combine design, technology, and programming to create user interfaces that provide clear and understandable products with end-user appeal. Another front-end consideration is the importance of integrating the business line product rules (e.g., rules for negative interest rate changes or loan-to-value limitations) into the user interface. Front-end development may include web development, desktop development, mobile development, and graphics development. 210 Merriam-Webster defines “front end” as “a software interface (such as a graphical user interface) designed to enable user-friendly interaction with a computer.” 

&
* • Backend development (or server-side development): Backend211 development can be facilitated through hardware or software-based solutions. Backend development includes developing databases, internal APIs, business logic, microservices, web integration, servers, and server-based utilities. Users interact directly with the front end to communicate and engage with the backend, which is not visible to end users. Backend developers should understand front-end development and vice versa. Without that understanding, the risk of noncompliance with laws and regulation increases. For example, financial institution customers rely on loan calculators to provide accurate results relevant to their input scenario. Visible and correct results are only possible if the user interface is clear (front-end development) and the calculations are accurate (backend development).
* • Big data development: Big data development focuses on using, organizing, and maintaining large amounts of data that may originate from many sources. Big data development includes building data mining, data visualization, and quantitative analysis tools. In addition to developing specific tools, big data developers work with analysts to help them decide whether a set of data are appropriate for their analytics. Big data development can result in maintaining petabytes of complex unstructured, semi-structured, and structured data without rigid schemas. When appropriately controlled, big data can enable cost-effective processing of massive volumes of data, support multiple concurrent queries and other analytics tasks, and rapidly generate results. However, if big data environments are not adequately controlled, costs may increase rapidly, and the examined entity may rely on inaccurate information for business decisions. For additional information on big data, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet.

The following subsections of this booklet provide more information on additional development types, including model development and database development. 

#### V.D.1 Model Development 

For purposes of this discussion, “model” refers to a quantitative method, system, or approach that applies statistical, economic, financial, or mathematical theories, techniques, and assumptions to process input data into quantitative estimates.212 A model consists of three components: an information input component, which delivers assumptions and data to the model; a processing component, which transforms inputs into estimates; and a reporting component, which translates the estimates into useful business information. Models meeting this definition may be used in the following: 

* • Analyzing business strategies.
* • Informing business decisions.
* • Identifying and measuring risks.
* • Valuing exposures, instruments, or positions.
* • Stress testing. 211 Merriam-Webster defines “backend” as “the part of a software system that is not usually visible or accessible to a user of that system.” 

212 For purposes of this discussion, the term “model,” is used as described in joint agency guidance, FRB SR Letter 11-7, “Guidance on Model Risk Management,” and OCC Bulletin 2011-12, “Sound Practices for Model Risk Management: Supervisory Guidance on Model Risk Management.”
* • Assessing capital adequacy.
* • Managing client assets.
* • Measuring compliance.
* • Maintaining the formal control apparatus of the bank.
* • Meeting financial or regulatory reporting requirements.
* • Issuing public disclosures.
#### V.D.2 Database Development 

Databases are digital repositories of data designed to be accessed, managed, and updated. They can be internally developed or purchased from third parties. Commonly used database models include hierarchical, networked, relational, object-relational, and nonrelational. Developers should understand the different types, structures, and uses of databases to effectively mitigate database development risks. To do this, it is important to understand the benefits, limitations, and appropriate controls for the type of database used. Examples of risks developers of databases should consider include the following: 

* • Data errors and omissions.
* • Inappropriate database access privileges.
* • Misuse of legitimate privileges.
* • Database injection attacks (e.g., SQL injection).
* • Malware.
* • Storage media exposure (e.g., backups).
* • Exploitation of vulnerable databases (e.g., failure to patch and maintain the database).
* • Unmanaged sensitive data (e.g., failure to maintain an accurate database inventory that
* • Human error (e.g., failure to apply security controls, enforce policies, or implement
* • Maintaining a database inventory that includes the database location(s), contents, and
* • Assessing databases for any vulnerabilities.
* • Managing user access rights (e.g., removing user access and privileges when access is no
* • Logging and monitoring database access and usage to identify patterns and help detect data
* • Blocking inappropriate web requests.
* • Backing up the databases.
* • Encrypting databases.
* • Training database developers on their security-related development responsibilities, includes each database’s content and the content’s sensitivity). appropriate incident response processes).

Potential mitigation strategies include the following: sensitivity. longer required for business purposes). leakage, unauthorized or significant activity, and system and component attacks in real time. including identification of potential information security risks and appropriate mitigation practices. 

Prudent practices include choosing databases that meet business and other stakeholder objectives and implementing controls, including access controls, to protect the data consistent with their criticality and sensitivity. Additional database design and selection considerations are flexibility, scalability, data integrity, and retrieval efficiency. 

& 

## VI ACQUISITION 

### Action Summary 

Management should establish acquisition processes that are commensurate with the entity’s business and procurement needs. Management should also assess and mitigate procurement risks associated with an entity’s overall strategic, regulatory, and operational risks. 

Examiners should review the following: 

* • Project requests and plans for one or more recent acquisitions.
* • Strategic and business plans, risk assessments, due diligence activities, and acquisition-
* • Contracts and licensing agreements.
* • Acquisition policies, standards, and procedures, including evaluation criteria and
* • Acquisition training and entity guidance for stakeholders.
* • Acquisition and procurement-related audits. related meetings with minutes. documentation maintenance practices.

NIST defines “acquisition” as “all stages of the process of acquiring a system, product, or service, beginning with the process for determining the need for that system, component, product, or service and ending with contract completion and closeout.”213 While acquisition and procurement are terms often used interchangeably, for purposes of this booklet acquisition refers to the overarching process and procurement refers to the specific steps to obtain the system, product, or service. To effectively manage the risks inherent in acquired systems, components, products, or services, entity personnel identify key roles and responsibilities. For example, once management completes contract negotiation and takes control of the system, component, product, or service, management determines the activities related to and responsibilities for oversight (e.g., entity’s third-party or enterprise risk management office). 

An entity may acquire technology or technology services from a third party, rather than developing it in-house. An entity may use or acquire systems, components, products, and services from various sources, including internal development teams, technology and software development firms, co-sourced arrangements, open-source repositories, and commercial sources. When an entity purchases systems, components, products, or services, effective management ascertains whether the product specifications are “fit for purpose” and meet the entity’s requirements, whether purchasing directly from the OEM partners or a secondary market. This should be addressed in agreements with supply chain partners. 

The acquisition of system, components, products, and services (versus in-house development) poses certain risks at each step of the acquisition process that should be assessed and mitigated. Risks associated with the third-party product or service may vary depending upon the specific 

213 Refer to NIST Glossary. 

& 

situation. These may include strategic (e.g., the system does not align with business needs), regulatory (e.g., the solution does not consider GLBA), and operational risks (e.g., the provider does not have an adequate testing environment or sufficient resources to maintain the solution). In addition, there may be third-party risk management concerns,214 weaknesses in security controls, or other operational weaknesses at the third-party provider. 

An entity may mitigate the risks associated with acquisition in several ways. The following are examples of effective risk mitigation: 

* • Develop policies, standards, and procedures to effectively carry out the entity’s procurement
* • Perform potential supplier due diligence reviews.215 Due diligence rigor should align with a processes aligned with the entity’s acquisition activities. risk assessment that identifies the criticality of the business function supported, the information sensitivity the system or component stores or processes, business function complexity, and external factors such as the supplier’s location and ownership.
* • Implement contract and licensing processes for all acquisitions, particularly for more complex relationships. An entity’s processes should include contract and license review to help ensure that the rights, responsibilities, and accountability of each party are clear.

A structured procurement process (such as the procurement steps in figure 8) is likely to produce more consistent and sustainable results across an entity over time. The more critical the system, component, and service being procured the more important that each procurement step is successfully completed. 

In the example in figure 8 below, the procurement process begins with the identification of an entity’s business need for procuring a system, component, or service. Then management may engage in the following: 

* • Planning. Planning what information will be needed to procure the best system, component, or service, and requesting information from the project team and key stakeholders.
* • Defining requirements. From planning and information provided, clearly defining what
* • Solicitation.
* • Evaluation and selection. Evaluating proposals and determining the best choice.
* • Contract negotiation and award. Determining contract requirements and responsibilities, requirements are necessary. Requesting quotes or proposals. and which risks will not be covered in contract. 

214 Refer to the following guidance: Interagency Guidance on Third-Party Relationships: Risk Management, also noted in OCC Bulletin 2023-17, “Third-Party Relationships: Interagency Guidance on Risk Management”; FDIC FIL-29-2023, “Interagency Guidance on Third-Party Relationships: Risk Management”; and FRB SR Letter 23-4, “Interagency Guidance on Third-Party Relationships: Risk Management.” Also see CFPB Compliance Bulletin and Policy Guidance 2016-02, “Service Providers.” 

215 Refer to NIST SP 800-53, rev. 5, SR-3, Supply Chain Controls and Processes, notes that rigorous due diligence includes research on potential suppliers or products, as well as their upstream dependencies (e.g., fourth- and other parties beyond third-party suppliers), which can help enterprises avoid single points of failure in their supply chains. The results of this research can be helpful in shaping the sourcing approach and refining requirements.
* • Vendor management and ongoing administration. Oversight and maintenance of the relationship, if ongoing.
* • Preparing for the off-ramp. EOL or upgrade of system, component, or service. 

Figure 8: Procurement Steps: Example 

© -> 

D-> O- 

- - > 

-> 

Business 

Need 

Planning 

Request for 

Information 

Solicitation Request for Quote 

Request for Proposal Evaluation 

and 

Selection 

Contract Negotiation/ 

Award 

Vendor Management/ Administration 

Off-Ramp 

Requirements Definition 

An effective procurement process helps management and personnel to address each step in the process, communicate and meet combined stakeholder requirements, select appropriate systems and components, and support the entity’s overall business objectives. Additionally, an effective process helps minimize confusion (e.g., by identifying minimum requirements) and promotes coordination in the supply chain (e.g., by achieving efficiencies using one OEM for multiple products).
* •
* •
* •
* •
* •

Specific procurement risks to address include the following: 

Due diligence does not reveal a material third-party deficiency. 

Procured system does not interoperate with existing systems. 

Actual costs being materially higher than budget. 

Procured system, component, or service does not meet all stakeholder’s requirements. 

Procurement process informality leads to inconsistent system, component, and service selection over time. success. 

* • Contract or license does not specify characteristics critical to system, component, and service
* • Lack of visibility into supply chain partners for identification of weaknesses (e.g., security, interoperability, or incident response).
## VI.A 

### Acquisition Policies, Standards, and Procedures 

Acquisition policies, standards, and procedures that are enforced create acquisition consistency across the entity. Well-communicated and enforced policies, standards, and procedures are important for the acquisition process to help determine the appropriate technology for new IT procurement requests or requests for significant updates to current systems and components. Without adequate policies, standards, and procedures, management may expose the entity to the following: 

* •
* • Procurement of a system or component that does not address the business need. 

Products or services that fail to protect the confidentiality, integrity, availability, and resilience of the entity’s systems and components, which may adversely affect other systems in the entity’s supply chain.
* • Noncompliance with legal and regulatory requirements (e.g., Information Security Standards, Bank Service Company Act).
* • Inadequate contracts and licensing agreements, due to failure to communicate and involve key stakeholders (e.g., IT, information security, privacy, legal, and compliance personnel).

An effective entity’s acquisition policies, standards, and procedures address the following: 

* •
* •
* •
* •
* •
* •
* •
* • proposal. Checking references (e.g., through external user groups or banking association members) to ascertain current and past customer views on product and service quality. 

Evaluating and selecting (including criteria for selection) a third party.
* • Specialist stakeholders’ (e.g., subject matter, legal, and compliance experts) review of 

Contract negotiation to ensure that the contract contains terms amenable to the entity. 

Transferability or portability of systems, components, products, and services if a third-party 

Information requests, such as requests for information (RFI) and requests for proposals (RFP) to third parties. Responses to these requests provide the entity with vital information for identifying the best provider solution. Requests for quotes (RFQ) are also used before final selection to obtain the best pricing. For additional information on RFIs, RFPs, and security and resilience controls).
* • Reviewing system, component, and service operational and internal controls (e.g., relationship is discontinued.

Contract signature authority. RFQs, refer to the “Solicitation” section in this booklet. 

Third-party due diligence216 includes the following: 

* • Comprehensively assessing risks associated with third-party relationships.217

System, component, and service validation to ensure that user requirements are met before acceptance. 

In some cases, management may acquire systems, components, or services from foreign-based third parties. In addition to information security risks, there are several unique risk considerations in these relationships, including the following: 

216 Refer to the following guidance: Interagency Guidance on Third-Party Relationships: Risk Management. 

217 The risk assessment typically includes a third party’s reputation, personnel background checks, customer service issues, financial condition, stability, and fourth-party products or services. 

#### • Legal. 

Confusion over which country’s laws will control the relationship. Additionally, it is important to consider that there may be specific U.S. laws with which the entity and its third- party service providers may need to comply (e.g., the restriction on the export of software applications employing encryption techniques). 

#### • Country. 

The possibility that economic, social, or political conditions and events in a foreign country will adversely affect an entity’s financial and business interests (e.g., financial defaults by obligors in a foreign country, nationalization of private assets, government repudiation of external indebtedness, exchange controls, or significant currency devaluations). 

#### • 

Currency (or exchange rate). The risk that arises from the change in price of one currency in relation to another. Assets or business operations located across national borders are exposed to and affected by currency risk, creating unpredictable profits and losses, currency devaluations, and foreign exchange controls. 

#### • Geopolitical. 

Risk associated with wars, terrorist acts, and tensions between states that affect the normal and peaceful course of international relations. For example, regime change in the country of operations may result in a loss of control over the entity’s data stored in that country. 

#### • Resilience. 

The risk that operations and assets may be undermined or destroyed by crises. 

This includes the capacities and resources of business systems affected by risks, stresses, and shocks. For example, if there is a disruption of utilities in a country, it may disrupt data center operations. 

Management should be knowledgeable of these risks and their effects on the business before entering foreign-based third-party relationships. Therefore, effective management identifies, plans, and addresses the root causes of foreign-based risks or crises to minimize their effects on the entity’s operations. 

### VI.B Acquisition Projects 

If an entity has a PMO, acquisition projects may be managed according to established entity PMO processes. Smaller or less complex entities may not have the same formality or rigor in their acquisition project processes. However, it is still important to have project guidance and procedures for the management of acquisition projects. If a procurement project request is approved, the feasibility study should clearly define the IT, information security, functional, legal, and regulatory requirements in the RFIs and RFPs that management distributes to third parties in the solicitation process for bids, including RFQs. Acquisition projects should follow the same principles as noted above throughout section IV.N. “IT Project Management.” 

### VI.C Solicitation 

For procurement projects, management follows the entity’s requirements definition with solicitation for information and evaluation. These solicitations do not represent binding agreements between the entity and a third party. An entity’s solicitation process generally is initiated when it has a business need or problem to solve. Management may issue RFIs to determine potential third parties with solutions available to address the business need or problem and gather information. When the entity has gathered the appropriate information and narrowed down the number of potential third parties, management may issue an RFP to ask those third parties to propose specific solutions. This helps management evaluate and prioritize third parties and their solutions. When management has identified the third parties that can meet the business needs, it uses the RFQ to validate specific requirements and ask whether the third party is able to meet those requirements, and if so, to list all associated costs to help management determine its final selection. For smaller or less complex entities, these terms and steps may not be as clearly delineated or defined; however, management should still have a process that considers business needs, third-party solutions, specifications, and costs. A solicitation to a potential third party may involve an RFI, RFP, or RFQ, or a combination of the three if the entity chooses to move forward with a particular third party on a project, as shown in figure 9 and described in more detail below. 

Figure 9: Third-Party Solicitation Types and Inputs 

RFI Request for Information 

RFP Request for Proposal 

- 

© 

Management 

Evaluation of 

Solicitation 

Information 

Strategic 

Initiative 

Management 

Initiates 

Solicitation 

Process 

[S] 

#### RFQ 

Request for Quote 

#### • RFI: 

A request for information is a market research tool also referred to as a sources-sought notice that is used to obtain, for example, price, delivery, capabilities, and interest for planning purposes.218 Management may use an RFI to identify third parties that should be targeted for more specific information or further requests. The RFI includes the entity’s requirements and appropriate questions that will allow respondents to provide necessary information for stakeholders to make acquisition decisions. Third parties receive requests and provide information about their capabilities, including products or services they offer, and interest in establishing a relationship. There is no standard format for an RFI; however, a formal, well-crafted RFI may facilitate faster responses from potential third parties by providing an overview of the entity’s requirements, including any specific questions for the third party. The RFI should clearly identify the entity’s needs to avoid a third party’s confusion with the request and omission of critical information needed for decision-making. When management receives information from the third parties, assumptions should not made based on the responses. Instead, if appropriate, management should consider asking follow- up questions to clarify concerns or solicit more information. 

Additional considerations when reviewing third parties’ RFI responses include the following: 

* o RFI format: Whether the provider followed the format specified in the RFI. 218 For more information, refer to U.S. General Services Administration’s (GSA), “RFP, RFI, and RFQ: Understanding the Difference.”

o 

o 

Third-party interest: Whether the third party is interested in forming a relationship. 

Business size: Whether the third party has the resources (e.g., personnel and infrastructure) to support or provide resilience for the suggested solution. 

o 

Location: 

Proximity of the third party’s location to entity locations and effect on resilience. 

o 

Qualifications: 

Whether the third party’s personnel have appropriate knowledge and 

Development, Acquisition, and Maintenance experience, as well as whether the entity has the personnel and training to operate the solution. 

o 

Subcontractor involvement: Third-party standards for subcontracted work, responsibilities and liabilities for subcontractors, third-party due diligence on subcontractors, and percentage of work to be performed by subcontractors. 

o 

Conflicts of interest: Whether doing business with this provider causes conflicts with other entity third-party providers, internal conflicts of interest at the entity (e.g., a relative of entity personnel works at the third party), or anticipated conflicts of interest with the third parties. 

* •
#### RFP: 

A request for proposal is a solicitation method that communicates the entity’s requirements and requests proposals.219 An RFP is a formal procurement activity to solicit bids. When drafting an RFP, it is critical to communicate an entity’s key system and component requirements, especially those that may incur significant costs to implement. An RFP can include a solicitation for quotes. Bids in response to an RFP provide information needed to select a provider. Information such as the description of the bidder’s approach, price, and personnel expertise are helpful in differentiating between bidders to make a final selection. 

Additional considerations when reviewing third parties’ RFP responses include the following: 

o 

Terms and conditions that can help management identify limitations (e.g., length of agreement, resource ceilings, and potential interruptions in service) that the third party may have. 

o 

Whether a third party follows the RFP format and provides the required information (e.g., cost, experience of the third party, and resilience), which indicates the third party’s attention to RFP requirements. and with no exceptions to the solicitation). 

o 

Whether the third party’s responses are detailed, specific, and responsive (e.g., timely 

* •
#### RFQ: 

A request for quote is a solicitation method used to obtain price, cost, delivery, and related information from suppliers.220 An RFQ can provide more precise information for bidder comparison and budgeting. There is a potential risk in the RFQ process that bidders misunderstand when an entity is bound by an agreement and a contract is created. To 

219 

220 

Ibid. 

For more information, refer to GSA, “RFP, RFI, and RFQ: Understanding the Difference.” 

& 

mitigate this risk, an entity should include legal counsel to help guide the engagement and help avoid potential contractual issues. For additional information on contracting,221 refer to the “Contracts and Other Agreements” section of this booklet. 

For more information on third-party risk management, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services” booklet. 

### VI.D Evaluation 

A formal process for evaluating RFI, RFP, and RFQ responses produces higher quality selections of third parties across the entity and reduces legal risk. The process goal should be a fair and consistent approach to evaluating and eventually selecting a third-party provider. The process should include procedures to compare each proposal or quote to the entity’s defined requirements for the systems, components, or services needed. Then, the entity can compare all the proposals or quotes that meet those requirements. When the process includes pre-determined evaluation criteria, the process is more equitable and legal risk is reduced. Careful consideration helps management determine appropriate evaluation criteria that assists in the review of the widely varying proposals (e.g., bidders proposing either SaaS, infrastructure-as-a-service [IaaS], or platform-as-a-service [PaaS])222 to meet the basic requirements. Table 3 lists evaluation criteria examples. 

Table 3: Evaluation Criteria Examples for Third-Party Solicitations 

General criteria for all products and services: 

* • Ability to audit or receive independent audit
* • Confidentiality and privacy standards.
* • Copyright standards.
* • Delivery dates.
* • Liability limitations.
* • Licensing restrictions.
* • Maintenance procedures.
* • Financial performance and condition.
* • Information security requirements set by the entity.
* • Backup and resilience options.
* • Costs, fees, and discounts. reports.

Software products and services: 

* • Operations and internal controls.
* • End-of-service or EOL.
* • Legal and regulatory requirements.
* • Subcontractor details.
* • Testing standards.
* • Third-party service provider customer reference.
* • Training provided.
* • Warranty specifications.
* • Event or incident response roles and responsibilities.
* • Insurance considerations.
* • Compatibility of Oss.
* • Escrow criteria.
* • Next release date.
* • Programming language. 221 Refer to the following guidance: Interagency Guidance on Third-Party Relationships: Risk Management, as noted in OCC Bulletin 2023-17, “Third-Party Relationships: Interagency Guide on Risk Management”; FDIC FIL- 29-2023, “Interagency Guidance on Third-Party Relationships: Risk Management”; and FRB SR Letter 23-4, “Interagency Guidance on Third-Party Relationships: Risk Management.” Also see CFPB Compliance Bulletin and Policy Guidance; 2016-02, “Service Providers.” 

222 Refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet for more information on SaaS, IaaS, and PaaS.

& 

Hardware products and services: 

* • Maintenance requirements (for the entity and the third party).
* • Capacity (e.g., memory, bandwidth, storage, power).
* • Servicing options.
* • Performance capabilities.

For more information on evaluation considerations, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services,” “Architecture, Infrastructure, and Operations,” “Information Security,” and “Management” booklets. 

### VI.E Contracts and Other Agreements 

Contracts and other types of agreements are used to document the terms and conditions under which systems, components, and services are provided. Acquisition policies, standards, and procedures specify how contracts and other agreements are documented, reviewed, and approved. Agreements223 take many forms and may be included in a contract by reference. Agreement examples are statements of work (SOW), master services agreements (MSA), SLAs, and escrow agreements. To ensure that contracts and other agreements are legally enforceable, legal counsel should be involved in the acquisition process before finalization. Contracts are intended to be legally binding agreements between two or more parties. They generally identify the goods and services to be provided, the time frame for provision, and the associated costs and fees. There may be several documents involved in the procurement process; therefore, it is helpful to identify each of the agreements and contracts, which will assist management in completing the evaluation and selection steps. These documents may be useful to management in its effective oversight of the performance of the entity’s supply chain partners. The following subsections describe several agreements and contracts commonly encountered during examinations. 

#### VI.E.1 Statement of Work 

An SOW is one supporting document for contracts, detailing the activities to be performed and the activity output in system and component development (e.g., performance level, operating reports, developer documentation, and user manuals). This documentation is critical to system and component maintenance because it details maintenance standards for operations. SOWs can also specify the security assurance requirements (e.g., code reviews, penetration tests, and SOC reports). The security assurance requirements should include the processes that the developer and other staff will follow. Additionally, the SOW may specify the verification process for delivery of products and services, including what task completion evidence is required for payment. SOWs often become part of a binding agreement, such as a contract. 

While the contract defines the legal aspects of the relationship, the SOW generally contains elements, such as the following: 

* • Purpose of the relationship. 223 For purposes of this booklet, Black’s Law Dictionary defines “agreement” as “the consent of two or more persons concurring, the one in parting with, the other in receiving, some property, right, or benefit.”
* • Project objectives.
* • Services and products to be provided (i.e., scope of work).
* • Schedule, including deliverables and delivery deadlines.
* • Requirements for providing the desired services and products, including potential penalties or
* • Objective measure of satisfactory completion of work.
* • Payment due date and method.
* • Legal and regulatory requirements.
* • Location and duration of the work.
* • Acceptance criteria. FFIEC IT Examination Handbook Development, Acquisition, and Maintenance payment retention for unsatisfactory work.

There is no standard SOW format across entities and industries. It is up to appropriate stakeholders at the examined entity to determine the format according to the entity’s needs. Effective entities provide guidance to relevant personnel in support of a structured approach to SOW development to promote consistent and positive acquisition results, often achieved through SOW training. Similarly, involving all stakeholders in SOW development and establishing an appropriate management review and approval process are both effective practices in achieving positive acquisition results consistently across an entity. 

SOW details are important because the type, duration, and complexity of work varies significantly. Clear and specific SOWs help increase the likelihood that bids are comparable, that selection decisions are made quickly, and that miscommunication and misunderstanding are avoided. For example, the SOW should identify the responsibilities of all parties involved. One risk is that service and outsourcing providers can become so focused on the customer entity’s needs and requirements that they overlook their own. In order to meet requirements and provide for delivery of a quality product or service, it is important that the provider’s needs and requirements (e.g., price, security, and interoperability) also be specified and met. Another example of effective SOW details includes the documentation required from supply chain partners.224 When an SOW is specific, it can be used to measure whether requirements have been met to an acceptable level. 

An SOW may include elements, such as the following: 

* • Statement of confidentiality.
* • Description of work with assumptions and constraints.
* • Services to be provided.
* • Facility and security requirements.
* • Marketing requirements.
* • Transition requirements.
* • Training and reporting requirements.
* • Roles and responsibilities.
* • Schedule. 224 Refer to NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations, and NIST’s Response to Executive Order 14028, Software Supply Chain Guidance: Software Security in Supply Chains.
* •
* •
* •
* • Pricing. 

Approvals. 

Glossary. 

Appendix (e.g., containing an incident response plan with contractor responsibilities).

In addition to SOWs, there are alternative methods225 to document details for proposals (e.g., RFI, RFP, and RFQ), which support the contract or other agreements. One example of these alternatives includes a statement of objectives (SOO), which identifies the broad business outcomes and objectives for performance.226 An entity makes a request for detailed proposals (i.e., an SOO), which are provided in response. Another alternative is a performance work statement (PWS),227 which emphasizes outcomes, desired results, and objectives at a more detailed and measurable level. An appropriate response is furnished by prospective providers. These alternative methods may be used in conjunction with the other documents noted above (e.g., RFI, RFP, and RFQ). Information from the SOO or PWS may then be included into the contract to produce a more effective engagement. 

##### VI.E.2 

#### Master Services Agreement 

MSAs are “master” documents that govern multiple agreements or transactions between entities. The MSA often sets forth the principal legal terms that govern the parties’ relationship and are usually drafted by the service provider. An MSA usually governs or incorporates additional contract documents, such as software license agreements, policies and procedures, terms and conditions, data protection agreements, end-user license agreements, and SOWs. These additional contract documents provide important information to operations personnel. 

An MSA helps the parties change contracted services more quickly than without an MSA, because services do not have to be renegotiated each time there is a mutually agreed-upon change to underlying services. For example, a financial institution and a third-party core banking platform product or service provider may enter into an MSA that covers the core banking platform and the possible use of related software and services (e.g., payments software, consulting services, and cloud storage platform). Therefore, changes to the listed services noted in the MSA could occur without creating a new agreement. 

MSAs typically include items such as the following: 

* •
* •
* •
* •
* •
* • 225 

226 

227 

Service overview. 

Proprietary rights. 

Intellectual property rights. 

Insurance and taxes. 

Terms of agreement (e.g., payment, audit, subcontracting, or confidentiality). 

Representations and warranties (e.g., patents and trade secrets). 

Refer to GSA, “PWS, SOO, SOW - Finding the Best Fit,” for more information. 

Refer to GSA, “Respond to a Solicitation,” for more information. 

Refer to GSA, “Performance Work Statement,” for more information. 

&
* •
* •
* •
* • Limitation of liabilities (e.g., a force majeure clause).228 

Dispute resolution process. 

Agreement termination process. 

Legal jurisdiction (e.g., country, state, federal, or local).

##### VI.E.3 

#### Service Level Agreement 

An SLA is a formal agreement between two parties that records a common understanding about products or services to be delivered and how they will be delivered, including the following: 

* •
* •
* •
* •
* •
* •
* •
* •

Nature, quality, security, availability, and scope. 

Timeliness of delivery and response of the parties. 

Point(s) of contact for end-user problems. 

Metrics to monitor the effectiveness of the process. 

Approvals. 

Other measurable objectives. 

Expected day-to-day situations and unexpected or adverse events. 

Priorities, responsibilities, guarantees, and warranties between the parties. 

An SLA represents a commitment between a third party and one or more customers and addresses specific aspects of the service, such as responsibilities, details on the type of service, expected performance level (e.g., reliability, acceptable quality, and response times), and requirements for reporting, resolution, and termination.229 

SLAs are an effective practice to mitigate the risk of differing performance expectations. When procuring services related to a system or component, agreements should have clear and measurable expectations for the services provided, recourse when expectations are not met, and accountability for both parties. SLAs generally include how the third party expects to meet the SLA requirements and establishes incentives for the third party to meet, or penalties for failing to meet, those requirements. The SLA should be linked to clauses in the contract regarding incentives, penalties, and contract termination to protect the entity in the event of third-party performance failures. For more information, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services,” “Management,” and “Information Security” booklets. 

##### VI.E.4 

#### Contracts 

Contracts between an entity and its third parties should clearly describe the rights and responsibilities of the respective parties. Contracts are formal binding documents, usually preferable to agreements, which can be informal and may not be enforceable in a court of law. 

228 A contract or agreement clause pertaining to “force majeure” (i.e., “act of God”) risk, irresistible force, or uncontrollable event (e.g., war or civil unrest) that refers to an event or circumstances “when business is disrupted due to a factor beyond control.” This type of clause allocates the risk of loss if performance is hindered, delayed, or prevented because of an event that the parties could not have anticipated or controlled. It helps provide a contractual defense, the scope and effect of which depends on the express terms of a particular contract. 

229 

Refer to NIST SP 800-47, rev. 1, Managing the Security of Information Exchanges. 

An example of important rights to specify are license rights230 when the entity is using systems and components developed by third parties. Another example is rights and liabilities relating to leased hardware necessary to operate related software. The consequences for failure to meet contractual obligations should also be specified. Examples of software development and maintenance-related contract clauses may include the following: 

* • Software functional and performance specifications.
* • Development process milestones and associated payments.
* • Development roles and responsibilities for the third party and the entity.
* • SLA information and pricing methods.
* • Controls over foreign based third-party activities (i.e., activities performed by entities subject
* • Software modification restrictions.
* • Objective pre-acceptance performance standards to measure the software’s functionality. For to international laws and regulations). example, the contract may identify particular tests that will be used to determine whether the software complies with the contract’s performance and security standards.
* • Training specifications.

Examples of hardware development or maintenance-related contract clauses may include the following: 

* • Hardware may not be altered from OEM status, as-delivered (i.e., alterations may void the contract or warranty).
* • Proprietary hardware remains the property of the vendor or service provider, and access to it is limited.

A third-party’s contributions to the mitigation of major risks are particularly important to specify in contract clauses. For example, security and privacy standards to be followed by third-party service providers or vendors that process, store, or transmit sensitive customer data should be specified in the contract. Table 4 has additional examples of contract clauses. 

Table 4: Contract Clause Examples 



| Clause | Considerations |
| --- | --- |
| Legal and regulatory requirements | Outlines responsibility for maintaining software so functionality complies with applicable laws and regulations. |
| Representations, | Express representations, warranties, and indemnifications including provisions such as: |
| warranties, and indemnifications | * • Licensed software does not infringe on the intellectual property rights of any third parties worldwide.231 |

230 Typically, the developing entity provides licenses to the entity that is using the systems or components, granting it certain rights for their use. 

231 Under some state laws, noninfringement warranties are limited to the United States unless otherwise specifically stated. 

& 



| Clause | Considerations |
| --- | --- |
| Third-party liability limitations | Proposed limitations of liability in the contract should be reasonable based on the amount of loss or disruption the entity might experience. For mission-critical systems or components, broad exculpatory (i.e., cleared from fault) clauses limiting a third party’s liability could adversely affect the safety and soundness of an entity (e.g., excessive force majeure clauses and nested third-party activity exclusions that exceed the entity’s capital risk parameters). |
| Payments | • Partial payments at specified development milestones, with final payment due after Payment schedule and expense details (e.g., installation, conversion, maintenance, and travel). A payments clause may include provisions such as: successful system and component acceptance tests. Properly defined milestones can break development projects into segments with deliverables, allowing management to monitor developer progress and identify any potential problems. |
| Dispute resolution | Dispute resolution clauses specify the process to be used to resolve problems in a timely manner. Dispute resolution clauses may specify that system and component |
| Agreement | development will continue during a dispute resolution process. These clauses mitigate the risk that the agreement is not modified without appropriate |
| modifications Bankruptcy233 | approval because agreement modification may affect pricing or result in necessary modification to systems and components. example, a clause may specify a software code escrow process that would provide the entity access to the code (that is ordinarily accessed only by the third party) in the event of the third party’s insolvency. A second example is a clause specifying that the entity Clauses that protect the examined entity in the event of third-party bankruptcy. For |
| Information | Clauses that identify the information security requirements (e.g., compliance or performance standards) and align with the entity’s information security program. to the FFIEC IT Handbook’s “Information Security” booklet. Examples are: |
| security | • Clauses that specify the third party’s ongoing responsibilities for maintaining the Refer |

* • Warranties232 that software performs according to specifications and how a third
* • Specifications for the length of the warranty and how the warranty relates to
* • Determination of compensation (e.g., based on the developer’s time and materials
* • Consequences if the third party fails to meet any of the requirements stipulated in
* • Clauses guaranteeing that third party-developed systems and components do not 
will have direct access to cloud-based services and production data used by the third party for the entity’s benefit in the case of the third party’s bankruptcy. 

versus a fixed-price agreement with specific payment milestones). Clearly defined compensation information allows for management control over the development process and total project costs. the contract, such as failure to deliver system or component features and functions. The contract should allow for the right to reject the deliverable and withhold payment until the third party meets all contractual requirements. party responds in the event of problems. maintenance obligations and agreements.
* • Representations that software does not contain undisclosed restrictive code or automatic restraints not specifically authorized in the agreement. information security and confidentiality of an entity’s resources and data. Provisions should address prohibitions on the third party and its contractors or agents using or disclosing an entity’s information, except as necessary to provide contracted services. and will not permit unauthorized or unknown access (e.g., “backdoors”) to the system, component, or the entity’s systems or data. 

232 Warranties generally address events and distinguish between mission-critical failures, which should receive an expedited response, and noncritical failures, which management can resolve in a routine manner. It is helpful to review warranties compared to the latest independent certification report demonstrating the software’s capabilities. 

233 Refer to relevant provisions of the U.S. Bankruptcy Code.

& 



| Clause | Considerations |
| --- | --- |
| Change in control | * • Clauses that specify the third party’s actions in a breach, such as reporting * • Legal, regulatory, and entity standards. For example, applicable regulatory Clauses addressing contract revision after third party change of control (e.g., merger, requirements regarding the incident, its resolution, and communication timeliness. For more information on incident response, refer to the FFIEC IT Handbook’s “Information Security,” “Outsourcing Technology Services,” and “Business Continuity Management” booklets. standards include GLBA234 for financial institutions and the Federal Trade Commission’s (FTC) Standards for Safeguarding Customer Information for financial institutions subject to the FTC’s enforcement authority.235 |
| Subcontracting | acquisition, or change of ownership). This is important as service quality and support may not be maintained after a change in control. • Clauses specifying that the third party is responsible for the performance and |
| Audit | “Right to audit” clause allowing for periodic audits of critical third parties’ Periodic audits help validate that third-party service providers comply with the agreement’s control terms such as the entity’s information security requirements. |
|  | operations. |
| Continuing vendor support | Clause regarding system and component support including upgrading, patching, and bug fixing through EOL. The clause should include a minimum time frame for notification of the EOL date. |

* • Notification and approval requirements regarding changes in subcontractors. 
security of the systems and components regardless of who designed or developed them. Some third parties may subcontract with other parties (referred to as subcontractors or fourth parties) to develop systems and components for their customers. Management should consider contract clauses that allow for a contract to be revisited if a key subcontractor changes, which may affect critical entity services. For more information, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services” booklet.

Appropriate entity personnel should be involved in contract drafting to help ensure that contracts cover all relevant aspects of the development, acquisition, and maintenance of the entity’s systems, components, and services, including those that are customized for the examined entity. Contracts should contain such details as performance specifications, source code accessibility, software and data security, and hardware viability and replacement. Contracts should identify the recourse available to the entity if the vendor fails to meet defined requirements and user acceptance criteria. For more information, refer to the FFIEC IT Handbook’s “Outsourcing Technology Services” booklet. 

Before opening negotiations or issuing an RFP for customized systems and components, management should define objectives and understand the entity’s present and planned IT architecture, infrastructure, and operations. During contract negotiation, entity management may encounter situations in which third parties cannot or will not agree to the terms an entity sets out in the draft contract. Under such circumstances, management should determine whether it is willing to accept or can mitigate the risks related to systems or components without the requested terms. Any accepted risk or compensating control factors should be clearly documented with appropriate approval consistent with the entity’s policies and governance structure. If management cannot accept or mitigate the risk, it is important to consider alternative solutions. After contract negotiation or agreement execution, periodic audits help to verify that the third party is meeting its contractual responsibilities, such as agreed-on security controls and compliance with laws and regulations. 

234 Refer to GLBA further implemented by FFIEC members as follows: FDIC: 12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards,” and 12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice”; FRB: Regulation H, 12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards,” and Regulation Y, 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards”; NCUA: 12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information”; OCC: 12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards,” (especially the requirement under Section III, D.2, for national banks and federal savings associations to “[r]equire its service providers by contract to implement appropriate measures designed to meet the objectives of these Guidelines”). 

235 Refer to FTC 16 CFR 314, “Standards for Safeguarding Customer Information.” 

When negotiating contracts or agreements, management should anticipate that it may decide to convert to different products or providers in the future. Contracts or agreements should enable and facilitate conversions (e.g., minimize restrictions or provide appropriate assistance) to new systems or components. For example, when converting to a different product at the same provider, management and the provider should facilitate coordination between the old and new product teams and entity personnel should be aware of any differences among the products (e.g., hardware, interfacing software, and storage). Additionally, clauses should provide the ability to convert data to a new format as needed. Finally, if converting to a new provider, clauses that allow the old and new providers to coordinate in the conversion process may mitigate conversion related issues (e.g., incompatibility, integration problems, or lack of data availability). 

#### VI.E.5 Escrowed Source Code Agreements and Documentation 

Programs are written using proprietary or open-source code. Proprietary systems and components are normally copyrighted trade secrets of the company that wrote or owns the programs. Generally, to protect the integrity of code and software copyrights, vendors do not release proprietary code to the entities that buy or lease the products. Typically, an independent third-party escrow agent retains the source code and related documentation in escrow;236 however, entity management is responsible for verifying annually that the third party maintains a current version of the source code in escrow. Some escrow agents provide services for reviewing and confirming source code version numbers and dates. Some agents perform automated code reviews to confirm integrity of the escrowed code. 

The documentation held by the escrow agent should include system narratives, system flowcharts, program source listings, program narratives, file and record layouts, descriptions of individual fields in the records, and calculation routines. Portions of this documentation may be included with the user guides that are provided to the entity. These documents should cover transaction codes and descriptions of input forms and output reports. In addition, management should consider protecting the entity’s escrow rights by contractually requiring third parties to inform the entity if the software vendor pledges the software as loan collateral. It is important to consider the risks associated with a foreign-based escrow agreement. 

236 Merriam-Webster defines “escrow” as “a deed, a bond, money, or a piece of property held in trust by a third party to be turned over to the grantee only on fulfillment of a condition.” For purposes of this booklet, the code in escrow is held by a third party and provided to the entity only on the fulfillment of some condition. 

* • Requirements to include minimum code documentation with the code in escrow.
* • System and component maintenance procedure documentation to be escrowed.
* • Conditions that should be present before an entity can access the source code and related
* • Assurances that the escrow agent will hold current versions of the source code and related
* • Arrangements for auditing or testing escrowed code integrity.
* • Source code descriptions and related documentation including the storage type and location documentation to validate that escrowed information is updated whenever significant program changes are made. (e.g., magnetic tape or cloud).
* • Assurances that the source code storage type and location and related documentation is Effective escrow agreement provisions may include the following: documentation. 

FFIEC IT Examination Handbook Development, Acquisition, and Maintenance accessible, operable, and compatible with an entity’s existing IT environment.
* • Assurances that the source code can be compiled into executable code.
* • If the escrow agent is based outside the United States, consideration of the practical and legal implications of establishing foreign-based escrow arrangements.
#### VI.E.6 Exit Strategy 

An exit strategy is an entity’s plan for transitioning to a replacement system, component, or service, or for terminating a system, component, or service. Entities design exit strategies to minimize disruption. Having a well-defined exit strategy is part of ongoing, effective strategic planning. During the procurement process, management should develop an exit strategy that at a minimum addresses the third party not meeting the contract terms. 

To have the most leverage, entity personnel should negotiate default and termination language in the initial contract. The default and termination language may provide opportunities or methods to remedy contract defaults. Contract clauses should define termination rights; document time frames for transferring services to another third party or bringing the service in-house; and provide for how data, records, and IT assets are preserved, transferred, or destroyed. 

Default and termination language may provide for the initial steps in executing an exit strategy, but it is important to consider identifying alternative third parties that provide similar products and services at the onset of the relationship. This could provide management with an initial plan to execute a transition between third parties. For more information on exit strategy planning, refer to the FFIEC IT Handbook’s “Management,” “Outsourcing Technology Services,” and “Business Continuity Management” booklets. 

& 

## VII MAINTENANCE 

### Action Summary 

Management should establish policies, standards, and procedures for maintaining systems and components that include detailed roles and responsibilities. It is important that policies and procedures effectively ensure the availability and continued operability of systems and components. 

Examiners should review the following: 

* • System and component inventory adequacy for key information (e.g., to facilitate the entity identifying and addressing vulnerabilities).
* • Maintenance plans, including maintenance schedules and logs, vendor and developer recommendations, cost-benefit analyses, operational risk assessments, and qualified staffing adequacy.
* • Change management processes, including change types, authorizations, and related risk
* • Security monitoring reports (e.g., anomalous activity).
* • Configuration management practices to validate appropriate implementation and
* • Vulnerability and threat identification processes, including remediation plans.
* • Any maintenance-related reports to the board of directors and senior management.
* • IT asset inventory, including considerations for EOL, such as planned obsolescence and
* • Termination, disposal, and off-boarding processes of systems, components, and change in planning for upgrades to legacy systems and components. third-party relationships.
* • Maintenance documentation for any system, component, and configuration updates. assessments. enforcement of established change processes.

The maintenance237 and operations238 SDLC activities are necessary whether systems and components have been developed internally or by a third party. They include the routine servicing and periodic modification of everything needed for a system or component to run correctly including the network, hardware, system software, databases, and the related documentation. An entity’s maintenance policies and procedures should include maintenance roles and responsibilities (which may include third-party roles and responsibilities), maintenance access policy (internal and remote), and maintenance monitoring and auditing mechanisms. 

237 As noted in the FFIEC Glossary, “maintenance” is “any act that either prevents the failure or malfunction of equipment or restores its operating capability.” 

238 As noted in the FFIEC Glossary, “operations” are “the performance of activities comprising methods, principles, processes, procedures, and services that support business functions.” IT operations include the tactical management of technology assets and daily delivery of services to capture, transmit, process, and store transactions and information that support the entity’s overall business processes. 

Well-managed modifications can improve a system’s or component’s functionality, confidentiality, integrity, availability, and resilience. Periodic modifications may address user functional requirements, correct security vulnerabilities, enhance performance, or increase storage. 

An accurate and complete IT asset inventory, including system and component maintenance, is central to ITAM. For example, an inventory that contains system and component versions and patch levels allows an entity to quickly determine how a newly discovered vulnerability affects the organization. Another use of the IT asset inventory is to determine which systems are affected by components reaching their EOL. IT asset inventories should include IoT products.239 For more information on ITAM, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

## VII.A Preventive Maintenance 

Preventive maintenance is the activity to proactively address situations that may cause issues or disruptions. For example, an entity may review a system’s storage utilization periodically to determine whether storage is adequate to prevent related outages. 

Management should establish a preventive maintenance plan, especially for mission-critical systems and components. When developing the preventive maintenance schedule, it is important to consider system or component criticality, developer maintenance recommendations, operational risks, and other relevant factors (e.g., emerging technologies and threats). These maintenance plans should be aligned with business plans. Appropriate entity personnel schedule maintenance activities during time frames that minimize the risk of interruption to business processes such as after business hours, during weekends, and during holidays. 

System and component access for maintenance activities should be limited to only that part of the system needed to perform the maintenance and only for the time necessary to conduct the maintenance activity. Capturing and reviewing maintenance activity logs minimizes the risk that malicious activity occurs during a maintenance window. 

For more information, refer to the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations” booklet. 

## VII.B Change Management 

Change management encompasses the planning, governance (including approvals), testing, and implementation of any form of change. Examples of changes that are important to manage are configuration changes, software patches, and functional changes. 

A key piece of change management is change control, further explained in the “Implementing Changes” section of this booklet. Changes may be necessary for a variety of reasons, including updates or modifications to systems or components, requests from users, and results from vulnerability scans or penetration tests. The speed with which these changes should be implemented varies. For example, configuration changes or software patches that address a newly discovered vulnerability in a critical system should be completed quickly, while changes to improve user functionality in a low criticality system may have a slower implementation time frame. 

239 For more information, refer to NIST IR 8425, Profile of the IoT Core Baseline for Consumer IoT Products, and NIST IR 8259A, IoT Device Cybersecurity Capability Core Baseline. 

The complexity and, in some cases, the system’s or component’s age may determine the type and frequency of changes needed to maintain the system or component. A system that is complex and contains multiple components may need to be changed more frequently than a simple system that is less reliant on multiple components. Similarly, a system or component that is new may experience more changes when it is initially placed into a production environment versus a system or component that has existed in a production environment for many years. Additionally, systems and components used by large groups may involve more frequent changes to meet the needs of a greater number of users. 

Management should be aware of and manage the risks associated with unauthorized, untested, and unplanned changes. These risks include breach of confidentiality, breach of integrity (e.g., accidental configuration errors), lack of availability (e.g., system failure resulting from an inappropriate change or not implementing a change), or lack of resilience. Appropriate processes should be followed to manage changes (e.g., configuration management, vulnerability management, and patch management) regardless of whether the system or component was developed internally. 

* • Configuration management: Configuration management policies, standards, and procedures for developed and procured systems and components should be established, and validation performed to ensure that they are followed. The policies, standards, and procedures should include the identification and the use of system and component baseline configurations240 (or original versions). The policies, standards, and procedures should specify that management evaluates, approves, documents, and disseminates changes to baseline configurations. Automated tools may simplify and promote consistency throughout the process. As previously stated, effective management helps ensure that changes to the configuration follow an established change management process. For more information, refer to the FFIEC IT Handbook’s “Information Security” and “Architecture, Infrastructure, and Operations” booklets.
* • Vulnerability management: Sources of vulnerability information (e.g., including threat intelligence) for the entity’s systems and components should be identified. These sources may include the vendor, supplier, or developer, public-private information-sharing partnerships (e.g., the Financial Services Information Sharing and Analysis Center [FS- ISAC]241 and NIST National Vulnerability Database242), and internal and external testing. Entity personnel should remediate relevant vulnerabilities and address threats continually and efficiently. The criticality of the identified vulnerability and the affected system or component can dictate the timing of the remediation. Appropriate senior leadership should review vulnerability management results, such as whether the most severe vulnerabilities are remediated within appropriate time frames, as specified in policy. Open or unresolved vulnerabilities in an entity’s systems and components could result in loss of confidentiality, integrity, availability, and resilience. 240 NIST defines “baseline configuration” as “the documented set of specifications for a system, or a configuration item within a system, that has been formally reviewed and agreed on at a given point in time, and which can be changed only through change control procedures.”
* • Patch management: Patch management processes are a critical part of an entity’s effective change management practices. The entity’s patch management processes should include procedures for identifying, evaluating, approving, testing, installing, and documenting patches or updates for systems and components. Regardless of whether the systems or components are developed internally or by a third party, it is critical to have a process for the timing, prioritization, testing, and deployment of patches to minimize the potential of vulnerability exploits that may result in system compromise or service disruption. Reasons for not applying patches should be documented and periodically reviewed by appropriate personnel, independent of the decision to not apply the patch. These processes help mitigate the risk that unaddressed vulnerabilities exist in systems and components and lead to system compromise. For more information, refer to the FFIEC IT Handbook’s “Information Security,” “Architecture, Infrastructure, and Operations,” and “Audit” booklets.

### VII.B.1 Implementing Changes 

#### Action Summary 

Management should have a process for the request, decision, approval or rejection, test, and implementation of changes. The goal of the change process should always be system or component confidentiality, integrity, availability, and resilience. 

Examiners should review the following: 

* • Change management policies and procedures.
* • Change logs.
* • Relevant access controls.
* • Processes for controlling system and software versions.
* • Sample change documentation (e.g., change requests and approvals), including risk
* • Change management program training.
* • Conversion plans and coordination with conversion partners and stakeholders. assessments. 241 FS-ISAC is an industry consortium dedicated to reducing cyber risk in the global financial system. 

242 NIST’s National Vulnerability Database is the U.S. government’s repository of standards-based vulnerability management data represented using the Security Content Automation Protocol. These data enable automation of vulnerability management, security measurement, and compliance. The database includes security checklist references, security-related software flaws, misconfigurations, product names, and impact metrics.

The process of implementing changes is sometimes referred to as change control. This process helps ensure that IT-related modifications are appropriately authorized, tested, documented, implemented, and monitored. Effective change control processes help management ensure that patches, updates, and configuration changes will not adversely affect a system, component, or application on the network. The characteristics and risks of a system, activity, or change should dictate the formality of the change control process. Management should maintain policies, standards, and procedures that specify the change control process, including defined roles and responsibilities. Examples of key roles with associated responsibilities are the project sponsor, change manager, quality manager, information security manager, auditor, network and system administrators, user support, and users. 

A change manager is responsible for managing all changes affecting the entity to realize the intended improvements with minimal or no disruptions to operations. A group of stakeholders can aid the change manager in the assessment, prioritization, and scheduling of changes. Examples of this type of group include change advisory boards and change control review boards, which often consist of representatives from all areas in the entity’s IT department, affected business lines, and third parties. This individual or group should develop communication protocols to ensure that all affected stakeholders are notified of changes. 

Management should prioritize and categorize changes. Changes may be prioritized based on entity requirements (e.g., IT and information security); resources required; and legal, regulatory, and contractual reasons for the change. Change requests may be categorized as rejected, approved, or closed. Prioritizing focuses the organization on completion of the most important changes first. Categorizing changes helps the entity monitor change management performance. Therefore, appropriate change performance metrics and reports should be established. 

Effective management has a method to track and report changes (e.g., standard change request forms, library and version controls, and spreadsheets or automated change logs). A change control tracking and reporting process, which may be manual or automated, gives management information about the number, priority, and status of change requests, allowing management to make informed decisions and adjustments as necessary. Maintaining and reviewing detailed change logs is critical for any change control processes. The absence of sound controls and adequate documentation of implemented changes can cause problems when designated personnel install subsequent system changes. Without adequate documentation and controls, personnel will not have the necessary information and may make a change that has an adverse effect on operations. 

Effective management follows a defined change control process to make routine and planned changes to systems or components, adjust configuration settings, and make changes to remediate flaws. Management should also account for emergency and unscheduled changes in the change control process. When planning the change, effective management prepares for unexpected problems or failures with the change by creating a back-out plan and documenting the steps taken during the change in the order they occurred. This allows management to back out of a change partially if not all systems and components are affected. Generally, a change control process consists of defined steps, which may address the following: 

#### • Request: 

The change request should include details of the change (e.g., system or component to be changed, description of the change, and justification); impact analysis to identify security needs, risks, and affected systems; change time frame; and back-out plan. 

#### • Review: 

Stakeholders review change requests to determine their viability and business practicality.243 If reviewers approve a change request, they also prioritize it based on the system’s criticality, type of change, interdependencies and interconnections with the involved system, and duration of the change (i.e., time the involved system may be offline or degraded). 

#### • Approval: 

An appropriate level of management, sometimes in collaboration with personnel or a committee, should determine approval of change decisions. Documentation of the decision and approval depends on the type of change initiated. Entity personnel should decide on changes in a timely manner (i.e., in advance of the change). Standard processes may not be followed in emergency situations. However, emergency changes should still be documented, even if after the fact. Emergency change processes should include a list of personnel approved to authorize emergency changes. All changes should be captured through the change control tracking and reporting process. 

#### • 

Design and build: The developer (both internal and external) designs and builds the change to fulfill a request. When completed, the developer provides the requested change to the team or individual responsible for testing. 

#### • Test: 

The team tests the proposed change independently for security, functionality, and any potential adverse effects of the change. Testing should verify that the change performs as intended, identifies any flaws (e.g., integrity issues), and that the change integrates with other systems as intended. Patches and updates that are deployed without testing may have unintended consequences (e.g., deployment delays and operational disruptions) and result in change rollback. Testing should be documented so that testing policy and procedure implementation may be audited. 

#### • Implementation: 

Before deploying a change, an implementation plan (i.e., steps to deploy the change) should be created, full copy of the current production version backed up, and the back-out plan finalized. The team should deploy the approved change according to the implementation plan, preferably during off-peak hours or planned system downtime to minimize the system’s or component’s time offline. 

#### • 

Verify and close: After implementation, management should perform a post-implementation review to verify that the change was deployed according to the implementation plan and functions appropriately. A comparison of modified programs with change authorization documents serves to validate that only approved changes were implemented. After verification, effective management follows processes to document completion of the change and close the change request. After closing, management should report on the status of the change and monitor the implemented change for unintended issues. 

Security is critical when implementing changes for different systems or functions, such as network and client-server environments, mainframes, operating and application programs, and development and procurement projects. To help ensure that modifications do not adversely affect the security posture of varying systems, effective management integrates security into its change 

243 The review may be performed by IT management and stakeholders (e.g., system owner, technical staff, or financial personnel). The reviewers may form a formal committee (e.g., IT steering or operations) depending on the proposed change’s scope, costs, risks, impact, and implementation time frame. 

& 

control processes. Failure to include information security considerations when implementing changes can result in operational disruptions, degradation in a system’s performance, or inappropriate security controls in the system. A change impact analysis can help entity personnel determine the extent to which a change to a system or component may affect its operational, security, and compliance posture. Inaccurately assessing a change’s effect could increase the likelihood of an operational disruption or a threat exploiting a vulnerability at the entity. 

An impact analysis is completed before the entity makes a final decision regarding the change in the case of a planned change, or after implementation in the case of emergency changes. For a significant change, post-implementation reviews should identify any material impacts that were not anticipated, especially if there were any adverse effects on confidentiality, integrity, availability, resilience, or compliance. 

### VII.B.2 Additional Control Considerations in Change Management 

### VII.B.2(a) Data Controls in the Testing Environment 

Use of production data in test environments should be accompanied by appropriate controls. Some entities have a testing environment that allows the testing of patches, updates, and fixes in a nonproduction environment that is similar or identical to the production environment, including the same configurations and data sets. Use of a test environment that matches the production environment raises the probability that testing will be effective in identifying flaws. If production data is copied into the test environment, it should be protected as if it were in the production environment. Another option is for an entity to generate synthetic data244 for use in the test environment instead of using production data. Additionally, the testing environment should be isolated and otherwise protected to avoid it being a vulnerable exploit vector. 

### VII.B.2(b) Library Controls 

Effective management strictly controls the movement of programs and files among development, quality management, and production libraries245 for purposes of change control. Libraries allow programmers to access frequently used routines246 and add them to programs without having to rewrite code. Libraries include executable code modules that run as part of larger applications. Inappropriate segregation of duties between development staff and non-development staff who manage the libraries can lead to production system defects, or the introduction of malicious programs, which in turn can negatively affect system confidentiality, integrity, availability, or resilience. 

244 According to NIST Glossary, “synthetic data generation” is “a process in which seed data are used to create artificial data that have some of the statistical characteristics of the seed data.” 

245 In computing, the term “libraries” refers to collections of stored documentation, programs, and data typically segregated by the type of stored information, such as development, testing, and production-related programs, data, or documentation, and arranged for quick identification and reuse. Program libraries include reusable program routines or modules stored in source or object code formats. 

246 For purposes of this discussion, a “routine” is defined as “a sequence of computer instructions for performing a particular task.” 

& 

Assigning librarian functions to independent personnel (e.g., quality management personnel in more complex entities or non-operations personnel in less complex entities) reduces the risk of errant or malicious code being moved to production environments. Additionally, independent program integrity verification, library activity logs, and documented approval processes also mitigate this risk. These controls should ensure that code in libraries is not altered or deleted. Additional library controls, to mitigate these risks include the following: 

* • Object grouping and associated access controls: Rather than establishing controls on
* • Role-based, automated library applications: When feasible, the implementation of role- individual objects in libraries, which can create security administration burden, entity personnel or automated programs group similar objects (e.g., executable and nonexecutable routines, test data, and production data) into libraries based on object type. Access can then be granted at library levels. based, automated library applications can help management by restricting access at library or object levels. Additionally, such applications can produce reports that identify who accessed a library and what, if any, changes were made.

Effective management considers using these automated change controls commensurate with the complexity of the entity’s IT environment and the number, types, and complexities of changes in that environment. Regardless of whether the entity has automated change control tools, management should strictly control access to production software libraries, particularly in distributed environments. 

### VII.B.2(c) Code Repository Controls 

Code247 can be stored in repositories.248 They are used in the process of development and configuration management. Through version-control features, code repositories help management track and control different versions of developed source code and program documentation during development, as well as deployment scripts and configuration files. Code repositories may be hosted in-house, on third-party platforms, or on publicly available collaboration venues. 

Management should establish code repository use policies. The policies should specify which code repositories the entity uses and where code repository data actually resides, especially for any cloud-based repositories (e.g., public, private, and community clouds). Effective policies and practices include the following actions: 

* • Prohibiting, when appropriate, the use of any public-based forums, especially if using a private account for entity business or data use.
* • Establishing source code ownership. 247 Code types include source code, executable code, and configuration-as-code. 

248 Repositories are locations where assets may be stored in no certain order. Repositories may contain assets such as libraries, data, and code.
* • Requiring business account use to manage entity repository data and correspondingly
* • Controlling and tracking entity accounts for personnel if cloud repositories are authorized.
* • Prohibiting posting entity-owned code in open (i.e., public) forums.
* • Evaluating security and other repository risks before using them.
* • Implementing technical or logical controls (e.g., data loss prevention filters) to block
* • Searching open (i.e., public) code repositories for entity-owned source code for unauthorized prohibiting personal account use.
* • Prohibiting entity credential use (e.g., email address, password) when creating personal repository accounts.
* o Using available security measures, such as MFA.
* o Auditing to determine that all repository-suggested practices, including security
* o Ensuring sanitization of data, if applicable.
* o Restricting exfiltration of code to personal accounts. measures, are appropriately adopted.

FFIEC IT Examination Handbook Development, Acquisition, and Maintenance sensitive data from being published to unapproved repositories. posting of company-owned source code. 

Code repositories can be used to manage software changes. For example, code repositories often have built-in version control functionality. Version control tools can be used to manage both software code and associated documentation. Lack of version control can result in updates to the wrong code version and inappropriate access to code. Additionally, inconsistency in code location and naming convention can result in development and maintenance inefficiency. Therefore, available version control features should be used to track changes made to the code and to increase individual accountability for changes.249 

Another important security control for code repositories is access control. To prevent unauthorized access to or modification of code, access to code repositories should be role-based, follow the principle of least privilege, and limit access to authorized personnel, tools, and services. Management may consider authorization strategies (e.g., zero trust) to mitigate risk. The following are examples of effective access controls: 

* • Request and approval processes for access to code repositories (e.g., development, staging, or
* • MFA requirement for access to all (internal and cloud-based) code repositories.
* • Appropriate segregation of duties to prevent developer access to the staging and production
* • Periodic review processes for access roles and repository logs. production). code repositories, prevent quality management personnel from having access to production code repositories, and grant access to production code repositories only to release management personnel. 249 Refer to NIST SP 800-218, Secure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software Vulnerabilities.

The entity’s continuity planning should include code repository backup to facilitate recovery when the development, staging, or production environments are disrupted. Additional information related to the principles and concepts discussed in this section is available in the FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations,” “Information Security,” “Management,” and “Audit” booklets. 

### VII.B.3 Change Types 

There are several change or modification types that can be controlled through use of a defined change process. The change types are routine or planned modifications, major modifications, and emergency modifications. Effective management has procedures for changes that include change request, review, and approval that direct management to plan, test, and document changes before implementation. Regardless of the change type, management should ensure that changes to any IT system, component, or service are supported by an orderly, adaptable, documented, and measurable process to promote the consistent implementation of changes as well as provide an audit trail for changes. This gives management the necessary information for resilience purposes (e.g., specific rebuild point) or if there are problems when implementing the change (e.g., specific back-out procedures). 

### VII.B.3(a) Routine Modifications 

Routine or planned modifications include changes to systems or components to improve performance, add functionality, enhance usability, address defects, improve security, or comply with a new law or regulation. Sometimes referred to as standard changes, routine modifications can be simple or complex but are not considered major and generally can be implemented during the normal course of business. Routine modifications follow repeatable procedures and are often implemented with automation. They include patches, version updates, and firewall changes. They also may include replacing or upgrading network hardware (e.g., printers, user computers, and networking devices). Defined implementation plans, which often include using automated deployment tools to deploy the modifications, are important especially when changes are implemented over numerous systems or components, or across widely dispersed networks. 

Effective management plans and coordinates routine modifications because IT changes often affect multiple business lines. Change management discussions should involve sufficient representation from lines of business, IT, information security, quality management, and audit. It is important for involved personnel to receive training to ensure that changes support entity objectives and do not adversely affect confidentiality, integrity, availability, and resilience. Centralized oversight (e.g., through a committee) helps to manage the interdependencies of the entity’s systems and operations. Committees providing oversight help clarify request requirements set by the entity and help ensure that all departments are aware of pending changes. Change management discussions to coordinate change activities may happen using specialized change control committees (e.g., CCB) or less formally through management discussions (e.g., during IT steering committee meetings). 

After completing a routine modification, all systems and components should be backed up to an off-site location, secured, and maintained to ensure adequate confidentiality, integrity, availability, and resilience. Management should have an inventory of changes, including routine modifications, for back-out, resilience, and tracking purposes. 

### VII.B.3(b) Major Modifications 

Major modifications include significant functional modifications to an existing system, conversion to a new system, or introduction of new systems, components, or data because of corporate mergers or acquisitions. In some cases, these may be referred to as “normal” changes as they are common but more complex than routine changes. These changes rely on extensive planning and additional management oversight as they often are longer-term; affect more of the entity’s systems, components, departments, and personnel; and incur higher cost. Major modifications should be implemented by adhering to a structured change management process, as noted in the “Implementing Changes” section of this booklet; however, some changes may need to go through the SDLC, particularly if there is any significant development activity. The goal of this process is to minimize risk, promote integrity and security, and maintain uninterrupted delivery of the service during and after a significant modification is implemented. 

Entity personnel should assess risks related to major modification and all security-related changes. Key stakeholders should formally discuss these major modification requests and associated risks identified before approving the requests. Major modification policies and procedures should specify the decision criteria, accounting for requirements, feasibility, cost, project planning, software design, programming, testing, and implementation. 

Entity personnel should determine the training required to make the conversion or major hardware and software upgrade successful. Training may start with ensuring that the major modification is adequately documented (e.g., new system information, user manuals, updates made to the system, and training information). Users affected by the changes should receive appropriate communication and training. Additionally, evaluation of the type, volume, and timing of training needs for each affected line of business and coordinate training programs with applicable third parties should be performed. 

System conversions (and associated deconversions) are a major modification subset. A system conversion is a major change to an existing system and may involve migrating the system from one platform type to another (e.g., from on-premises to a cloud environment, or from one core provider to another). System conversions occur because of the introduction of new systems or corporate mergers and acquisitions. Changes to the foundation of the core platform may have additional effects throughout an entity’s operations, resulting in increased risk. Therefore, strong conversion controls (including documented conversion plans, adherence to entity change management processes, and comprehensive management oversight) are critical to prevent data corruption, performance degradation, and operational disruption. An improperly planned and executed conversion can disrupt the business and create inefficiencies, internal and external user dissatisfaction, and accounting problems, resulting in customer dissatisfaction, customer loss, and damaged entity, product, or service reputation. 

Successful conversions rely on a comprehensive analysis of a conversion’s impact on existing operations (e.g., business processes and associated data processing, storage, and communication requirements), while accounting for interdependencies. Effective conversion policies, standards, and procedures should include provisions for internal and external communication channels, appropriate reporting, and lines of authority for timely decision-making and issue resolution. Elements such as the following should be considered when planning a conversion: 

* • Conversion team: The conversion team should include stakeholders with knowledge of the
* • Strategic fit: The new system should meet as many of the entity’s strategic and business interdependencies of the system being converted and ability to articulate how the new system solves issues or improves outcomes. objectives as possible (to limit the need for additional products or add-ons).
* • Integration: The new system should integrate with existing systems and components. This often involves using internal APIs to securely connect to internal systems across lines of business and using external APIs to securely connect with the entity’s third parties (e.g., cloud providers, fintechs,250 third-party developers, partners, and customers).
* • Business intelligence: The new system should enable comprehensive data analysis to support daily business activities and customer relationship management.
* • Ease of use: The new system should be easily navigable and intuitive for entity personnel, which can improve workflow efficiency even if workflow efficiency was not an objective.
* • Evolution: The new system should efficiently support evolving functional needs, changing technologies (e.g., evolution from on-premises to a cloud environment, artificial intelligence [AI], and quantum computing), and increasing capacity needs.
* • Compliance: The new system should meet the entity’s regulatory and internal policy requirements.
* • Security: The new system should meet the entity’s enterprise-wide information and cybersecurity requirements (e.g., security protocols, cyberattack monitoring, and resilience).
* • Training:
* • Conversion plans: A key factor in conversion plans is ensuring the capability of personnel New system training should be available in a variety of formats (e.g., prerecorded, in-person, and virtual) and for a variety of users (e.g., end users and administrators).
* • Remote work flexibility: An important variable to consider is whether the solution supports entity personnel remote work. to map existing entity systems and components to the new system, to identify interdependencies, and to transfer data to the new systems. Additionally, an after-action review of the conversion can be useful for minimizing potential issues in future conversions.
* • Support:
* • Cloud: Third parties should be able to support the conversion and provide ongoing support to the entity after the conversion. 

Cloud-based solutions should meet applicable compliance requirements, include technology support, and integrate with the entity’s existing systems and components.

Reference checking with a conversion partner’s other clients can be helpful to learn the lessons from their conversions and improve the entity’s conversion plan. 

### VII.B.3(c) Emergency Modifications 

Emergency modifications correct severe and unexpected problems with systems and components and minimize operational disruptions after an incident. Examples of situations that may require emergency modifications include the following:251 

250 As previously stated, for purposes of this booklet, the term “fintech” refers to using technology in novel ways to provide financial services. 

* •
* •
* •
* • Natural disasters (e.g., floods, earthquakes, and storms) that disrupt critical facilities (e.g., data center outages and building evacuations for extended periods).
* • Loss of a critical vendor or other supply chain component (e.g., cloud vendor, network vendor, telecom provider, electricity provider, and water system). 

IT incidents (e.g., denial of service attacks, malware, and network cable cuts). 

Emergency security patches released by vendors. 

Zero-day vulnerabilities that require timely configuration or other changes to mitigate risk until a patch can be developed, tested, and installed.

Entities that plan for emergency modifications are better able to limit negative effects on their business when situations like the above occur. To plan for emergency modifications, entities’ policies, standards, and procedures should address expected emergency steps, such as the following: 

* •
* • Specify who can declare an emergency. 

Designate a group (e.g., emergency change control review board) that can meet on extremely short notice to evaluate and approve proposed emergency modifications. The group could include senior leadership, critical line-of-business management, and key IT management.
* • Create an emergency modification plan that includes a list of individuals in the emergency group (e.g., emergency change control review board) with contact information, and the procedures that are modified from standard change control and security processes to enable quick action.
* • Plan for multiple methods of communication (e.g., in-person, phone, text, email, and collaboration site) in case the emergency occurs outside normal business hours, or a method is unavailable or insecure.
* •
* • Identify the responsible parties for enacting emergency changes and plan for their continuity. 

Compress certain phases of the implementation process to save time and still test, model, or simulate252 before releasing the changes into the production environment. Any unwarranted delays in patching increases the risk that malicious actors or malware can exploit unpatched systems. For more information on exploits, refer to the FFIEC IT Handbook’s “Information Security” booklet. Methods for reducing deployment time include the following: 


	+ o Reducing the number of use cases addressed in testing and modeling, as well as planning to remediate issues with specific use cases. o 
	
	Performing smaller scale testing in the modeling environment, such as deploying patches to 10 test machines instead of 50 or 500. 
	
	251 Refer to CISA’s CRR Supplemental Resource Guide, Vol. 3: Configuration and Change Management, Version 1.1, and CRR Supplemental Resource Guide, Vol. 5: Incident Management, Version 1.1. 
	
	252 In computing, “modeling” or “simulation” is defined by Merriam-Webster as “the imitative representation of the functioning of one system or process by means of the functioning of another.”
	+ o Maintaining a list of users who have the authority and access rights to easily acclimate to emergency changes and can communicate temporary remediation tactics to their peers.
	+ • Establish emergency minimum recovery point objectives with stakeholders to reduce the time required to perform system backups.
	+ • Establish emergency downtime procedures (e.g., failover to alternate systems) that allow
	+ • Perform periodic emergency drills in the test and modeling environment to prepare IT staff to systems to be taken completely offline in emergencies. This helps minimize the need for outages and reboots in times of heavy use and expedites change completion. deal with the stress of emergency modifications. Review the results of these drills and adjust emergency modification plans accordingly.

As identified above, testing emergency modifications before deployment is preferable to minimize potential disruptions. Effective management weighs the potential damage from an untested emergency change against the known damage from the subject issue to determine the level of testing required. Because testing is likely to be shortened, it is even more critical in emergency situations to have backup files and programs available and to establish a back-out plan before emergency modifications are implemented. Appropriate backups, established back- out plans and procedures, and detailed documentation provide the ability to reverse a change if it disrupts the system. 

The number of emergency modifications should be kept to a minimum, and management should validate every emergency modification after implementation to determine whether it was correctly classified. Control should be maintained over personnel attempting to circumvent routine modification or major modification control processes by incorrectly classifying changes as emergencies to avoid resource constraints (e.g., time, personnel, and cost). 

Detailed documentation enhances management’s ability to analyze the effect of the emergency modification during a post-implementation review and verify that the change was deployed appropriately. Evaluations and documentation reviews of emergency modifications should be completed as soon as possible after implementation. Findings from these evaluations and reviews are used to improve existing change control policies, standards, and procedures. 

For more information, refer to the FFIEC IT Handbook’s “Business Continuity Management,” “Architecture, Infrastructure, and Operations,” “Information Security,” and “Management” booklets. 

### VII.B.4 Change Management Documentation 

Documentation related to changes allows management to analyze changes over time, learn lessons from those changes, and the effect of those changes on the entity’s systems and components. Documentation of all changes (e.g., configuration changes, patches applied, system conversions, and emergency modifications) and their impact on systems and components should be maintained. Some examples of change-related documentation are covered in the following subsections. 

### VII.B.4(a) Change Request Form 

Entities use change request forms to communicate the specifics of the change to all stakeholders for analysis purposes after the change is completed. The forms should provide a clear description of the requested changes as well as sufficient information for affected parties to understand the effect of a change. Change requests typically include elements such as the following:253 

* • Change request title.
* • Change control identification number.
* • Requestor’s name.
* • Request date.
* • Detailed description of the change, including system, component, or configuration item
* • Proposed date and time of the change.
* • Stakeholder groups affected.
* • Business justification for the change.
* • Resources (e.g., personnel, expertise, cost, and time) needed to implement the change.
* • Expected impact of the change.
* • Expected impact on resilience requirements for the asset.
* • Backup procedures.
* • Rollback (or back-out) procedures.
* • Change urgency (e.g., low, medium, high, or emergency; and scheduled, urgent, or
* • If the change is an emergency, justification for emergency change.
* • Change control review board input, such as the following: involved. unscheduled).
* o Preliminary assessment of change.
* o Decision (e.g., approved, rejected, more information required, or deferred) and further action if not approved.
* o Comments.
* o Authorized approver’s signature and date.
### VII.B.4(b) Impact Analysis 

Documented impact analyses assist in communicating the effect of a change on the entity’s information security. The impact analysis is generally maintained with and may be presented with the change request to serve as supporting information for decision purposes. The impact analysis typically includes elements such as the following:254 

253 Refer to CISA’s CRR Supplemental Resource Guide, Vol. 3: Configuration and Change Management, Version 1.1, and CRR Supplemental Resource Guide, Vol. 5: Incident Management, Version 1.1. Also refer to NIST SP 800- 128, Guide for Security-Focused Configuration Management of Information Systems. 

* • Change request title.
* • Change control identification number.
* • Requestor’s name.
* • Request date.
* • Analyst performing the impact analysis.
* • Technical implications, such as other systems or components affected by the change or
* • Functional impact, such as required changes to existing applications.
* • Schedule impact.
* • Financial impact, such as funding required to implement the change.
* • People impact, such as end users, customers, expertise, and training.
* • Security impact, including information security, cybersecurity, and physical security.
* • Resilience impact.
* • Entity risks from this change.
* • Rollback (or back-out) implications.
* • Alternatives to change and impact of not making the change.
* • Authorized approval signature and date of approval.

VII.B.4(c) Rollback or Back-Out Plan interface and integration issues (including with third parties). 

When implementing changes, there is always the potential that the deployment does not go as planned. When issues arise after a change, it may be necessary to rollback (or revert) to a prior version or level or back out a change and restore a system to its earlier state. Entity personnel should prepare for the possibility of a failed or incomplete deployment and have a plan with procedures to address the issues. Entity personnel should develop a rollback or back-out plan to reverse a failed deployment. 

A rollback or back-out plan identifies the steps necessary for restoration to a previous secure and functional version of the baseline configuration.255 This plan can help an entity recover from a system or component update that is not functioning correctly. The plan can explain what to do (e.g., shut down, failover, or replace) if a service or component fails and how to resume secure operations on a redundant system while still providing uninterrupted service to end users. Entity personnel should consider the time required to perform rollback procedures and when to trigger the rollback plan. Entity personnel should establish rollback plan timing that minimizes business disruption. 

Change implementation failures or incomplete changes can cause expensive damage to systems and components. One effective plan step is to minimize damage by identifying a stable recovery point and archiving or imaging the system or component at that point. Entity personnel would develop and test related rollback procedures and identify spare systems and components (e.g., power supplies, system motherboards, hard drives, and communication switchboards) that may be needed, consistent with the criticality of the system or component. The entity documents the stable recovery point so multiple personnel can participate and view the same information during rollback (e.g., hardware, software, firmware, configuration files, and other configuration records). 

254 Refer to CISA’s CRR Supplemental Resource Guide, Vol. 3: Configuration and Change Management, Version 1.1, and CRR Supplemental Resource Guide, Vol. 5: Incident Management, Version 1.1. Also refer to NIST SP 800- 128, Guide for Security-Focused Configuration Management of Information Systems. 

255 Refer to NIST SP 800-128, Guide for Security-Focused Configuration Management of Information Systems. 

It is important to control rollback tools because an unauthorized rollback could allow an attacker to restore a system or component to a prior vulnerable image, which in turn could allow the attacker to corrupt the system or component or inject malware. Effective management has appropriate security controls to prevent unauthorized rollback. The entity may have a special update process (e.g., physical presence of personnel) for rolling back the installed systems and components to an earlier version. This mechanism provides a dual control for management to guard against attackers using automation to install old systems and components with known vulnerabilities. 

Effective management tracks and reports issues that lead to the use of a back-out plan and the effects of a failed or incomplete change deployment. Documentation of failed or incomplete deployments should include lessons learned for future change implementations. 

## VII.C End-of-Life 

With respect to technology, EOL is a time frame usually defined by a technology vendor to describe when an asset has reached the end of its useful life cycle and when the vendor will no longer maintain and support the asset or continue to sell or license it. This is also applicable to a service provided in support of purchased IT assets. When the vendor no longer updates or plans to sunset services that support the IT asset or discontinues the sale of licensing of support services, this form of EOL is considered “end-of-service.”256 If the IT asset was created in-house, EOL occurs when the entity has decided to no longer update and otherwise maintain it. 

A vendor generally determines the useful life of the IT assets it sells. The vendor identifies when it will stop providing updates and communicates a timeline along which it will sunset the systems and components. Entity personnel who purchase IT assets from vendors should evaluate the expected life of the IT asset as part of their due diligence. EOL considerations should occur as part of the initial contract negotiation and at contract renewal and be specified in the resulting contract. For example, the contract should contain a clause specifying the amount of advanced notice the vendor will provide the entity before it discontinues updates and other support of the IT asset. This notification is critical to the entity in planning replacements (including migrations from the legacy system to the replacement), and in planning for the off-boarding of the IT asset. Therefore, management should have a process to determine EOL decisions (e.g., replace, upgrade, or migrate to a new system) before a system’s or component’s EOL. 

256 System, component, and service providers sometimes use the term “end-of-service” to indicate when maintenance services and updates will no longer be supported or provided. 

If developed internally, the entity should plan for system or component obsolescence. Management, development staff, and users may have input into the system’s or component’s useful life timeline. If a system or component no longer meets users’ needs, or maintenance costs are too high, management may conclude that the system or component has reached EOL and should be replaced. 

The entity’s IT asset inventory should have information about the useful life of IT assets in order for the entity to plan for orderly transitions from one system or component to another. An effective ITAM process includes monitoring each IT asset’s depreciation and obsolescence schedule and planning well in advance for EOL. Items to consider in the process include the party responsible for development, version, patch levels (available and currently deployed), and the system’s or component’s expected life. An entity may leverage existing tools (e.g., depreciation schedule and IT asset inventory) to facilitate obsolescence planning and ensure that replacement resources have been provided for. 

An IT asset that is obsolete and at EOL or end-of-service may be more vulnerable to exploitation; therefore, this risk should be managed to maintain confidentiality, integrity, availability, and resilience. With older and less resilient IT assets, an increased number of security vulnerabilities may result in greater risk of intrusion and exploitation (e.g., malware, ransomware, and data breaches). The potential impacts from these risks increases for interconnected systems and components because of the number and types of access points. These risks also exist for components provided by all parties in the supply chain. Continuously assessing the risks of using aging, outdated, and unsupported systems and components is the foundation for mitigating the risks. Effective risk mitigations include the following: 

* • Replacing systems and component in a timely manner.
* • Establishing processes for vendors to notify the entity of component EOL status changes
* • Extending support from the vendor.257
* • Adding or augmenting system or component controls: (e.g., end-of-production, end-of-service).
* o Segregating the system or component from the network until it can be replaced or removed.
* o Locking down system or component devices and ports for access.
* o Increasing access controls and monitoring.
* o Minimizing connections to the system or component.

Management should consider EOL risks tied to maintaining legacy systems and components for extended periods of time. When continuing to use legacy systems, management should consider weaknesses related to the design, development, manufacturing, production, shipping and receiving, delivery, and operation of the system and component that can be exploited at EOL by & 

257 Third-party providers often charge additional fees to continue providing updates after a system’s or component’s EOL. Extending support beyond EOL may result in risks, such as operating systems and components with compounded vulnerabilities and diminishing availability of expertise. 

a threat source.258 These legacy-related risks are two-fold. If management continues to use legacy systems or components, management puts its supply chain partners at risk; and if the entity’s supply chain partners continue to operate legacy or unsupported systems or components, the entity may be at risk for EOL or end-of-support vulnerabilities. Effective management addresses EOL and the use of legacy systems and components and time frames for necessary replacement, upgrade, or migration in contracts between the entity and its supply chain partners. 

For more information on ITAM and EOL, refer to FFIEC IT Handbook’s “Architecture, Infrastructure, and Operations,” “Information Security,” “Outsourcing Technology Services,” “Business Continuity Management,” and “Management” booklets. 

## VII.D Termination and Disposal 

When a system or component becomes obsolete, is no longer supported, no longer meets the users’ or entity’s needs, or becomes too costly to maintain, management may decide to terminate its use and dispose of the system or component. Effective management has appropriate termination and off-boarding procedures. The procedures should identify who has the responsibility to decide whether to terminate a vendor relationship, as well as an approval and acknowledgment process in which contracted parties agree to the relationship termination. Effective management negotiates contract clauses that specify termination criteria, including related to fourth or nth party relationships (e.g., affiliates, subcontractors) if necessary. It is important that the termination clauses address confidentiality, integrity, availability, and resilience of data and operations throughout the off-boarding process. 

There are several important considerations when terminating a system, component, or service including disposing of decommissioned systems and components, and safely migrating and disposing of data and documentation. Data are particularly important when being transferred to a new replacement system to maintain confidentiality, integrity, availability, and resilience. Effective management has procedures for activities such as the following: 

* • Shutdown (i.e., sunset) of the systems and components.
* • Identification of the tasks involved.
* • Data identification and preservation (i.e., archival or transfer) or disposal.
* • Secure disposal of unnecessary systems and components (e.g., hardware and software).

Effective management validates that appropriate personnel are aware of the procedures to coordinate the orderly disposition of the system, its components, and the data.259 The entity’s critical or sensitive data and documents should be removed (e.g., wiped, sanitized, or otherwise destroyed) logically and physically from the system and components before disposal. This extends to any data or documents maintained by the third party on behalf of the entity, and effective management addresses the entity’s requirements in the contract termination and disposal clauses. 

258 Refer to “CISA Insights – Cyber: Remediate Vulnerabilities for Internet-Accessible Systems.” 

259 Refer to U.S. Department of Justice’s Systems Development Life Cycle Guidance Document, chapter 12, “Disposition Phase.” 

& 

## VII.E Maintenance Documentation 

Maintenance documentation provides valuable descriptions for the upkeep of an entity’s systems and components and significantly enhances management’s ability to maintain, operate, and administer IT assets. The larger and more dispersed an entity, the greater role documentation plays in effective maintenance across the entity. Advantages of documentation for users include access to operation manuals, training materials, and online application help features. Documentation enhances IT personnel’s ability to maintain and update systems efficiently, track updates to the systems and components, and identify and correct programming defects. 

Developing and maintaining current and accurate maintenance documentation can be complicated, time-consuming, and expensive. However, maintaining standardized documentation and indexing procedures are important to help ensure the uniform accessibility of existing maintenance documentation. Authorized personnel should update the documentation with system, component, and configuration updates according to the entity’s or third party’s prescribed standards, as applicable. Effective management works with third parties to help ensure that the entity receives current system, component, and user maintenance documentation. 

& 

# APPENDIX A: EXAMINATION PROCEDURES 

## Examination Objectives 

Examiners should use these procedures (also referred to as the work program) intended to help them determine the quality and effectiveness of the entity’s management of IT, particularly regarding development, acquisition, and maintenance-related risks as outlined in this booklet. Examiners should use these procedures to measure the adequacy of the entity’s ITRM process, including management awareness and participation, risk assessment, policies, standards, and procedures, reporting, ongoing monitoring, and follow-up. 

Examiners may choose to use only particular examination procedure work steps based on the size, complexity, and nature of the entity’s business. 

Objective 1: Determine the appropriate scope and objectives for the examination. 

* 1. Review past reports for outstanding issues or previous problems. Consider the following: 
	+ a. Regulatory reports of examination.
	+ b. Internal and external audit reports (e.g., SSAE18).
	+ c. Internal or independent tests or reviews of controls (e.g., penetration tests, vulnerability assessments, SOC reports, business continuity reviews, and third-party management reviews).
	+ d. Regulatory and audit reports on service providers.
* 2. Review management’s response to issues raised during, or since, the last examination. Consider the following: 
	+ a. Adequacy and timing of corrective action.
	+ b. Resolution of root causes rather than just specific issues.
	+ c. Existence of any outstanding issues.
	+ d. Whether management has taken positive action toward correcting exceptions reported in audit and examination reports.
	+ e. Independent review of resolution and reporting of resolution to the audit committee.
* 3. Interview management and review responses to pre-examination information requests to identify changes to the technology infrastructure or new products and services that might increase the entity’s risk. Consider the following: 
	+ a. Any significant strategic or business line changes, including any third-party changes.
	+ b. Products or services delivered to either internal or external users.
	+ c. Current network diagrams and data flow diagrams, including changes to configuration or components.
	+ d. Hardware and software inventories.
	+ e. Loss or addition of key personnel.
	+ f. Inventories of third-party providers and software vendors, including services provided.
	+ g. Organizational charts that include reporting relationships between business units and control functions (e.g., enterprise risk management, ITRM, and internal audit).
	+ h. Credit or operating losses primarily attributable (or thought to be attributable) to IT (e.g., system problems, inadequate controls, improperly implemented changes to systems, and fraud resulting from cybersecurity attacks, such as account takeover).
	+ i. Changes to internal business processes.
	+ j. Internal reorganizations.Objective 2: Management establishes, and the board of directors (board) oversees, an effective governance structure that includes development, acquisition, and maintenance activities. Additionally, the board oversees related IT project management processes used to manage projects related to those activities. (Section II, “Governance of Development, Acquisition, and Maintenance”) 

Review the following documents to understand the overall structure and hierarchy of management and oversight activities related to development, acquisition, and maintenance: 


	+ • Enterprise-wide IT policies, procedures, and standards describing the entity’s requirements
	+ • Charters (e.g., board, management, or committee), organizational charts, relevant throughout the development, acquisition, and maintenance life cycle. documentation, and practices to determine whether appropriate roles and responsibilities are identified and assigned with suitable decision-making authority.
	+ • Project plans and meeting minutes of the board and committees to ensure that activities and projects align with the entity’s strategic objectives and the board’s risk appetite.
	+ • Project audit reports to determine whether the audit function provides independent, objective
	+ • Documentation of controls for personnel with access to program code to limit placement into assurance of the effectiveness of an entity’s development, acquisition, and maintenance activities. the production environment.
	+ • QA reports to evaluate processes for the detection of potential coding errors.
	+ 1. Determine whether the board and senior management provides for the following: 
		- a. An effective governance structure that allows for the effective oversight and management of the development, acquisition, and maintenance of the entity’s systems and components.
		- b. Oversight of development, acquisition, and maintenance IT project management processes and projects related to those activities.
		- c. Oversight of significant projects to ensure that they align with an entity’s strategic plans.
		- d. Consideration of business strategies and objectives, resilience needs, information security requirements, legal and regulatory requirements, and allocation of resources (e.g., personnel, budget, and time) when evaluating IT projects and activities. regarding IT development, acquisition, and maintenance activities.
		- e. Consideration of the needs of internal and external stakeholders when making decisions
		- f. Establishment of audit’s role in reviewing development, acquisition, and maintenance activities, and ability to raise objections if they believe the control environment is inadequate.
	+ 2. Determine whether the board and senior management develops and implements comprehensive, entity-wide IT policies, procedures, and standards addressing entity requirements throughout the development, acquisition, and maintenance life cycle. Does the board, senior management, and designated committees of the board perform the following: 
		- a. Regularly review and approve IT policies and standards.
		- b. Review and approve procedures to meet changing IT policies and standards.
		- c. Provide for policies that clearly delineate development, acquisition, and maintenance responsibilities and provide for communication to all personnel, stakeholders, and appropriate third parties.
		- d. Review and approve deviations from policies, standards, and procedures related to development, acquisition, and maintenance.
		- e. Identify and assign appropriate roles and responsibilities for the entity’s development, acquisition, and maintenance activities.
		- f. Identify and address training needs to support development, acquisition, and maintenance responsibilities.
		- g. Provide for an escalation process for development, acquisition, and maintenance issues.
	+ 3. Determine whether the board and senior management identified and provided for key management responsibilities related to development, acquisition, and maintenance activities. Examples of key roles which carry those responsibilities include the following: 
		- a. Board and senior management.
		- b. CIO.
		- c. CISO.
		- d. IT steering committee.
		- e. Business line management.
	+ 4. Determine whether management identified and provided for the responsibilities of IT project management related to development, acquisition, and maintenance activities. Examples of key project management roles that carry those responsibilities include the following: 
		- a. Sponsor.
		- b. Project owners.
		- c. Product owner.
		- d. Project or program manager.
		- e. Business change manager.
		- f. Program management office or organization personnel.
		- g. Stakeholders.
	+ 5. Determine whether management identified and provided for the responsibilities of key roles in development activities. Examples of key development roles that carry those responsibilities include the following: 
		- a. Network architects.
		- b. Developers.
		- c. Software engineers.
		- d. Hardware engineers.
		- e. Information security analysts.
		- f. Systems analysts.
	+ 6. Determine whether management identified and provided for the responsibilities of key roles in acquisition activities, including examples such as procurement manager or third-party risk manager.
	+ 7. Determine whether maintenance personnel provide for appropriate maintenance throughout the life cycle of systems and components. Determine whether maintenance personnel 
		- a. Have knowledge and understanding of all relevant systems and components they are expected to operate and maintain.
		- b. Analyze and understand the costs of maintenance (e.g., budget, time, or personnel) versus the costs of not performing maintenance (e.g., system failures, data breaches, and customer dissatisfaction).
		- c. Track the analysis of costs for reporting to management.
		- d. Maintain independence from development roles to prevent developers from accessing production environments.
	+ 8. Evaluate audit’s role in reviewing development, acquisition, and maintenance activities. Consider the following audit activities: 
		- a. Validating that sufficient time is built into project schedules to define controls and verify that all appropriate stakeholders are involved.
		- b. Determining the effectiveness of controls necessary in the entity’s development, acquisition, and maintenance activities and recommending appropriate mitigation.
		- c. Guiding developers in considering appropriate control standards and frameworks throughout IT projects.
		- d. Reviewing the internal controls, testing, and audit trails included in systems and components during each SDLC phase.
		- e. Performing post-implementation reviews shortly after implementation of new or revised systems or components.Objective 3: Evaluate whether management implements continuous risk management processes within the entity’s development, acquisition, and maintenance activities to identify reasonably foreseeable internal and external risks and threats, including those that could result in unauthorized disclosure, misuse, alteration, or destruction of customer information or customer information systems. (Section III, “Risk Management of Development, Acquisition, and Maintenance”) 
	
	
		- 1. Examiners should review management’s continuous risk management processes for development, acquisition, and maintenance. Consider the following: a. Policies, standards, and procedures for identifying, measuring, mitigating, monitoring, and reporting risks related to development, acquisition, and maintenance activities. 
		
		
			* b. Documented processes and metrics used to measure the level of risk.
			* c. Detailed documentation of processes used to review, accept, and document risks that management cannot mitigate or transfer.
			* d. Documentation of risk assessment processes to identify key risks at the onset of IT projects and throughout their life cycles. acquisition, and maintenance activities. including emerging risks related to development, acquisition, and maintenance
			* e. Risk assessments that highlight internal and external risks related to development,
			* f. Documentation of ongoing processes and reports to monitor and communicate risk, activities.
			* g. Reports to stakeholders that are timely, accurate, and include clear, relevant metrics.
		- 2. Evaluate whether management has identified reasonably foreseeable internal and external risks and threats, including those that could result in unauthorized disclosure, misuse, alteration, or destruction of customer information or customer information systems. Consider management’s risk management actions in addressing the following: 
			* a. Risks that could result in a severe disruption or material compromise to critical service delivery.b. Policies, standards, and procedures for identifying, measuring, mitigating, monitoring, and reporting risks related to development, acquisition, and maintenance activities. 
		
		
			* c. Repeatable process adoption, to ensure that risks are consistently addressed across the entity over time.
			* d. Risk identification and assessments involving stakeholders with business process knowledge who may be affected by the development, acquisition, or maintenance activities or the related IT projects. appropriateness of security policies, standards, and procedures.
			* e. Threat model usage commensurate with the overall threats to the entity, to assess
			* f. Process to review, accept, and document risk when management cannot mitigate or transfer risk, and its acceptance by the board.
			* g. Regular review and approval of risk acceptance decisions consistent with the entity’s governance structure.
			* h. Information security concerns.
		- 3. Determine whether management has established effective risk measurement, monitoring, FFIEC IT Examination Handbook Development, Acquisition, and Maintenance and reporting processes, including for emerging risks. Consider the following: 
		
		
			* a. Implementation of effective standards to measure risk in the entity’s development, acquisition, and maintenance activities.
			* b. Establishment of an ongoing risk measurement process, commensurate with the size and complexity of the entity’s activities.
			* c. Communication of technical aspects through reports to the board that are clear and understandable to board members (e.g., explaining acronyms or technical jargon) and that relate IT issues to business concerns.
			* d. Receipt of reports on IT project risks, such as critical projects that may miss key milestone dates, identification of negative test results, or changes to business or technical requirements. Objective 4: Evaluate whether management has implemented effective risk mitigation throughout development, acquisition, and maintenance activities regardless of the phase of the project in the life cycle and agnostic as to the type of technology. Specific risks and controls should be considered depending on management’s chosen solution. (Section IV, “Common Development, Acquisition, and Maintenance Risk Topics”) 
			
			For this objective, examiners should review and assess the following: 
			
			
				+ • Systems, components, and services, including related contracts and licenses, throughout the
				+ • Secure coding standards, configurations, and security controls used to harden each system or
				+ • Processes for access controls, authorization, and authentication for systems and components,
				+ • Process of selecting and implementing methodologies to enable effective management and
				+ • Operating parameters (e.g., timing, speed, throughput, and data validation) for systems and
				+ • Activity logs related to systems, components, and data to identify operating risks.
				+ • Monitoring processes of development and maintenance activity for identification of
				+ • Reporting processes for decision-making and measuring the level of project success.
				+ • Training on development, acquisition, and maintenance concepts (e.g., methodologies); supply chain for appropriate risk identification and mitigation. component, data, and activity logs for appropriate processes and implementation and maintenance of confidentiality, integrity, and availability.
				+ • Inventory of all systems, components (e.g., open-source, proprietary, APIs, and container images and registries), including related licenses, and data as part of ITAM. data, and related documentation throughout the supply chain to ensure appropriate security.
				+ • Roles and responsibilities to evaluate segregation of duties in and ongoing management commitment to development, acquisition, and maintenance activities. control of development, acquisition, or maintenance projects and alignment with entity objectives. components to determine performance. anomalies and unauthorized access or modification to systems, components, and data. effectiveness of training; and capability of personnel to implement concepts learned.
				+ • Documentation of internally developed programs and externally procured products and services to effectively operate and maintain the systems and components.
				+ • Evaluation process (e.g., post-implementation review, stakeholder interview, problem documentation and resolution, cost-benefit analysis, and reports to senior management) for development, acquisition, and maintenance projects. 
					- 1. Evaluate management’s oversight of use of open-source and COTS components. Consider the following: 
						* a. Identification and mitigation of risks related to the use of open-source components.
						* b. Evaluation of documentation providing support if there are open-source components supporting any line of business.
						* c. Proactive maintenance of updated application and user documentation, especially when code changes are made.
						* d. Consultation with third-party providers and vendors regarding recommended security controls to harden the COTS solution.
						* e. Mitigation of risks related to integration (e.g., lack of interoperability or integration between systems and components).
					- 2. Evaluate management’s ability to negotiate, administer, and implement practices regarding licenses, agreements, and copyright protection. Consider whether management 
						* a. Accurately assesses current and future needs and ensures that licenses continue to meet the entity’s needs.
						* b. Reviews licenses, obtaining confirmation that they clearly state whether system or component usage is exclusive, the number of user licenses, and whether there are any time, place, manner, or other types of limitations with the system or component’s use. minimum amount of notice required for license termination.
						* c. Specifies in its agreements the appropriate time periods for all licenses and the
						* d. Periodically reviews system and component licenses to compare all installed licensed
						* e. Determines whether a third-party vendor provides access to source or object code
						* f. Reviews licenses to determine whether they include retention and use of backup systems and components with the respective license terms. (“code”) when drafting agreements. copies of any mission-critical system or component on which the entity may rely for disaster recovery or business continuity purposes at remote sites.g. Negotiates, when possible, with licensors to ensure the inclusion of retention and use of backup copies if they are omitted from the terms of a license. 
					
					
						* h. Understands any resulting limitations and consequent risks if involved in difficult license agreement negotiations, including when an entity has limited negotiating
						* i. Periodically reviews system and component licenses to compare all installed licensed
						* j. Considers what is stated in the licenses; costs of obtaining them; and risks, fines, and power. systems and components with the respective license terms. other compliance liabilities for violating their provisions or requirements.
						* k. Includes related entities (e.g., subsidiaries or contractors) as users in their licenses when the entity plans to provide the systems or components to them.
						* l. Implements appropriate licenses for the systems or components developed when management is responsible for developing systems and components and providing them to other entities or its subsidiaries.
						* m. Maintains awareness of the liabilities that come with licensing activities, including considerations related to hardware maintenance, integration, compatibility, and fraud, when the entity builds hardware and licenses that hardware to other entities.
						* n. Specifies in its agreements the appropriate time periods for all licenses and the minimum amount of notice required for license termination.
						* o. Addresses inappropriate usage if there is a discrepancy between actual usage and the total number of installed licenses allowed by the agreement.
						* p. Addresses maintenance agreements, which outline available maintenance services (e.g., provision of new versions, releases, or updates).
						* q. Obtains appropriate vendor permission and participation for modifications to the code for systems and components. documentation when any changes are made to procured systems or components.
						* r. Ensures that the agreement addresses and prompts updates to application and user
					- 3. Assess whether management’s ITAM program includes oversight and management of the software and hardware licenses for components used by the entity. Consider management 
						* a. Awareness of the liabilities that come with licensing activities, including considerations related to software maintenance, integration, compatibility, and fraud if an entity develops software and licenses that software to others.
						* b. Maintenance of an accurate inventory of FOSS as part of an effective ITAM process and understanding of and abiding by the requirements of FOSS licenses.
						* c. Awareness of what information is shared when contributing in return to the FOSS development community.
						* d. Maintenance of program provisions for identification and management of any hardware licenses.
					- 4. Evaluate management’s oversight of copyright protections. Consider management’s actions 
						* a. When deploying procured systems or components for use in the entity’s infrastructure, including physical and virtual networks.
						* b. When reviewing and approving the procurement and use of systems or components in the entity’s IT environment to ensure appropriate use.
					- 5. Assess management’s actions to promote secure development practices for products and services developed and used. Consider management’s actions to a. Monitor third parties’ activities to enforce conformance with the entity’s contract requirements, Information Security Standards, and legal and regulatory requirements when management outsources development to third parties. 
						* b. Evaluate or have a method to evaluate the third party’s secure coding standards (e.g., through independent certification or audit) when acquiring systems and components.
						* c. Determine that secure development standards apply to the development of any system or component changes (e.g., patches or updates) for the maintenance of systems and components.
						* d. Incorporate security in the code, and implement quality management, which is critical to the secure development process.
						* e. Determine that the embedded rules of the code review tools are appropriately configured and used if an automated code review process is implemented.
						* f. Maintain a secure operating environment throughout development, acquisition, and maintenance activities, promoting secure development practices whether operations are performed in-house by entity personnel or outsourced to a third party.
					- 6. Assess management’s actions to securely manage data. Consider management’s actions to 
						* a. Identify the data, their characteristics (e.g., customer sensitive information or proprietary information), and sensitivity (e.g., confidential, internal use only, or public).
						* b. Document the data in an inventory that includes locations and uses of data in development, acquisition, and maintenance activities and in IT projects.
						* c. Include data security in development, acquisition, and maintenance activities.
						* d. Provide appropriate data confidentiality, integrity, availability, and resilience procedures for data input and output, including the use of data in IT projects.
					- 7. Assess management of microservices activities related to development, acquisition, and maintenance. Consider the following management actions: 
						* a. Setting parameters for the processes of registration to and deregistration from the service registry.
						* b. Implementation options that meet the entity’s security requirements.
						* c. Implementation and management of microservices-based architectures, including monitoring of the many services, which may be running on different servers or written in different languages.
						* d. Consideration of the following monitoring controls: 
							+ • Monitoring at the gateway and service level.
							+ • Implementing a centralized dashboard to display the status of multiple services
							+ • Creating a baseline and implementing intrusion detection to provide alerts on and network segments. deviations from the baseline.
					- 8. Assess management’s consideration of risk in the use of containers, such as image risk, registry risk, orchestrator risk, container risk, and host OS risk, and effective countermeasures to risk. Consider management actions to address data isolation when setting up containers.
					- 9. Evaluate management’s risk mitigation strategies for API activities. Consider the FFIEC IT Examination Handbook Development, Acquisition, and Maintenance following: 
					
					
						* a. Configuration of the API with the necessary infrastructure services.
						* b. Application of extra layers of security beyond those for standard end-point security, and implementation of appropriate authorization checks at the object level.
						* c. Implementation of appropriate security, patches, updates for APIs, and disabling of unnecessary functions.
						* d. Appropriate setting of all API processing parameters (e.g., execution timeouts, maximum allocatable memory, number of file descriptors, number of processes, request size, number of requests per client or resource, and number of records per page to return in a single request response).
						* e. Verification that all access is denied by default and employ specific role-based permissions for users to gain access to functions.
						* f. Denial of access to properties unnecessary for the user’s role, and access only allowed when necessary.
						* g. Validation and filtering of all data coming to an API with appropriate parameters.
						* h. Maintenance of logging of API activity (e.g., authentication, errors, redirects, rate limiting, and end points, including their parameters, requests, and responses). failed authentication attempts, denied access, and input validation errors). confidentiality and integrity of sensitive data in activity logs.
						* i. Implementation of continuous logging and monitoring of relevant API activity (e.g.,
						* j. Maintenance of secure logs and ensuring only appropriate access to them to maintain
					- 10. Assess management’s implementation and use of any methodologies for project management. Consider management actions 
						* a. Establishing appropriate methodologies to enable effective management and control of system and component development, acquisition, and maintenance activities.
						* b. Aligning implementation of any methodology with the overall strategic and business objectives.
						* c. Promoting effective planning through IT project management and support training for developers, quality management members, testers, and maintenance personnel.
						* d. Considering the risk of not following established control procedures when using prototyping models. methodologies and determining appropriate mitigation strategies.
						* e. Considering security development process weaknesses when using agile
					- 11. Evaluate quality management actions. Consider 
						* a. Implementation of compensating controls when they cannot fully achieve segregation of duties between quality management and development roles.
						* b. Provision of adequate support for projects throughout an entity to promote success of a project.&
					- 12. Assess documentation standards. Consider management’s process for a. Maintenance of documentation for internally developed programs and externally procured products and services. 
						* b. Maintenance of necessary information and documentation to understand and convey how a system or component was developed, how it functions, and where appropriate security and resilience points are included.
						* c. Maintenance of detailed documentation for each system and component in development and production.
						* d. Implementation of established policies to prepare documentation before deployment and additionally when appropriate, such as when management makes changes.
						* e. Obtaining documentation from the third party and incorporating it into the entity’s own stored documentation for acquired systems and components.
						* f. Validating before purchase (through an internal review or a third-party certification) that a procured system’s documentation meets the entity’s documentation needs and standards.
					- 13. Assess management’s post-implementation review processes. Consider effective evaluation of development, acquisition, and maintenance projects and management actions, such as a. Conducting post-implementation reviews at the end of a project to validate completion of project objectives and assess development activities.
					- b. Interviewing key stakeholders actively involved in the operational use of a product to determine effectiveness of the completed project.
					- c. Documenting and addressing any identified problems to improve future projects and remediate issues in current projects.
					- d. Analyzing effectiveness of project management activities by comparing, among other things, planned and actual costs, benefits, risks, return on investment information, and development time frames. should be informed of any operational or project management deficiencies.
					- e. Documenting results and presenting them to senior management and determining whoObjective 5: Evaluate whether management has developed and followed consistent processes to identify risks and oversee IT projects to address any risks identified. IT projects should be managed according to the size and complexity of the entity and its project characteristics and risks. (Section IV.N “IT Project Management”) 
				
				For this objective, examiners should review and assess
				+ • Project plans, proposals, and status reports to determine whether the IT project manager
				+ • Board and committee minutes to evaluate whether management reviews and prioritizes works with stakeholders (e.g., PMO) to oversee and carry out IT projects. projects and whether it considers the project’s effect on operations and the entity’s needs.
				+ • Project plans, project requests, and documentation standards to determine whether they are
				+ • Documentation of management approvals of any addition or modification of functional,
				+ • Testing and quality management plans used to validate that the project meets the entity’s structured appropriately to clearly define the project purpose, entity’s requirements, and include deliverables for each project phase to address business needs. security, or control features and demonstration that changes are aligned with the project charter and project plan. project goals and stakeholder requirements.
				+ • Documentation for the closeout of the entity’s IT projects.
				+ 1. Assess whether management develops and follows consistent processes to identify risks and oversee IT projects to address any risks identified. Consider whether management 
					- a. Establishes project management policies, standards, and procedures that apply enterprise-wide.
					- b. Develops and follows consistent processes to identify risks and oversee IT projects to address any risks identified. information security, lines of business, customer needs, and regulatory and legal compliance) when reviewing and prioritizing projects.
					- c. Considers the project’s effect on operations and the entity’s needs (e.g., IT,
					- d. Performs analysis of system or component needs for a given project.
					- e. Monitors changes for any addition or modification of functional, security, or control features to help ensure that these changes are approved and aligned with the project charter and project plan.
					- f. Develops and executes testing plans, which validate whether the entity’s project goals and stakeholder requirements are met.
					- g. Maintains comprehensive and accurate documentation reflecting the testing methodology employed, actual tests performed, and test results throughout the testing process.
					- h. Implements quality management (also may be referred to as QA and QC) processes to help ensure that project requirements are met and validated. entity’s IT projects. foster a consistent and accurate process across projects.
					- i. Defines and maintains the required elements for documentation of the closeout of the
					- j. Establishes standards and maintains appropriate documentation for IT projects to
					- k. Maintains processes for developing IT project plans that describe existing system benefits and weaknesses and explain project objectives.Objective 6: Evaluate whether management has an SDLC to manage systems and system components throughout their life cycle; to achieve the objectives of confidentiality, integrity, availability, and resilience; and to meet the entity’s business objectives. (Section IV.O “System 
			
			Development Life Cycle”) 
			
			For this objective, examiners should review and assess 
			
			
				+ • The documented management and control processes for development.
				+ • Description and detail of entity SDLC-related controls, including for supply chain partners.
				+ • Responsibility and accountability assignment.
				+ • Key stakeholder involvement.
				+ • Clear evidence of stakeholder communication and tracking of all SDLC phases and actions.
				+ 1. Assess management’s oversight of the SDLC process. Consider management’s
				+ 2. Evaluate management's maintenance of protections (e.g., information security and FFIEC IT Examination Handbook Development, Acquisition, and Maintenance implementation of a documented process, such as an SDLC, used to manage and control development activities, if the entity engages in internal development activities. resilience) in the information systems, components, and networks for data in transit and at rest, including for the entity’s and supply chain partners’ information, through all phases of the SDLC.Objective 7: Evaluate whether management implements effective processes to address the plans and actions needed in each phase of an IT project, as part of the SDLC. (Section IV.O.1 “SDLC Phases”) 
			
			For this objective, examiners should review and assess the activities associated with the entity’s SDLC phases, such as the following example phases: 
			
			Initiation Phase 
			
			
				+ • Description of the project’s purpose, expected benefits, support for entity business objectives,
				+ • Plans for addressing additional costs, resource needs, and alternate solutions.
				+ • Validation of initial impact analysis, including any baseline security concerns.
				+ • Documentation of the project proposal for all stakeholders in the supply chain.
				+ • Documentation of design specifications.
				+ • Documentation of mitigation strategies for risks identified in the impact analysis.
				+ • Risk assessments, baseline controls design, and effectiveness of security controls.
				+ • Documentation of initial development testing, conversion, implementation, and training
				+ • Documentation of additional design requirements and development changes.
				+ • Documentation of draft user, operator, and maintenance manuals.
				+ • Documentation of design reviews and system tests, including any new specifications.
				+ • Documentation of deployment approach selected.
				+ • Training provided, including user and system support documentation.
				+ • Post-implementation review, including any configuration changes.Implementation and Assessment Phase 
			
			Development or Acquisition Phase plans, including confirmation of the functionality and controls. and any legal and regulatory requirements. 
			
			
				+ • Documentation of performance and controls monitoring.
				+ • Documentation of configuration and change management controls and proposed changes.
				+ • ITAM inventory and associated risk assessments.
				+ • Plans and validation measures for accessible data retrieval from archives.
				+ • Documentation of off-boarding procedures, including for third-party providers.
				+ • Documentation of a post-disposal review, including processes and lessons learned.Sunset and Disposal Phase 
			
			Operations and Maintenance Phase 
			
			
				+ 1. Assess management’s oversight of SDLC phases. Consider whether management 
					- a. Understands the SDLC phases and the actions in each phase.
					- b. Identifies the actions and assign responsibility and accountability for completing those actions. completion of each phase to promote transparency and accountability for, and agreement and acceptance by, the stakeholders.
					- c. Defines the phases that will be included in the entity’s SDLC and helps ensure the
				+ 2. Assess management’s actions during the initiation phase of the SDLC. Consider management’s actions to a. Describe the development project’s purpose, identify expected benefits, and explain how the proposed system or component supports the entity’s objectives. 
					- b. Address legal and regulatory requirements.
					- c. Identify alternative solutions and explain the entity’s confidentiality, integrity, availability, and resilience requirements.
					- d. Consider and address any potential baseline security concerns during this phase by performing an initial impact analysis.
					- e. Address planning items, including the following: 
						* • Responsibilities of third-party service providers, internal audit, information security, and IT staff.
						* • Established acceptance criteria for each SDLC phase.
						* • Established review and approval procedures to help ensure that development teams complete all SDLC phase or independent sprint requirements before moving into subsequent phases. implemented. disruptions to the development process. authority, and risk management procedures. and software used during the project) as well as soft costs in budgeting
						* • Identify control and security features to be designed, built or acquired, and
						* • Create processes for development and change management to minimize
						* • Create processes that address project methodology selection, approval
						* • Identify costs associated with project overhead (e.g., office space, hardware, personnel expenses and outsourced activities.&
					- f. Consider input from all stakeholders.
					- g. Evaluate the appropriateness of each requested functional requirement.
					- h. Consider all proposals and analyze them to determine whether to develop or acquire the system or component.
				+ 3. Assess management’s actions during the development or acquisition phase of the SDLC. Consider management’s actions to a. Determine other functionality, such as whether the configuration of the system or component (e.g., an IoT product) is possible, whether the system or component can be restored to a secure default setting, and whether there are restrictions on users or services that can make changes. 
					- b. Consider the results of the impact analysis performed in the SDLC initiation phase and review those results throughout the SDLC.
					- c. Address or mitigate concerns from the impact analysis or new concerns that present risk beyond the board’s risk appetite.
					- d. Conduct a risk assessment and use the results to design baseline controls to meet the entity’s requirements.
					- e. Build in appropriate controls, including for network interfaces, to any products the
					- f. Review the appropriateness of new or modified design requirements or development entity develops or acquires to maintain confidentiality, integrity, availability, and resilience throughout the supply chain. changes and monitor for and minimize scope creep.
				+ 4. Assess management’s actions during the implementation and assessment phase of the SDLC. Consider management’s actions to a. Perform design reviews and system tests before implementation of the system or component to ensure that all entity specifications are met. 
					- b. Perform additional acceptance tests if new features or controls are added to the system or component.
					- c. Use and document the results of the design reviews and system tests, update documentation after performing new reviews or tests, and maintain test results for future review and use.
					- d. Determine the appropriate implementation strategy for the entity and system or component being deployed.
					- e. Coordinate training logistics, including who should be trained, what the training involves, and when training should be conducted.
					- f. Organize a training and awareness campaign, and notify users of any implementation and training responsibilities.
					- g. Perform a post-implementation review once the product is implemented.
					- h. Validate the initial impact analysis during the post-implementation review and report on any changes to the results.
					- i. Confirm that the implementation occurred as planned, and determine whether there were any unanticipated effects of the change on existing controls. &
					- j. Validate whether configurations (e.g., security, functionality, or performance) on the new system are appropriate.
				+ 5. Assess management’s actions during the operations and maintenance phase of the SDLC. Consider management’s actions to a. Monitor performance of a system or component to help ensure that it is consistent with pre-established user, security, and other entity requirements, and making necessary modifications. 
					- b. Conduct configuration management and control activities and document any proposed or actual changes in the entity’s security or operational plan of the system or component.
					- c. Assess and document changes in the entity’s ITAM inventory and related risk assessments.
					- d. Follow established change management policies, standards, and procedures to minimize the potential of a modification disrupting or degrading operations.
					- e. Perform operations and maintenance phase tasks regardless of whether entity personnel or a third party performs them.
				+ 6. Assess management’s actions during the sunset and disposal phase of the SDLC. Consider management’s actions to a. Consider the need and plan for methods for future data retrieval before archiving information and if necessary.
				+ b. Maintain archived data in an accessible and readable format, adhering to data retention guidelines.
				+ c. Periodically validate the accessibility of the archived data or develop a plan to migrate potentially inaccessible data to an accessible format.
				+ d. Maintain confidentiality, integrity, availability, and resilience throughout this phase.
				+ e. Develop comprehensive off-boarding procedures if the system or component requiring disposal is managed by, or the related data are stored by, a third party.
				+ f. Perform a post-disposal review at the end of the sunset and disposal phase that details the processes and lessons learned from shutting down and archiving the terminated system or component.Objective 8: Evaluate management’s third-party relationship risk management processes related to development, acquisition, and maintenance. (Section IV.P “Third-Party Relationship Risk Management”) 
			
			
				+ 1. Assess management’s due diligence practices as part of its third-party selection and relationship risk management processes. Consider whether management 
					- a. Identifies and documents any limitations of its due diligence, understands the risks from such limitations, and considers alternatives regarding how to mitigate development, acquisition, and maintenance risks.
					- b. Evaluates the conclusions from supplemental due diligence efforts, such as information derived from third parties (e.g., industry utilities or consortiums, consultations with other organizations, or engaging in joint efforts), based on the entity’s own specific circumstances and performance criteria for the activity.
					- c. Involves the board, through its oversight responsibilities, to ensure awareness of— and, as appropriate, request approval or delegated approval of—contracts involving higher-risk development, acquisition, and maintenance activities.Objective 9: Evaluate whether management implements policies to measure, monitor, and track changes and use all related information obtained to inform SCRM activities. (Section IV.Q “Supply Chain Considerations”) 
			
			Examiners should review 
			
			
				+ • Policies, procedures, project plans, and SDLC procedures to determine whether SCRM
				+ • Control configurations and reports used by management to monitor, control, and protect
				+ • Topologies and process flow diagrams that identify interconnectivities and potential single
				+ • Architectural designs, software development techniques, and systems engineering principles that promote effective information security throughout the supply chain. activities are integrated into the SDLC for the entity and applicable third parties. communications at the key access points of supply chain information systems. points of failure, while also considering continuity and resilience.
				+ • Inventory and validation of documentation (e.g., due diligence, including contracts) for supply chain partners, as well as documentation for provenance of systems, components, and data.
				+ • Communication processes and documented communication of threat intelligence and
				+ • Management’s assessment of inauthentic or unapproved systems or components (e.g.,
				+ • SCRM controls in maintenance-related situations, including monitoring for unauthorized
				+ 1. Assess implementation of policies for tracking changes and use of the obtained counterfeit or shadow IT). modifications, communicating changes, and monitoring for EOL. vulnerability identification with supply chain partners. information to inform the entity’s SCRM activities. Consider management’s actions to a. Ensure that SCRM activities are integrated into the SDLC for the entity and applicable third parties. b. Monitor, control, and protect communications (i.e., information transmitted or received) at key access points (e.g., external boundaries and key internal boundaries) of supply chain information systems. 
				
				
					- c. Use architectural designs, software development techniques, and systems engineering principles that promote effective information security in the supply chain.
					- d. Identify potential single points of failure among all entities in the entity’s supply chain numerous interconnectivities and risks from all partners.
					- e. Identify and consider any nested third-party relationships through common ownership (e.g., affiliates, subsidiaries).
					- f. Identify and consider risks related to supply chains by tracking interdependencies between all parties involved (e.g., owners and third-party service providers, including vendors) in the supply chain.
					- g. Consider any information pertinent to the security, integrity, resilience, quality, trustworthiness (e.g., not on the OFAC list, other concerns), or authenticity of their supply chain partners or products.
					- h. Evaluate supply chain partners consistently, based on available information, and depending on the specific context and purpose for which the assessment is being conducted, select additional factors for consideration. quality of information (e.g., its relevance, completeness, and accuracy) relied on for supply chain assessments.
					- i. Document the reference sources for assessment information to help establish the
				+ 2. Assess supply chain risk management practices. Consider management’s processes and plans to analyze policies, standards, and procedures, which outline and describe an entity and third parties’ processes for SCRM (including for subcontractors). Consider activities such as the following: 
					- a. Maintaining a current and accurate inventory of all applicable suppliers and identify their criticality to the business.
					- b. Considering established national and international standards, as applicable, as a baseline for security requirements for the entity’s supply chain.
					- c. Assessing and addressing supply chain risks associated with a given geographic location and apply appropriate risk responses (e.g., defining acceptable locations).
					- d. Defining roles and responsibilities for personnel (e.g., development, acquisition, and maintenance) to address various supply chain activities.
					- e. Providing general controls and processes.f. Developing, documenting, and maintaining an accurate inventory of third parties that reflects the entity’s key supply chain partners.
				+ g. Considering configuration management minimum security requirements for the supply chain.
				+ h. Applying appropriate configuration management controls to its own systems and encouraging or requiring the use of comparable controls by all parties in the entity’s supply chain through contracts.
				+ i. Understanding and mitigating all relevant risks associated with interdependencies throughout the various supply chains potentially affecting the entity.
				+ j. Planning for resilience, including scenarios related to supply chain issues.
				+ k. Documenting provenance for systems, components, and data, and monitoring for changes in the chain of custody that may increase risk to the entity throughout the SDLC. agreements with supply chain partners, and take appropriate mitigation action, as necessary.
				+ l. Considering provisions for excess capacity, bandwidth, and redundancy in
				+ m. Considering creation of SBOM for applicable and appropriate classes of software (e.g., purchased, open-source, and in-house developed software).
				+ n. Validating that existing SCRM capabilities (e.g., vulnerability management practices and vendor risk assessments) are not deprioritized under the mistaken assumption that SBOM replaces these activities.
				+ o. Ensuring the quality of information (e.g., its relevance, completeness, and accuracy) relied on for an assessment and documenting the reference sources for assessment information.
				+ p. Establishing effective project management processes that can help identify critical components, especially those that are used by multiple business lines, functions, systems, and components, such as the following: 
					- • Determine whether there is potential foreign ownership or influence, and whether the supply chain partner may have relationships with OFAC- sanctioned individuals, organizations, or countries.
					- • Evaluate supply chain partner oversight of its subcontractors (i.e., fourth
					- • Identify the level of open-source systems and components used by the entity,
					- • Conduct research on COTS systems and components (e.g., via publicly
					- • Use authorized resellers or distributors with an ongoing relationship with the
					- • Acquire directly from vetted OEMs or their authorized distributors and
					- • Track chain of custody of systems, components, and underlying code as they parties) or developers. and determine how the supply chain partner demonstrates its compliance with applicable open-source licensing agreements. available resources) or request proof to determine whether the supply chain partner (e.g., OEM) has performed testing as part of their quality or security processes. supply chain partner for systems and components not directly acquired from an OEM entity. resellers when obtaining alternative sources for continued support. move throughout the supply chain to minimize the potential for counterfeit or altered products.
				+ q. Communicating with its supply chain partners to promote awareness of threat intelligence and relevant vulnerabilities in the entity’s supply chain to inform operational security processes.
				+ r. Monitoring for supply chain system and component security and threat intelligence alerts and advisories from supply chain partners and taking appropriate actions in
				+ s. Considering employment of techniques to introduce randomness into entity
				+ t. Considering concealment techniques, such as masking metadata that may be response. operations and assets in the entity’s systems or networks. accessible in downloads or deliveries of systems and components, whether developed or acquired.
				+ u. Consulting with the entity’s legal counsel and board, as appropriate, regarding advanced security protection techniques (e.g., misdirection, honeypots) beyond standard industry techniques (e.g., basic randomness and concealment) techniques before implementation, as they may present liability and additional risk to the entity.
				+ v. Considering incident response-related information (e.g., definition of an incident, roles, and responsibilities) in its agreements with its supply chain partners.
				+ w. Considering correlation of available threat information with potential threats and vulnerabilities.
				+ x. Considering implementation of advanced monitoring over activities performed by higher-risk personnel (e.g., users with elevated authority or privileges).
				+ y. Considering information-sharing clauses in agreements and contracts.
				+ z. Performing the following when implementing maintenance processes throughout the supply chain: 
					- • Defining agreements that identify roles, responsibilities, and practices that may be used for maintenance activities, especially when third parties are responsible for maintaining the entity’s systems or components. or components (e.g., use of counterfeit systems and components, malware) in the supply chain. replacement or upgrade to the systems and components. and components, or providing agreements to continue support for legacy systems or components until a change can be made without significant
					- • Monitoring for unauthorized modification or removal of the entity’s systems
					- • Monitoring systems and components for planning for EOL to prepare for
					- • Considering any potential availability issues in the supply chain for systems disruption to operations.
					- aa. Understanding and considering interconnectivities throughout the supply chain to effectively manage supply chain risks.
					- bb. Incorporating third parties into business continuity and resilience activities throughout the supply chain, when applicable.
					- cc. Considering use of available information, such as that provided by third-party user groups and associations, to augment ongoing monitoring and due diligence, threat intelligence, and security throughout the supply chain.
					- dd. Implementing a process to validate the effectiveness of the security of systems and components throughout the supply chain when performing development, acquisition, and maintenance activities, and make appropriate adjustments to risk assessments to account for interconnectivity risk.
					- ee. Considering risk management factors in the entire life cycle of a third-party relationship, including planning, due diligence, contract negotiation, ongoing monitoring, and termination.Objective 10: Evaluate whether management implements sound processes for the development of systems and components supporting the entity’s business needs and operations. (Section V “Development”) 
			
			Examiners should review the following: 
			
			
				+ • Documentation of training in secure design and coding techniques for those responsible for
				+ • Development standards, including procedures for managing changes and a back-out plan.
				+ • Evidence of communication throughout the supply chain regarding identification of critical development activities. systems and components, potential threats and vulnerabilities, configurations, and responsibilities for selection and maintenance of system and network components.
				+ • Entity coding standards and list of entity-approved software development languages.
				+ • Documentation of security certification for completed systems and component-related code.
				+ • Development designs used to validate security and functionality throughout the supply chain.
				+ • Documentation of risk assessment related to use of or switch to a DevOps approach and
				+ 1. Assess management’s ability to provide policies, procedures, and practices to oversee and FFIEC IT Examination Handbook Development, Acquisition, and Maintenance effectiveness of controls. manage development activities. Consider management’s actions to a. Provide access to training in secure design and coding techniques to those responsible for development activities to securely design and address key issues early in the development process for entities that develop or modify their own systems and software.
				+ b. Maintain and follow policies, standards, and procedures documented for developing systems and components incorporating the entity’s requirements for confidentiality, integrity, availability, and resilience.
				+ c. Appropriately manage risks (e.g., eliminating inaccurate techniques or outdated tools and prototypes) with use of any additional design and coding techniques beyond standard coding techniques (e.g., computer-aided design) and prototypes.d. Develop, as part of the SDLC, a trustworthy system that meets specific security and other critical requirements defined and set by entity management.
			* e. Employ secure program coding practices to help develop a trustworthy system.
			* f. Incorporate supply chain processes when choosing system and network components.
			* g. Plan for maintenance activities from the outset of the development process to address secure continuity of operations.
* 2. Assess management’s development of standards and controls. Consider the following: 
	+ a. Procedures for managing changes during the development process, that address: 
		- • System controls.
		- • Quality management.
		- • Release management.
		- • Documentation.
		- • Reporting.
	+ b. Documentation of reasons for using specific programming styles and languages on a project or service in project documentation.
	+ c. Documentation of completed systems and component-related code that have passed security certification in program libraries as discussed in the “Additional Control Considerations in Change Management” section of this booklet.
	+ d. Design of information systems, components, and elements to be difficult to disable (e.g., tamper-proofing techniques), and, if they are disabled, trigger notification methods such as audit trails, tamper evidence, or alarms. exposure or access to the supply chain and systems or components traversing the supply chain.
	+ e. Design of delivery mechanisms (e.g., downloads for software) to avoid unnecessary &
	+ f. Design of relevant validation mechanisms to be used during implementation and operation.
	+ g. Agreement with partners on standards and controls used in customized system and component development throughout the supply chain.
	+ h. Work with suppliers and partners to ensure that critical systems and components are identified.
	+ i. Validate that suppliers or the entity itself has a continued ability to maintain customized systems and components that are critical to the entity’s operations.Objective 11: Evaluate whether management maintains formal testing processes and standards to govern the effectiveness of testing internally and externally developed systems and components. (Section V.B “Testing”) 

Examiners should review the following: 


	+ • Testing policies and procedures to confirm that systems and components meet the entity’s
	+ • Testing scope documentation, including for application interoperability and discovery of
	+ • Documentation of the type of testing, testing results, corrective actions, and testing in testing. conflicts. completion.
	+ • Documentation of testing for any new controls added to systems and components to avoid requirements. vulnerabilities.
	+ • Documentation regarding appropriate controls and approvals over the use of production data
	+ • Updates to manuals and training plans after testing.
	+ 1. Assess whether management appropriately tests systems and components to identify and mitigate risks or vulnerabilities before deployment. Consider the following management actions: 
		- a. Determining the need for use of production data in testing and employing appropriate controls (e.g., masking) if its use is deemed necessary.
		- b. Documenting approval of the use of nonsanitized data by the board when sanitizing data is not feasible and implementing and maintaining controls similar to those used in the production environment to appropriately protect the data for compliance with legal and regulatory requirements.
		- c. Performing additional acceptance tests of new controls if they are added to the system to help ensure that new controls meet security specifications and do not conflict with or invalidate existing controls or functionality.
		- d. Establishing a methodical process to define and conduct testing necessary to demonstrate the effectiveness of a developed system or component.
		- e. Implementing practices to document, report, and address identified issues, including security-related issues, in a timely manner, regardless of the testing methods used.
		- f. Reviewing and finalizing all supporting documentation, such as user, operator, and maintenance manuals as well as any conversion, implementation, and training plans associated with a new release or significant update during the implementation and assessment phase.
	+ 2. Assess management’s oversight and control of DevOps and DevSecOps activities. Consider management’s activities to a. Assess risks involved in using or switching to a DevOps approach and implementing appropriate controls. 
		- b. Consider controls to secure the CI/CD pipeline process, such as the following: 
			* • Hardening servers hosting code and artifact repositories.
			* • Securing credentials (e.g., authorization tokens) used for accessing repositories. container image registries.
			* • Implementing controls on who can check in and check out artifacts in
			* • Logging all code and build update activities.
			* • Sending build reports to developers and stopping further pipeline tasks when a
			* • Sending build reports to the security team and stop further pipeline tasks when
			* • Ensuring that developers can only access the application code.
			* • Digitally signing (preferably multiparty digital signing) the release artifact
			* • Verifying that all required digital signatures are present during production build or test fails in the CI pipeline and configuring code repositories to automatically block all subsequent pull requests from CD or continuous deployment pipeline until issues are resolved. a code or build audit fails. during each required CI/CD stage during the build and release process. release to ensure that no one bypasses the pipeline.
	+ 3. Assess management’s oversight of database development. Consider management’s actions to a. Understand the different types, structures, and uses of databases to effectively mitigate the risks of database development.
* b. Understand the benefits, limitations, and appropriate controls for the type of database used.
* c. Choose the appropriate database to meet business and stakeholder objectives.
* d. Consider access needed and services (e.g., management, analysis, and data services) that the databases will provide for internal and external customers.

Objective 12: Evaluate whether management establishes acquisition processes that are commensurate with the entity’s business and procurement needs and assesses and mitigates procurement risks associated with overall entity strategic, regulatory, and operational risks. 

(Section VI “Acquisition”) 

Examiners should review the following: 

* • Project requests and plans related to acquisition.
* • Risk assessments, strategic and business plans, and due diligence activities, including
* • Contracts and licensing agreements for appropriate provisions, responsibilities and
* • Documentation standards and procedures, including for updating documentation.
* • Stakeholder training and guidance in the acquisition process.
* • Audits related to the acquisition process and procurement. meeting minutes related to the acquisition process. accountability, and mitigation strategies.
* • Acquisition-related requests containing documented evaluation criteria and sufficient information for decision-making.
* 1. Assess management’s mitigation of the risks associated with acquisition of systems or components. Consider its actions to coordinate implementation of the following: 
	+ a. Ascertaining whether the product specifications are “fit for purpose” and meet the entity’s requirements, (regardless of whether the entity purchases directly from OEM partners or a secondary market) and are addressed in agreements with supply chain partners.
	+ b. Developing policies, standards, and procedures to effectively carry out the entity’s procurement processes aligned with the entity’s acquisition activities.
	+ c. Performing rigorous due diligence reviews of potential suppliers.
	+ d. Aligning the depth of the due diligence evaluation with the complexity, scope, and risk assigned by the risk assessment for the system or component to be procured.
	+ e. Implementing contract and licensing processes.
	+ f. Reviewing contracts and licensing agreements to help ensure that the rights and responsibilities of each party are clear and identify accountability.
* 2. Assess management’s procurement process. Consider management actions to a. Develop and manage an effective IT procurement process to meet the entity’s acquisition and contract fulfillment needs. 
	+ b. Follow a structured procurement process for any IT procurement, but particularly when procuring significant systems, components, products, and services to help ensure that each step in the process is addressed.
	+ c. Ascertain that, at a minimum, procured hardware, software, and services adhere to entity standards.
* 3. Assess whether management has established policies, standards, and procedures to better assist in the effective and consistent management of the entity’s acquisition process. Consider management’s actions to a. Provide for acquisition policies, standards, and procedures that promote the • Definition of a process for issuing information requests (e.g., RFIs and RFPs) to third parties. 
	+ • Performance of appropriate third-party due diligence processes.
	+ • Negotiation of the contract to ensure that it contains terms amenable to entity
	+ • Establishment of processes for the entity’s contract signature authority and
	+ • Validation of the systems, components, products, and services to ensure that management and types of IT-related provisions to consider before contract execution. process for specialist review (e.g., subject matter experts, key stakeholder, legal, and compliance) of IT-related contracts before approval and signature. they meet user requirements before acceptance.
	+ • Transferability or portability of systems, components, products, and services if a third-party relationship is discontinued.
	+ b. Understand the following risks and their effects on the business before entering foreign-based third-party relationships: 
		- • Legal.
		- • Country.
		- • Currency (or exchange rate).
		- • Geopolitical.
		- • Resilience.c. Identify, plan, and address the root causes of foreign-based risks or crises to minimize their effects on the entity’s operations.
	+ d. Plan for maintenance activities from the outset of the acquisition process to address secure continuity of operations.
* 4. Assess management’s project selection process. Consider management’s actions to a. Consider business needs, third-party solutions, specifications, and costs. 
	+ b. Involve appropriate stakeholders in defining the entity’s IT, information security, and functional requirements, and that the project meets applicable legal and regulatory expectations.
	+ c. Identify the entity’s needs to avoid a third party’s confusion with a request for information and omission of critical information needed for decision-making.
	+ d. Refrain from making assumptions based on third-party responses when management receives information from them, and ask follow-up questions to clarify concerns or solicit more information.
	+ e. Determine when a relationship is established and a contract is created when using an RFQ.
	+ f. Consult with the entity’s legal counsel to identify and resolve contractual issues.
	+ g. Implement a formal process for evaluating information, proposals, and quotes received from the RFIs, RFPs, and RFQs that includes key information to help management select appropriate providers.
* 5. Assess management’s oversight of contracts and agreements. Consider management’s actions to a. Implement standards and procedures for documentation, review, and approval. 
	+ b. Consult with legal representation to determine the entity’s rights and enforceability of terms, because agreements may not always be enforceable in a court of law. &
	+ c. Identify each of the agreements and contracts that help management complete the evaluation and selection steps.
	+ d. Validate that contracts have clauses that address relevant security and privacy standards with third-party service providers or vendors that process, store, or transmit sensitive customer data or provide critical services to meet applicable legal and regulatory requirements.
	+ e. Consider providing training and guidance to support a structured approach to SOW development.
	+ f. Involve appropriate personnel (e.g., relevant stakeholders) in developing an SOW and establish an appropriate senior management review and approval process.
	+ g. Validate that the provider’s needs and requirements (e.g., price, security, and interoperability) are met in order to provide for delivery of a quality product or service.
	+ h. Establish clear and measurable expectations for the services provided, recourse when expectations are not met, and accountability for both parties if management is procuring services related to a system or component.
	+ i. Link SLAs to clauses in the contract regarding incentives, penalties, and contract termination to protect the entity in the event of third-party performance failures.
	+ j. Outline rights in contracts, including licenses, if applicable, when using systems and components developed by third parties.
	+ k. Consider risks and address them through contract clauses (e.g., representations, warranties, and indemnifications to vendor liability limitations, information security, and agreement modifications).
	+ l. Ensure that contracts have clauses that address relevant security and privacy standards with third-party service providers or vendors that process, store, or transmit sensitive customer data or provide critical services to meet applicable legal and regulatory requirements.
	+ m. Consider contract clauses that allow for a contract to be revisited if a key subcontractor changes, which may affect critical services in the entity.
	+ n. Determine during contract negotiation whether management is willing to accept or can mitigate the risks related to systems or components without requested terms in situations when third parties cannot or will not agree to the terms an entity sets out in the draft contract.o. Document, with appropriate approvals consistent with the entity’s policies and governance structure, any accepted risk or compensating control factors if third parties cannot or will not agree to the terms an entity sets out in the draft contract. 


	+ p. Validate that the third-party software developer’s development policies and standards meet or exceed those of the entity.
	+ q. Validate that third-party developers are following industry standards, at a minimum.
	+ r. Negotiate terms, if possible, that would enable another third-party service provider to
	+ s. Consider alternative solutions if management cannot accept or mitigate the risk. access an affected system or component and help management in the conversion without violating agreement restrictions.
* 6. Assess whether management has provided appropriate oversight of escrow arrangements with third parties. Consider management’s actions to & a. Validate, at least annually, that the third party maintains a current version of the source code for software in escrow. 


	+ b. Consider incorporating provisions into escrow agreements such as • Definitions of minimum programming and system and component documentation.
	+ • Definitions of system and component maintenance procedures.
	+ • Conditions that should be present before an entity can access the source code
	+ • Assurances that the escrow agent will hold current versions of the source code
	+ • Arrangements for auditing or testing the integrity of the escrowed code.
	+ • Descriptions of the source code and related documentation and the storage
	+ • Assurances that the storage type or location containing the source code and
	+ • Assurances that the source code can be compiled into executable code.
	+ • If the escrow agent is based outside the United States, consideration of the and related documentation. and related documentation to validate that escrowed information is updated whenever significant program changes are made. type or location (e.g., magnetic tape or cloud) containing it. related documentation is accessible, operable, and compatible with an entity’s existing IT environment. practical and legal implications of establishing foreign-based escrow arrangements.
* 7. Assess management’s exit strategy plan for transitioning or terminating a product, service, or third-party relationship. Consider management’s actions to a. Help minimize disruption to an entity’s operations.
* b. Develop an initial exit strategy during the procurement process to address a situation when a third party cannot or does not meet the contract terms. services at the onset of the relationship.
* c. Consider identifying alternative third parties that provide similar products and

Objective 13: Evaluate whether management establishes formal policies, procedures, and responsibilities for managing systems and component maintenance, and processes that ensure the availability and continued operability of systems and components. (Section VII, “Maintenance”) 

Examiners should review the following: 

* • System and component inventory for key information (e.g., version, update, and patch level) to identify and address vulnerabilities.
* • Maintenance plans, including maintenance schedule and logs, vendor and developer
* • Change authorizations and review any reports for identification of anomalous activity.
* • Change types and risk assessment processes for those changes. recommendations, cost-benefit analyses, operational risks, availability of qualified personnel, and other relevant industry factors.
* • Configuration management practices to validate appropriate implementation and enforcement
* • Vulnerability and threat identification processes and remediation plans.
* • Reports to board and senior management regarding maintenance issues.
* • IT asset inventory including considerations for EOL, vulnerability management, planned
* • Termination, disposal, and off-boarding processes of systems, components, and third-party 
	+ 1. Assess whether management provides for development of policies for the maintenance of obsolescence, and legacy systems and components. relationships.
* • Maintenance documentation for any system, component, and configuration updates. of established change processes. FFIEC IT Examination Handbook Development, Acquisition, and Maintenance systems and components, including remote access for performing maintenance, roles and responsibilities of personnel with access for maintenance activities, and monitoring and audit mechanisms of maintenance activities. Consider management’s actions to a. Analyze and understand the costs of maintenance (e.g., budget, time, or personnel) versus the costs of not performing maintenance (e.g., system failures, data breaches, and customer dissatisfaction), and track costs for reporting purposes.
* b. Plan for maintenance activities from the outset of the acquisition and development processes to address secure continuity of operations. minimize catastrophic failure and promote confidentiality, integrity, availability, and resilience.
* c. Perform preventive maintenance throughout an IT asset’s useful life to prevent or
* d. Consider vendor or developer recommendations, cost-benefit analyses, operational risks, availability of qualified personnel, and other relevant industry factors (e.g., emerging technologies and threats) when developing the schedule for the maintenance plan.
* e. Track system and component information, such as version, update, and patch level, as tracking and using this information helps personnel manage (e.g., through regular updates, data protection, and digital forensics) technology vulnerabilities.
* f. Develop a process for identifying maintenance and vulnerability information and mechanisms for responding to user questions about developed or acquired IoT systems and components.
* g. Validate that while a system or component is in use, it is appropriately maintained and updated through preventative maintenance and change management.
* h. Establish a preventive maintenance plan, especially for mission-critical systems and components.
* i. Maintain logs of maintenance activities and perform reviews of those logs as needed for authorization of changes, as well as anomalous or malicious activity.
* j. Maintain awareness of the risks associated with unauthorized, untested, or unplanned changes.
* k. Consider the capability of the product to receive, verify, and apply verified updates for configuration, patch, and vulnerability management for developed or acquired products.
* l. Implement processes to manage changes regardless of whether the system or component was developed internally.
* m. Establish configuration management processes for developed and procured systems and components and help ensure that those processes are followed and enforced.
* n. Validate that only authorized personnel implement configuration changes and make those changes only to designated systems.
* o. Identify the sources of vulnerability information and threat intelligence for the entity’s systems and components.
* p. Receive the results of internal or external vulnerability scanning and penetration testing and identify remediation plans to resolve any issues detected through these tests.
* q. Evaluate and mitigate the risk associated with the vulnerability to the entity’s affected systems and components when obtaining vulnerability and threat intelligence from vendors, developers, third parties, and other sources.
* r. Report the results of the testing and the remediation plans to the board.
* s. Validate that the entity’s patch management processes include procedures for identifying, evaluating, approving, testing, installing, and documenting patches or updates for systems and components.
* 2. Assess management’s oversight of end-of-life activities. Consider management’s actions to 
	+ a. Maintain an accurate inventory of the entity’s IT assets, including systems and components, regardless of whether they are developed internally or acquired from a third party.
	+ b. Account for planned obsolescence if systems or components are developed internally.
	+ c. Include a contract clause regarding advanced notification before the vendor’s sunset timeline of an IT asset if a vendor decides not to replace, upgrade, or continue to support the asset.
	+ d. Implement a process to determine EOL decisions (e.g., replace, upgrade, or migrate
	+ e. Document and monitor depreciation and obsolescence schedules of the entity’s
	+ f. Consider EOL risks tied to interconnections in the supply chain derived from to a new system) before a system or component’s EOL. systems and components in its ITAM inventory to plan for EOL, as a part of its ITAM process. maintaining legacy systems and components for an extended period of time.
	+ g. Address EOL and the use of legacy systems and components, including time frames for necessary replacement or upgrade in contracts between the entity and its supply chain partners.
	+ h. Address EOL risks related to the use of legacy systems and components by mitigation strategies such as the following: 
		- • Assess the risks of continued use of aging, outdated, and unsupported systems
		- • Consider transitioning to newer, supported systems and components.
		- • Employ compensating controls. and components.
* 3. Assess management’s practices for termination and disposal of systems and components. FFIEC IT Examination Handbook Development, Acquisition, and Maintenance Consider management’s actions to a. Implement appropriate termination and off-boarding procedures. 


	+ b. Include appropriate clauses in contracts with third parties to manage the termination of services, including related relationships (e.g., affiliates, subcontractors), if necessary. Clauses and contracts should address 
		- • Maintaining confidentiality, integrity, availability, and resilience of data and operations throughout the off-boarding process.
		- • Specifying criteria defining termination.
		- • Shutdown (i.e., sunset) of the systems and components.
		- • Identification of the tasks involved.
	+ c. Develop and implement procedures for the following: 
		- • Preservation and identification of the data and its disposition (i.e., archival or transfer).
		- • Secure disposal of unnecessary systems and components (e.g., hardware and software).
	+ d. Validate that appropriate personnel are aware of the procedures to coordinate the
	+ e. Develop and implement procedures to help ensure that the entity’s critical or sensitive
	+ f. Validate that data or documents maintained by the third party on behalf of the entity are orderly disposition of the system, its components, and the data. data and documents are removed (e.g., wiped, sanitized, or otherwise destroyed) logically and physically from the system and components before disposal. addressed by the entity’s requirements in the termination and disposal clauses of the contract.
* 4. Assess management’s oversight of maintenance documentation, including working with third parties to help ensure that the entity receives current system, component, and user maintenance documentation.

Objective 14: Evaluate whether management establishes a formal process for the review, justification, approval, implementation, testing, and disposition of changes, and maintains confidentiality, integrity, availability, and resilience in the change management process. (Section VII.B, “Change Management”) 

Examiners should review the following: 

* • Change requests demonstrating prioritization, categorization, tracking, and reporting.
* • Change control process, including for back-out plans and inventory, for all change types.
* • Change management controls, including change logs, access control, and version control
* • Risk assessment and change documentation, including approvals.
* • Training for change management.
* • Conversion plans and coordination with conversion partners and stakeholders.
* • Reviews of change control processes for comprehensiveness and ongoing effectiveness, features. including review of all significant change reports and related documentation.
* 1. Assess whether management maintains policies, standards, and procedures that guide the change control process, including defined roles and responsibilities of key personnel in the change control process. Consider management’s actions to a. Designate personnel with the ability to create or initiate a request for a change and provide the processes they should follow. 
	+ b. Designate an individual (e.g., change manager) to facilitate a change who is responsible for managing all changes affecting the entity with minimal or no disruptions to operations.
	+ c. Consider using a group of stakeholders that can aid the change manager in the assessment, prioritization, and scheduling of changes.
	+ d. Prioritize and categorize changes.
	+ e. Implement a method to track and report changes (e.g., standard change request forms, library and version controls, and spreadsheets or automated change logs).
* 2. Assess management’s defined change control process to make routine and planned changes to systems or components, adjust configuration settings, and make changes to remediate flaws. Consider management’s actions to a. Follow a defined change control process to make routine and planned changes to systems or components, adjust configuration settings, and make changes to remediate flaws. 
	+ b. Account for a back-out plan and documenting the steps taken during the change in the order they occurred. • Emergency and unscheduled changes in the change control process. 
		- • Preparations for unexpected problems or failures with the change by defining
		- • Requests for change.
		- • Review of changes.
		- • Approval of changes.
		- • Design and build of changes.
		- • Testing of changes.
		- • Implementation of changes.
		- • Verification of changes and close of the change process.
	+ c. Follow processes, after verification of changes, to document completion of the change and close the change request.
	+ d. Report on the status of the change after closing and monitor the implemented change for unintended issues.
	+ e. Integrate security into its change control processes to help ensure that modifications
	+ f. Define the implementation plan (i.e., steps to deploy the change), create a full copy of do not adversely affect the security posture of varying systems. the current version in production, and finalize the back-out plan before deploying the change.
	+ g. Perform a post-implementation review to verify that the change was deployed according to the implementation plan and functions appropriately.
	+ h. Follow processes after verification to document completion of the change and close the change request.
	+ i. Report on the status of the change after closing and monitor the implemented change for unintended issues.
* 3. Assess additional controls in change management. Consider management’s actions to a. Isolate and protect the testing environment to avoid it being a vulnerable vector for exploit in the entity. 
	+ b. Strictly control the movement of programs and files among development, quality management, and production libraries for purposes of change control.
	+ c. Assign librarian functions to independent personnel, such as quality management personnel in larger, or more complex entities, or to nonoperations personnel in smaller or less complex entities.
	+ d. Validate that library attributes include an auditable activity log with appropriate controls to ensure that information has not been altered or deleted.
	+ e. Implement library controls, such as • Automated access controls. 
		- • Automated library applications.
	+ f. Consider using these automated change controls commensurate with the complexity of the entity’s IT environment and the number, types, and complexities of changes in that environment.
	+ g. Strictly control access to production software libraries, particularly in distributed environments, regardless of whether the entity has automated change control tools.
	+ h. Establish appropriate policies for the use of code repositories, such as determining what code repositories they use and where code repository data actually resides, especially for any cloud-based repositories (e.g., public, private, and community clouds).
	+ i. Conduct periodic reconnaissance of open (i.e., public) code repositories for personal employee accounts and unauthorized posting of company-owned source code.
	+ j. Use available version control features to track changes made to the code in the repository, providing accountability to the individual account that made the changes.
	+ k. Implement access control processes, such as the following: 
		- • Request and approval processes for access to code repositories (e.g., development, staging, or production). (internal and cloud-based) code repositories.
		- • Appropriate access controls, such as use of MFA for employee access to all
		- • Appropriate segregation of duties to prevent developer access to the staging and production code repositories, prevent quality management personnel from having access to production code repositories, and grant access to production code repositories only to release management personnel.
		- • Periodic review processes for access roles and repository logs.
* 4. Assess management’s oversight of change or modification types. Consider management’s actions to a. Develop procedures for changes that include change request, review, and approval that direct management to plan, test, and document changes before implementation. 
	+ b. Validate that changes to any IT system, component, or service are supported by an orderly, adaptable, documented, and measurable process to promote the consistent implementation of changes and provide an audit trail for changes, regardless of the change type.
	+ c. Train personnel involved in changes to ensure that those changes support entity objectives and do not adversely affect confidentiality, integrity, availability, and resilience.
	+ d. Coordinate change management for routine modifications, as IT changes often affect multiple business lines.
	+ e. Develop an inventory of changes, including routine modifications, for back-out, resilience, and tracking purposes.
* 5. Assess management’s oversight of planned changes. Consider management’s actions to a. Perform a risk assessment for all major modifications and significant security-related changes. 
	+ b. Discuss requests for major modifications formally and assign appropriate key stakeholders or committees to have responsibility for approving the requests, based on predefined criteria.
	+ c. Define the entity’s training requirements associated with conversions or major hardware and software upgrades.
	+ d. Evaluate the type, volume, and timing of training needs for each affected line of business and coordinate training programs with applicable third parties.
	+ e. Plan when a conversion affects a core platform supporting business operations whether managed on-premises or at a third party to minimize conversion issues and costs.
	+ f. Consider costs related to deconversions, system and component upgrades, and training for changes with the new system.
	+ g. Effectively manage conversions beginning with due diligence, including a comprehensive analysis of a conversion’s impact on existing operations (e.g., processing, storage, and communication requirements), while accounting for interdependencies.
	+ h. Establish communication procedures, reporting needs, and lines of authority for timely decision-making and issue resolution, when working with a third-party partner.
	+ i. Coordinate with conversion partners to consider the entity’s conversion needs.
* 6. Assess management oversight of emergency modifications. Consider management’s actions to a. Maintain appropriate implementation control standards, although an emergency modification should be completed quickly. 
	+ b. Periodically review the change control processes to optimize efficiency and determine whether they need revision.
	+ c. Perform testing before deployment in the case of an emergency change, if possible, as untested changes may cause even more damage than the initial risk being mitigated.
	+ d. Evaluate whether the potential damage resulting from an untested emergency change outweighs the immediate damage from the identified risk to determine the appropriateness of the decision to implement the emergency change. to help ensure that emergency modifications go through the change control process,
	+ e. Develop a process for system and component owners to identify all sources of change even if it is after the fact.
	+ f. Accelerate change management processes to implement changes rapidly to effectively mitigate the impact of emergency situations.
	+ g. Develop effective processes to address emergency situations.
	+ h. Strategically plan for emergency modifications, including budgeting contingency funds for execution and management of emergency situations.
	+ i. Consider appropriate measures to help effectively implement changes during emergencies. Examples include the following: 
		- • Organize a group (e.g., emergency change control review board) that can meet on extremely short notice to approve changes that need immediate implementation. The group could include senior leadership, management of critical lines of business, and management of key IT areas. case the emergency occurs outside normal business hours. individuals in the emergency group (e.g., emergency change control review board) and a list of procedures that are modified from standard change control and security processes. perform testing and modeling or simulation before releasing the changes into the production environment. for emergencies to reduce the time required to perform backups of systems to adequately implement an emergency modification. systems) that allow systems to be taken completely offline in emergencies.
		- • Plan for multiple methods of meeting (e.g., in-person, phone, and virtual) in
		- • Create an emergency modification implementation plan that includes a list of
		- • Compress certain phases of the implementation process to save time but still
		- • Discuss and implement minimum recovery point objectives with stakeholders
		- • Define and use emergency downtime procedures (e.g., failover to alternate
		- • Leverage senior management to communicate the urgency of emergency
		- • Follow emergency procedures, such as use of “out-of-band” communication provisions, if normal channels for secure transmission of information becomes unavailable. modifications and help achieve rapid consensus for decisions affecting the change implementation timeline.
		- • Perform periodic emergency drills in the test and modeling environment to prepare IT staff to deal with the stress of emergency modifications. Review the results of these drills and document lessons learned.
	+ j. Plan for emergency modifications, such as doing the following: 
		- • Establish who can declare an emergency and facilitate decision-making during emergencies.
		- • Designate individuals who can approve emergency changes and maintain contact information.
		- • Develop a plan that outlines the responsible parties and procedures for enacting emergency changes.
		- • Identify personnel responsible for change testing and implementation, as well as for initiating a back-out plan if implementation fails.
	+ k. Validate every emergency modification after implementation to determine whether it was correctly classified, in order to keep the number of emergency modifications to a minimum.
	+ l. Review reports of emergency modifications periodically for appropriateness of classification.
	+ m. Control attempts by personnel to circumvent routine modification or planned change control processes by classifying changes as emergencies to avoid resource constraints (e.g., time, personnel, and cost).
	+ n. Complete evaluations and documentation reviews of emergency modifications as soon as possible after implementation.
* 7. Assess management’s change management documentation practices. Consider management’s actions to a. Maintain documentation to track all changes (e.g., configuration settings, patches applied, system conversions, and emergency modifications) to systems and components.
* b. Maintain appropriate documentation to support the impact analysis.
* c. Prepare for the possibility of a failed or incomplete deployment and have procedures to address the issues and develop rollback or back-out procedures to reverse a failed deployment.
* d. Consider the time required to perform rollback procedures, when to trigger the rollback plan, and how long it may take to roll back.
* e. Determine whether the rollback plan can be accomplished in the defined timeline for the maintenance action.
* f. Implement appropriate security controls to prevent unauthorized rollback.
* g. Track and report issues that lead to the use of a back-out plan and the effects of a failed or incomplete change deployment.

Objective 15: Communicate and discuss findings, conclusions, and corrective actions. 

* 1. Review preliminary conclusions with the examiner-in-charge regarding 
	+ a. Violations of law and regulation.
	+ b. Significant issues warranting inclusion as matters requiring attention or recommendations in the report of examination.
	+ c. Proposed Uniform Rating System for Information Technology management component rating and the potential impact of the examiner’s conclusions on composite or other component IT ratings.
	+ d. Potential impact of the examiner’s conclusions on the entity’s risk assessment.&
* 2. Discuss findings with management and obtain proposed corrective action for significant deficiencies.
* 3. Document conclusions in a memorandum to the examiner-in-charge that provides report- ready comments for all relevant sections of the report of examination and guidance to future examiners.
* 4. Organize work papers to ensure clear support for significant findings by examination objective.

& 

# APPENDIX B: GLOSSARY 

The purpose of the glossary is to define technical terms used in the FFIEC IT Examination Handbook booklets in the context of supervisory activities for the entities over which FFIEC members may have supervisory authority. The FFIEC members strive to align terminology in the glossary with appropriate authoritative standards, including the NIST Computer Security Resource Center Glossary (NIST Glossary) as the primary source for cyber-related definitions, as appropriate. FFIEC members employed the following process to select, modify, or develop definitions. 

When a NIST definition existed: 

* • If NIST had a defined term and modifications to the definition were unnecessary, the FFIEC members included the NIST definition in this glossary. When multiple NIST definitions were available for the same term, the FFIEC members selected a definition for supervisory purposes.
* • If NIST had a defined term, but the definition needed additional clarity for supervisory purposes to assist with the identification of safety and soundness and enterprise risks related to IT, the FFIEC members included both the NIST definition and the FFIEC-adapted definition. These definitions are labeled “FFIEC Adapted for Supervisory Purposes” in this glossary’s source column.

When a NIST definition did not exist, or the definition was not appropriate for supervisory purposes: 

* • If NIST did not have a defined term, but there was an appropriate authoritative third-party source (e.g., the ISO Glossary), the FFIEC members included that authoritative definition.
* • If NIST did not have a defined term and there was not an appropriate authoritative third-party source, the FFIEC members developed a definition for supervisory purposes. These definitions are labeled “FFIEC Developed for Supervisory Purposes” in this glossary’s source column.

Due to the constantly evolving nature of IT and its associated risks, the FFIEC members may update definitions to maintain alignment with other government agencies and the financial services industry. 

Table 5: Glossary of Terms for Development, Acquisition, and Maintenance 



| Term | Definition | Source |
| --- | --- | --- |
|  | A |  |
| Access control | Procedures and controls that limit or detect access to critical information resources. This can be accomplished through software, biometrics devices, or physical access to a controlled space. | NIST Glossary |
| Acquisition | All stages of the process of acquiring a product or services, beginning with the process for determining the need for the product or services and ending with contract completion and closeout. | NIST Glossary |
| Application | A system for collecting, saving, processing, and presenting data by means of a computer. The term “application” is generally used when referring to a component of software that can be executed. The | NIST Glossary |

& 



| Term | Definition | Source |
| --- | --- | --- |
| Application programming interface | synonymously. A system access point or library function that has a well-defined syntax and is accessible from application programs or user code to provide well-defined functionality. | NIST Glossary |
| (API) | Software code that allows two or more different programs to communicate with each other. | FFIEC Adapted for Supervisory Purposes FFIEC Developed for Supervisory |
| Architecture | and software infrastructure components (e.g., devices, systems, and networks) are organized and integrated to achieve and support the entity’s business objectives. Refers to the manner in which the strategic design of the hardware | Purposes |
| Artificial intelligence (AI) | Refers to the ability of machines to perform tasks that normally require human intelligence—for example, recognizing patterns, learning from experience, drawing conclusions, making predictions, or taking action—whether digitally or as the smart software behind autonomous physical systems. | U.S. Department of Defense, Summary of the 2018 Department Of Defense Artificial Intelligence Strategy |
| Assembler | A computer program that automatically converts instructions written in assembly language into machine language. | Merriam-Webster |
| Attack surface | component, or an environment where an attacker can try to enter, cause an effect on, or extract data from, that system, component, or environment. The set of points on the boundary of a system, a system | NIST Glossary |
| Authentication | assurance of an entity’s identity or provides assurance of the integrity of communications sessions, messages, documents or stored data.  A process that establishes the source of information, provides | NIST Glossary |
|  | validity of a transmission, message, or originator, or a means of verifying an individual’s authorization to receive specific categories of information. A process designed to establish the source of the information, | FFIEC Adapted for Supervisory Purposes |
| Authorization | process.  The granting or denying of access rights to a user, program, or | NIST Glossary |
| Availability | Ensuring timely and reliable access to and use of information. | NIST Glossary |
| Backdoor | An undocumented way of gaining access to a computer system. A backdoor is a potential security risk. | NIST Glossary |
| Barcode | An optical machine-readable representation of data about an object. | Identification Technologies for Forensic Science” NIST, “Automated |
| Baseline configuration | A set of specifications for a system, or configuration item within a system, that has been formally reviewed and agreed on at a given point in time, and which can be changed only through change control procedures. The baseline configuration is used as a basis | NIST Glossary |
| Big data | Extensive datasets—primarily in the characteristics of volume, variety, velocity, and/or variability—that require a scalable architecture for efficient storage, manipulation, and analysis. | NIST SP 1500-1r2, NIST Big Data Interoperability Framework: Volume1, |
| Blockchain | A distributed digital ledger of cryptographically signed transactions that are grouped into blocks. Each block is cryptographically linked to the previous one (making it tamper evident) after validation and undergoing a consensus decision. As new blocks are added, older | Definitions NIST Glossary |

terms “application” and “software application” are often used 

NIST Glossary 

B 

Backup A copy of files and programs made to facilitate recovery, if 

necessary. 


for future builds, releases, and/or changes. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Bounded context | New blocks are replicated across copies of the ledger in the network, and any conflicts are resolved automatically using established rules. In relation to microservices, it refers to having limited responsibility and dependence on other services. | NIST SP 800-204, Security Strategies for Microservices- Based Application Systems |
| Business case | A business case defines the value a project will deliver. | Management Institute (PMI), “Is This Really Worth the Effort? The Need for a Business Case” Project |
|  | An evaluation of the benefit, cost, feasibility, and risk of alternative options to justify undertaking a project, program, or portfolio and define the value it will deliver. | FFIEC Adapted for Supervisory Purposes |
| Capacity | C process of planning and monitoring an entity’s | FFIEC Developed |
| management | The technology resources to support current and future strategic objectives. | for Supervisory Purposes Information |
| Central processing unit (CPU) | Computer hardware that houses the electronic circuits that control/direct all operations of the computer system. | Systems Audit and Control Association (ISACA) Glossary |
| Change control | Change control is the process through which all requests to change the approved baseline of a project, program, or portfolio are captured, evaluated and then approved, rejected, or deferred. Change control is the process through which all requests to change the approved baseline of a project, program, or portfolio are documented, evaluated and then approved, rejected, or deferred. Change control is an element in an overall change management | Association for Project Management FFIEC Adapted for Supervisory Purposes |
| Change control board (CCB) | regulating and approving changes to hardware, firmware, software, and documentation throughout the development and operational life cycle of an information system. Also referred to as a configuration control board. A group of qualified people with responsibility for the process of | NIST Glossary |
| Change management | The continuous process of maintaining the integrity of hardware, software, firmware, and documentation and controlling and approving changes (e.g., addition, modification, or elimination) to information or technology assets or related infrastructure (aka configuration and change management). | CISA, CRR Supplemental Resource Guide, Volume 3: Configuration and Change |
| Checksum Circuit | A value computed on data to detect error or manipulation. A dedicated single connection between two end points on a | NIST Glossary NIST Glossary |
| Cloud access security broker | A software tool or service that sits between an entity’s on-premises infrastructure and a cloud service provider’s infrastructure as a “gatekeeper” to monitor activity and enforce the entity’s security policies (e.g., authentication, single sign-on, authorization, credential mapping, and encryption) as the cloud-based resources | FFIEC Developed for Supervisory Purposes |
| Cloud computing | access to a shared pool of configurable computing resources (e.g., A model for enabling ubiquitous, convenient, on-demand network | NIST Glossary |

blocks become more difficult to modify (creating tamper resistance). 


process. 


Management, Version 1.1 

network. 


are accessed. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Cloud service provider | service provider interaction. A cloud service provider, or CSP, is a company that offers some component of cloud computing; typically, when you search the internet a cloud service is defined as infrastructure as a service (IaaS), software as a service (SaaS), or platform as a service (PaaS) to other businesses or individuals. | Cloud Security Alliance |
|  | A third-party service provider who offers clients services over the public internet. Examples of services could be applications (SaaS), operating systems (PaaS), or infrastructure (IaaS). | FFIEC Adapted for Supervisory Purposes |
| Code | See machine code. |  |
| Commercial off- the-shelf (COTS) software | A software and/or hardware product that is commercially ready- made and available for sale, lease, or license to the general public. Also referred to as off-the-shelf. | NIST Glossary |
| Compiled | Processed through software that translates a complete set of high- level computer instructions into machine language before executing any of them. | Merriam-Webster |
| Component | function, or finish a product. A unique part of a system that is needed to do something, perform a  A unique part of a larger system, such as hardware, software, and | Black’s Law Dictionary |
|  | firmware, that is a building block to do something, perform a function, or finish a product. | FFIEC Adapted for Supervisory Purposes |
| Compromise | The unauthorized disclosure, modification, substitution, or use of sensitive data (e.g., keying material and other security-related information). | NIST Glossary |
| Confidentiality | The property that sensitive information is not disclosed to unauthorized entities. | NIST Glossary |
| Configuration | The selection of one of the sets of possible combinations of features of a system. | NIST Glossary |
|  | The selection of combinations of conditions, parameters, features, and specifications of a system. | FFIEC Adapted for Supervisory Purposes |
| Configuration control board (CCB) | A group of qualified people with responsibility for the process of regulating and approving changes to hardware, firmware, software, and documentation throughout the development and operational life cycle of an information system. Also referred to as a change control board. | NIST Glossary |
| Configuration settings | The set of parameters that can be changed in hardware, software, or firmware that affect the security posture and/or functionality of the information system. | NIST Glossary |
| Container | A container is a standard unit of software that packages up code and all its dependencies, down to, but not including the operating system (OS). It is a lightweight, standalone, executable package of software that includes everything needed to run an application except the OS: code, runtime, system tools, system libraries, and settings. | DOD Enterprise DevSecOps Reference Design: Version 1.0 |
| Container image | A package that contains all the files required to run a container. | NIST SP 800-190, Application |

networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort or 

A collection of activities focused on establishing and maintaining the 

integrity of information technology products and systems, through FFIEC Adapted for Supervisory 

control of processes for initializing, changing, and monitoring the 

configurations of those products and systems throughout the system development life cycle. 


Purposes 


Container Security Guide 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Container runtime | The environment for each container; comprised of binaries coordinating multiple operating system components that isolate resources and resource usage for running containers. Software that coordinates multiple operating system components to isolate resource and resource usage for running containers and managing container images on a node. | NIST Glossary FFIEC Adapted for |
| Continuous integration/ continuous | The set of tools and the associated process workflows to achieve CI and CD with build, test, security, and release delivery activities, which are steered by a CI/CD orchestrator and automated as much as practice allows. | Supervisory Purposes DOD Enterprise DevSecOps |
| delivery or deployment (CI/CD) pipeline Contract Copyright | A binding agreement between two or more parties, which may A type of intellectual property that protects original works of indicate prices and goods and services to be provided. authorship as soon as an author fixes the work in a tangible form of | Fundamentals Merriam-Webster U.S. Copyright Office |
| Counterfeit item | A counterfeit item is a suspect item that is a copy or substitute without legal right or authority to do so or one whose materials, performance, or characteristics are knowingly misrepresented by the vendor, supplier, distributor, or manufacturer. An item that does not conform to established requirements is not normally considered an S/CI if the nonconformity results from one or more of the following conditions, which should be controlled by site procedures as nonconforming items: defects resulting from inadequate design or production quality control; damage during shipping, handling, or storage; improper installation; deterioration during service; degradation during removal; failure resulting from aging or misapplication; or other controllable causes. | U.S. Department of Energy, Suspect/ Counterfeit Items Awareness Training |
| Cyber | Risk of financial loss, operational disruption, or damage from the failure of the digital technologies employed for informational and/or operational functions introduced to a manufacturing system via electronic means from the unauthorized access, use, disclosure, disruption, modification, or destruction of the manufacturing Risk of financial loss, operational disruption, or damage from the failure of the digital technologies employed for informational and/or operational functions introduced to a system via electronic means | NIST Glossary |
| risk | system. | FFIEC Adapted for Supervisory |
| Cybersecurity | from the unauthorized access, use, disclosure, disruption, modification, or destruction of the system. The process of protecting consumer and bank information by preventing, detecting, and responding to attacks. | Purposes NIST Glossary |
| Dashboard | D A tool that consolidates and communicates information relevant to the entity in near real-time. It is generally visual and often uses a | NIST SP 800-137, Information Security |
| Data | A representation of information as stored or transmitted. A physical or digital representation of information processed, stored (at rest), or transmitted (in transit). | FFIEC Adapted for Supervisory Purposes NIST Glossary |
| Data analytics | The systematic process of evaluating and organizing data sets to draw insights, make predictions, and reveal trends using logical analysis. A facility that houses virtual and/or physical information technology | FFIEC Developed for Supervisory Purposes |
| Data center | infrastructure(s) (e.g., computer, server, and networking systems and components) designed to store, process, and serve large amounts of data in support of an entity’s strategic and business | FFIEC Developed for Supervisory Purposes |

expression. 

variety of charts. 

Continuous Monitoring for Federal Information Systems and Organizations 

& 



| Term | Definition | Source |
| --- | --- | --- |
|  | objectives. A data center may be a dedicated facility or an area or room that contains computer, server, and networking systems and components, and may be private or shared (e.g., a co-location facility). |  |
| Data classification | confidentiality, integrity, or availability), value, and criticality to the entity. Categorizing data based on its level of sensitivity (e.g., | FFIEC Developed for Supervisory Purposes |
| Data communications | The transfer of data over networks using a combination of telecommunication services and network devices. | FFIEC Developed for Supervisory Purposes |
| Data governance | A set of processes that ensures that data assets are formally managed throughout the enterprise. A data governance model establishes authority and management and decision-making parameters related to the data produced or managed by the enterprise. | NIST Glossary |
| Data management | The practice of putting into place policies, procedures and best practices to ensure that data are understandable, trusted, visible, accessible and interoperable. The practice of putting into place policies, procedures, and best | DHS Lexicon Terms and Definitions FFIEC Adapted for |
| Database | traditional relational database system. A repository of information or data organized to be accessed, A repository of information or data, which may or may not be a | FFIEC Adapted for Supervisory NIST Glossary |
|  | managed, and updated. A person or group that designs and/or builds, and/or and/or configures the hardware and/or software of | Purposes ISACA Glossary |
| Developer | documents computerized systems  A person or group that designs, builds, documents, and |  |
|  | configures the hardware and software of systems. | FFIEC Adapted for Supervisory Purposes |
| Development DevOps | useful materials, devices, and systems or methods that leverage the results of applied research activities; includes validation and demonstration of a chosen technology in laboratory, representative and operational environments, improving on research prototypes, integration into systems and subsystems, addressing manufacturing, producibility and sustainability needs, and independent operational test and evaluation. The systematic application of knowledge toward the production of useful materials, devices, and systems or processes of defining, designing, testing, and implementing systems or components. Development includes validation and demonstration of a chosen technology, use of test and production environments, improvement of developed prototypes, integration into systems and subsystems, and inclusion of hardware builds. The systematic application of knowledge toward the production of | DHS Lexicon Terms and Definitions FFIEC Adapted for Supervisory Purposes Merriam-Webster |
| Device | A piece of equipment or a mechanism designed to serve a special purpose or perform a special function. |  |
|  | A set of practices for automating the processes between software development and information technology operations teams so that they can build, test, and release software faster and more reliably. The goal is to shorten the SDLC and improve reliability while delivering features, fixes, and updates frequently in close alignment with business objectives. | NIST Glossary |

practices to ensure that data are understandable, trusted, visible, 

Supervisory 

accessible, and interoperable to ensure that user needs are met. 

Purposes 

& 



| Term | Definition |  |
| --- | --- | --- |
| DevSecOps | An organizational software engineering culture and practice that aims at unifying software development (Dev), security (Sec) and operations (Ops). A software engineering culture and practice that aims at unifying software development (Dev), security (Sec), and operations (Ops). | Source NIST SP 800-204C, Implementation of DevSecOps for a Microservices- Based Application With Services Mesh FFIEC Adapted for Supervisory |
| Digital signature | The main characteristic of DevSecOps is to automate, monitor, and apply security at all phases of the SDLC. provides assurance that the claimed signatory signed the information, and the information was not modified after signature generation. An electronic analogue of a written signature, a digital signature that operates by executing a program using a set of input | Purposes NIST Computer Security Resource Center |
| Dynamic analysis | use-cases and analyzing the program’s runtime behavior. Testing | OWASP Vulnerability Management Guide (OVMG) |
|  | E |  |
| Encryption | Any procedure used in cryptography to convert plain text into cipher text to prevent anyone but the intended recipient from reading that data. | NIST Glossary |
| End-of-life (EOL) | With respect to technology, a time frame usually defined by a technology vendor to describe when an asset has reached the end of its useful life cycle and when the vendor no longer maintains and supports the asset or continues to sell or license it. | FFIEC Developed for Supervisory Purposes |
| Feasibility study | F An analysis of a known problem or anticipated need and its solutions that considers all relevant factors—including An analysis of the known or anticipated need for a product, system or component to assess the degree to which the requirements, designs or plans can be implemented. | ISACA Glossary |
|  | potential economic, technical, legal, and scheduling considerations—to determine a project’s viability, costs, and benefits. | FFIEC Adapted for Supervisory Purposes |
| Firewall | local security policy. when power is turned off. A gateway that limits access between networks in accordance with Memory chips with embedded program code that hold their content | NIST Glossary ISACA |
| Firmware | A type of software, often included in read-only memory, that is | Glossary |
|  | embedded directly in a piece of hardware to make the hardware work as intended. Software is retained even when power is turned off. | FFIEC Adapted for Supervisory Purposes |
| Fourth party Functional testing | third parties, which, in turn, provide services to the primary enterprise. Also referred to as subcontractor. Fourth (or nth) parties provide services to support the operations of Testing that verifies that an implementation of some function | ISACA NIST Glossary |
| Fuzz testing | injection in an automated fashion by tools referred to as “fuzzers,” which are programs or scripts that submit some combination of inputs to the test target to reveal how it responds. A black box software testing technique, which basically consists in finding implementation bugs using malformed/semi-malformed data | OWASP, Code Review Guide 2.0 |
|  | A black box software testing technique, which basically consists in finding implementation bugs using malformed/semi-malformed data injection in an automated fashion. | FFIEC Adapted for Supervisory Purposes |
| Gateway | An intermediate system (interface, relay) that attaches to two (or more) computer networks that have similar functions but dissimilar implementations and that enables either one-way or two-way | NIST Glossary |

 G 

operates correctly. 


communication between the networks. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Hardening | A process to eliminate as many security risks as possible by H removing all nonessential software programs, protocols, services, and utilities from the system. (Referred to as system hardening) A process intended to eliminate as many security risks as possible by implementing security controls (e.g., changing default | ISACA Glossary FFIEC Adapted for Supervisory |
| Hardware | and removing all nonessential software programs, protocols, and utilities from the system. The physical components of an information system. A service offered via telephone/Internet by an enterprise to its or employees that provides information, assistance and | NIST Glossary |
| Help desk | clients troubleshooting advice regarding software, hardware, or networks. Consisting of dissimilar or diverse elements. Involving or serving as an aid to learning, discovery, or problem- | ISACA Glossary |
| Heterogeneity Heuristics | Any hardware device that has the capability of permitting access solving by experimental and especially trial-and-error methods. | Merriam-Webster |
|  | a | Merriam-Webster |
| Host | to network via a user interface, specialized software, network address, protocol stack, or any other means. Some examples include computers, personal electronic devices, thin clients, and multifunctional devices. | NIST Glossary |
| Human-readable code | Code that includes source code, scripts, and any other form of code that an organization deems human-readable. | NIST SP 800-218, Secure Software Development Framework (SSDF) Version 1.1: Recommendations for Mitigating the Risk of Software |
| Hypertext transfer protocol (HTTP) | A standard method for communication between clients and web servers. A protocol for accessing a secure web server, whereby all data | NIST Glossary ISACA Glossary |
| Hypertext transfer protocol secure (HTTPS) Hypervisor | transferred are encrypted. Standard port number is 443. systems (OS) on a host and controls the flow of instructions between the guest OSs and the physical hardware. The virtualization component that manages the guest operating | NIST Glossary |
| Identity and access management (IAM) | Encapsulates people, processes, and products to identify and manage the data used in an information system to authenticate users and grant or deny access rights to data and system resources. | ISACA Glossary |
| Incident | and compliance. confidentiality, integrity, or availability of a system or the information the system processes, stores, or transmits or that constitutes a An occurrence that actually or potentially jeopardizes the | NIST |
|  | violation or imminent threat of violation of security policies, security | Glossary |

passwords, enabling security settings, and protecting privileged 

accounts), patching vulnerabilities, turning off nonessential services, 

Purposes 


Vulnerabilities 


NIST SP 800-128, 

Guide for Security- 

Focused 

Configuration Management of Information Systems 

FFIEC Adapted for 

Supervisory Purposes 

 I 

the extent to which a change to the information system have 

affected the security state of the system. Referred to as a security 

impact analysis. 

 The analysis conducted by qualified staff in an organization to 

determine the extent to which changes to the system affect the 

security posture of the system. This may involve security, resilience, 


procedures, or acceptable use policies. 

Impact analysis The analysis conducted by an organizational official to determine 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Incident management | The process of identifying, analyzing, and correcting disruptions to operations and preventing future recurrences. The goal of incident management is to limit the disruption and restore operations as quickly as possible. | FFIEC Developed for Supervisory Purposes |
| Incident response | Responds to crises or urgent situations within the pertinent domain to mitigate immediate and potential threats. Uses mitigation, preparedness, and response and recovery approaches, as needed, to maximize survival of life, preservation of property, and information security. Investigates and analyzes all relevant | DOD Cyber Exchange |
| Information security | The protection of information and information systems from unauthorized access, use, disclosure, disruption, modification, or destruction in order to provide confidentiality, integrity, and availability. | NIST Glossary |
| Information technology asset management (ITAM) | Refers to a set of policies and procedures that an organization uses to track, audit, and monitor the state of its IT assets, and maintain system configurations. | NIST SP 1800-5, IT Asset Management |
| Infrastructure | System of facilities, equipment, and services needed for the operation of an organization. | ISO Online Browsing Platform, Terms & Definitions |
|  | The physical elements, products, and services necessary to provide and maintain ongoing operations to support business activity, including the maintenance of physical facilities. | FFIEC Adapted for Supervisory Purposes NIST SP 500-316, |
| Infrastructure as a service (IaaS) | IaaS provides entities with the ability to provision processing, storage, networks, and other fundamental computing resources where the entity is able to deploy and run software, which can include operating systems and applications. The entity does not manage or control the underlying cloud infrastructure; however, it has control over operating systems, storage, and deployed | Framework for Cloud Usability |
| Integration testing | An orderly progression of testing in which software elements, hardware elements or both are combined and tested to evaluate their interactions, until the entire system has been integrated. | ISACA Glossary |
| Integrity | A property whereby data has not been altered in an unauthorized manner since it was created, transmitted or stored. | NIST Glossary |
| Interdependencies | When two or more departments, processes, functions, or third-party providers interact to successfully complete a task, business function, or process. | FFIEC Developed for Supervisory Purposes |
| Internet of things (IoT) | Refers to the collection of technologies that allow information to be sent to and received from physical devices (e.g., security systems, HVAC systems, intelligent personal assistants, and kitchen appliances), that were not traditionally thought of as IT assets, using the internet. These devices have the ability to send and receive data over a network without necessarily requiring human-to-human or human-to-computer interaction using embedded computing capability and network connectivity and unique identifiers (e.g., | FFIEC Developed for Supervisory Purposes |
| Intrusion detection system (IDS) | A security service that monitors and analyzes network or system events for the purpose of finding, and providing real-time or near real-time warning of, attempts to access system resources in an unauthorized manner. | NIST Glossary |
| Intrusion prevention system (IPS) | A system that can detect an intrusive activity and can also attempt to stop the activity, ideally before it reaches its targets. | NIST Glossary |
| Kernel | Core that provides basic services for all other parts of the OS. | FFIEC Developed for Supervisory |

response activities. 


applications. Entities have the maximum flexibility to customize their cloud services and user interfaces. 


internet protocol address). 

 K 

Purposes 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Legacy | A custom environment containing older systems or applications that L may need to be secured to meet today’s threats, but often use older, less secure communication mechanisms and need to be able to communicate with other systems (aka legacy environment). Relates to older, outdated technology systems, components, or | NIST Glossary FFIEC Adapted for |
|  | A permission granted by competent authority to engage in a applications that may be critical to day-to-day operations. Often, they may need to be secured, updated, or replaced to meet current threats. | Supervisory Purposes |
| License | business or occupation or in an activity otherwise unlawful. | Merriam-Webster |
| Log | A record of events occurring within an entity’s systems and An approach to designing systems so that linked networks. | NIST Glossary |
| Loose coupling | components of networks, software, and services can be scaled to operate as independently as possible to avoid issues with one component adversely affecting others. | FFIEC Developed for Supervisory Purposes |
| Machine code | M Also referred to as “code” or “machine language.” Computer | ISACA Glossary |
| Machine language | instructions and definitions expressed in a form (binary code) that can be recognized by the CPU of a computer. All source code, regardless of the language in which it was programmed, is eventually converted to machine code. See machine code. |  |
| Machine learning * (ML) | The process of using an algorithm(s) to help computers learn without being explicitly programmed and identify patterns in data. Those patterns are then used to create a data model that can make predictions. | FFIEC Developed for Supervisory Purposes |
| Mainframe | A large, high-speed computer, especially one supporting numerous workstations or peripherals. | ISACA Glossary |
| Maintenance | Any act that either prevents the failure or malfunction of equipment or restores its operating capability. | NIST Glossary |
| Malicious code | Unwanted files or programs that can cause harm to a computer or compromise data stored on a computer. Various classifications of malicious code include viruses, worms, and Trojan horses. | CISA, “Protecting Against Malicious Code” |
| Malware | A program that is inserted into a system, usually covertly, with the intent of compromising the confidentiality, integrity, or availability of the victim’s data, applications, or operating system or of otherwise annoying or disrupting the victim. | NIST Glossary |
| Markup language | document that indicates its logical structure (such as paragraphs) and gives instructions for its layout on the page especially for electronic transmission and display.  A type of language used to annotate text and embed tags in a text A system (such as HTML or SGML) for marking or tagging a | Merriam-Webster FFIEC Adapted for |
| Masking | value in a way that does not preserve the analytic utility of the value, such as replacing a phone number with asterisks or a randomly generated pseudonym. The process of systematically removing a field or replacing it with a | NIST Glossary |
| Master services agreement (MSA) | One legal document that consolidates separate but related agreements between the same signing parties. Also known as master contract. Also known as a “master contract,” it is a legal document that | Black’s Law Dictionary |
|  | consolidates and governs multiple service agreements or transactions between the same signing parties or entities, and often addresses the terms that will govern future transactions or agreements. | FFIEC Adapted for Supervisory Purposes |

document to control its structure, formatting, display, or the 

relationship between its parts to facilitate automated processing and 

use by humans. 

Supervisory Purposes 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Metadata | Data about data. For file systems, metadata are data that provide information about a file’s contents. | NIST Glossary |
| Microchip | Data about data. Examples of metadata include purpose of the data, creator or owner of the data, file size, location where the data were created, and source of the data. A very small piece of silicon inside a computer. It has electronic | FFIEC Adapted for Supervisory Purposes Collins Dictionary |
| Microcontroller | circuits on it and can hold large quantities of information or perform mathematical and logical operations. An integrated circuit that contains a microprocessor along with | Merriam-Webster |
|  | memory and associated circuits and that controls some or all of the functions of an electronic device (such as a home appliance) or system. |  |
| Microservices Middleware | a go between for two other programs. A set of containers that work together to compose an application. Middleware is a term used for a computer program that functions as | NIST Glossary DHS, Access Control Technologies |
| Misdirection | environments and directing adversary activities to those resources The process of maintaining and employing deception resources or | NIST Glossary |
| Mobile device | A portable computing device that: (i) has a small form factor such that it can easily be carried by a single individual; (ii) is designed to operate without a physical connection (e.g., wirelessly transmit or receive information); (iii) possesses local, non-removable data storage; and (iv) is powered-on for extended periods of time with a | NIST Glossary |
| Multifactor authentication (MFA) | Authentication using two or more factors to achieve authentication. Factors include: (i) something you know (e.g., password or personal identification number (PIN)); (ii) something you have (e.g., cryptographic identification device or token); or (iii) something you are (e.g., biometric). | NIST Glossary |
|  | N |  |
| Network | A system implemented with a collection of interconnected components. Such components may include routers, hubs, cabling, telecommunications controllers, key distribution centers, and technical control devices. | NIST Glossary |
| Network diagram | topology) is a visual representation of nodes and connections in a computer network. A network diagram (also referred to as a network map or network | FFIEC Developed for Supervisory Purposes |
| Networked | records to have multiple owners and thus providing multiples access paths to the data. Database management systems (DBMSs) providing such capabilities are also referred to as CODASYL A database organized according to ownership of records, allowing | Gartner Glossary |
| Network operations center (NOC) | The central location or department responsible for monitoring the health and performance of the network, including analyzing and maintaining network traffic, telecommunications, and network disruptions. | FFIEC Developed for Supervisory Purposes |
| Nonproduction environment | Systems (e.g., applications, infrastructure, networks, and operating systems) that are not used for production purposes. For example, systems that are used as development or test environments for new software or technologies or changes to existing software or technologies. | FFIEC Developed for Supervisory Purposes |
| Object code | A code expressed in machine language (“1”s and “0”s), which is normally an output of a given translation" process that is ready to be executed by a computer. | U.S. Food and Drug Administration, Glossary of Computer System |


Handbook 


or environments. 


self-contained power source. 


(Conference on Data Systems Languages) DBMSs. 

 O 


Software 

& 



| Term | Definition | Source Development |
| --- | --- | --- |
| Open-source software | Software released under a license that allows the software and its source code to be accessed, used, modified, and shared by anyone. | NIST S 6106.01, “Open Source Code” |
| Operating system * (OS) | The software “master control application” that runs the computer. It is the first program loaded when the computer is turned on, and its main component, the kernel, resides in memory at all times. The operating system sets the standards for all application programs (such as the Web server) that run in the computer. The applications communicate with the operating system for most user interface and | NIST Glossary |
| Operations | processes, procedures, and services that support business functions. The performance of activities comprising methods, principles, | FFIEC Developed for Supervisory Purposes |
| Operations management | The process of overseeing the methods, activities, or performance of practical work, and application of principles, processes, procedures, and services of an entity, using business resources. | FFIEC Developed for Supervisory Purposes |
| Orchestrator | their behalf to pull images from registries, deploy those images into containers, and manage the running containers. Orchestrators are responsible for monitoring container resource consumption, job A tool that enables DevOps personas or automation working on | NIST Glossary |
| Original equipment manufacturer | Technology providers (e.g., IT hardware vendors, hardware component makers, software vendors, resellers, and distributors) that distribute output devices and services produced by another company under their own brand name. | FFIEC Developed for Supervisory Purposes |
| Out-of-Band | differs from the current method of communication. P Communication between parties utilizing a means or method that | NIST Glossary |
| Patch | Fixes to software programming errors and vulnerabilities. | ISACA Glossary |
| Patch management | The systematic notification, identification, deployment, installation, and verification of operating system and application software code revisions. These revisions are referred to as patches, hot fixes, and service packs. | NIST Glossary |
| Penetration testing | A test methodology in which assessors, using all available documentation (e.g., system design, source code, manuals) and working under specific constraints, attempt to circumvent the security features of an information system. | NIST Glossary |
|  | A test methodology in which assessors, typically working under specific constraints and using all available documentation, attempt to circumvent or defeat the security features of a system, such as the network, application, its data, or its environment resources. Penetration tests often involve analyzing for individual and combinations of vulnerabilities on a system or multiple systems that can be used to gain access beyond what is achieved through a | FFIEC Adapted for Supervisory Purposes |
| Planned obsolescence | The practice of making or designing something in such a way that it will only be usable for a short time so that people will have to buy another one. | Merriam-Webster |
| Platform | A system disposal strategy developed and implemented, as needed, to address technology refresh in budget planning to limit the use of obsolete systems that present security or reliability risks. A computer or hardware device and/or associated operating | FFIEC Adapted for Supervisory Purposes NIST Glossary |
| Platform as a service (PaaS) | The capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages, libraries, services, and tools supported by the provider. The consumer does not manage or | NIST Glossary |


file management operations. 


execution, and machine health across hosts. 


Terminology 


single vulnerability. 

system, or a virtual environment, on which software can be installed or run. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Policies | control the underlying cloud infrastructure including network, servers, operating systems, or storage, but has control over the deployed applications and possibly configuration settings for the application-hosting environment. Statements, rules, or assertions that specify the correct or expected | NIST Glossary |
| Post- implementation review (PIR) | The process for reviewing IT projects in order to learn from past investments and initiatives by comparing actual results to estimates. PIRs also serve as vehicles for evaluating the entire IT investment management process. | U.S. Government Accountability Office, Information Technology Investment |
|  | An evaluation of projects that provides a feedback mechanism to management that can measure project results, comparing actual results to estimates, and gather data necessary to analyze what corrective action may be required, if necessary. | FFIEC Adapted for Supervisory Purposes |
| Problem Procedures | In IT, the unknown underlying cause of one or more incidents. A document containing a detailed description of the steps necessary to perform specific operations in conformance with applicable | ISACA Glossary ISACA Glossary |
|  | standards. Procedures are defined as part of processes. The process of obtaining a system, product, or service. The corporate processes and functions that involve governance | NIST Glossary FFIEC Adapted |
| Procurement | over purchasing decisions for obtaining a system, product, or service. | for Supervisory Purposes |
| Project | organization. as possible. Organizational unit that supports the management of projects and An activity chartered to create a specified deliverable as efficiently |  |
| Project |  | PMI PMI, "The PMO: |
| management office (PMO) | project-based organizations. | Your Key to Strategy Execution and Results Delivery” NIST Glossary |
| Protocol Prototyping | A set of rules (i.e., formats and procedures) to implement and The process of quickly putting together a working model (a control some type of association (e.g., communication) between systems. | ISACA Glossary |
| Provenance | end-user screens and reports. Internal controls are not a priority item since this is only a model. Origin or source. activity of obtaining the equipment and resources you need particular activity. activity of obtaining, modifying, and making available the |  |
| Provisioning | The for a The equipment, resources, software, or services a user needs to carry | Merriam-Webster Cambridge Dictionary FFIEC Adapted for Supervisory |
| Quality assurance * (QA) | A planned and systematic pattern of all actions necessary to provide adequate confidence that an item or product conforms to established technical requirements A planned and systematic pattern of all actions necessary to provide | ISACA Glossary FFIEC Adapted for |
| Quality assurance/ quality control (QA/QC) | Part of quality management focused on providing confidence that quality requirements will be fulfilled. | NIST Glossary |

behavior of an entity. 


Management 

projects and other activities, over time, to deliver benefits to the 


PMI 

Program An activity that focuses on the coordination of a number of related 

prototype) to test various aspects of a design, illustrate ideas or features, and gather early user feedback. Prototyping uses programmed simulation techniques to represent a model of the final system to the user for advisement and critique. The emphasis is on 

out a particular activity. 

Purposes 

 Q 

adequate confidence that a system, component, or facility conforms 

to established requirements. 


Supervisory 

Purposes 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Quality control * (QC) | The operational techniques and procedures used to achieve quality requirements. | ISACA Glossary |
| Quality of service | requirements. The measurable end-to-end performance properties of a network service, which can be guaranteed in advance by a Service Level Agreement between a user and a service provider, so as to satisfy specific customer application requirements. Properties may include | Purposes Committee on National Security Systems Glossary |
| Quality management | Coordinated activities to direct and control an organization with regard to quality. In databases, a request for data or information from a table or | NIST Glossary |
| Query | combination of tables. | FFIEC Developed for Supervisory Purposes |
|  | R |  |
| Radio frequency identification (RFID) | A form of automatic identification and data capture technology that uses electric or magnetic fields at radio frequencies to transmit information. | NIST SP 800-98, Guidelines for Securing Radio Frequency Identification (RFID) Systems |
| Random access memory (RAM) | The computer’s primary working memory. Each byte of RAM can be accessed randomly regardless of adjacent bytes. The computer’s primary working memory, which is kept where each byte of RAM can be quickly accessed by the device’s processor. | ISACA Glossary FFIEC Adapted for Supervisory |
| Registry | A service that allows developers to easily store images as they are created; tag and catalog images for identification and version control to aid in discovery and reuse; and find and download images that others have created. | NIST SP 800-190, Application Container Security Guide |
| Regression | Defect or bug (in terms of code). | OWASP, Code Review Guide 2.0 |
| Release | A collection of new and/or changed configuration items, which are tested and introduced into a production environment together. | NIST Glossary |
| Relational database | A database organized according to ownership of records, allowing records to have multiple owners and thus providing multiple access paths to the data. Database management systems (DBMSs) providing such capabilities are also referred to as CODASYL | Gartner Glossary |
| Remote access | information system) communicating through an external, nonorganization-controlled network (e.g., the Internet). Access to an organizational information system by a user (or an | NIST Glossary |
| Report | A detailed account or statement. For purposes of IT, the report provides analysis that supports informed decision-making. | Merriam-Webster |
| Request for information (RFI) | A market research tool used to obtain price, delivery, capabilities, and interest for planning purposes. Also referred to as a sources- sought notice. | GSA, “RFP, RFI, and RFQ: Understanding the Difference” |
| Request for proposal (RFP) | A solicitation method which communicates the [entity’s] requirements and requests proposals. | GSA, “RFP, RFI, and RFQ: Understanding the Difference” |
| Request for quote (RFQ) | A solicitation method used to obtain price, cost, delivery, and related information from suppliers. | Understanding the Difference” GSA, “RFP, RFI, and RFQ: |

The operational techniques and procedures (such as design 

FFIEC Adapted for 

analysis and inspection for defects) used to achieve quality 

Supervisory 


throughput (bandwidth), transit delay (latency), error rates, priority, security, packet loss, and packet jitter. 


Purposes 


(Conference on Data Systems Languages) DBMSs. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Resilience | The ability to prepare for and adapt to changing conditions and withstand and recover rapidly from disruptions. Resilience includes the ability to withstand and recover from deliberate attacks, accidents, or naturally occurring threats or incidents. | NIST Glossary |
| Role-based access | A model for controlling access to resources where permitted actions on resources are identified with roles rather than with individual subject identities. | NIST Glossary |
| Rollback | Updates to earlier firmware versions may provide a means to recover from a firmware update that is not functioning correctly. | NIST SP 800-193, Platform Firmware Resiliency |
|  | A means to recover from an update that is not functioning correctly or restore to a previous secure and functional version that may require the physical presence of a user. | FFIEC Adapted for Supervisory Purposes |
| Runtime | The period during which a computer program is executing. S | NIST Glossary |
| Scalability | Refers to how well a hardware and software system can adapt to ordinary and, for some forms of sanitization, extraordinary means. increased demands. For example, a scalable network system would be one that can start with just a few nodes but can easily expand to thousands of nodes. Scalability can be a very important feature | FFIEC Developed for Supervisory Purposes |
| Scheduling | and establish the sequence of computer job processing. A method used in the information processing facility to determine | ISACA Glossary |
| Scope creep | changes in a project’s scope. Scope creep can occur when the scope of a project is not properly defined, documented, and controlled. Typically, the scope increase consists of either new products or new features of already approved products. Hence, the project team drifts away from its original purpose. Because of one’s tendency to focus on only one dimension of a project, scope creep can also result in a project team overrunning its original budget and schedule. For example, scope creep can be a result of poor change control, lack of proper identification of what products and features are required to bring about the achievement of project objectives in the first place, or a weak project manager or executive sponsor. Also referred to as requirement creep, this refers to uncontrolled | ISACA Glossary |
|  | Scope creep refers to uncontrolled changes in a project’s scope, adding features and functionality without addressing the effects on time, costs, and resources. These changes may result from a lack of effective project change management, without approval (e.g., management or customer), or when the scope is not properly defined, documented, and controlled. | FFIEC Adapted for Supervisory Purposes |
| Secure code review | The process of auditing the source code of an application to verify that the proper security and logical controls are present, that they as intended, and that they have been invoked in the right Code review aims to identify security flaws in the | OWASP, Code Review Guide |
|  | work places. application related to its features and design, along with the exact root causes. The process of auditing the source code of an application to verify | 2.0 |
| Secure development | that the proper security and logical controls are present, work as intended, and have been invoked in the right places. A hardware and software development approach with an objective | FFIEC Adapted for Supervisory Purposes FFIEC Developed |
| Security | control, authentication, and logging capabilities). information, service or network entity is assured. The state in which the integrity, confidentiality, and accessibility of | NIST Glossary |


Guidelines 

Sanitization Actions taken to render data written on media unrecoverable by 

NIST Glossary 


because it means the entity can invest in a system with confidence 


that the entity will not quickly outgrow it. 

of building systems and components while minimizing the potential 

for Supervisory 

for vulnerabilities and reducing the attack surface. This is done 

through measures such as secure coding practices, comprehensive development testing, and built-in security mechanisms (e.g., access 

Purposes 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Security impact analysis | The analysis conducted by qualified staff in an organization to determine the extent to which changes to the system affect the security posture of the system. | NIST 800-128, Guide for Security- Focused Configuration Management of Information Systems |
| Security testing | Testing that attempts to verify that an implementation protects data and maintains functionality as intended. Testing that attempts to verify that a modified or new system implementation includes appropriate controls and does not introduce any security holes that might compromise other systems or allow for any misuse of the system or its information and protects | NIST Glossary FFIEC Adapted for Supervisory Purposes |
| Server | A computer or device on a network that manages network resources. Examples include file servers (to store files), print servers (to manage one or more printers), network servers (to manage network traffic), and database servers (to process database queries). | NIST Glossary |
| Service deregistration | Removal of a service from the service registry. | for Supervisory Purposes FFIEC Developed |
| Service discovery | The process by which an application learns what services are available on the network, and by which the network learns what services the application can provide. | Science Direct Topics in Computer Science |
| Service improvement | The actions taken to identify and execute methods to improve an entity’s services and align them with its business objectives. | Purposes FFIEC Developed for Supervisory |
| Service level agreement (SLA) | Defines the specific responsibilities of the service provider and sets the customer expectations. formal agreement between two parties that records a common about products or services to be delivered, | NIST Glossary |
|  | A understanding priorities, responsibilities, guarantees, and warranties between the parties. In addition, the agreement describes the nature, quality, security, availability, scope, and timeliness of delivery and response of the parties, the point(s) of contact for end-user problems, and the metrics by which the effectiveness of the process is monitored and approved and may include other measurable objectives. The agreement should cover not only expected day-to-day situations, but also unexpected or adverse events, as the need for the service may vary. | FFIEC Adapted Definition for Supervisory Purposes |
| Service | The service registry service is used by microservices that are online to publish their locations in a process referred to as registration and is used by microservices seeking to registered services. process of microservices using the registry service to publish | NIST Glossary |
| registration | coming service discover The their locations when they come online. It is used by microservices | FFIEC Adapted for Supervisory |
| Service registry | seeking to discover other registered services. microservices-based application register themselves while service instances going offline are deleted from it. A directory where new service instances created for the | Purposes NIST SP 800-204A, Building Secure Microservices- Based Applications |


Microservices- Based Applications Using Service- Mesh Architecture 


data and maintains functionality as intended. 

Service mesh A distributed computing middleware that optimizes communications 

between application services. NIST SP 800-204A, 

Building Secure 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Shadow IT | Refers to unauthorized hardware and other devices, software, or services operating in an entity’s IT environment. | FFIEC Developed for Supervisory Purposes |
| Signature | A recognizable, distinguishing pattern associated with an attack, such as a binary string in a virus or a particular set of keystrokes used to gain unauthorized access to a system. | NIST Glossary |
| Signature-based detection | This intrusion detection method compares network traffic to a set of pre-defined signatures and triggers an alert when a match is detected. Signatures are derived from numerous sources and are specific machine-readable patterns of network traffic that affect the integrity, confidentiality, or availability of computer networks, systems, and information. | DHS, Privacy Impact Assessment for the National Cybersecurity Protection System (NCPS) - Intrusion |
| Single point of failure | An element in the design, configuration, or implementation of a system that can cause the entire system to fail if it stops working. | FFIEC Developed for Supervisory |
| Social engineering | The act of deceiving an individual into revealing sensitive information, obtaining unauthorized access, or committing fraud by | NIST Glossary |
| Software | Computer programs (which are stored in and executed by computer hardware) and associated data (which also is stored in the hardware) that may be dynamically written or modified during execution. | NIST Glossary |
| Software as a service (SaaS) | The capability provided to the consumer is to use the provider’s applications running on a cloud infrastructure. The applications are accessible from various client devices through either a thin client interface, such as a web browser (e.g., web-based email), or a program interface. The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited user-specific application configuration | NIST Glossary |
| Software bill of material (SBOM) | A formal record containing the details and supply chain relationships of various components used in building software. Software developers and vendors often create products by assembling existing open-source and commercial software components. The | NIST Glossary |
| Source code | Computer commands written in a computer programming language that is meant to be read by people. | U.S. Department of Commerce, “Open Source Code” FFIEC Adapted for Supervisory |
|  | Computer commands written in a computer programming language that is meant to be read by people. Source code is not executable by the computer directly. It must first be converted (e.g., via compiler, assembler) into a machine language. The “Spiral” model divides a software development project into | Purposes NIST IR 7499, for and |
| Spiral model | several smaller projects that address the major risks first. | Guidelines Planning Development of Software for Buildings and Building Systems |
|  | A risk-driven software development process model that divides a software development project into several smaller projects that address the major risks first. The model illustrates activities (e.g., requirements analysis, preliminary and detailed design, coding, integration, and testing) that are performed iteratively until | FFIEC Adapted for Supervisory Purposes |

Using Service- Mesh Architecture 


Detection 


Purposes 


associating with the individual to gain confidence and trust. 

settings. 


SBOM enumerates these components in a product. 


development is complete. 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Standard image | The approved set of server configurations, applications, and systems, which can be used to deploy servers consistently and rebuild them more easily and quickly, when necessary. | FFIEC Developed for Supervisory Purposes |
| Standards | Rules, conditions, or requirements describing the following information for products, systems, services or practices: (i) Classification of components. * (ii) Specification of materials, performance, or operations; or (iii) Delineation of procedures. | NIST Glossary |
| State | A condition or mode of existence in which a system, component or simulation may be, e.g., the preflight state of an aircraft navigation program or the input state of a given channel.  A condition or mode of existence in which a system, component, | ISACA Glossary |
|  | or simulation (including stored data and inputs) may be at a given point in time. | FFIEC Adapted for Supervisory Purposes |
| Stateful | Refers to a data representation or a process that is dependent on an external data store. Refers to a data representation or a process that is dependent on some external information or other process and has the ability to | NIST Glossary FFIEC Adapted for Supervisory |
| Stateful inspection | packets that deviate from the expected state. Packet filtering that tracks the state of connections and blocks | NIST Glossary |
| Stateful protocol analysis | A firewalling capability that improves upon standard stateful inspection by adding basic intrusion detection technology. This technology consists of an inspection engine that analyzes protocols at the application layer to compare vendor-developed profiles of benign protocol activity against observed events to identify deviations, allowing a firewall to allow or deny access based on how an application is running over a network. | NIST Glossary |
| Stateless | and does not depend on any external data store. Refers to a data representation or a process that is self-contained Refers to a data representation or a process that is self-contained and does not depend on any external information or other process | NIST Glossary |
|  | and it does not store or reuse data. When the government is open to a wide range of solutions to meet their | FFIEC Adapted for Supervisory Purposes |
| Statement of objective (SOO) | objective(s), it will use a SOO. You will need to develop and include in your offer a proposed PWS (i.e., your solutions), performance metrics, a measurement plan, and a quality assurance plan. When an entity is open to a wide range of solutions to meet their | GSA FFIEC Adapted for |
| Statement of work (SOW) | A document that details the developer’s responsibilities in the performance of the contract. Documentation developed under the contract, for example, is specified in the SOW. Security assurance requirements, which detail many aspects of the processes the developer follows and what evidence must be provided to assure the organization that the processes have been conducted correctly | NIST IR 7622, Notional Supply Chain Risk Management Practices for Federal Information |
| Static analysis | Detecting software vulnerabilities by examining the app source code and binary code and attempting to reason over all possible behaviors that might arise at runtime. Also referred to as static testing. | NIST 800-163, rev. 1, Vetting the Security of Mobile Applications |
| Structured data | Data that has a predefined data model or is organized in a predefined way. | NIST SP 1500-1r2, NIST Big Data Interoperability Framework: Vol. 1, |
| Subcontractor | An individual or business firm contracting to perform part or all of another’s contract. | Merriam-Webster |

retain or store the data for reuse. 

Purposes 

objective(s), it may use a SOO. You will need to develop and 

include in your offer a proposed PWS (i.e., your solutions), 

performance metrics, a measurement plan, and a quality assurance plan. 

Supervisory 

Purposes 

and completely, may be specified in the SOW. 

Systems 


Definitions 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Supplier | Organization or an individual that enters into an agreement with the acquirer for the supply of a product or service. External or internal organization, business unit, or individual that enters into an agreement with the acquirer for the supply of a | NIST Glossary FFIEC Adapted for Supervisory |
| Supply chain | A system of organizations, people, activities, information, and product, component, or service. This includes suppliers, developers, and manufacturers in the supply chain. resources, possibly international in scope, that provides products or | Purposes NIST Glossary |
| Supply chain risk management (SCRM) | The process of identifying, assessing, and mitigating the risks associated with the global and distributed nature of information and communications technology product and service supply chains. services to consumers. | NIST Glossary |
|  | interconnected throughout the supply chains and their components, such as susceptibilities, vulnerabilities, and threats, associated with the global and distributed nature of information and communications technology product and service supply chains. The process of identifying, assessing, and mitigating the risks | FFIEC Adapted for Supervisory Purposes |
| System | more stated purposes. A combination of interacting elements organized to achieve one or | NIST Glossary |
| System and organization controls (SOC) | The suite of services CPAs may provide relating to system-level controls of a service organization and system- or entity-level controls of other organizations. Formerly, SOC referred to service organization controls. By redefining that acronym, the American Institute of Certified Public Accountants [AICPA] enables the introduction of new internal control examinations that may be performed (a) for other types of organizations, in addition to service organizations, and (b) on either system-level or entity-level controls | AICPA, System and Organization Controls: SOC Suite of Services |
| System development life | of such organizations. The scope of activities associated with a system, encompassing the system’s initiation, development and acquisition, implementation, operation and maintenance, and ultimately its disposal that instigates another system initiation. | NIST Glossary |
| cycle (SDLC) | test performed on a complete system to evaluate its compliance specified requirements. T | NIST Glossary |
| System test | A with |  |
| Telecommunicatio ns | The transmission, between or among points specified by the user, of information of the user’s choosing, without change in the form or content of the information as sent and received. | NIST Glossary |
| Term of support | The length of time for which the device will be supported by the manufacturer or supporting parties for such actions and materials as part replacements, software updates, vulnerability notices, technical support questions, etc. | NIST Glossary |
|  | The length of time for which the software, hardware, or service will be supported by the manufacturer or supporting parties for such actions and materials as part replacements, software updates, vulnerability notices, and technical support questions. | FFIEC Adapted for Supervisory Purposes |
| Third-party service provider Threat intelligence | Threat information that has been aggregated, transformed, Any independent party to whom an entity outsources activities that the entity itself is authorized to perform, including a technology service provider. | FFIEC Developed for Supervisory Purposes NIST Glossary |
| Threat model | defense sides of a logical entity, such as a piece of data, an application, a host, a system, or an environment. A form of risk assessment that models aspects of the attack and | NIST Glossary |
| Transmission | The act of sending or conveying data, voice, audio, or video from one person or place to another. An act, process, or instance of transmitting. | Merriam-Webster FFIEC Adapted for Supervisory |

analyzed, interpreted, or enriched to provide the necessary context for decision-making processes. 


Purposes 

& 



| Term | Definition | Source |
| --- | --- | --- |
| Unit testing | A testing technique that is used to test program logic in a particular program or module. The purpose of the test is to ensure that the internal operation of the program performs according to specification. It uses a set of test cases that focus on the control structure of the procedural design. | ISACA Glossary |
| Unstructured data | Data that does not have a predefined data model or is not organized in a predefined way. | NIST SP 1500-1r2, NIST Big Data Interoperability |
| Useful life | The normal expected operating life of an asset. | Service Internal Revenue |
| User acceptance testing (UAT) | Testing that involves taking use cases or procedures for how the system was designed to perform and ensuring that someone who follows the procedure gets the intended result; however, it does not necessarily demonstrate how well the system supports users in performing those functions. | NIST IR 7741, NIST Guide to the Processes Approach for Improving the Usability of Electronic Health Records |
| Virtualization | V The simulation of the software and/or hardware upon which other | NIST Glossary |
| Virtual machine * (VM) | Software that allows a single host to run one or more guest operating systems. simulated environment created by virtualization using | NIST Glossary |
|  | A software that allows a single host to run one or more guest operating systems. | FFIEC Adapted for Supervisory Purposes |
| Vulnerability | Weakness in system security procedures, design, implementation, internal controls, etc., that could be accidentally triggered or intentionally exploited and result in a violation of the system’s security policy. | NIST Glossary |
| Vulnerability assessment | Systematic examination of an information system or product to determine the adequacy of security and privacy measures, identify security and privacy deficiencies, provide data from which to predict the effectiveness of proposed security and privacy measures, and confirm the adequacy of such measures after implementation. | NIST Glossary |
| management | mitigation of vulnerabilities in systems, subsystems, and system components. | Vulnerability Management NIST Glossary 8531.01; DoD |
| Vulnerability scanning | A technique used to identify hosts/host attributes and associated vulnerabilities.  W |  |
| Workstation | Z design. A computer used for tasks such as programming, engineering, and | NIST Glossary |
| Zero-day exploit | Referred to as zero-day attack; an attack that exploits a previously unknown hardware, firmware, or software vulnerability. | NIST Glossary |

FFIEC IT Examination Handbook Development, Acquisition, and Maintenance  U 


Framework: Vol. 1, Definitions 

software runs. 

Vulnerability 

The practice of identification, classification, remediation, and 

DoD Instruction 

 An exploit that exploits a previously unknown hardware, firmware, or 

software vulnerability. FFIEC Adapted for 

Supervisory Purposes 

AI artificial intelligence 

AICPA American Institute of Certified Public Accountants 

API application programming interface 

ATM automated teller machine 

CA Consumer Affairs (for FRB SR Letters) 

CCB configuration or change control board 

CD continuous delivery 

CFPB Consumer Financial Protection Bureau 

CFR Code of Federal Regulations 

CI continuous integration 

CIO chief information officer 

CISA Cybersecurity and Infrastructure Security Agency 

CISO chief information security officer 

COTS commercial off-the-shelf 

CPU central processing unit 

DevOps development and operations 

DevSecOps development security operations 

DOD Department of Defense 

EOL end-of-life 

EULA end user license agreement 

FDIC Federal Deposit Insurance Corporation 

FFIEC Federal Financial Institutions Examination Council 

Fintech financial technology 

FOSS free and open-source software 

FIL Financial Institution Letter 

FRB Board of Governors of the Federal Reserve System 

FS-ISAC Financial Services Information Sharing and Analysis Center 

FTC Federal Trade Commission 

GLBA Gramm–Leach–Bliley Act 

GSA U.S. General Services Administration 

HVAC heating, ventilation, and air conditioning 

IaaS infrastructure-as-a-service 

IoT internet of things 

IR Internal Report 

ISACA Information Systems Audit and Control Association 

ISAC information sharing and analysis center 

IT information technology 

ITAM IT asset management 

ITL Information Technology Laboratory 

# APPENDIX C: ABBREVIATIONS 

ITRM IT risk management 

FFIEC IT Handbook FFIEC Information Technology Examination Handbook 

MFA multifactor authentication 

MSA master services agreement 

NCUA National Credit Union Administration 



| NIST | National Institute of Standards and Technology |
| --- | --- |
| NTIA | National Telecommunications and Information Administration |
| OCC | Office of the Comptroller of the Currency |
| OEM | original equipment manufacturer |
| OFAC | Office of Foreign Assets Control |
| OWASP | Open Worldwide Application Security Project |
| OS | operating system |
| PaaS | platform-as-a-service |
| PIR | post-implementation review |
| PMI | Project Management Institute |
| PMO | program management office |
| PWS | performance work statement |
| QA | quality assurance |
| QC | quality control |
| RAM | random access memory |
| RFI | request for information |
| RFID | radio frequency identification |
| RFP | request for proposal |
| RFQ | request for quote |
| SaaS | software-as-a-service |
| SBOM | software bill of material |
| SCRM | supply chain risk management |
| SDLC | system development life cycle |
| SLA | service-level agreement |
| SLC | State Liaison Committee |
| SOC | security operations center |
| SOC | system and organization control |
| SOW | statement of work |
| SP | Special Publication |
| SQL | Structured Query Language |
| SR | Supervision and Regulation Letter |
| UAT | user acceptance testing |
| USB | universal serial bus |
| USC | U.S. Code |

& 

## Laws 

# APPENDIX D: REFERENCES 

11 USC 101–112, “Bankruptcy” and “Office of the Law Revision Counsel: U.S. Code; Title 11” 

12 USC 226, “Title X of the Financial Institutions Regulatory and Interest Rate Control Act of 1978” 

12 USC 1461–1468, “Home Owners’ Loan Act” 12 USC 1813.3(u), “Institution-Affiliated Party” 12 USC 1841–1852, “Bank Holding Company Act” 12 USC 1861–1867, “Bank Service Company Act” 12 USC 1882, “Bank Protection Act of 1968” 

12 USC 5481(14) and (26), 5514, 5515, and 5531, “Dodd–Frank Wall Street Reform and Consumer Protection Act” 

15 USC 1681w, “Fair and Accurate Credit Transactions Act” 

15 USC 6801–6809 and 6821–6827, “Financial Modernization Act of 1999” (“Gramm– Leach–Bliley Act” [GLBA]) 

17 USC 1–8, 10–12, “Copyright Law of the United States” 

18 USC 1030, “Fraud and Related Activity in Connection With Computers” 29 USC 794d, “Rehabilitation Act of 1973, Section 508” 

## Consumer Financial Protection Bureau 

### Regulations 

### Guidance 

12 CFR 1005, “Electronic Fund Transfers (Regulation E)” 

12 CFR 1016, “Privacy of Consumer Financial Information (Regulation P)” 12 CFR 1022, “Fair Credit Reporting Act (Regulation V)” 

CFPB Compliance Bulletin and Policy Guidance 2016-02, “Service Providers” (October 2016) 

Federal Deposit Insurance Corporation 

### Regulations 

12 CFR 304.3(d), “Notification of Performance of Bank Services, Form FDIC 6120/06” 12 CFR 326, subpart A, “Minimum Security Procedures” 12 CFR 332, “Privacy of Consumer Financial Information” 

12 CFR 364, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

& 

12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 364, supplement A to appendix B, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” 

### Guidance 

FIL-29-2023, “Interagency Guidance on Third-Party Relationships: Risk Management” (June 6, 2023) 

FIL-10-2023, “Financial Institutions Are Required to Meet Contractual Obligations With Bridge Banks” (March 14, 2023) 

FIL-08-2023, “Joint Statement on Liquidity Risks to Banking Organizations Resulting From Crypto-Asset Market Vulnerabilities” (February 23, 2023) 

FIL-01-2023, “Joint Statement on Crypto-Asset Risks to Banking Organizations” (January 5, 2023) 

FIL-35-2022, “Advisory to FDIC-Insured Institutions Regarding Deposit Insurance and Dealings With Crypto Companies” (July 29, 2022) 

FIL-30-2022, “FDIC Updates on Brokered Deposits” (July 15, 2022) FIL-16-2022, “Notification of Engaging in Crypto-Related Activities” (April 7, 2022) FIL-12-2022, “Computer-Security Incident Notification Implementation” (March 29, 2022) FIL-74-2021, “Computer-Security Incident Notification Final Rule” (November 18, 2021) FIL-59-2021, “Conducting Due Diligence on Financial Technology Companies: A Guide for Community Banks” (August 27, 2021) 

FIL-55-2021, “Authentication and Access to Financial Institution Services and Systems” (August 11, 2021) 

FIL-27-2021, “Bank Secrecy Act: Agencies Address Model Risk Management for Bank Models and Systems Supporting Bank Secrecy Act/Anti-Money Laundering and Office of Foreign Assets Control Compliance” (April 9, 2021) 

FIL-103-2020, “The FDIC Publishes Sound Practices to Strengthen Operational Resilience” (November 2, 2020) 

FIL-52-2020, “FFIEC Joint Statement on Risk Management for Cloud Computing Services” (April 30, 2020) 

FIL-14-2020, “Interagency Statement on Pandemic Planning” (March 6, 2020) FIL-19-2019, “Technology Service Provider Contracts” (April 2, 2019) FIL-16-2018, “FFIEC Issues Joint Statement: Cyber Insurance and Its Potential Role in Risk Management Programs” (April 10, 2018) 

FIL-68-2016, “FFIEC Cybersecurity Assessment Tool: Frequently Asked Questions” (October 18, 2016) 

FIL-43-2016, “Information Technology Risk Examination (InTREx) Program” (June 30, 2016) 

FIL-37-2016, “FFIEC Joint Statement on Cybersecurity of Interbank Messaging and Wholesale Payment Networks” (June 7, 2016) 

FIL-28-2015, “Cybersecurity Assessment Tool” (July 2, 2015) FIL-13-2015, “FFIEC Joint Statements on Destructive Malware and Compromised Credentials” (March 30, 2015) 

& 

FIL-49-2014, “Technology Alert: GNU Bourne-Again Shell (Bash) Vulnerability” (September 29, 2014) 

FIL-41-2014, “FDIC Clarifying Supervisory Approach to Institutions Establishing Account Relationships with Third-Party Payment Processors” (July 28, 2014) FIL-16-2014, “Technology Alert: OpenSSL “Heartbleed” Vulnerability” (April 11, 2014) FIL-13-2014, “Technology Outsourcing: Informational Tools for Community Bankers” (April 7, 2014) 

FIL-3-2012, “Payment Processor Relationships Revised Guidance (Revised July 2014)” (January 31, 2012) 

FIL-4-2009, “Risk Management of Remote Deposit Capture” (January 14, 2009) FIL-127-2008, “Guidance on Payment Processor Relationships” (November 7, 2008) FIL-44-2008, “Third-Party Risk: Guidance for Managing Third-Party Risk” (June 6, 2008) FIL-77-2006, “Authentication in an Internet Banking Environment: Frequently Asked Questions” (August 21, 2006) 

FIL-52-2006, “Foreign-Based Third-Party Service Providers: Guidance on Managing Risks in These Outsourcing Relationships” (June 21, 2006) 

FIL-69-2005, “Voice Over Internet Protocol: Guidance on the Security Risks of VoIP” (July 27, 2005) 

FIL-66-2005, “Spyware: Guidance on Mitigating Risks From Spyware” (July 22, 2005) FIL-121-2004, “Computer Software Due Diligence Guidance on Developing an Effective Computer Software Evaluation Program to Assure Quality and Regulatory Compliance” (November 16, 2004) 

FIL-114-2004, “Risk Management of Free and Open Source Software” (October 21, 2004) FIL-84-2004, “Guidance on Instant Messaging” (July 21, 2004) 

FIL-27-2004, “Guidance on Safeguarding Customers Against E-Mail and Internet-Related Fraudulent Schemes” (March 12, 2004) 

FIL-43-2003, “Guidance on Developing an Effective Software Patch Management Program” (May 29, 2003) 

FIL-30-2003, “Federal Bank and Credit Union Regulatory Agencies Jointly Issue Guidance on the Risks Associated With Weblinking” (April 23, 2003) 

FIL-8-2002, “Guidance on Managing Risks Associated With Wireless Networks and Customer Access” (February 1, 2002) 

FIL-50-2001, “Bank Technology Bulletin on Outsourcing” (June 4, 2001) FIL-81-2000, “FFIEC Guidance on Managing Risks Associated With Outsourcing Technology Services” (November 29, 2000) 

FIL-49-1999, “Bank Service Company Act” (June 3, 1999) 

FIL-12-99, “FFIEC Adopts Updated Uniform Rating System for Information Technology” (February 5, 1999) 

FIL-82-96, “Interagency Statement on the Risks to Financial Institutions Involving Client/Server Computer Systems” (October 8, 1996) 

FIL-46-95, “Minimum Security Devices and Procedures” (July 7, 1995) 

Note: While listed FIL announcements may be noted as inactive, the underlying guidance remains in effect, unless specifically superseded or rescinded. 

& 

## Board of Governors of the Federal Reserve System 

### Regulations 

### Regulation H 

12 CFR 208, appendix D-1, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 208.61, “Bank Security Procedures” 

### Regulation K 

12 CFR 211.5 and 211.24 (i), “Protection of Customer and Consumer Information” 

### Regulation Y 

12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards” 

### Guidance 

SR Letter 23-4, “Interagency Guidance on Third-Party Relationships: Risk Management” (June 7, 2023) 

SR Letter 22-4/CA 22-3, “Contact Information in Relation to Computer-Security Incident Notification Requirements” (March 29, 2022) 

SR Letter 21-14, “Authentication and Access to Financial Institution Services and Systems” (August 11, 2021) 

SR Letter 20-24, “Interagency Paper on Sound Practices to Strengthen Operational Resilience” (November 2, 2020) 

SR Letter 20-3/CA 20-2, “Interagency Statement on Pandemic Planning” (March 10, 2020) SR Letter 16-11, “Supervisory Guidance for Assessing Risk Management at Supervised Institutions With Total Consolidated Assets Less than $100 Billion” (June 8, 2016, revised February 17, 2021) 

SR Letter 15-9, “FFIEC Cybersecurity Assessment Tool for Chief Executive Officers and Boards of Directors” (July 2, 2015) 

SR Letter 12-17/CA 12-14, “Consolidated Supervision Framework for Large Financial Institutions” (December 17, 2012) 

SR Letter 11-7, “Guidance on Model Risk Management” (April 4, 2011) 

SR Letter 05-23/CA 05-10, “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” (December 1, 2005) 

SR Letter 04-17, “FFIEC Guidance on the Use of Free and Open Source Software” (December 6, 2004) 

SR Letter 01-15, “Standards for Safeguarding Customer Information” (May 31, 2001) SR Letter 99-8, “Uniform Rating System for Information Technology” (March 31, 1999) SR Letter 98-9, “Assessment of Information Technology in the Risk-Focused Frameworks for the Supervision of Community Banks and Large Complex Banking Organizations” (April 20, 1998, revised February 26, 2021) 

& 

SR Letter 96-14, “Risk-Focused Safety and Soundness Examinations and Inspections” (May 24, 1996) 

## National Credit Union Administration 

### Regulations 

12 CFR 748, “Security Program, Suspicious Transactions, Catastrophic Acts, Cyber Incidents, and Bank Secrecy Act Compliance” 

12 CFR 748, appendix A, “Guidelines for Safeguarding Member Information” 12 CFR 749, “Records Preservation Program and Appendices—Record Retention Guidelines; Catastrophic Act Preparedness Guidelines” 12 CFR 749, appendix A, “Record Retention Guidelines” 

### Guidance 

Letter to Credit Unions 22-CU-07, “Federally Insured Credit Union Use of Distributed Ledger Technologies” (May 2022) 

Letter to Credit Unions 07-CU-13, “Evaluating Third Party Relationships” (December 2007) Letter to Credit Unions 06-CU-07, “IT Security Compliance Guide for Credit Unions” (April 2006) 

Letter to Credit Unions 03-CU-14, “Computer Software Patch Management” (September 2003) 

Letter to Credit Unions 01-CU-20, “Due Diligence Over Third Party Service Providers” (November 2001) 

Letter to Credit Unions 00-CU-11, “Risk Management of Outsourced Technology Services” (December 2000) 

## Office of the Comptroller of the Currency 

### Regulations 

12 CFR 5.30, “Establishment, Acquisition, and Relocation of a Branch of a National Bank” 12 CFR 5.31, “Establishment, Acquisition, and Relocation of a Branch and Establishment of an Agency Office of a Federal Savings Association” 

12 CFR 30, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 30, appendix D, “OCC Guidelines Establishing Heightened Standards for Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

12 CFR 30, appendix E, “OCC Guidelines Establishing Standards for Recovery Planning by Certain Large Insured National Banks, Insured Federal Savings Associations, and Insured Federal Branches” 

12 CFR 41.83, “Proper Disposal of Records Containing Consumer Information” 

& 

### Guidance 

OCC Bulletin 2023-22, “Cybersecurity: Cybersecurity Supervision Work Program” (June 26, 2023) 

OCC Bulletin 2023-17, “Third-Party Relationships: Interagency Guidance on Risk Management” (June 6, 2023) 

OCC Bulletin 2023-1, “Crypto-Assets: Joint Statement on Crypto-Asset Risks to Banking Organizations” (January 3, 2023) 

OCC Bulletin 2022-22, “Cybersecurity: 2022 Cybersecurity Resource Guide for Financial Institutions” (October 6, 2022) 

OCC Bulletin 2022-8, “Information Technology: OCC Points of Contact for Banks’ Computer-Security Incident Notifications” (March 29, 2022) 

OCC Bulletin 2021-55, “Computer-Security Incident Notification: Final Rule” (November 23, 2021) 

OCC Bulletin 2021-40, “Third-Party Relationships: Conducting Due Diligence on Financial Technology Companies: A Guide for Community Banks” (August 27, 2021) 

OCC Bulletin 2021-36, “Information Security: FFIEC Statement on Authentication and Access to Financial Institution Services and Systems” (August 11, 2021) 

OCC Bulletin 2021-30, “FFIEC Information Technology Examination Handbook: New Architecture, Infrastructure, and Operations Booklet” (June 30, 2021) 

OCC Bulletin 2021-17, “Artificial Intelligence: Request for Information on Financial Institutions' Use of Artificial Intelligence, Including Machine Learning” (March 31, 2021) 

OCC Bulletin 2020-94, “Operational Risk: Sound Practices to Strengthen Operational Resilience” (October 30, 2020) 

OCC Bulletin 2020-46, “Cybersecurity: Joint Statement on Security in a Cloud Computing Environment” (April 30, 2020) 

OCC Bulletin 2020-23, “Pandemic Planning: Essential Critical Infrastructure Workers in the Financial Services Sector” (March 25, 2020) 

OCC Bulletin 2020-13, “Pandemic Planning: Updated FFIEC Guidance” (March 6, 2020) OCC Bulletin 2020-5, “Cybersecurity: Joint Statement on Heightened Cybersecurity Risk” (January 16, 2020) 

OCC Bulletin 2019-57, “FFIEC Information Technology Examination Handbook: Revised Business Continuity Management Booklet” (November 14, 2019) 

OCC Bulletin 2019-37, “Operational Risk: Fraud Risk Management Principles” (July 24, 2019) 

OCC Bulletin 2019-13, “Recovery Planning: Updated Comptroller's Handbook Booklet and Rescissions” (March 15, 2019) 

OCC Bulletin 2018-40, “Cybersecurity: Cyber-Related Sanctions” (November 5, 2018) OCC Bulletin 2017-43, “New, Modified, or Expanded Bank Products and Services: Risk Management Principles” (October 20, 2017) 

OCC Bulletin 2017-7, “Third-Party Relationships: Supplemental Examination Procedures” (January 24, 2017) 

OCC Bulletin 2016-34, “Cybersecurity: Frequently Asked Questions on the FFIEC Cybersecurity Assessment Tool” (October 17, 2916) 

& 

OCC Bulletin 2016-18, “Cybersecurity of Interbank Messaging and Wholesale Payment Networks: FFIEC Statement” (June 7, 2016) 

OCC Bulletin 2015-44, “FFIEC Information Technology Examination Handbook: Revised Management Booklet” (November 10, 2015) 

OCC Bulletin 2015-40, “Cybersecurity: Joint Statement on Cyber Attacks Involving Extortion” (November 3, 2015) 

OCC Bulletin 2015-31, “Cybersecurity: FFIEC Cybersecurity Assessment Tool” (June 30, 2015) 

OCC Bulletin 2015-20, “Cybersecurity: Destructive Malware Joint Statement” (March 30, 2015) 

OCC Bulletin 2015-19, “Cybersecurity: Cyber Attacks Compromising Credentials Joint Statement” (March 30, 2015) 

OCC Bulletin 2014-48, “Bourne-Again Shell (Bash) ‘Shellshock’ Vulnerability: FFIEC Alert” (September 26, 2014) 

OCC Bulletin 2014-17, “Information Security Vulnerability in OpenSSL Encryption Tool (Heartbleed): Joint Statement” (April 25, 2014) 

OCC Bulletin 2014-13, “Cyber Attacks on Financial Institutions’ Automated Teller Machine and Card Authorization Systems: Joint Statement” (April 2, 2014) 

OCC Bulletin 2011-12, “Sound Practices for Model Risk Management: Supervisory Guidance on Model Risk Management” (April 4, 2011) 

OCC Bulletin 2008-16, “Information Security: Application Security” (May 8, 2008) OCC Bulletin 2006-35, “Authentication in an Internet Banking Environment: Frequently Asked Questions” (August 15, 2006) 

OCC Bulletin 2006-31, “FFIEC Information Security Booklet: Information Security Guidance” (July 27, 2006) 

OCC Bulletin 2005-13, “Response Programs for Unauthorized Access to Customer Information and Customer Notice - Final Guidance: Interagency Guidance” (April 14, 2005) 

OCC Bulletin 2004-47, “FFIEC Guidance: Risk Management for the Use of Free and Open Source Software” (October 27, 2004) 

OCC Bulletin 2004-32, “FFIEC Information Technology Examination Handbook: FFIEC IT Booklets on Outsourcing Technology Services and Management” (July 15, 2004) 

OCC Bulletin 2002-16, “Bank Use of Foreign-Based Third-Party Service Providers: Risk Management Guidance” (May 15, 2002) 

OCC Bulletin 2002-10, “Country Risk: Sound Risk Management Practices” (March 11, 2002) 

OCC Bulletin 2001-35, “Examination Procedures to Evaluate Compliance With the Guidelines to Safeguard Customer Information: Examination Procedures” (July 18, 2001) OCC Bulletin 2001-12, “Bank-Provided Account Aggregation Services: Guidance to Banks” (February 28, 2001) 

OCC Bulletin 1998-31, “Guidance on Electronic Financial Services and Consumer Compliance: FFIEC Guidance” (July 30, 1998) 

OCC Bulletin 1998-3, “Technology Risk Management: Guidance for Bankers and Examiners” (February 4, 1998) 

& 

## Other References 

### Federal Regulations 

16 CFR 314 (FTC), “Standards for Safeguarding Customer Information” 

16 CFR 314.4(j) (FTC), “Amendment to Standards for Safeguarding Customer Information” 

### National Institute of Standards and Technology (NIST) 

NIST, “Automated Identification Technologies for Forensic Science” NIST Glossary 

National Checklist Program (security configurations) National Vulnerability Database 

NIST Advanced Manufacturing Series 100-40, Agile for Model-Based-Standards Development 

#### NIST SP 500-292, NIST Cloud Computing Reference Architecture: Recommendations of the National Institute of Standards and Technology 

NIST SP 500-316, Framework for Cloud Usability 

NIST SP 800-28, version 2, Guidelines on Active Content and Mobile Code NIST SP 800-37, rev. 2, Risk Management Framework for Information Systems and Organizations: A System Life Cycle Approach for Security and Privacy 

NIST SP 800-47, rev. 1, Managing the Security of Information Exchanges 

NIST SP 800-53, rev. 5, Security and Privacy Controls for Information Systems and Organizations 

NIST SP 800-53, rev. 5, SR-3, Supply Chain Controls and Processes NIST SP 800-58, Security Considerations for Voice Over IP Systems NIST SP 800-63-3, Digital Identity Guidelines 

NIST SP 800-82, rev. 3, Guide to Operational Technology (OT) Security 

NIST 800-98, Guidelines for Securing Radio Frequency Identification (RFID) Systems NIST SP 800-115, Technical Guide to Information Security Testing and Assessment NIST SP 800-125, Guide to Security for Full Virtualization Technologies 

#### NIST SP 800-128, Guide for Security-Focused Configuration Management of Information Systems 

#### NIST SP 800-137, Information Security Continuous Monitoring (ISCM) for Federal Systems and Organizations 

#### NIST SP 800-145, The NIST Definition of Cloud Computing: Recommendations of the National Institute of Standards and Technology 

NIST SP 800-146, Cloud Computing Synopsis and Recommendations NIST SP 800-160, vol. 1, rev. 1, Engineering Trustworthy Secure Systems 

NIST SP 800-160, vol. 2, rev. 1, Developing Cyber Resilient Systems: A Systems Security Engineering Approach 

#### NIST SP 800-161r1, Cybersecurity Supply Chain Risk Management Practices for Systems and Organizations 

NIST SP 800-163, rev. 1, Vetting the Security of Mobile Applications NIST SP 800-190, Application Container Security Guide 

NIST SP 800-193, Platform Firmware Resiliency Guidelines 

NIST SP 800-204, Security Strategies for Microservices-Based Application Systems NIST SP 800-204A, Building Secure Microservices-Based Applications Using Service-Mesh Architecture 

#### NIST SP 800-204C, Implementation of DevSecOps for a Microservices-Based Application With Service Mesh 

NIST SP 800-207, Zero Trust Architecture 

NIST SP 800-210, General Access Control Guidance for Cloud Systems NIST SP 800-218, Secure Software Development Framework (SSDF) Version 1: Recommendations for Mitigating the Risks of Software Vulnerabilities 

NIST SP 1500-1r2, NIST Big Data Interoperability Framework: Volume 1, Definitions NIST SP 1800-5, IT Asset Management 

NIST SP 1800-16, Securing Web Transactions: TLS Server Certificate Management. NIST Response to Executive Order 14028, Software Security in Supply Chains NIST Information Technology Laboratory (ITL) Bulletin, “Security Considerations for Exchanging Files Over the Internet” (August 2020) 

NIST ITL Bulletin, “Security for Enterprise Telework, Remote Access, and Bring Your Own Device (BYOD) Solutions”(March 2020) 

NIST ITL Bulletin, “The System Development Life Cycle (SDLC)” (April 2009) NIST National Construction Safety Team Act Report (NCSTAR) 1-4B, Fire Suppression Systems 

NIST Directive S 6106.01, “Open Source Code” 

NIST Internal Report (IR) 7499, Guidelines for Planning and Development of Software for Buildings and Building Systems 

NIST IR 7622, Notional Supply Chain Risk Management for Federal Information Systems NIST IR 7741, NIST Guide to the Processes Approach for Improving the Usability of Electronic Health Records 

#### NIST IR 8228, Considerations for Managing Internet of Things (IoT) Cybersecurity and Privacy Risks 

NIST IR 8259A, IoT Device Cybersecurity Capability Core Baseline 

NIST IR 8397, Guidelines on Minimum Standards for Developer Verification of Software NIST IR 8419, Block Chain and Related Technologies to Support Manufacturing Supply Chain Traceability: Needs and Industry Perspectives 

NIST IR 8425, Profile of the IoT Core Baseline for Consumer IoT Products 

### Documents referenced by NIST 

Gallagher, Leonard, and Jeff Offutt, “Test Sequence Generation for Integration Testing of Component Software,” Computer Journal, 2005 

Martzloff, François, A New IEC Standard on the Measurement of Power Quality Parameters Rapp, Paul, Copyright Law 

& 

### Other Federal Government 

### Bureau of Labor Statistics 

#### Occupational Outlook Handbook 

“Customer Service Representatives” “Purchasing Managers, Buyers, and Purchasing Agents” “Software Developers, Quality Assurance Analysts, and Testers” 

### Centers for Disease Control 

“Implementation Phase” 

### Cybersecurity and Infrastructure Security Agency (CISA) 

“CISA Insights - Cyber: Remediate Vulnerabilities for Internet Accessible Systems” CRR Supplemental Resource Guide, Volume 3: Configuration and Change Management, Version 1.1 

#### CRR Supplemental Resource Guide, Volume 5: Incident Management Resource Guide, Version 1.1 

“Infrastructure Dependency Primer” “Protecting Against Malicious Code” 

Securing the Software Supply Chain: Recommended Practices Guide for Developers Shifting the Balance of Cybersecurity Risk: Principles and Approaches for Security-by- Design and -Default 

### Department of Defense (DOD) 

#### DOD Enterprise DevSecOps Fundamentals 

DoD Enterprise DevSecOps Reference Design: Version 1.0 Securing Defense-Critical Supply Chains “DoD Open Source Software FAQ” 

#### DOD Instruction 8531.01: DoD Vulnerability Management 

### Documents referenced by DOD 

#### Davis, Noopur, Secure Software Development Life Cycle Processes: A Technology Scouting Report, Carnegie Mellon University Software Engineering Institute (Defense Technical Information Center) 

& 

### Food and Drug Administration 

Glossary of Computer System Software Development Terminology 

### National Aeronautics and Space Administration 

#### A Software Development Simulation Model of a Spiral Process (NASA Technical Reports Server) 

### National Telecommunications and Information Administration (NTIA) 

#### Framing Software Component Transparency: Establishing a Common Software Bill of Materials (SBOM) 

“SBOM at a Glance” “SBOM Myths vs. Facts” 

### U.S. Department of Commerce 

“Open Source Code” 

U.S. Copyright Office “Copyright in General” “What Is Copyright?” 

### U.S. Department of Energy 

#### Copyright Law of the United States (Title 17) 

#### Suspect/Counterfeit Items Awareness Training 

### U.S. Department of Homeland Security 

#### Access Control Technologies Handbook DHS Lexicon Terms and Definitions 

#### Privacy Impact Assessment for the National Cybersecurity Protection System (NCPS) – Intrusion Detection 

#### Systems Engineering Life Cycle 

### U.S. Department of Justice 

Systems Development Life Cycle Guidance, chapter 12, “Disposition Phase” 

& 

### U.S. Government Accountability Office 

#### Information Technology Investment Management The Post-Implementation Review 

### U.S. General Services Administration (GSA) 

“Performance Work Statement” “PWS, SOO, SOW - Finding the Best Fit” “Respond to a Solicitation” 

“RFP, RFI, and RFQ: Understanding the Difference” 

### U.S. Patent and Trademark Office 

“Copyright Basics” “Trademark, Patent, or Copyright” 

### State Government 

### New York State Office of Information Technology Services 

#### NYS Project Management Guidebook Release 2 System Implementation 

### Industry References 

### American Institute of Certified Public Accountants (AICPA) 

#### System and Organization Controls: SOC Suite of Services 

“What Are You Doing to Prevent Cyberattacks? SOC 2 and SOC for Cybersecurity: How They’re Different and How They Can Help” 

### Center for Internet Security 

“CIS Critical Security Control 7: Continuous Vulnerability Management” 

### Cloud Security Alliance 

“Understanding the OWASP API Security Top 10” 

& 

### Creative Commons 

CC0 

### Financial Accounting Standards Board 

“Post-Implementation Review” 

### Financial Services Information Sharing and Analysis Center (FS-ISAC) 

### Information Systems Audit and Control Association (ISACA) 

ISACA Glossary 

### International Organization for Standardization (ISO)/International Electrotechnical Commission (IEC) 

ISO Online Browsing Platform, Terms & Definitions 

### Internet Engineering Task Force (IETF) 

“OAuth 2.0 Dynamic Client Registration Protocol” 

### The MITRE Corporation (MITRE) 

#### Improperly Controlled Modification of Dynamically-Determined Object Attributes 

### The National Automated Clearinghouse Association (Nacha) 

### National Council of ISACs 

### Open Worldwide Application Security Project (OWASP) 

“OWASP API Security Project” Component Analysis Fuzzing 

#### OWASP Vulnerability Management Guide (OVMG) Code Review Guide 2.0 

### Payments Card Industry (PCI) Security Standards Council 

& 

### Project Management Institute (PMI) 

A Guide to the Project Management Body of Knowledge, fifth edition “Running IS Maintenance as a Project” 

“Statement of Work: The Foundation for Delivering Successful Service Projects” “What Is Project Management?” 

“Is This Really Worth the Effort? The Need for a Business Case” 

### Society for Human Resource Management 

“Top Database Security Threats and How to Mitigate Them” 

### Other References 

#### Black’s Law Dictionary 

#### Law Insider Dictionary 

“IT Security Health Check” 

## FFIEC Information Technology Examination Handbook 

# Information Security 

SEPTEMBER 2016 

Contents 

INTRODUCTION ............................................................................................................. 1 

I GOVERNANCE OF THE INFORMATION SECURITY PROGRAM ......... 3 

I.A Security Culture ...................................................................................... 3 

I.B Responsibility and Accountability ........................................................ 3 

I.C Resources ............................................................................................... 5 

II INFORMATION SECURITY PROGRAM MANAGEMENT ...................... 6 

II.A Risk Identification ................................................................................... 7 

II.A.1 Threats ..................................................................................................... 8 

II.A.2 Vulnerabilities ........................................................................................... 8 

II.A.3 Supervision of Cybersecurity Risk and Resources for Cybersecurity Preparedness ........................................................................................... 9 

II.B Risk Measurement ................................................................................ 10 

II.C Risk Mitigation ...................................................................................... 11 

II.C.1 Policies, Standards, and Procedures ...................................................... 11 

II.C.2 Technology Design ................................................................................. 12 

II.C.3 Control Types ......................................................................................... 12 

II.C.4 Control Implementation .......................................................................... 13 

II.C.5 Inventory and Classification of Assets .................................................... 14 

II.C.6 Mitigating Interconnectivity Risk ............................................................. 14 

II.C.7 User Security Controls ............................................................................ 15 

II.C.8 Physical Security .................................................................................... 18 

II.C.9 Network Controls .................................................................................... 19 

II.C.10 Change Management Within the IT Environment ................................... 21 

II.C.11 End-of-Life Management ........................................................................ 25 

II.C.12 Malware Mitigation .................................................................................. 25 

II.C.13 Control of Information ............................................................................. 26 

II.C.14 Supply Chain .......................................................................................... 29 

II.C.15 Logical Security ...................................................................................... 30 

II.C.16 Customer Remote Access to Financial Services .................................... 35 

II.C.17 Application Security ................................................................................ 38 

II.C.18 Database Security .................................................................................. 40 

II.C.19 Encryption .............................................................................................. 40 

II.C.20 Oversight of Third-Party Service Providers ............................................ 42 II.C.21 

II.C.22 

Business Continuity Considerations ....................................................... 43 

Log Management.................................................................................... 44 

II.D 

Risk Monitoring and Reporting ........................................................... 45 

## II.D.1 

### III 

### III.A 

### III.B 

### III.C 

### III.D 

IV 

IV.A 

Metrics .................................................................................................... 45 

SECURITY OPERATIONS ..................................................................... 46 

Threat Identification and Assessment ................................................ 47 

Threat Monitoring ................................................................................. 48 

Incident Identification and Assessment ............................................. 49 

Incident Response ................................................................................ 50 

INFORMATION SECURITY PROGRAM EFFECTIVENESS ................. 52 

Assurance and Testing ........................................................................ 53 

IV.A.1 

Key Testing Factors ................................................................................ 53 

## IV.A.2 

## IV.A.3 

Types of Tests and Evaluations ............................................................. 54 

Independence of Tests and Audits ......................................................... 56 

IV.A.4 

Assurance Reporting .............................................................................. 56 

APPENDIX A: EXAMINATION PROCEDURES ........................................................... 57 

APPENDIX B: GLOSSARY .......................................................................................... 75 

APPENDIX C: LAWS, REGULATIONS, AND GUIDANCE .......................................... 89 

## Introduction 

This “Information Security” booklet is an integral part of the Federal Financial Institutions Examination Council (FFIEC)1 Information Technology Examination Handbook (IT Handbook) and should be read in conjunction with the other booklets in the IT Handbook. This booklet provides guidance to examiners and addresses factors necessary to assess the level of security risks to a financial institution’s2 information systems.3 It also helps examiners evaluate the adequacy of the information security program’s integration into overall risk management.4 

Information security is the process by which a financial institution protects the creation, collection, storage, use, transmission, and disposal of sensitive information, including the protection of hardware and infrastructure used to store and transmit such information. Information security promotes the commonly accepted objectives of confidentiality, integrity, and availability of information and is essential to the overall safety and soundness of an institution. Information security exists to provide protection from malicious and non-malicious actions that increase the risk of adverse effects on earnings, capital, or enterprise value. The potential adverse effects can arise from the following: 

* • Disclosure of information to unauthorized individuals.
* • Unavailability or degradation of services.
* • Misappropriation or theft of information or services.
* • Modification or destruction of systems or information.
* • Records that are not timely, accurate, complete, or consistent. 1 The FFIEC was established on March 10, 1979, pursuant to Title X of the Financial Institutions Regulatory and Interest Rate Control Act of 1978, Public Law 95-630. The FFIEC is composed of the principals of the following: the Board of Governors of the Federal Reserve System (FRB), the Federal Deposit Insurance Corporation (FDIC), the National Credit Union Administration (NCUA), the Office of the Comptroller of the Currency (OCC), the State Liaison Committee (SLC), and the Consumer Financial Protection Bureau (CFPB). 

2 The term “financial institution” includes national banks, federal savings associations, state savings associations, state member banks, state nonmember banks, and credit unions. The term is used interchangeably with “institution” in this booklet. 

3 Examiners should also use this booklet to evaluate the performance by third-party service providers, including technology service providers, of services on behalf of financial institutions. 

4 This booklet addresses regulatory expectations regarding the security of all information systems and information maintained by or on behalf of a financial institution, including a financial institution’s own information and that of all of its customers. An institution’s overall information security program must also address the specific information security requirements applicable to “customer information” set forth in the “Interagency Guidelines Establishing Information Security Standards” implementing section 501(b) of the Gramm–Leach–Bliley Act and section 216 of the Fair and Accurate Credit Transactions Act of 2003. See 12 CFR 30, appendix B (OCC); 12 CFR 208, appendix D-2 and 225, appendix F (FRB); 12 CFR 364, appendix B (FDIC); and 12 CFR 748, appendix A (NCUA) (collectively referenced in this booklet as the “Information Security Standards”).

Institutions should maintain effective information security programs commensurate with their operational complexities.5 Information security programs should have strong board and senior management support, promote integration of security activities and controls throughout the institution’s business processes, and establish clear accountability for carrying out security responsibilities. In addition, because of the frequency and severity of cyber attacks, the institution should place an increasing focus on cybersecurity controls, a key component of information security. 

Institutions should also assess and refine their controls on an ongoing basis. The condition of a financial institution’s controls, however, is just one indicator of its overall security posture. Other indicators include the ability of the institution’s board and management to continually review the institution’s security posture and react appropriately in the face of rapidly changing threats, technologies, and business conditions. Information security is far more effective when management does the following: 

* • Integrates processes, people, and technology to maintain a risk profile that is in accordance with the board’s risk appetite.6
* • Aligns the information security program with the enterprise risk management program and identifies, measures, mitigates, and monitors risk.

Because risk mitigation frequently depends on institution-specific factors, this booklet describes processes and controls that an institution can use to protect information and supporting systems from various threats. Management should be able to identify and characterize the threats, assess the risks, make decisions regarding the implementation of appropriate controls, and provide appropriate monitoring and reporting. 

Financial institutions may outsource some or all of their IT-related functions. Although the use of outsourcing may change the location of certain activities from financial institutions to third- party service providers, outsourcing does not change the regulatory expectations for an effective information security program. Examiners should use this booklet when evaluating a financial institution’s risk management process, including the duties, obligations, and responsibilities of the third-party service provider regarding information security and the oversight exercised by the financial institution. 

5 See also Information Security Standards, section II.A, requiring each financial institution to have a comprehensive written information security program, appropriate to its size and complexity, designed to (1) ensure the security and confidentiality of “customer information”; (2) protect against any anticipated threats or hazards to the security or integrity of such information; (3) protect against unauthorized access to or use of such information that could result in a substantial harm or inconvenience to any customer; and (4) ensure the proper disposal of both “customer information” and any “consumer information.” 

6 Risk appetite can be defined as the amount of risk a financial institution is prepared to accept when trying to achieve its objectives. 

## I Governance of the Information Security Program 

### Action Summary 

Management should promote effective IT governance by doing the following: 

* • Establishing an information security culture that promotes an effective information security program and the role of all employees in protecting the institution’s information and systems.
* • Clearly defining and communicating information security responsibilities and accountability throughout the institution.
* • Providing adequate resources to effectively support the information security program.

While IT governance is generally addressed in the IT Handbook’s “Management” booklet, this booklet addresses specific governance topics related to information security, including the following: 

* • Implementation and promotion of security culture.
* • Assignment of responsibilities and accountability.
* • Effective funding and use of resources.
### I.A Security Culture 

An institution’s security culture contributes to the effectiveness of the information security program. The information security program is more effective when security processes are deeply embedded in the institution’s culture. 

The board and management should understand and support information security and provide appropriate resources for developing, implementing, and maintaining the information security program. The result of this understanding and support is a program in which management and employees are committed to integrating the program into the institution’s lines of business, support functions, and third-party management program. 

The introduction of new business initiatives (such as new service offerings or applications) can reveal the maturity of and degree to which information security is part of the institution’s culture. An institution with a stronger security culture generally integrates information security into new initiatives from the outset and throughout the life cycles of services and applications. Another indicator of an effective culture is whether management and employees are held accountable for complying with the institution’s information security program. 

### I.B Responsibility and Accountability 

The board, or designated board committee, should be responsible for overseeing the development, implementation, and maintenance of the institution’s information security program and holding senior management accountable for its actions. The board should reasonably understand the business case for information security and the business implications of information security risks; provide management with direction; approve information security plans, policies, and programs; review assessments of the information security program’s effectiveness; and, when appropriate, discuss management’s recommendations for corrective action. The board should provide management with its expectations and requirements and hold management accountable for central oversight and coordination, assignment of responsibility, and effectiveness of the information security program. 

The board, or designated board committee, should approve the institution’s written information security program; affirm responsibilities for the development, implementation, and maintenance of the program; and review a report on the overall status of the program at least annually.7 

Management should provide a report to the board at least annually8 that describes the overall status of the program and material matters related to the program, including the following: 

* • Risk assessment process, including threat identification and assessment.
* • Risk management and control decisions, including risk acceptance and avoidance.
* • Third-party service provider arrangements.
* • Results of testing.
* • Security breaches or violations of law or regulation and management’s responses to such incidents.
* • Recommendations for updates to the information security program.

When providing reports on information security, management should include the results of management assessments and reviews; internal and external audit activity related to information security; third-party reviews of the information security program and information security measures; and other internal or external reviews designed to assess the adequacy of the information security program, processes, policies, and controls. 

Management also should do the following: 

* • Implement the board-approved information security program.
* • Establish appropriate policies, standards, and procedures to support the information security program.
* • Participate in assessing the effect of security threats or incidents on the institution and its lines of business and processes.
* • Delineate clear lines of responsibility and communicate accountability for information security. 7 See also Information Security Standards, section III.A, requiring the board of directors or an appropriate committee of the board of each financial institution to approve the institution’s written information security program, and oversee the development, implementation, and maintenance of the program, including assigning specific responsibility for its implementation and reviewing management reports. 

8 See also Information Security Standards, section III.F, requiring each financial institution to report to its board or an appropriate committee of the board at least annually. The report should include a description of the institution’s compliance with the Information Security Standards and discuss material matters related to its information security program.
* • Adhere to board-approved risk thresholds relating to information security threats or incidents, including those relating to cybersecurity.
* • Oversee risk mitigation activities that support the information security program.
* • Implement a risk acceptance process that identifies the risk and when, how, to what extent, and who in management has accepted the risk associated with identified vulnerabilities.
* • Establish segregation of duties.
* • Coordinate information and physical security.
* • Integrate security controls throughout the institution.
* • Require that data with similar criticality and sensitivity be protected consistently throughout the institution.
* • Establish and monitor the information security responsibilities of third parties, as further described in the “Oversight of Third-Party Service Providers” section of this booklet.
* • Maintain job descriptions or employment contracts that include specific information security responsibilities.
* • Provide information security and awareness training and ongoing security-related communications to employees, and ensure employees complete such training annually.

Management should designate at least one information security officer responsible and accountable for implementing and monitoring the information security program. Information security management responsibilities may be distributed across various lines of business depending on where the risk decisions are made and the institution’s size, complexity, culture, nature of operations, or other factors. 

Information security officers should report directly to the board or senior management and have sufficient authority, stature within the organization, knowledge, background, training, and independence to perform their assigned tasks. To ensure appropriate segregation of duties, the information security officers should be independent of the IT operations staff and should not report to IT operations management. Information security officers should be responsible for responding to security events by ordering emergency actions to protect the institution and its customers from imminent loss of information; managing the negative effects on the confidentiality, integrity, availability, or value of information; and minimizing the disruption or degradation of critical services. 

Internal auditors should implement a risk-based audit program to ensure management maintains and the board oversees an effective information security program. Additionally, management should issue appropriate reports to the board. Refer to the IT Handbook’s “Audit” booklet. 

### I.C Resources 

Funding, along with technical and managerial talent, also contributes to the effectiveness of the information security program. Management should provide, and the board should oversee, adequate funding to develop, implement, and maintain a successful information security program. The program should be staffed by sufficient personnel who have skills that are aligned with the institution’s technical and managerial needs and commensurate with its size, complexity, and risk profile. Knowledge of technology standards, practices, and risk methodologies is particularly important to the success of the information security program. 

When third-party service providers supplement an institution’s technical and managerial capabilities, management oversight should be commensurate with the sensitivity and criticality of the information and business processes supported by the third-party service provider. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for more information. 

## II Information Security Program Management 

### Action Summary 

Management should develop and implement an information security program that does the following: 

* • Supports the institution’s IT risk management (ITRM) process by identifying threats, measuring risk, defining information security requirements, and implementing controls.
* • Integrates with lines of business and support functions in which risk decisions are made.
* • Integrates third-party service provider activities with the information security program.

The institution should have a robust and effective information security program that supports the institution’s ITRM process.9 An effective information security program includes the following: 

* • Risk identification
* • Risk measurement
* • Risk mitigation
* • Risk monitoring and reporting

Refer to the IT Handbook’s “Management” booklet for more information. A comprehensive information security program should incorporate cybersecurity elements, and management should identify, measure, mitigate, monitor, and report cybersecurity-related risks in accordance with the information security program and the ITRM process. In addition, to determine the overall effectiveness of the information security program, management should have comprehensive assurance and testing processes. 

Management should integrate the information security program with the institution’s lines of business and support functions. An integrated program provides management the ability to assess the likelihood and potential damage to the institution from an incident, identify the root cause(s) of the incident, and implement controls to address identified issues. 

Institutions that outsource technology, line of business activities, and support functions should ensure integration of these activities with the information security program through an effective third-party service provider management program.10 Effective integration of these programs is evident when the institution creates and enforces expectations that align with the internal information security program in such a way that the combined activities of the institution and its third-party service providers result in an acceptable level of risk. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for more information. 

9 See also Information Security Standards, section III.B, requiring each financial institution to assess risk including through the identification of reasonably foreseeable internal and external threats that could result in unauthorized disclosure, misuse, alteration, or destruction of “customer information” or “customer information systems,” and section III.C, requiring each financial institution to manage and control its risks by (1) designing an information security program to control risks it identifies commensurate with the sensitivity of the information and the complexity and scope of the institution’s activities, and (2) adopting an enumerated list of controls, as appropriate. 

### II.A Risk Identification 

#### Action Summary 

Management should develop and implement a process to identify risk. 

Risk is the potential that events, expected or unanticipated, may adversely affect the institution’s earnings, capital, or reputation. Risk is considered in terms of categories, one of which is operational risk. Operational risk is the risk of failure or loss resulting from inadequate or failed processes, people, or systems. Internal and external events can affect operational risk. Internal events include human errors, misconduct, and insider attacks. External events affecting IT and the institution’s ability to meet its operating objectives include natural disasters, cyber attacks, changes in market conditions, new competitors, new technologies, litigation, and new laws or regulations. These events pose risks and opportunities, and the institution should factor them into the risk identification process. 

To be effective, an information security program should have documented processes to identify threats and vulnerabilities continuously. Risk identification should produce groupings of threats, including significant cybersecurity threats. A taxonomy11 for categorizing threats, sources, and vulnerabilities can help support the risk identification process. Management should perform these risk identification activities to determine the institution’s information security risk profile, including cybersecurity risk. 

10 See also Information Security Standards, section III.D, requiring each financial institution to oversee service provider arrangements by (1) exercising appropriate due diligence in selecting its service providers; (2) requiring its service providers by contract to implement appropriate measures designed to ensure the security and confidentiality of the institution’s “customer information”; and (3) where indicated by the institution’s risk assessment, monitoring its service providers to confirm that the service providers have satisfied their contractual obligations, including by reviewing audits, summaries of test results, or other equivalent evaluations of its service providers. 

11 A taxonomy is a method for classifying items into ordered categories. Institutions use taxonomies to find relevant information from a large collection of data and to better detect or understand the patterns and trends. 

#### II.A.1 Threats 

According to the National Institute of Standards and Technology (NIST), a threat is any circumstance or event with the potential to create loss.12 A threat can be a natural occurrence, technology or physical failure, a person with intent to harm, or a person who unintentionally causes harm. Information about threats is available from public and private sources. Public sources include the news media, blogs, government publications and announcements, and various websites. Private sources include information security vendors and information-sharing organizations. 

The threat identification process is a means to collect data on potential threats that can assist management in its identification of information security risks. Threat modeling is a structured approach that enables an institution to aggregate and quantify potential threats. Institutions should consider using threat modeling to better understand the nature, frequency, and sophistication of threats; evaluate the information security risks to the institution; and apply this knowledge to the institution’s information security program. As threats evolve rapidly, however, it is understood that modeling may not account for attacks that have not previously been seen, such as zero-day attacks, but could have significant impacts. 

#### II.A.2 Vulnerabilities 

A vulnerability is a weakness in an information system, system security procedure, internal control, or implementation that could be exploited by a threat source.13 A technical vulnerability can be a flaw in hardware, firmware, or software that leaves an information system open to potential exploitation. These flaws provide opportunities for hackers to gain access to a computer system, execute commands as another user, or access data contrary to specified access restrictions. Institutions can use automated vulnerability scanners to scan their computer systems for known security exposures, as well as services available from third parties, such as the Mitre Corporation’s Common Vulnerability and Exposures (CVE),14 to track vulnerabilities. 

In addition to technology-based vulnerabilities, weaknesses in business operational processes can create security vulnerabilities, exposing financial institutions to unwarranted risk. These vulnerabilities can include weaknesses in security procedures, administrative controls, physical layout, or internal controls that could be exploited to gain unauthorized access to information or to disrupt critical services. For example, an institution’s systems architecture may be designed based on management’s assumption that manual validation of wire transfers takes place before execution, when in practice the business process does not perform that validation until after transfers have taken place. 

12 NIST SP (Special Publication) 800-30, revision 1, “Information Security: Guide for Conducting Risk Assessments,” September 2012. 

13 Ibid. 

14 CVE is a dictionary of publicly known information security vulnerabilities and exposures. The Mitre Corporation maintains the system. CVE is sponsored by the U.S. Computer Emergency Readiness Team in the Office of Cybersecurity and Communications at the U.S. Department of Homeland Security. 

In addition to the vulnerabilities within a financial institution’s system, vulnerabilities may also arise from interdependent and interconnected systems. Financial institutions connect their systems through mergers and acquisitions and through relationships with third parties. Over time, as these systems become increasingly interdependent and complex, new vulnerabilities may be introduced. Moreover, financial institutions are dependent on a vast array of hardware and services that may result in vulnerabilities from their supply chains, including those found in hardware and software products. 

Management should assess whether the institution has processes and procedures in place to identify and maintain a catalogue of relevant vulnerabilities, determine which pose a significant risk to the institution, and effectively mitigate and monitor the risks posed by those vulnerabilities. When management cannot or chooses not to mitigate a vulnerability, management should document the decision to accept the risk, the level of risk associated with the vulnerability, and the person accountable for accepting the risk. Refer to the “Security Operations” section of this booklet for more information. 

#### II.A.3 Supervision of Cybersecurity Risk and Resources for Cybersecurity Preparedness 

#### II.A.3(a) Supervision of Cybersecurity Risk 

Cybersecurity is the process of protecting consumer and bank information by preventing, detecting, and responding to attacks. As part of cybersecurity, institutions should consider management of internal and external threats and vulnerabilities to protect information assets and the supporting infrastructure from technology-based attacks. In light of the increasing volume and sophistication of cybersecurity threats, examiners should focus on cybersecurity preparedness in assessing the effectiveness of an institution’s overall information security program. 

#### II.A.3(b) Resources for Cybersecurity Preparedness 

The FFIEC members issued a voluntary Cybersecurity Assessment Tool15 to help institution boards and management identify risks to their institutions and evaluate their institution’s cybersecurity preparedness. In addition, there are other resources available to help management develop and evaluate information security and cyber resilience, such as the NIST Cybersecurity Framework, common approaches developed by the Mitre Corporation, and the U.S. Computer Emergency Readiness Team’s (US-CERT)16 National Cyber Awareness System. Institution management can select a single framework or use a combination of resources to help identify its risks and determine its cybersecurity preparedness. Regardless of the source, frameworks can help management identify a cybersecurity and resilience posture that is commensurate with the institution’s risk and complexity. 

15 Refer to the Cybersecurity Assessment Tool on the FFIEC website. 

16 US-CERT, of the Department of Homeland Security, responds to major incidents, analyzes threats, and exchanges critical cybersecurity information with trusted partners around the world. 

### II.B Risk Measurement 

#### Action Summary 

Management should develop risk measurement processes that evaluate the inherent risk to the institution. 

The risk measurement process should be used to understand the institution’s inherent risk and determine the risk associated with different threats. Management should use its measurement of the risks to guide its recommendations for and use of mitigating controls. 

Threat analysis tools assist in understanding and supporting the measurement of information security-related risks. Such tools can include event trees,17 attack trees,18 kill chains,19 and other security-related schemata.20 These tools help management deconstruct an event into stages, better understand the event, identify the most effective and efficient means of mitigating risk, and improve the information security program. Additionally, management could use a taxonomy for security-related events to help accomplish the following: 

* • Map threats and vulnerabilities.
* • Incorporate legal and regulatory requirements.
* • Improve consistency in risk measurement.
* • Highlight potential areas for mitigation.
* • Select proper controls to cover various attack stages, channels, and assets.
* • Allow comparisons among different threats, events, and potential mitigating controls.

Refer to the IT Handbook’s “Management” booklet for more information. 

17 An event tree is a diagram of a chronological series of events in a system or activity that displays sequence progression, end states, and dependencies across time. 

18 An attack tree is a diagram showing how an asset, or target, might be attacked through various attack scenarios. Using an attack tree helps describe threats on computer systems and possible attacks to realize those threats. 

19 A kill chain originally was used as a military concept related to the structure of an attack. In information security, a kill chain is a method for modeling intrusions on a computer network. 

20 Security-related schemata are lists of software vulnerabilities and include the Mitre Corporation’s Common Attack Pattern Enumeration and Classification, CVE, Common Weakness Enumeration, “ATT&CK Matrix,” and Malware Attribute Enumeration and Characterization, and Mandiant’s Open Indicators of Compromise. 

### II.C Risk Mitigation 

#### Action Summary 

Management should develop and implement appropriate controls to mitigate identified risks. 

Once management has identified and measured the risks, it should develop and implement an appropriate plan to mitigate those risks. This plan should include an understanding of the extent and quality of the current control environment. When conducting an evaluation of the strength of controls, or the ability to mitigate risk, the institution should consider the system of controls rather than any discrete control. 

Management should also obtain, analyze, and respond to information from various sources (e.g., Financial Services Information Sharing and Analysis Center [FS-ISAC]) on cyber threats and vulnerabilities that may affect the institution. Management should incorporate available information on cyber events into the institution’s information security program. Additionally, management should develop, maintain, and update a repository of cybersecurity threat and vulnerability information that may be used in conducting risk assessments and provide updates to senior management and the board on cyber risk trends. 

##### II.C.1 Policies, Standards, and Procedures 

Information security policies, standards, and procedures should define the institution’s control environment through a governance structure and provide descriptions of required, expected, and prohibited activities. Policies, standards, and procedures guide decisions and activities of users, developers, administrators, and managers and inform those individuals of their information security responsibilities. Policies, standards, and procedures should also specify the mechanisms through which responsibilities can be met. In addition, they should provide guidance on acquiring, designing, implementing, configuring, operating, maintaining, and auditing information systems. Policies, standards, and procedures that address the information security program should describe the roles of the information security department, lines of business, and IT organization in administering the information security program. Information security policies, standards, and procedures form the means by which the objectives of the information security program are achieved. Key attributes that contribute to the success of information security policies, standards, and procedures include the following: 

* • Scope that describes the expectations for appropriate actions by affected parties.
* • Sufficient details to guide behavior.
* • Implementation through ordinary means, such as system administration procedures and acceptable use policies.
* • Enforcement through security tools and restrictions.
* • Delineation of the areas of responsibility for users, developers, administrators, and managers.
* • Clear and easily understandable communications to all affected parties.
* • Certification that employees have read and understand the policies.
* • Flexibility to address changes in the environment.
* • Annual board review and approval.
##### II.C.2 Technology Design 

While technology can introduce risk, it can also serve as a mitigation tool. Management should understand the benefits and limitations of the technology that the institution uses and whether other types of controls are necessary to compensate for those limitations. 

Information security issues arise when (a) the design of the technology and the policies governing its use do not effectively defend against identified and unidentified threats, (b) threats change in ways not envisioned by the designers, and (c) the controls are not operating as intended. Management should continually assess the capability of the institution’s processes, people, and technologies to sustain the appropriate level of information security based on the institution’s risk profile, size, complexity, and risk appetite. 

##### II.C.3 Control Types 

Management may mitigate information security risks by implementing controls. Controls may be categorized according to timing and nature. 

Table 1: Examples of Timing- and Nature-Related Controls 



| Timing | | |
| --- | --- | --- |
| Control type | Description | Example |
| Preventive | Controls designed to prevent incidents from occurring | Access controls to applications and systems that prevent unauthorized individuals from performing transactions |
| Detective | Controls designed to alert management when incidents occur | Reports that show suspicious activity |
| Corrective | Controls that lessen impact to the institution when adverse incidents occur | Business continuity plans |
| Nature | | |
| Control type | Description | Example |
| Administrative | Controls that align with the board- approved risk appetite and inform employees of management’s expectations | Policies or procedures that guide implementation of the information security program |
| Technical | Software or hardware (or both) that prevents unauthorized activity | A firewall that prevents unauthorized logical access to or from a network |
| Physical | Devices to prevent unauthorized physical access to a facility or computer system | A deadbolt lock on a door |

It is important to have a layered control system, which deploys different controls at different points of a business process and throughout an IT system so that the strength of one control can compensate for weaknesses in or possible failure of another control. Therefore, layered controls function in an integrated fashion to more effectively mitigate risk. 

Economic and technical considerations generally affect prevention and detection or response choices in system design. Compensating controls are controls that adjust for weaknesses within the system or process. An example of compensating controls would be a review of activity logs for applications that do not allow proper segregation of duties. 

##### II.C.4 Control Implementation 

Management should implement controls that align security with the nature of the institution’s operations and strategic direction. Based on the institution’s risk assessment, the controls should include, but may not be limited to, patch management, asset and configuration management, vulnerability scanning and penetration testing, end-point security, resilience controls, logging and monitoring, and secure software development (including third-party software development). In implementing controls, management should ensure it has the necessary resources, personnel training, and testing to maximize the effectiveness of the controls. 

The level at which controls are implemented should depend on the institution’s size, complexity, and risk profile, but all institutions should implement appropriate controls. In light of increasing cybersecurity risks, management should implement risk-based controls for managing cybersecurity threats and vulnerabilities, such as interconnectivity risk. Management should review and update the security controls as necessary depending on changes to the internal and external operating environment, technologies, business processes, and other factors. 

The institution can reference one or more recognized technology frameworks and industry standards. Several organizations have published control listings in addition to implementation guidance, including the following: 

* • NIST 800 series of publications. These publications provide descriptions of some management processes and technical guidance on many individual controls.
* • Control Objectives for Information and Related Technology (COBIT). COBIT provides a broad and deep framework for governance and management of enterprise IT.
* • IT Infrastructure Library (ITIL). ITIL provides a list of recognized practices for IT service management.
* • International Organization for Standardization (ISO)21 27000 series. The ISO 27000 series provides control standards specific to information security.
* • Industry publications and sources.22 Management and staff may find these useful for discrete controls and processes. 21 ISO is an independent, non-governmental, international organization that brings together experts to share knowledge and develop voluntary, consensus-based, market-relevant international standards. 

22 Some industry publications or organizations that provide security-related information include the ISACA Journal, SANS Institute, the Financial Services Roundtable, the Council on Cybersecurity, and the Open Web Application Security Project.
* • Vendor-provided publications, bulletin boards, and user groups. Vendors often publish recommendations for securing their products. Additionally, some offer bulletin boards and user groups for clients to interact among themselves.
##### II.C.5 Inventory and Classification of Assets 

#### Action Summary 

Management should inventory and classify assets, including hardware, software, information, and connections. 

Management should maintain and keep updated an inventory of technology assets that classifies the sensitivity and criticality of those assets, including hardware, software, information, and connections. Management should have policies to govern the inventory and classification of assets both at inception and throughout their life cycle, and wherever the assets are stored, transmitted, or processed. Inventories enable management and staff to identify assets and their functions. Classification enables the institution to determine the sensitivity and criticality of assets. Management should use this classification to implement controls required to safeguard the institution’s physical and information assets. Additionally, management can use the inventory to discover specific vulnerabilities, such as unauthorized software. 

Inventories are important for management to identify assets that require additional protection, such as those that store, transmit, or process sensitive customer information, trade secrets, or other information or assets that could be a target of cyber criminals. Knowing what information assets the institution has and where they are stored, transmitted, or processed helps management comply with federal and state laws and regulations regarding privacy and security of sensitive customer information. 

After inventorying the assets, management should classify the information according to the appropriate level of protection needed. For example, systems containing sensitive customer information may require access controls based on job responsibilities. These systems should have stronger controls than systems containing information meant for the general public. Some institutions classify information as public, non-public, or institution-confidential, while others use the classifications high, moderate, and low. Additional classifications, such as critical and noncritical, may be helpful to certain types of institutions. 

##### II.C.6 Mitigating Interconnectivity Risk 

Business processes often require institutions to share information with other institutions and third-party service providers that require connectivity. The extent of interconnectivity is a function of network architecture, network complexity, traffic volume, and number of connections. Interconnectivity risk arises from misuse, mismanagement, or compromise of these connections. 

To mitigate interconnectivity risk, management should do the following: 

* • Identify connections with third parties, including other financial institutions, financial institution intermediaries, and third-party service providers.
* • Identify all access points and connection types that pose risk, such as local area network (LAN) connections to other networks or Internet service providers (ISP), Wi-Fi, and cellular connections.
* • Identify connections between and access across low-risk and high-risk systems.
* • Assess all connections with third parties that provide remote access capability or control over internal systems.
* • Implement and assess the adequacy of controls to ensure the security of connections regardless of criticality or sensitivity.

Management should maintain network and connectivity diagrams and data flow charts to ensure adequacy of layered controls and to facilitate more timely recovery and restoration of systems when incidents occur. 

##### II.C.7 User Security Controls 

#### Action Summary 

Management should mitigate the risks posed by users by doing the following: 

* • Establishing and administering security screening in IT hiring practices.
* • Establishing and administering a user access program for physical and logical access.
* • Employing segregation of duties.
* • Obtaining agreements covering confidentiality, nondisclosure, and authorized use.
* • Providing training to support awareness and policy compliance.

Users should be granted access to systems, applications, and databases based on their job responsibilities. Access rights should be granted in accordance with the institution’s physical and logical access control policies. Authorized users with elevated or administrator privileges can pose a potential threat to systems and data. Employees, contractors, or third-party service providers can exploit their legitimate computer access for unauthorized purposes. Additionally, the degree of internal access granted to some users increases the risk of damage or loss of information and systems. Risk exposures from internal users include the following: 

* • Alteration of data.
* • Deletion of production and backup data.
* • Misdirected data.
* • Disruption of systems.
* • Destruction of systems.
* • Misuse of systems for personal gain or to damage the institution.
* • Appropriation of strategic or customer data for espionage or fraud schemes.
* • Extortion for stolen data.
* • Misuse of data following the termination or change in job responsibility of an employee.

Management should understand the risks to the institution’s information-processing environment and establish appropriate user access controls to mitigate these and other potential risks to the institution’s assets. Users should understand and confirm their understanding of their roles and responsibilities in maintaining a sound security environment, which includes both physical and logical areas. 

##### II.C.7(a) Security Screening in Hiring Practices 

Management should have a process to verify job application information for all new employees. The sensitivity of a particular job or access level may warrant additional screening and recurring background and credit checks. Management should verify that contractors are subject to similar screening procedures. In addition to initial screening, management should remain alert to changes in personal circumstances of employees and contractors that could increase incentives for system misuse or fraud. 

##### II.C.7(b) User Access Program 

Management should develop a user access program to implement and administer physical and logical access controls to safeguard the institution’s information assets and technology. This program should include the following elements: 

* • Principle of least privilege, which recommends minimum user profile privileges for both physical and logical access based on job necessity.
* • Alignment of employee job descriptions to the user access program.
* • Requirements for business and application owners to define user profiles.
* • Ongoing reviews by business line and application owners to verify appropriate access based on job roles with changes reported on a timely basis to security administration personnel.
* • Timely notification from human resources to security administrators to adjust user access based on job changes, including terminations.
* • Periodic independent reviews that ensure effective administration of user access, both physical and logical.

For more information, refer to the “Physical Security” and “Logical Security” sections of this booklet. 

##### II.C.7(c) Segregation of Duties 

Segregation of duties, or job designs that require more than one person to complete critical or sensitive tasks, can help mitigate risk. Employees and third parties with access to sensitive resources could cause substantial damage and potential loss. System administrators, for instance, have the most powerful role in the user access process and have unlimited access to an institution’s information assets and technology. Given this extensive access, management should evaluate the process for determining which individuals should be granted system administrator privileges. Such access should be appropriately monitored for unauthorized or inappropriate activity. Management should incorporate independent reviews or approvals for individuals who perform multiple functions to minimize the potential for fraud, irregularities, and errors. Examples of segregation of duties include the following: 

* • Independent monitoring of the activities performed by the users with increased privileges (e.g., system administrators and super users23).
* • Distribution of system administration activities so no administrator can hide his or her activities or control an entire system.
* • Additional levels of approval as the criticality and sensitivity of decisions increase.

If an activity is conducted without appropriate segregation of duties, management should require an independent review (e.g., audit) of that activity. 

##### II.C.7(d) Confidentiality Agreements 

The institution should protect the confidentiality of customer and institution information. A breach in confidentiality could disclose proprietary information, increase fraud risk, damage the institution’s reputation, violate customer privacy and associated rights, and violate laws or regulations. Confidentiality agreements can be used to put all parties on notice that the financial institution owns its information, expects strict confidentiality, and prohibits information sharing outside of that required for legitimate business needs. Management should obtain signed confidentiality agreements before granting employees and contractors access to IT systems. 

##### II.C.7(e) Training 

Training ensures personnel have the necessary knowledge and skills to perform their job functions.24 Training should support security awareness and strengthen compliance with security and acceptable use policies. Ultimately, management’s behavior and priorities heavily influence employee awareness and policy compliance, so training and the commitment to security should start with management. Management should educate users about their security roles and responsibilities and communicate them through acceptable use policies. Management should hold all employees, officers, and contractors accountable for complying with security and acceptable use policies and should ensure that the institution’s information and other assets are protected. Management should have the ability to impose sanctions for noncompliance. 

Training materials for most users focus on issues such as end-point security, log-in requirements, and password administration guidelines. Training programs should include scenarios capturing areas of significant and growing concern, such as phishing and social engineering attempts, loss of data through e-mail or removable media, or unintentional posting of confidential or proprietary information on social media. As the risk environment changes, so should the training. The institution should collect signed acknowledgments of the employee acceptable use policy as part of the annual training program. 

23 In computing, the super user is a special user account used for system administration. Depending on the operating system, the name of this account might be root, administrator, admin, or supervisor. 

24 See also Information Security Standards, section III.C.2, requiring each financial institution to train staff to implement its information security program. 

##### II.C.8 Physical Security 

#### Action Summary 

Management should implement appropriate preventive, detective, and corrective controls for physical security. 

Physical access and damage or destruction to physical components can impair the confidentiality, integrity, and availability of information. Management should implement appropriate preventive, detective, and corrective controls for mitigating the risks inherent to those physical security zones. 

A data center houses an institution’s most important information system components. When selecting a site for a data center, one major objective should be to limit the risk of exposure from internal and external threats, including, where possible, environmental threats inherent to physical locations (e.g., hurricanes, earthquakes, and blizzards). The selection process should include reviewing the surrounding area to determine whether it is relatively safe from exposure to fire, flood, explosion, or similar environmental hazards. Guards, fences, barriers, surveillance equipment, or other devices can deter intruders. Because access to key information systems’ hardware and software should be limited, appropriate physical controls should be in place. Additionally, the location should not be identified or advertised by signage or other indicators. 

Detection devices, when applicable, should be used to prevent theft and safeguard the equipment. The devices should provide continuous coverage. Detection devices have two purposes—to send alarms when responses are necessary and to support subsequent forensics. Alarms are useful only when response will occur. Some detection devices include the following: 

* • Switches that activate alarms when electrical circuits are broken.
* • Light and laser beams, ultraviolet beams, sound, or vibration detectors that are invisible to intruders, and ultrasonic or radar devices that detect movement.
* • Closed-circuit television (CCTV) that provides visual observation and records intrusions.

A combination of fire suppression, smoke alarms, raised flooring, and heat and moisture sensors should address risks from environmental threats (e.g., fire, flood, and excessive heat). Environmental threat monitoring should be continuous, and responses should occur when alarms activate. 

Physical security devices frequently need preventive maintenance to function properly. The institution should be able to provide maintenance logs to demonstrate that physical security devices are regularly maintained. Periodic testing provides assurance that the devices are operating correctly. 

The institution should have policies governing the duties and responsibilities of security guards. Employees who access secured areas should have proper identification and authorization to enter the areas. All non-employees should provide identification to a security guard before obtaining access. Security guards should be trained to restrict the removal of technology assets from the premises and to record the identity of anyone attempting to remove those assets. Management should implement a specific and formal authorization process for the removal of hardware and software from the premises. 

Access should be restricted to the following equipment or areas: 

* • Operations centers (e.g., data center operations, security operations center, and network operations center) or server rooms; uninterruptible power supplies and backup generators.
* • Funds transfer and automated clearinghouse routers.
* • Telecommunications equipment.
* • Media libraries.
* • Equipment removed from the network and awaiting disposal.
* • Spare or backup devices.

##### II.C.9 Network Controls 

#### Action Summary 

Management should secure access to computer networks through multiple layers of access controls by doing the following: 

* • Establishing zones (e.g., trusted and untrusted) according to the risk profile and criticality of assets contained within the zones and appropriate access requirements within and between each security zone.
* • Maintaining accurate network diagrams and data flow charts.
* • Implementing appropriate controls over wired and wireless networks.

Networks should be protected by a secure boundary, identifying “trusted” and “untrusted” zones. Internal zones, typically trusted, should segregate various components into distinct areas, each with the level of controls appropriate to the content and function of the assets within the zone. The institution’s trusted network should be protected through appropriate configuration and patch management, privileged access controls, segregation of duties, implementation of effective security policies, and use of perimeter devices and systems to prevent and detect unauthorized access. Tools used to enforce and detect perimeter protection include routers, firewalls, intrusion detection systems (IDS) and intrusion prevention systems, proxies, gateways, jump boxes,25 demilitarized zones, virtual private networks (VPN), virtual LANs (VLAN), log monitoring and network traffic inspecting systems, data loss prevention (DLP) systems, and access control lists. 

The trusted network should be further segregated into internal layers, including production, staging, and development environments. Within those environments, management should consider segregating sensitive traffic, by using Voice Over Internet Protocol26 (VOIP) and network management (such as virtualization infrastructure that carries server boot images between storage devices and hosts). Each zone should have a security policy appropriate to its use, ensuring that zone restrictions are defined by risk, sensitivity of data, user roles, and appropriate access to application systems. Access to zones should be controlled according to the principle of least privilege and segregation of duties. To ensure appropriate network security, management should maintain accurate network and data flow diagrams, and store them securely, providing access only to essential personnel. These diagrams should identify hardware, software, and network components, internal and external connections, and types of information passed between systems to facilitate the development of a defense-in-depth security architecture. 

25 A jump box, or jump server, provides administrators with access to or control of other servers or devices in the network. Because of this capability, additional security measures should be implemented. 

##### II.C.9(a) Wireless Network Considerations 

A wireless LAN (WLAN) is a medium of network connectivity, supported by radio wave transmissions that provides more convenient network access to employees or devices that need flexibility to connect to multiple locations within the institution’s facilities. Because the user is not physically connected to the network and the wireless signal is broadcast and available to others, wireless networks are inherently less secure than wired networks and require additional scrutiny, controls, and oversight. Wireless access points are the devices that broadcast the radio wave signals and should be physically secure to prevent compromise and securely configured to provide the same level of control as a wired connection. Wireless gateways can allow management to implement more complex access controls, including advanced identity management capabilities and services to detect and remediate malicious software. 

Policies should prohibit installation of wireless access points and gateways without approval and formal inclusion in the hardware inventory. Network monitoring systems should be configured to detect the addition of new devices. Alternatively, network access control (NAC) systems could prevent the recognition of any unauthorized device.27 Management should consider limiting the WLAN signal to authorized areas, within the boundaries of the institution, if feasible. Management should use an industry-accepted level of encryption with strength commensurate with the institution’s risk profile on the institution’s wireless networks. 

Malicious insiders and attackers may also set up rogue or unauthorized wireless access points and trick employees into connecting. Such access points allow attackers to monitor employee activities. The institution should scan the network regularly to detect rogue access points and consider implementing NAC systems to prevent the successful connection of unauthorized devices. 

26 VOIP is the transmission of voice telephone conversations using the Internet or IP networks. 

27 A NAC system typically provides an IP address only after validating that the newly connected device is authorized, by means of some identification (such as a computer’s physical address—MAC address—or certificate) or pre-installed client software. 

The institution may provide guests with access to a wired or wireless network. The guest network generally is used to provide access to the Internet and should be configured to prevent access to any portion of the production network. 

Institutions often provide remote network connectivity for employees or third-party service providers28 who are not located within or around the institution’s facilities. This connectivity presents operational advantages, but steps should be taken to ensure that the connection is encrypted and secured. VPN connections should be used for both broadband networks and wireless air card connections to isolate and encrypt remote traffic to institution networks. IP geolocation information may not always be available when using broadband networks, which can limit the effectiveness of monitoring. Therefore, management should consider implementing compensating controls, such as restricting access to network resources. 

##### II.C.10 Change Management Within the IT Environment 

#### Action Summary 

Management should have a process to introduce changes to the environment in a controlled manner. Changes to the IT environment include the following: 

* • Configuration management of IT systems and applications.
* • Hardening of systems and applications.
* • Use of standard builds.
* • Patch management.

The IT environment consists of operating systems,29 middleware,30 applications, file systems, and communications protocols. The institution should have an effective process to introduce application and system changes, including hardware, software, and network devices, into the IT environment. The process for introducing software should encompass securely developing, implementing, and testing changes to both internally developed and acquired software. 

Application and system control considerations for introducing changes to the IT environment before implementation should include the following: 

* • Developing procedures to guide the process of introducing changes to the environment.
* • Clearly defining requirements for changes.
* • Restricting changes to authorized users. 28 In some cases, the institution provides remote access via VPN to a third-party service provider. Controls over third-party access should be commensurate with the sensitivity and criticality of the system and information accessed. 

29 An operating system is fundamental software that supports and manages software applications, allocates system resources, provides access and security controls, maintains file systems, and manages communications between end users and hardware devices. 

30 Middleware is software that connects two or more software components or applications.
* • Reviewing the impact that changes have on security controls.
* • Identifying all system components affected by the changes.
* • Developing test scripts and implementation plans.
* • Performing necessary tests of all changes to the environment (e.g., systems testing, integration testing, functional testing, user acceptance testing, and security testing).
* • Defining rollback procedures in the event of unintended or negative consequences with the introduced changes.
* • Ensuring the application or system owner has authorized changes in advance.
* • Maintaining strict version control of all software updates.
* • Validating that new hardware complies with institution policies.
* • Ensuring network devices are properly configured and function appropriately within the environment.
* • Maintaining an audit trail of all changes.

Refer to the IT Handbook’s “Development and Acquisition” booklet for more information. 

##### II.C.10(a) Configuration Management 

Configuration management is a process to securely maintain the institution’s technology by developing expected baselines for tracking, controlling, and managing systems settings. To mitigate information security risk, management should control configurations of systems, applications, and other technology. Effective configuration management relies on policies and procedures to ensure compliance with minimally acceptable system configuration requirements. When information systems change, management should update baselines; confirm security settings; and track, verify, and report configuration items. Configurations should be monitored for unauthorized changes, and misconfigurations should be identified. Management can use automated solutions to help track, manage, and identify necessary corrections. 

##### II.C.10(b) Hardening 

Institutions typically use commercial off-the-shelf (COTS) software for operating systems and applications, on such diverse platforms as network infrastructure, servers, desktops, laptops, and mobile devices. COTS systems generally provide more functions than are required for the specific purposes for which they are employed. A default installation of a server operating system may include mail, web, and file-sharing services on a system that does not require those functions. Unnecessary software and services represent a potential security weakness. Their presence increases the potential number of discovered and undiscovered vulnerabilities in the system. Additionally, system administrators may not install patches or monitor the unused software and services to the same degree as they would operational software and services. Protection against those risks begins when the systems are constructed and software installed through a process that is referred to as hardening a system. 

Management should consult operating system and software vendor-recommended security controls. When deploying COTS applications and systems, management should harden the resulting applications and systems. Hardening can include the following actions: 

* • Determining the purpose of the applications and systems and documenting minimum software and hardware requirements and services to be included.
* • Installing the minimum hardware, software, and services necessary to meet the requirements using a documented installation procedure.
* • Installing necessary patches.
* • Installing the most secure and up-to-date versions of applications.
* • Configuring privilege and access controls by first denying all, then granting back the minimum necessary to each user (i.e., enforcing the principle of least privilege).
* • Configuring security settings as appropriate, enabling allowed activity, and prohibiting non- approved activities.
* • Enabling logging.
* • Creating cryptographic hashes31 of key files.
* • Archiving the configuration and checksums32 in secure storage before system deployment.
* • Using secure replication procedures for additional, identically configured systems and making configuration changes on a case-by-case basis.
* • Changing all default passwords.
* • Testing the system to ensure a secure configuration.

Additionally, the systems should be audited periodically to ensure that the hardware, software, and services are authorized and properly configured. 

##### II.C.10(c) Standard Builds 

Consistency in system configuration makes security easier to implement and maintain. The institution should use standard builds, which allow one documented configuration to be applied to multiple computers in a controlled manner. Some institutions, depending on their size and complexity, may have many standard builds for the different system configurations needed to address various business functions. Through standard builds, an institution simplifies the following activities: 

* • Creating hardware and software inventories.
* • Updating and patching systems.
* • Restoring systems in the event of a disaster or outage.
* • Investigating anomalous activity.
* • Auditing configurations for conformance with the approved configuration.

The institution may not be able to meet all of its requirements from its standard builds. The use of nonstandard builds should be documented and approved by management, with appropriate changes made to patch management and disaster recovery plans. 

31 A hash is a fixed-length cryptographic output of variables, such as a message, being operated on by a formula or cryptographic algorithm. 

32 A checksum is a simple error-detection scheme in which each transmitted message is accompanied by a numerical value based on the number of set bits in the message, which allows the receiver to verify the accuracy of the message. 

##### II.C.10(d) Patch Management 

Frequently, security vulnerabilities are discovered in operating systems and other software after deployment. Hackers often will attempt to exploit these known vulnerabilities to try to gain access to the institution’s systems. Third parties issue patches to address vulnerabilities found on institution systems and applications.33 Management should implement automated patch management systems and software to ensure all network components (virtual machines, routers, switches, mobile devices, firewalls, etc.) are appropriately updated. In addition, management should use vulnerability scanners periodically to identify vulnerabilities in a timely manner. 

As part of the institution’s patch management process, management should establish and implement the following: 

* • A monitoring process that identifies the availability of software patches.
* • A process to evaluate the patches against the threat and network environment.
* • A prioritization process to determine which patches to apply across classes of computers and applications.
* • A process for obtaining, testing, and securely installing patches, including in the institution’s virtual environments.
* • An exception process, with appropriate documentation, for patches that management decides to delay or not apply.
* • A process to ensure that all patches installed in the production environment are also installed in the disaster recovery environment in a timely manner.
* • A documentation process to ensure the institution’s information assets and technology inventory and disaster recovery plans are updated as appropriate when patches are applied.

The institution should have procedures that include how to implement patches to mitigate risks of changing systems and address systems with unique configurations. Before applying a patch, management should back up the production system. Additionally, management should define appropriate patch windows and, whenever possible, restrict the implementation of patches to defined time frames to minimize business impact or potential down time. 

Patches make direct changes to the software and configuration of each system to which they are applied. While patches are necessary and useful, they may have unintended negative consequences, such as introducing new vulnerabilities, reintroducing old vulnerabilities, or degrading system performance. The following actions can help ensure patches do not compromise the security of the institution’s systems: 

* • Obtain the patch from a known, trusted source.
* • Verify the integrity of the patch through comparisons of cryptographic hashes to ensure the patch obtained is correct and unaltered.
* • Protect and monitor the systems used to distribute patches to ensure only authorized patches are distributed. 33 If an institution develops or maintains software in-house, management should have a process to update the software with appropriate patches.
* • Apply the patch to an isolated test system before installing on the production system to ensure the patch is compatible with other software used on systems, does not alter the system’s security posture in unexpected ways (such as altering log settings), and corrects the pertinent vulnerability.
* • Test the resulting system to validate the effectiveness of the applied patch.
##### II.C.11 End-of-Life Management 

Management should plan for a system’s life cycle, eventual end of life, and any corresponding security and business impacts. The institution’s strategy should incorporate planned changes to systems, including an evaluation of the current environment to identify potential vulnerabilities, upgrade opportunities, or new defense layers. Also included in this strategy should be considerations for the support provided by third-party system vendors and the risks related to operating unsupported legacy systems. Management should have policies to manage both the hardware and software life cycles. Security risks related to reaching a system’s end of life include (a) the increased potential for vulnerabilities because the third party no longer provides patches or support, (b) incompatibility with other systems in the institution’s environment, and (c) limitations in security features in older or obsolete systems. 

Effective end-of-life management should include the following: 

* • Maintaining inventories of systems and applications.
* • Adhering to an approved end-of-life or sunset policy for older systems.
* • Tracking changes made to the systems and applications, availability of updates, and the planned end of support by the vendor.
* • Conducting risk assessments on systems and applications to help determine end-of-life.
* • Planning for the replacement of systems nearing obsolescence and complying with policy requirements for implementing new systems or applications.
* • Developing specific procedures for the secure destruction or data wiping of hard drives returned to vendors or donated, to prevent the inadvertent disclosure of sensitive information.

If an end-of-life system or application must remain in use, management should ensure appropriate mitigating controls are in place, which may include segregating the system or application from the network. Management should also have a plan to replace the system or application and implement compensating controls until replacement. Strategies for replacing and updating hardware and software should incorporate and align with overall information security and business strategies as appropriate. 

##### II.C.12 Malware Mitigation 

Attackers use malware to obtain access to an institution’s environment and to execute an attack within the environment. Malware may enter through public or private networks and from devices attached to the network. Although protective mechanisms may block most malware before it does damage, even a single malicious executable34 may create a significant potential for loss. 

Management should implement defense-in-depth to protect, detect, and respond to malware. The institution can use many tools to block malware before it enters the environment and to detect it and respond if it is not blocked. Methods or systems that management should consider include the following: 

* • Hardware-based roots of trust, which use cryptographic means to verify the integrity of
* • Servers that run active content at the gateway and disallow content based on policy.
* • Blacklists that disallow code execution based on code fragments, Internet locations, and other
* • White lists of allowed programs.
* • Port monitoring to identify unauthorized network connections.
* • Network segregation.
* • Computer configuration to permit the least amount of privileges necessary to perform the
* • Application sandboxing35 to limit the access and functionality of executed code.
* • Monitoring for unauthorized software and disallowing the ability to install unauthorized
* • Monitoring for anomalous activity for malware and polymorphic code.
* • Monitoring of network traffic.
* • User education in awareness, safe computing practices, indicators of malicious code, and software. factors that correlate with malicious code. user’s job. software. response actions.
##### II.C.13 Control of Information 

#### Action Summary 

Management should control and protect access to and transmission of information to avoid loss or damage and do the following: 

* • Establish and supervise compliance with policies for storing and handling information, including storing data on mobile devices and cloud services.
* • Define and implement appropriate controls over the electronic transmission of information.
* • Facilitate safe and secure disposal of sensitive information.
* • Secure physical media in transit. 34 In computing, an executable is a file or a program that is able to be run by a computer. 

35 Sandboxing is the use of a restricted, controlled execution environment that prevents potentially malicious software, such as mobile code, from accessing any system resources except those for which the software is authorized.

##### II.C.13(a) Storage 

Management should implement policies to govern the secure storage of all types of sensitive information, whether on computer systems, on physical media, or in hard-copy documents. Management can achieve secure storage with physical controls,36 logical controls (e.g., passwords, tokens, and biometrics), and environmental controls (e.g., fire and flood protection). In addition, stored information, in any form, should be classified and inventoried so that it can be retrieved when needed. Inventories should be updated periodically to remain current. 

More sensitive information, such as system documentation, application source code, and production transaction data, should have more extensive controls to guard against alteration (e.g., integrity checkers and cryptographic hashes). Management should have appropriate logging and monitoring controls over stored information to ensure authorized access and appropriate use. Periodically, the security staff, audit staff, and data owners should review access rights to ensure the access rights remain appropriate and current. 

Data storage in portable devices, such as laptops, smart phones, and tablets, poses unique problems. These devices may be lost, stolen, or subject to unauthorized and undetected use. Risk mitigation typically involves data encryption, host-provided access controls, homing beacons,37 and remote deletion38 capabilities. Management should implement appropriate controls (such as the use of a DLP program) over portable devices and the sensitive information contained on them. 

Many institutions create or use a third-party cloud for storage. Cloud storage39 provides unique issues and challenges. Management should understand the nature of the cloud technology being used; the physical location(s) where the data are stored and related legal jurisdiction; the access controls used and protection of the institution’s data (e.g., how access is controlled and how that information is retrieved); and the frequency and method of backup used by the cloud provider. Management should verify that the cloud provider offers the capability for the institution to monitor its system activity, significant security incidents, performance and uptime, and success and failure of backups. 

##### II.C.13(b) Electronic Transmission of Information 

Electronic transmission of information can include e-mail, file transfer protocol (FTP), secure FTP (sFTP), secure shell, dedicated line, short message service/texting, and transmission via the Internet. Management should determine the type of transmission method, sensitivity of the information to be transmitted, and types of safeguards available to protect information. Management should implement appropriate controls or, if they are not available, restrict the type of information that can be transmitted. When transmitting sensitive information over a public network, information should be encrypted to protect it from interception or eavesdropping. Techniques include secure e-mail protocols, sFTP, and secure sockets layer (SSL) certificates. 

36 Refer to the “Physical Security” section of this booklet. 

37 Homing beacons send messages to the institution when they connect to a network and enable recovery of the device. 

38 Remote deletion is a technology that enables the institution to remotely delete certain data from a portable device. 

39 Cloud storage is a model of data storage in which the digital data are stored in logical pools, the physical storage spans multiple servers (and often locations), and the physical environment is typically owned and managed by a hosting company. 

##### II.C.13(c) Disposal of Information 

The institution should have appropriate disposal procedures for paper-based and electronic information.40 Designating a single individual, department, or function to be responsible for disposal facilitates accountability and promotes compliance with disposal policies. 

Policies should prohibit employees from discarding paper-based information containing sensitive information by using the same disposal system as regular garbage to avoid accidental disclosure. Many institutions shred paper-based media on-site while others use collection and disposal services to ensure the media are rendered unreadable and unlikely to be reconstructed. Institutions that contract with third-party service providers should conduct due diligence to ensure those third parties conduct adequate employee background checks and employ appropriate controls. Contracts with third-party disposal firms should address acceptable disposal procedures. 

Electronic information and computer-based media present distinct disposal challenges. In addition to disk drives and other forms of storage, information frequently is contained in or on the memory of other devices (e.g., printers, fax machines, and cellphones). Residual data frequently remain on media, even after deletion. Because the data can be recovered, additional disposal techniques should be applied to devices containing sensitive data. Overwriting destroys data by replacing it with new, random data. Overwriting may be preferable when the media will be reused. To be effective, overwriting may have to be performed many times. 

Another disposal technique is degaussing, which scrambles the data recorded on the media with powerful, varying magnetic fields. Physical destruction of the media can make the data unrecoverable. Data can sometimes be destroyed after overwriting. Management should determine the most effective method of disposal based on the type of information. Policies and procedures should address making data non-recoverable. The institution should base its disposal policies on the sensitivity of the information. Policies, procedures, and training should inform employees about what actions should be taken to securely dispose of computer-based media and protect the data from the risks of reconstruction. Management should log the disposal of sensitive media. Logs should record the party responsible for disposal, as well as the date, media type, hardware serial number, and method of disposal. In cases when such devices are rented, rather than owned, by the institution, media sanitization should be addressed contractually so that sensitive information is disposed of properly before returning equipment at the end of the rental period. 

40 See also Information Security Standards, section III.C.4., requiring each financial institution to develop, implement, and maintain, as part of its information security program, appropriate measures to properly dispose of “customer information” and “consumer information.” 

##### II.C.13(d) Transit of Physical Media 

Management should implement policies for maintaining the security of physical media (including backup tapes) containing sensitive information while in transit, including to off-site storage, or when shared with third parties. Policies should include the following: 

* • Contractual requirements that incorporate necessary risk-based controls.
* • Restrictions on the carriers used.
* • Procedures to verify the identity of couriers.
* • Requirements for appropriate packaging to protect the media from damage.
* • Use of adequate encryption of sensitive information recorded on media that is being physically transported.
* • Tracking of shipments to provide early indications of loss or damage.
* • Security reviews or independent security reports of receiving companies.
* • Use of nondisclosure agreements for couriers and third parties.
##### II.C.13(e) Rogue or Shadow IT 

Management should have policies explaining that employees should not and are not authorized to use unsanctioned or unapproved IT resources (e.g., online storage services, unapproved mobile device applications, and unapproved devices). Security awareness or information security training should include procedures for identifying and reporting shadow IT. 

##### II.C.14 Supply Chain 

The typical institution purchases a wide variety of hardware and software, which often is manufactured or developed internationally. In a supply chain attack, a threat source incorporates unidentified and harmful features into the purchased items before delivery. During the risk identification process, management should identify factors that may increase risk from supply chain attacks and respond with appropriate risk mitigations. An effective information security program seeks to limit the potential for harm through techniques tailored to specific acquisitions and services. Examples of techniques to mitigate the risk from such attacks include the following: 

* • Only making purchases through reputable sellers who demonstrate an ability to control their own supply chains.
* • Purchasing hardware and software through third parties to shield the institution’s identity.
* • Reviewing hardware for anomalies.
* • Using automated software testing and code reviews for software.
* • Regularly reviewing the reliability of software and hardware items purchased through activity monitoring and evaluations by user groups.
##### II.C.15 Logical Security 

#### Action Summary 

Management should have an effective process to administer logical security access rights for the network, operating systems, applications, databases, and network devices, which should include the following: 

* • Assigning users and devices the access required to perform required functions.
* • Updating access rights based on personnel or system changes.
* • Reviewing users’ access rights at an appropriate frequency based on the risk to the application or system.
* • Designing appropriate acceptable-use policies and requiring users to agree to them.
* • Controlling privileged access.
* • Changing or disabling default user accounts and passwords.

System devices, programs, and data are system resources. Because users may access these resources through the institution’s network, management should identify and restrict logical access to all system resources to the minimum required for legitimate and approved work activities, according to the principle of least privilege. Access beyond the minimum required for work to be performed exposes the institution’s systems and information to a potential loss of confidentiality, integrity, and availability. The institution’s logical security policy and procedures should address access rights and how those rights are to be administered. Management and system administrators should regularly evaluate information system access. 

Logical user access rights administration consists of three processes: 

* • Enrolling new users to the system.
* • Authorizing modifications to user access and deletions.
* • Monitoring access rights granted to each user, including periodic review and validation of access rights.

The enrollment process establishes the user’s identity and anticipated business needs for information and systems. Management should identify and evaluate all users, including new employees, IT outsourcing relationships, and contractors. The assignment of access rights is typically performed by the employee’s manager and the application or data owners responsible for each accessed resource, with documented approval. The assignment of rights may also be established by the employee’s role or group membership, which confers certain user access rights. 

Management should have an authorization process to enable the employee’s manager and the application or data owners to modify or delete existing user access rights to information and systems. The authorization process should include controls to verify that proper authorizations were granted or removed. Modifications to access rights should occur when an individual’s business needs change. Job changes can result in an expansion, reduction, or deletion of needed access rights. Job changes that could trigger a modification or deletion of access rights include transfers, mandatory leave, resignations, and terminations. The institution should promptly review, and modify as needed, access rights for all users who experience job changes, particularly those with privileged access, remote access privileges, and access to customer information. 

As part of the user access rights monitoring process, management should perform regular reviews to validate user access. Reviews should test whether access rights continue to be appropriate or whether they should be modified or deleted. Management should review access rights on a schedule commensurate with risk. 

Logical user access rights administration also constrains user activities through an acceptable use policy that details permitted system uses, user activities, and the consequences of noncompliance. Management should maintain an acceptable use policy, and employees should be required to acknowledge and agree in writing to the policy. When implemented correctly, an acceptable use policy is a key control for user awareness and administrative policing of system activities. Elements of an acceptable use policy can include the following: 

* • Specific access devices that can be used to access the network.
* • Hardware and software changes the user can make to his or her access device.
* • Purpose and scope of network activity.
* • Permitted network services.
* • Information that can or cannot be transmitted, and authorized transmission methods.
* • Bans on attempts to break into accounts, crack passwords, or disrupt service.
* • Responsibilities for secure operation.
* • Consequences of noncompliance.

Authorization for privileged access should be tightly controlled. Privileged access refers to the ability to override system or application controls, and may include system administrator access. All individuals who are granted privileged access should have the appropriate training commensurate with the risk and complexity of the systems and information they access. Prudent practices for controlling privileged access include the following: 

* • Identifying each privilege associated with each system resource.
* • Implementing a process to allocate privileges on a need-to-use or an event-by-event basis.
* • Documenting the granting and extent of privileged access.
* • Assigning privileges to a unique user ID apart from the one used for normal business use.
* • Prohibiting shared privileged user accounts.
* • Logging and independent monitoring of the use of privileged access.
* • Reviewing, by an independent party, privileged access rights and allocations at appropriate intervals.

Access rights to new software and hardware present a different problem. Typically, hardware and software are shipped with default users and at least one default user has privileged access. Lists of default accounts and passwords are readily available and can enable anyone with access to the system to obtain privileged access. These passwords should be changed, and the accounts should be disabled. Alternately, if these accounts are not disabled, access should be monitored closely. 

##### II.C.15(a) Operating System Access 

Access to the operating system and system utilities provide users with the authority to make fundamental changes to the system. System utilities are programs that perform repetitive functions, such as creating, deleting, changing, or copying files. System utilities also could include numerous types of system management software that can supplement operating system functionality by supporting common system tasks, such as security, system monitoring, or transaction processing. 

Unauthorized access to the operating system and system utilities could result in significant financial and operational losses. System and security administrators should restrict and monitor privileged access to operating systems and system utilities. Many operating systems have integrated or third-party access control software, which is often essential to effective access control and can be used to integrate the security management of the operating system and applications. To prevent unauthorized access to or inappropriate activity on the operating system and system utilities, management should do the following: 

* • Implement effective user access to appropriately restrict system access for both users and applications and, depending on the sensitivity, extend protection at the program, file, record, or field level.
* • Limit the number of employees with access to operating systems and grant only the minimum level of access required to perform job responsibilities.
* • Restrict and log access to and activity on operating system parameters, system utilities (especially those with data-altering capabilities), and sensitive system resources (including files, programs, and processes), and supplement with additional security software, as necessary.
* • Restrict operating system access to specific terminals in physically secure and monitored locations.
* • Secure or remove external drives and portable media from system consoles, terminals, or personal computers (PC) running terminal emulations, residing outside of physically secure locations.
* • Prohibit remote access to operating system and system utilities, where feasible, and, at a minimum, require strong authentication and encrypted sessions before allowing such remote access.
* • Filter and review logs for potential security events and provide adequate reports and alerts.
* • Independently monitor operating system access by user, terminal, date, and time of access.
##### II.C.15(b) Application Access 

Sensitive or mission-critical applications should incorporate appropriate access controls that restrict which functions are available to users and other applications. These access controls allow authorized users and other applications to interface with related databases. Some security software programs integrate access control between the operating system and some applications. 

Such software is useful when applications do not have their own access controls or when the institution uses security software instead of the application’s native access controls. Management should understand the functionality and vulnerabilities of the application access control solutions and consider those issues in the risk management process. 

Management should implement effective application access controls by doing the following: 

* • Implementing a robust authentication41 method consistent with the criticality and sensitivity of the application.
* • Easing the administrative burden of managing application access rights by using group profiles. Managing access rights individually can lead to inconsistent or inappropriate access levels.
* • Periodically reviewing and approving the application access assigned to users for appropriateness.
* • Communicating and enforcing the responsibilities of programmers, security administrators, and application owners for maintaining effective application access control.
* • Setting time-of-day or terminal limitations for some applications or for more sensitive functions within an application.
* • Logging access and events, defining alerts for significant events, and developing processes to monitor and respond to anomalies and alerts.
##### II.C.15(c) Remote Access 

Management should develop policies to ensure that remote access by employees, whether using institution or personally owned devices, is provided in a safe and sound manner. Such policies and procedures should define how the institution provides remote access and the controls necessary to offer remote access securely. Management should employ the following measures: 

* • Disable remote communications if no business need exists.
* • Tightly control remote access through management approvals and subsequent audits.
* • Implement robust controls over configurations at both ends of the remote connection to prevent potential malicious use.
* • Log and monitor all remote access communications.
* • Secure remote access devices.
* • Restrict remote access during specific times.
* • Limit the applications available for remote access.
* • Use robust authentication methods for access and encryption to secure communications.

There are several methods to provide remote access to employees. A prevalent form of remote access is through a VPN, which provides employees with a remote connection to the institution’s network through a secure channel. The VPN connection uses public telecommunication infrastructure, such as the Internet, to provide remote offices or individual users with secure access to their organization's network. VPN provides an encrypted isolated “tunnel” or connection between a remote user’s computer and the internal network. 

41 Stronger authentication and layered security methods, such as the use of tokens, public-key infrastructure-based systems, or out-of-band verification coupled with a robust identity and access management process, can reduce the potential for unauthorized access. 

Because VPN connections provide access to sensitive internal networks, the connections require additional authentication from the remote user. Use of physical token devices is a common method that can provide one-time passwords to strongly authenticate remote users. 

While VPNs effectively connect the remote computer to the internal network, other alternatives provide virtual desktop capability. In these cases, the remote computer connects to a special purpose software system (sometimes a website), authenticates the user, and establishes a secure connection to an internal network server. That server establishes a local internal network desktop session and connects it to the screen, keyboard, mouse, and speakers of the remote computer. This is an actual remote control environment, where the remote user’s actions have the same effect as if connected to an actual internal network desktop. The remote control configuration may permit file transfer between the remote and internal computers. If the remote access method allows users to store sensitive institution information, management should consider limiting this access to institution-owned devices. 

Other methods of remote access are available, including remote control software and third-party services, file transfer software (e.g., FTP), conferencing/session sharing tools, and other remote desktop software. Management should conduct a risk assessment and implement appropriate controls before adopting any remote access solution. 

If the institution allows employees to use authorized remote access methods with institution- owned devices, management should implement the following mitigating controls: 

* • Prevent users from installing software on the devices.
* • Prohibit users from having administrative privileges on the devices.
* • Use firewalls, host-based IDS, and packet content filtering to identify, monitor, and limit remote access activities.
##### II.C.15(d) Use of Remote Devices 

Management may choose to allow employees to connect remotely to the institution’s network using either an institution-owned or a personally owned device (often referred to as BYOD or “bring your own device”). Institution-owned devices are easier to secure because the institution controls the devices’ configuration and often can implement remote wiping if the devices are lost or stolen. It may be more difficult to implement remote wiping or a similar measure on an employee’s personally owned device. BYOD is becoming more popular, however, with institutions and employees because it reduces costs to the institution and enables employees to carry one device instead of two. 

For all remote devices, management should do the following to control employee remote access to the institution’s network: 

* • Disallow remote access unless a compelling business justification exists.
* • Require management approval of employee remote access.
* • Regularly review remote access approvals and rescind those that no longer have a compelling
* • Restrict remote access to authorized network areas and applications by using VLANs,
* • Log remote access communications (including date, time, user, user location, duration, and
* • Implement robust authentication methods for remote access.
* • Use encryption to protect communications between the access device and the institution.
* • Use application white-listing.42 business justification. permissions, and other techniques. activity), analyze logs in a timely manner, and follow up on anomalies.

For institution-owned devices, the institution should have the ability to manage the remote devices. The following controls should be implemented: 

* • Securely configure remote access devices.
* • Protect remote access devices against malware.
* • Patch, update, and maintain all software on remote access devices.
* • Encrypt sensitive data residing on the access device.
* • Implement secure containers with internal boundaries to store sensitive information, in a way that is not accessible to the device without permission.
* • Periodically audit the access device configurations and patch levels.
* • Remotely disable or wipe the device in the event of theft or loss.
* • Use geolocation of the device to support device recovery efforts.

For personally owned devices, the institution may not have the ability to configure the devices; therefore, management should have an effective method or solution to ensure that such devices meet defined institution security standards, such as operating system version, patch levels, and anti-malware solutions, before such devices are allowed to log on to the network. 

##### II.C.16 Customer Remote Access to Financial Services 

#### Action Summary 

Management should do the following: 

* • Develop and maintain policies and procedures to securely offer and strengthen the resilience of remote financial services, if the institution offers such services.
* • Plan for actions that adversely affect the availability of remote banking services to customers.
* • Coordinate appropriate responses with the institution’s ISPs and third-party service providers.
* • Regularly test the institution’s response plans. 42 Application white-listing is the maintenance and use of a list of applications and their components (e.g., libraries and configuration files) that are authorized to be present or active on a system according to a well-defined baseline.

Institutions increasingly offer services to customers through remotely accessible technology, such as the Internet and mobile financial services. If the institution offers such services, management should implement appropriate authentication techniques43 commensurate with the risk from remote banking activities. Beyond authentication, remote access controls should include additional layered security controls and may include some combination of the following: 

* • Application time-outs with mandatory re-authentication.
* • Fraud detection and monitoring systems that include consideration of customer history and behavior to alert management, and enable a timely and effective institution response.
* • Dual customer authorization through different access devices.
* • Out-of-band44 verification for transactions.
* • Positive pay,45 debit blocks, and other techniques to appropriately limit the transactional use of the account.
* • Supplementary controls over certain account activities, such as transaction value limits, restrictions on devices for adding payment recipients, limits on the number of transactions allowed per day, and allowable payment windows (e.g., days and times).
* • Reputation-based tools to block connections to the institution’s servers based on device or network indicators known or suspected to be associated with fraudulent activities.
* • Device authentication with appropriate enrollment and de-enrollment processes.
* • Policies for addressing customer devices identified as potentially compromised and identifying customers who may be facilitating fraud.
* • Controls over changes to account maintenance activities (e.g., address or password changes) performed by customers either online or through customer service channels.
* • Supplementary controls for system administrators who are granted privileges to set up or change system configurations of business accounts.46
* • Customer education to increase awareness of the fraud risk and effective techniques customers can use to mitigate the risk.

Institution customers may also use e-mail or other electronic means to transmit instructions. All instructions received through such channels should be authenticated and validated in accordance with institution policies. 

An area of heightened concern when financial institutions offer remote financial services is the potential for malicious activity against the institution’s mobile or online services. Malicious actors may restrict availability to those services through denial of service (DOS) attacks that target the institution’s ISPs, third-party service providers, infrastructure, or applications. 

43 Techniques include multiple factor authentication, device authentication, location consistency, and additional authentication for sensitive functions. 

44 Out-of-band refers to activity outside of the primary means of interfacing with the customer. For example, if a user is performing activity online, he or she may be authenticated through a one-time password sent via text message. 

45 Positive pay is a technique that can reduce check fraud by requesting businesses to send electronic files of information to the financial institution on all checks the business has issued. 

46 Refer to the FFIEC’s “Supplement to Authentication in an Internet Banking Environment.” 

Additionally, attacks on organizations that share infrastructure with the institution, including domain name services, may adversely affect the availability of remote services. Management should develop and maintain policies and procedures to identify, measure, mitigate, monitor, and report on significant security incidents to ensure the resilience of remote financial services. Planning and coordination by the institution and its third-party service providers may improve the resilience of services in the face of those attacks. To prevent or minimize exposure to these incidents, management should do the following: 

* • Monitor threat alerts.
* • Monitor service availability and diagnose causes of reduced availability.
* • Monitor applications and network traffic for indicators of nefarious activity.
* • Ensure traffic filtering by the institution’s ISP or upstream ISP,47 third-party service providers, and internal resources.
* • Design and implement applications to withstand application-level DOS.
* • Utilize distributed architecture.
* • Limit traffic (e.g., allow valid traffic and block known bad traffic by port or IP address).
* • Add bandwidth.
* • Enable access to services through alternative channels.

The institution should develop and test an incident response plan in conjunction with the institution’s ISPs and third-party service providers to mitigate the interruption of mobile or remote financial services. Refer to the “Incident Response” section of this booklet for more information. 

Customers may be provided with a website disclosure with the institution’s customer acceptable- use policy. Depending on the nature of the website, the institution may require customers to demonstrate knowledge of and agreement to abide by the terms of the acceptable use policy. That evidence can be paper-based or electronic. 

Refer to appendix E48 of the IT Handbook’s “Retail Payment Systems” booklet for more information about mobile financial services. 

##### II.C.16(a) Customer Awareness 

The institution’s customer awareness and education efforts should consider both retail and commercial account holders and include the following elements: 

* • An explanation of protections provided, and not provided, to account holders relative to electronic funds transfers under Regulation E, and a related explanation of the applicability of Regulation E to the types of accounts accessible online. 47 An upstream ISP is usually a large ISP that provides Internet access to a local ISP. 

48 See the IT Handbook’s “Retail Payment Systems” booklet, appendix E, “Mobile Financial Services.”
* • An explanation that while the institution may contact a customer regarding his or her account or suspicious activities related to his or her account, the institution should never ask the customer to provide his or her log-in credentials over the phone or via e-mail.
* • A list of recommended controls and prudent practices that the customer should implement when using the institution’s remote financial services.
* • A suggestion that commercial online customers perform a related risk assessment and controls evaluation periodically.
* • Recommendations of technical and business controls to commercial customers that can be implemented to mitigate the risks from fraud schemes such as Business Email Compromise.49
* • A method to contact the institution if customers notice suspicious account activity.
##### II.C.17 Application Security 

#### Action Summary 

Management should use applications that have been developed following secure development practices and that meet a prudent level of security. Management should develop security control requirements for all applications, whether the institution acquires or develops them. Information security personnel should be involved in monitoring the application development process to verify that secure development practices are followed, security controls are implemented, and information security needs are met. 

Institutions and their customers use a wide variety of applications. Such applications include core banking applications, web applications, and installable applications (e.g., downloadable mobile applications). 

A secure software development life cycle ensures that Internet- and client-facing applications have the necessary security controls. The institution should ensure that all applications are securely developed. To verify the controls have been developed and implemented appropriately, management should perform appropriate tests (e.g., penetration tests, vulnerability assessments, and application security tests) before launching or making significant changes to external-facing applications. Issues noted from tests should be remediated before launching applications or moving changes into production. At institutions that employ third parties to develop applications, management should ensure that the third parties meet the same controls. 

Applications should provide the ability for management to do the following: 

* • Implement a prudent set of security controls (e.g., password and audit policies), audit trails of security and access changes, and user activity logs for all applications.
* • Establish user and group profiles for applications if not part of a centralized identity access management system. 49 See Federal Bureau of Investigation, Alert I-012215-PSA.
* • Change and disable default application accounts upon installation.
* • Review and install patches for applications in a timely manner.
* • Implement validation controls for data entry50 and data processing.51
* • Integrate additional authentication and encryption controls, as necessary, to ensure integrity
* • Protect web or Internet-facing applications through additional controls, including web
* • Mitigate risks from potential flaws in applications allowing remote access by customers and
* • Obtain attestation or evidence from third-party developers that the application acquired by
* • Perform ongoing risk assessments to consider the adequacy of application-level controls in
* • Implement minimum controls recommended by the third-party service provider and consider
* • Review available audit reports, and consider and implement appropriate control
* • Collect data to build metrics and reporting of configuration management compliance, and confidentiality of data and non-repudiation of transactions. application firewalls, regular scanning for new or recurring vulnerabilities, mitigation or remediation of common security weaknesses, and network segregation to limit inappropriate access or connections to the application or other areas of the network. others through network, host, and application layer architecture considerations. the institution meets the necessary security requirements and that noted vulnerabilities or flaws are remediated in a timely manner. light of changing threat, network, and host environments. supplemental controls as appropriate. recommendations vulnerability management, and other measurable items as determined by management.

Whether the institution acquires or develops applications, management should establish security control requirements for new systems, system revisions, or new system acquisitions. Management should define the security control requirements based on its risk assessment process and evaluate the value of the information at risk and the potential impact of unauthorized access or damage within existing software development and acquisition processes. Management should have a process to determine risks posed by the system and necessary security requirements. Management may also refer to published, widely recognized industry standards as a starting point for establishing the institution’s security requirements. 

Information security personnel should be involved from the outset in the application development process to determine whether security controls are designed, tested, and implemented and information security needs are being met. Monitoring the development environment can help ensure that the implemented controls are functioning properly. Institutions that purchase applications typically rely on third-party service providers to develop applications with appropriate security built-in; management, however, should perform its own verification to determine whether the application meets the institution’s security requirements. Management should analyze the environment where the application will reside. As the environment changes, the security requirements and assurance needs for the application may also change. Management should leverage available resources52 to assist in risk identification and improve the institution’s application security practices. 

50 Data entry validation controls include access controls over entry and changes to data, error checks, review of suspicious or unusual data, and dual entry or additional review and authorization for highly sensitive transactions or data. 

51 Data processing controls include batch control totals, hash totals of data for comparison after processing, identification of any changes made to data outside the application (e.g., data-altering utilities), and job control checks to ensure programs run in correct sequence. 

##### II.C.18 Database Security 

#### Action Summary 

Management should implement effective controls for databases and restrict access appropriately. 

Databases are collections of information organized to be easily accessed, managed, and updated. Databases can be developed in-house or purchased from third parties and have their own controls and protective mechanisms configured to provide varying levels of protection. Along with many other security features, encryption helps to protect the stored information from theft or unauthorized viewing. Management should implement or enable controls commensurate with the sensitivity of the data stored in or accessed by the database. 

Database users may be people (e.g., employees, customers, and contractors) or other applications. Users have different levels of access and authorization. Some users may have extensive privileges, including the ability to change the database configuration and access controls. Other users may have restrictions in what they can view, manipulate, or store. When a person is the database user, authorizations can be tailored to that person, greatly limiting the amount of information that could be exposed in a security incident. When an application is the database user, the access granted to the application can be more extensive than a person would require. Accordingly, an attack on a database through an application could expose a larger and more damaging collection of data. For application accounts, management should strengthen authentication and monitoring requirements to minimize the potential for unauthorized use. 

Management should appropriately control user access and apply the principle of least privilege in assigning authorizations. The use and overall configuration of a database’s security features should be part of a well-designed, layered security program. 

##### II.C.19 Encryption 

#### Action Summary 

Management should implement the type and level of encryption commensurate with the sensitivity of the information. 

52 Resources include software tools, industry resources, specific certifications, and education courses. 

Encryption is used to secure communications and data storage, particularly authentication credentials and the transmission of sensitive information. Encryption can be used throughout a technological environment, including the operating systems, middleware, applications, file systems, and communications protocols. 

Encryption can be used as a preventive control, a detective control, or both. As a preventive control, encryption acts to protect data from disclosure to unauthorized parties. As a detective control, encryption is used to allow management to discover unauthorized changes to data. When prevention and detection are joined, encryption can be an important control in ensuring confidentiality, integrity, and availability. 

Institution management should employ encryption strength sufficient to protect information from disclosure. Encryption methods should be reviewed periodically to ensure that the types and methods of encryption are still secure as technology and threats evolve. Decisions regarding what data to encrypt and at what points to encrypt the data are typically based on the risk of disclosure and the costs of encryption. The need to encrypt data is determined by the institution’s data classification and risk assessment. 

Passwords should be hashed or encrypted in storage. Passwords that are hashed also should be salted.53 Files containing encrypted or hashed passwords used by systems to authenticate users should be readable only with elevated (or administrator) privileges. 

Key management54 is crucial to the effective use of encryption. Effective key management systems rely on an agreed set of standards, procedures, and secure methods that address the following:55 

* • Generating keys for different cryptographic systems and different applications.
* • Generating and obtaining public keys.
* • Distributing keys to intended users, including how keys should be activated when received.
* • Storing keys, including how authorized users obtain access to keys.
* • Changing or updating keys, including rules on when and how keys should be changed.
* • Addressing compromised keys.
* • Archiving, revoking, and specifying how keys should be withdrawn or deactivated.
* • Recovering keys that are lost or corrupted as part of business continuity management.
* • Logging the auditing of key management-related activities.
* • Instituting defined activation and deactivation dates, and limiting the usage period of keys. 53 In password protection, salt is a random string of data used to modify a password hash. 

54 Key management is the management of cryptographic keys. This includes dealing with the generation, exchange, storage, use, and replacement of keys. 

55 Refer to ISO/IEC 11770-1:2010, “Key Management—Part 1: Framework”; ISO/IEC 11770-2:2008, “Key Management—Part 2: Mechanisms Using Symmetric Techniques”; and ISO/IEC 11770-3:2015, “Key Management—Part 3: Mechanisms Using Asymmetric Techniques.”

##### II.C.20 Oversight of Third-Party Service Providers 

#### Action Summary 

Management should oversee outsourced operations through the following: 

* • Appropriate due diligence in third-party research, selection, and relationship management.
* • Contractual assurances for security responsibilities, controls, and reporting.
* • Nondisclosure agreements regarding the institution’s systems and data.
* • Independent review of the third party’s security through appropriate reports from audits and tests.
* • Coordination of incident response policies and contractual notification requirements.
* • Verification that information and cybersecurity risks are appropriately identified, measured, mitigated, monitored, and reported.

Management should conduct appropriate due diligence in selecting and monitoring third-party service providers. Management should be responsible for ensuring that such third parties use suitable information security controls when providing services to the institution. When indicated by the institution’s risk assessment, management should monitor third-party service providers to confirm that they are maintaining appropriate controls. If the third-party service provider stores, transmits, processes, or disposes of customer information, management should require third- party service providers by contract to implement appropriate measures designed to meet the Information Security Standards. 

Management should evaluate information security considerations of potential third-party service providers during initial due diligence. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for more information. 

Management should verify that third-party service providers implement and maintain controls sufficient to appropriately mitigate risks. The institution’s contracts should do the following: 

* • Include minimum control and reporting standards.
* • Provide for the right to require changes to standards as external and internal environments change.
* • Specify that the institution or an independent auditor has access to the service provider to perform evaluations of the service provider’s performance against the Information Security Standards.

Refer to the “Third-Party Reviews of Technology Service Providers” section of the IT Handbook’s “Audit” booklet for more information. 

Additionally, as part of the oversight of third-party service providers, management should determine whether cyber risks are identified, measured, mitigated, monitored, and reported by such third parties as third-party cyber threats can have an impact on the institution. Information security reporting by the institution should incorporate an assessment of these third-party risks to facilitate a comprehensive understanding of the institution’s exposure to third-party cyber threats. 

##### II.C.20(a) Outsourced Cloud Computing 

As with other forms of outsourcing, information security implications are key in the cloud computing model. Management may need to revise information security policies, standards, and procedures to incorporate the activities related to a cloud computing service provider. Refer to the FFIEC’s “Outsourced Cloud Computing” statement for more information.56 

##### II.C.20(b) Managed Security Service Providers 

Management may rely on third parties to provide security services; management, however, remains responsible for ensuring the security of the institution’s systems and information by overseeing the effectiveness of the services provided by the managed security services provider. Additional information is available in appendix D of the IT Handbook’s “Outsourcing Technology Services” booklet. 

##### II.C.21 Business Continuity Considerations 

#### Action Summary 

Management should do the following: 

* • Identify personnel who will have critical information security roles during a disaster, and train personnel in those roles.
* • Define information security needs for backup sites and alternate communication networks.
* • Establish and maintain policies that address the concepts of information security incident response and resilience, and test information security incident scenarios.

Business continuity plans should be reviewed as an integral part of the security process. Strategies should consider the different risk environments and the degree of risk mitigation necessary to protect the institution if continuity plans must be implemented. Management should train personnel regarding their security roles during a disaster. Additionally, management should update technologies and plans for backup sites and communications networks. These security considerations should be integrated with the testing of the business continuity plan. 

Information security events may trigger activation of the business continuity plan. Therefore, the institution’s plan should include steps that explicitly address information security incident response and resilience. Resilience testing should incorporate information security event scenarios identified by the institution. 

Refer to the IT Handbook’s “Business Continuity Planning” booklet for more information. 

56 See FFIEC, “Outsourced Cloud Computing,” July 10, 2012. 

#### II.C.22 Log Management 

Network and host activities typically are recorded on the host and sent across the network to a central logging repository. The data that arrive at the repository are in the format of the software that recorded the activity. The logging repository may process the data and can enable timely and effective log analysis. Management should have effective log retention policies that address the significance of maintaining logs for incident response and analysis needs. 

Log files are critical to the successful investigation and prosecution of security incidents and can potentially contain sensitive information. Intruders often attempt to conceal unauthorized access by editing or deleting log files. Therefore, institutions should strictly control and monitor access to log files whether on the host or in a centralized logging repository. Considerations for securing the integrity of log files include the following: 

* • Encrypting log files that contain sensitive data or that are transmitted over the network.
* • Ensuring adequate storage capacity to avoid gaps in data gathering.
* • Securing backup and disposal of log files.
* • Logging the data to a separate, isolated computer.
* • Logging the data to read-only media.
* • Setting logging parameters to disallow any modification to previously written data.
* • Restricting access to log files to a limited number of authorized users.

Additionally, logging practices should be reviewed periodically by an independent party to ensure appropriate log management. 

Logs are voluminous and challenging to read. They come from a variety of systems and can be difficult to manage and correlate. Security information and event management (SIEM) systems can provide a method for management to collect, aggregate, analyze, and correlate information from discrete systems and applications. Management can use SIEM systems to discern trends and identify potential information security incidents. SIEM systems can be used to gather information from the following: 

* • Network and security devices and systems.57
* • Identity and access management applications.
* • Vulnerability management and policy compliance tools.
* • Operating system, database, and application logs.
* • Physical and environmental monitoring systems.
* • External threat data.

Regardless of the method of log management, management should develop processes to collect, aggregate, analyze, and correlate security information. Policies should define retention periods for security and operational logs. Institutions maintain event logs to understand an incident or cyber event after it occurs. Monitoring event logs for anomalies and relating that information with other sources of information broadens the institution’s ability to understand trends, react to threats, and improve reports to management and the board. 

57 These can include intrusion detection and prevention systems, DLP solutions, and firewalls. 

### II.D Risk Monitoring and Reporting 

Risk monitoring is a process by which the institution tracks information about its inherent risk profile and identifies gaps in the effectiveness of risk mitigation activities. Risk monitoring should address changing threat conditions in both the institution and the greater financial industry. Threats change frequently, particularly in terms of the threat’s capabilities and intentions, as well as the vulnerabilities they may exploit. Vulnerabilities in software are continually announced, and other vulnerabilities may emerge as the institution’s systems are modified or updated. External requirements, including the use of new third-party service providers, also may change the institution’s inherent risk profile. 

Risk reporting is a process that produces information systems reports that address threats, capabilities, vulnerabilities, and inherent risk changes. Risk reporting should describe any information security events that the institution faces and the effectiveness of management’s response and resilience to those events. The reporting process should provide a method of disseminating those reports to appropriate members of management. The contents of the reports should prompt action, if necessary, in a timely manner to maintain appropriate levels of risk. 

#### II.D.1 Metrics 

A mature and effective information security program uses metrics to improve the program’s effectiveness and efficiency. Management should develop metrics that demonstrate the extent to which the security program is implemented and whether the program is effective. Metrics are used to measure security policy implementation, conformance with the information security program, the adequacy of security services delivery, and the impact of security events on business processes. The measurement of security characteristics can allow management to increase control and drive improvements to the security process. Metrics generally are formed to measure conformance to the standards and procedures that are used to implement policies. 

Management should utilize metrics to quantify and report risks of the information security program. Metrics should be gathered from external sources and internal data. The scope of metrics should be comprehensive and commensurate with the complexity of the institution’s operations. Reports should incorporate metrics tailored for different audiences and stakeholders. These metrics and other monitoring reports of the information security program should feed into ITRM reporting. 

## III Security Operations 

### Action Summary 

Management should design policies and procedures to effectively manage security operations with the following characteristics: 

* • Broadly scoped to address all ongoing security-related functions.
* • Guided by defined processes.
* • Integrated with lines of business and third parties.
* • Appropriately staffed and supplied with technology for continual incident detection and response activities.

Security operations involve a wide range of activities. Those activities may be centralized in a security operations center, distributed within the information security department and business lines, or outsourced in whole or in part. Security operations activities can include the following: 

* • Security software and device management (e.g., maintaining the signatures on signature- based devices and firewall rules).
* • Forensics (e.g., analysis of potentially compromised systems).
* • Threat identification and assessment.
* • Vulnerability identification (e.g., operation or supervision of vulnerability scans, self- assessments, penetration tests, and analysis of audit results).
* • Vulnerability cataloging and remediation tracking.
* • Physical security management (e.g., CCTV, guards, and badge systems).
* • Law enforcement interface (e.g., data retention and lawful intercepts).
* • Third-party integration (e.g., managed security services and incident detection services).
* • Network, host, and application activity monitoring.
* • Analysis of threat intelligence from external sources.
* • Engagement with information sharing groups.
* • Incident detection and management.
* • Enforcement of access controls.

Management should establish defined processes and appropriate governance to facilitate the performance of security operations. Policies should address the timing and extent of the security operations activities, reporting, escalation triggers, and response actions. Many institutions use an issue tracking system58 to record and manage requests and events. An issue tracking system can be a source of evidence, contain a variety of security information, and serve as a valuable tool to assist management when taking actions to strengthen the information security environment. 

58 An issue tracking system (also ITS, trouble ticket system, ticketing management system, support ticket system, request management system, or incident ticket system) is a computer software package that manages and maintains lists of security issues. 

Management should coordinate security operation activities with the institution’s lines of business and with third-party service providers. Regardless of how extensive the coordination is, the goal should be to maintain a sufficient security operation capability across the entire environment. 

Sufficient technology and staff should be available to support continual incident detection and response activities. Some institutions may rely on or supplement their activities with third parties to gain the necessary scope and depth of coverage. Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for more information. 

### III.A Threat Identification and Assessment 

#### Action Summary 

Management should do the following: 

* • Identify and assess threats.
* • Use threat knowledge to drive risk assessment and response.
* • Design policies to allow immediate and consequential threats to be dealt with expeditiously.

Threat identification and assessment involves discovering knowledge about threat sources and vulnerabilities and analyzing the potential for exploitation. This is much more focused than the risk identification process described in the “Risk Identification” section of this booklet. Information gained from threat identification and assessment should be used in risk assessment and response to drive protective and detective strategies and tactics. Strategies involve the information security program’s policies, standards, and procedures, and the implementing technologies. Examples of tactics include threat signatures used for incident identification and management of threat behaviors. NIST notes that types of threat sources include the following: 

* • Hostile cyber or physical attacks.
* • Human errors of omission or commission.
* • Structural failures of organization-controlled resources (e.g., hardware, software, and
* • Natural and man-made disasters, accidents, and failures beyond the control of the environmental controls). organization.59

Management should develop procedures for obtaining, monitoring, assessing, and responding to evolving threat and vulnerability information. The identification of threats involves the sources of threats, their capabilities, and their objectives. Information about threats generally comes from government (e.g., US-CERT), information-sharing organizations (e.g., FS-ISAC), industry sources, the institution, and third parties. Third-party information may be from organizations that specifically track and report on threats or from third-party reports of past activity. Some of those reports compile knowledge from incidents reported by many organizations worldwide. Different types of information supporting an assessment may be available through the following: 

59 NIST SP 800-30, revision 1, “Information Security: Guide for Conducting Risk Assessments,” September 2012. 

* • Incident data from reports published by security providers and others.
* • Attack data from sources including FS-ISAC and managed security service providers.
* • Threat data through reports available either free or for a fee.

The availability of threat information is often ad hoc, although some providers present threat information within a defined framework that readily lends itself to analytical operations. By using a threat taxonomy, the institution may greatly reduce the complexity of threat assessment and enable efficient understanding of reasonable risk mitigations. Specific factors in the threat assessment may include a description, context for operation, capabilities and intent, and, from the threat-source perspectives, benefits and negative consequences associated with an attack. 

Knowledge of threat sources is especially important to help identify vulnerabilities. Vulnerabilities can occur in many areas, such as the system design, the system operation, security procedures, business line controls, and the implementation of the system and controls. Self-assessments, audits, scans, penetration tests, and reviews of SIEM reports can identify vulnerabilities. Additionally, external individuals or groups can identify vulnerabilities. 

Tools for analyzing vulnerabilities in a layered security environment include attack trees, event trees, and kill chains. These tools attempt to model an attacker’s actions to enable identification of the most effective and efficient remediation options. 

Once a threat is identified and potential vulnerabilities are assessed, the significance of the threat should trigger a response. The response should be commensurate with the risk posed by the threat and should include remediation options. Management should design policies to allow for immediate and consequential threats to be dealt with expeditiously, while less significant threats are addressed as part of a broader risk management process. When management receives vulnerability information from external individuals or groups, management should have appropriate processes and procedures to evaluate the credibility of the information to appropriately address it. 

### III.B Threat Monitoring 

Threat monitoring policies should provide for continual and ad hoc monitoring of threat intelligence communications and systems, effective incident detection and response, and the use of monitoring reports in subsequent legal procedures. Management should establish the responsibility and authority of security personnel and system administrators for monitoring. Additionally, management should review and approve the tools used and the conditions for use. 

Threat monitoring should address indicators of vulnerabilities, attacks, compromised systems, and suspicious users, such as those who do not comply with or seek to evade security policies. Monitoring should address incoming and outgoing network traffic, seeking to identify malicious activity and data exfiltration. Additionally, the monitoring process should be established and documented to independently monitor administrators and other users with higher privileges. 

### III.C Incident Identification and Assessment 

#### Action Summary 

Management should have a process to enable the following: 

* • Identify indicators of compromise.
* • Analyze the event associated with the indicators.
* • Classify the event.
* • Escalate the event consistent with the classification.
* • Report internally and externally as appropriate.

Incident identification involves indicators and analysis. External indicators may arise through contact with customers, law enforcement, card organizations (e.g., credit or payment cards), other financial institutions, media, or others. Internal indicators may arise when internal users contact the help desk, IT operations follows up on anomalies, or security operations follows up on anomalies identified through security devices and network and systems activity. Indicators may also arise through the use of “hunt teams,” or dedicated analysts who actively search for indicators of compromise. Examples of technology-based intrusion identification systems and tools include the following: 

* • Threat intelligence data feeds (e.g., STIX/TAXII).60
* • Intrusion detection and prevention systems for networks and hosts.
* • End-point visibility tools (tools that can identify the function of end points and which end points contain or have access to sensitive information).
* • DLP tools.
* • Log correlation and analysis tools.
* • File integrity tools.
* • Malware detection tools.
* • Network behavior analysis systems.
* • “Big data” tools and analytics that aggregate and allow pre-formed and ad hoc analysis.

Technology-based indicators of compromise generally are anomalies in host state, host activity, and network traffic. A few examples are unexpected (1) processes, (2) changes to files, (3) packet source or destination, (4) protocols, (5) ports, (6) encryption, (7) log-ins, and (8) packet content. Other indicators include alerts triggered by black lists in anti-virus and network- monitoring products. 

Management should have a process for identifying indicators of compromise and rapidly reporting those indicators for investigation. The report should instigate an analysis that seeks to confirm whether a compromise took place and how that compromise should be classified. Investigation may require additional information from outside and inside the institution, such as a forensic review. Management should perform due diligence to identify external assistance in advance of incidents to ensure available resources. Classification of a compromise may require information on the specific hosts affected, data lost, and business processes affected. Information developed in the analysis may be useful to guide response activities. 

60 There are efforts to automate and structure operational cybersecurity information-sharing techniques across the globe. Of these, STIX (the Structured Threat Information eXpression) and TAXII (the Trusted Automated eXchange of Indicator Information) are two of the technical specifications that allow an automated exchange of threat source data using standardized language. 

Analysis should result in a classification of the event, implementation of escalation procedures, and reporting. Analysis should be guided by the following: 

* • Classification policies should be sufficiently clear to enable timely classification of incidents by level of severity, enabling the use of response teams and responses depending on the type and severity of events.
* • Escalation, response, and reporting should be commensurate with the level of severity.
* • Escalation policies should address when different personnel within the organization will be contacted and the responsibility those personnel have in incident analysis and response.
* • Escalation policies should include when to request or obtain external assistance, from both third parties and the federal government.
* • Reporting policies should address internal and external reporting, including coordination with third parties and reporting to external organizations (e.g., FS-ISAC).

Additionally, a policy should address who is empowered to declare an incident. A defined process should guide responses to incidents. The institution should develop procedures to test the incident escalation, response, and reporting processes. 

The sharing of attack data through organizations, such as FS-ISAC, also has the potential to benefit the industry at large by enabling other institutions to better assess and respond to current attacks. Management should consider whether to include such information sharing as a part of its strategy to protect the institution. 

Management should determine whether the institution’s or its managed security service provider’s analysts are sufficiently trained to appropriately analyze network, host, and application activity and to use the monitoring and analysis tools made available to them. Additionally, security analysts should coordinate and collaborate with others in the institution with knowledge and authority for specific types of malicious activity, such as fraud. 

### III.D Incident Response 

Management should have an incident response program.61 The goal of incident response is to minimize damage to the institution and its customers. The institution’s program should have defined protocols to declare and respond to an identified incident. More specifically, the incident response program should include, as appropriate, containing the incident, coordinating with law enforcement and third parties, restoring systems, preserving data and evidence, providing assistance to customers, and otherwise facilitating operational resilience of the institution. 

61 See also “Interagency Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice,” supplementing the Information Security Standards. 

The response involves a combination of people and technologies. The quality of incident response is attributable to the institution’s culture, policies, procedures, and training. Incident response is also a function of the relationships the institution formed before the incident with law enforcement, incident response consultants and attorneys, information-sharing entities (e.g., FS- ISAC), and others. Management should prepare for potential incidents by developing an incident response plan that is comprehensive, coordinated, and integrated with existing institution policies, procedures, and training. To validate the effectiveness of the institution’s incident response program, management should periodically test it through different test types, including scenario planning and tabletop testing, and perform the tests with appropriate internal and external parties. 

Preparation determines the success of any intrusion response. Such preparation involves defining the policies and procedures that guide the response; assigning responsibilities to individuals; providing appropriate training; formalizing information flows; and selecting, installing, and understanding the tools used in the response effort. Additionally, management should define thresholds for reporting significant security incidents, and consider developing processes for when the institution should notify its regulators of incidents that may affect the institution’s operations, reputation, or sensitive customer information. These incidents may include those that could affect the financial system. Primary considerations for incident response include the following: 

* • How to balance concerns regarding confidentiality, integrity, and availability for devices and data. This consideration is a key driver for a containment strategy and may involve legal and liability considerations. Management may decide that some systems must be disconnected or shut down at the first sign of intrusion, while others must be left on line.
* • When and under what circumstances to invoke the incident response activities, and how to ensure that the proper personnel are notified and available.
* • When to involve outside experts and how to ensure the proper expertise will be available when needed. This consideration addresses both containment and restoration.
* • Protocols to define when and under what circumstances to notify and involve regulators, customers, and law enforcement, including names and contact information for each group.
* • Which personnel have authority to perform specific actions in the containment of the intrusion and restoration of the system. This consideration affects the internal communications strategy, the commitment of personnel, and procedures that escalate involvement and decisions within the organization.
* • How, when, and what to communicate outside of the institution, whether to law enforcement, regulatory agencies, information-sharing organizations, customers, third-party service providers, potential victims, or others.
* • How to document and maintain the evidence, the decisions made, and the actions taken.
* • What criteria must be met before compromised services, equipment, and software are returned to the network.
* • How to learn from the intrusion and use lessons learned to improve the institution’s security.
* • How and when to prepare and file a Suspicious Activities Report.

Successful implementation of any response policy or procedure requires the assignment of responsibilities, training, and testing. Some institutions formalize the response program with the creation of a security incident response team (SIRT). The SIRT typically is tasked with performing, coordinating, and supporting responses to security incidents and intrusions. Because of the wide range of technical and nontechnical issues posed by an intrusion, typical SIRT membership includes individuals with a wide range of backgrounds and expertise from different areas within the institution. Those areas include management, legal, and public relations, as well as IT staff. Other organizations may outsource some of the SIRT functions (e.g., forensic examinations). When SIRT functions are outsourced, management should require the third-party service provider to follow the institution’s policies and maintain the confidentiality of data. 

Institutions should assess the adequacy of their preparation through testing. There are a variety of testing methods; therefore, management should consider the most applicable tests for its IT environment. Institutions can also participate with outside entities that provide testing activities (e.g., FS-ISAC). 

While containment strategies between institutions can vary, they typically include the following broad elements: 

* • Isolation of compromised systems or enhanced monitoring of intruder activities.
* • Search for additional compromised systems.
* • Collection and preservation of evidence.
* • Communication with affected parties and often the primary regulator, information-sharing organizations (e.g., FS-ISAC), or law enforcement.

Restoration and follow-up strategies should address the following: 

* • Elimination of an intruder’s means of access.
* • Restoration of systems, programs, and data to a known good state.
* • Initiation of customer notification and assistance activities consistent with laws, regulations, and interagency guidance.
* • Monitoring to detect similar or further incidents.

Management should periodically review the actions taken in response to intrusions to identify improvements and implement those improvements through changes in policy, standards, procedures, training, and practices. 

## IV Information Security Program Effectiveness 

The information security program should be subject to periodic review to ensure continual improvement in the program’s effectiveness. The review should address the program in the context of the environment in which the program now operates, both within the institution and outside. Lessons learned from experience, audit findings, and other indicators of opportunities for improvement should be identified and the program changed as appropriate. 

### IV.A Assurance and Testing 

#### Action Summary 

Management should ascertain that the information security program is operating securely, as expected, and reaching intended goals by doing the following: 

* • Testing and evaluating through self-assessments, tests, and audits with appropriate coverage, depth, and independence.
* • Aligning personnel skills and program needs.
* • Establishing and implementing a reporting process that includes the assembly and distribution of assurance reports that are timely, complete, transparent, and relevant to management decisions.

Assurance relates to the confidence that the information security program is mitigating risk as expected. Assurance targets two parts of the process: (1) the IT system’s design and (2) the IT system’s operation. The institution should carefully distinguish between the two because the former relates to risk decisions that change the security controls and the latter relates to the operation of the controls. Flaws in control design typically are corrected by a redesign, and flaws in operation typically are corrected through a compliance program. 

The institution should have a documented testing and evaluation plan that addresses the integration of security controls, level of assurance desired, and strategies and activities performed in obtaining that assurance. The plan should identify specific components of the system to address, methods by which the components are to be addressed, timing and frequency of the tests and evaluations, and criteria used to ascertain whether the test and evaluation results are acceptable and provide assurance.62 

#### IV.A.1 Key Testing Factors 

Management should consider the following key factors when developing and implementing independent tests: 

* • Scope.
* • Personnel.
* • Notifications. The tests and methods utilized, in the aggregate, should be sufficient to validate the effectiveness of the security process in identifying and appropriately controlling the risk from information security-related events. 

Technical testing is only as good as the personnel performing and supervising the test. Management should review qualifications of testing personnel to verify testers’ capabilities are adequate to support the test objectives. 

Management should consider whom to inform within the institution about the timing and nature of the tests. The need for protection of institution systems and the potential for disruptive false alarms should be balanced against the need to test personnel reactions to unexpected activities. 

62 See also Information Security Standards, section III.C.3, requiring each financial institution to test the key controls, systems, and procedures of its information security program using independent third parties or staff independent of those that develop or maintain the program.
* • Confidentiality, integrity, and availability. Management should carefully control information security tests to limit the risks to confidentiality, integrity, and system availability. Because testing may uncover sensitive customer information, management should use appropriate safeguards to protect such information. Management should ensure that employee and contract personnel who perform the tests or have access to the test results have passed appropriate background checks and that contract personnel are appropriately bonded. Because certain tests may pose more risk to system availability than other tests, management should have personnel who perform those tests maintain logs of testing actions. Those logs are helpful if the systems react unexpectedly.
* • Confidentiality of test plans and data. Because knowledge of test planning and results may facilitate a security breach, the institution should carefully limit the distribution of testing information. Management should restrict test plans and data only to those individuals involved in the testing. Results should be made available in a usable form only to those responsible for following up on tests. Additionally, management should require contractors to sign nondisclosure agreements and to return information they obtained in their testing to the institution.
* • Frequency. The institution’s ITRM process should determine the frequency of independent testing. Factors that may increase testing frequency include changes to network configurations, changes to or additions of systems and applications, significant changes in potential attacker profiles and techniques, and results of other testing. For instance, management should have a testing process for security and usability over the life cycle of testing (during development, before placing a new or modified system into production, and periodic testing of the production system or application).
* • Proxy testing. Proxy testing refers to testing that is conducted on like systems and with like interfaces, rather than the actual system, to avoid disruptions on a system that may be too critical for a comprehensive continuity test. Proxy tests are conducted using the same hardware and operating software, are sometimes used as a replacement for actual tests, and should provide similar results. Independent testing of a proxy system is generally not effective in validating the effectiveness of a security process. Proxy testing, by its nature, does not test the operational system’s policies and procedures or its integration with other systems. It also does not test the reaction of personnel to unusual events. Proxy testing may be the best choice, however, when management is unable to test the operational system without creating excessive risk.
#### IV.A.2 Types of Tests and Evaluations 

Information security management may use several tools to gain confidence that the information security program is operating as expected and reaching the intended goals. The primary tools include self-assessments, penetration tests, vulnerability assessments, and audits. The coverage and depth of the various tools directly relates to the confidence gained in the information security program. 

#### IV.A.2(a) Self-Assessments 

Periodic self-assessments typically should be performed by the organizational unit being assessed. Self-assessments capture subjective opinions on the achievement of objectives. 

Although they may provide valuable information related to perceived changes in the level of risk and effectiveness of controls, they are affected by the breadth and depth of the assessor’s knowledge, the completeness and reliability of information used to complete the assessment, and the assessor’s biases. Self-assessment frequency should be a function of the level of assurance needed by the institution, determined by the risk management process. Results from self- assessments can be informative to the overall test and evaluation process. Management should use the results to help strengthen the organizational unit’s information security. 

#### IV.A.2(b) Penetration Tests 

A penetration test subjects a system to real-world attacks selected and conducted by the testers. A penetration test targets systems and users to identify weaknesses in business processes and technical controls. The test mimics a threat source’s search for and exploitation of vulnerabilities to demonstrate a potential for loss. Some tests focus on only a subset of the institution’s systems and may not accurately simulate a determined threat actor. There are many types of penetration tests (e.g., network, client-side, web application, and social engineering), and management should determine the level and types of tests employed to ensure effective and comprehensive coverage. 

The frequency and scope of a penetration test should be a function of the level of assurance needed by the institution and determined by the risk assessment process. The test can be performed internally by independent groups, internally by the organizational unit, or by an independent third party. Management should determine the level of independence required of the test. 

#### IV.A.2(c) Vulnerability Assessments 

A vulnerability assessment is a process that defines, identifies, and classifies the vulnerabilities in a computer, network, or communications infrastructure. Technical vulnerabilities can be identified through the use of scanners and other tools. Scanners search for known vulnerabilities (e.g., Mitre’s CVE) or for known vulnerability classes (e.g., Structured Query Language [SQL] injection and cross-site scripting). They also can search for compliance with approved configurations. Scanners identify vulnerabilities by inspecting network traffic or hosts. When inspecting hosts, they may require agents to be placed on the hosts with high-level access. If host agents are required, the security over the use of credentials in the scan should be a prime consideration for management. 

Similar to penetration testing, the frequency of the performance of vulnerability assessments should be determined by the risk management process. Scanners and other tools can be run continuously, generating metrics that are reported and acted upon continuously. Alternatively, they can be run periodically. Vulnerability assessments can be performed internally or by external testers, but they are often run as part of internal testing processes. 

#### IV.A.2(d) Audits 

Independent internal departments or third parties typically perform audits. Audits should review every aspect of the information security program, the environment in which the program runs, and outputs of the program. Audits should assess the reasonableness and appropriateness of, and compliance with, policies, standards, and procedures; report on information security activity and control deficiencies to decision makers; identify root causes and recommendations to address deficiencies; and test the effectiveness of controls within the program. Internal audit should track the results and the remediation of control deficiencies reported in audits and additional technical reviews, such as penetration tests and vulnerability assessments. 

Refer to the IT Handbook’s “Audit” booklet for more information. 

#### IV.A.3 Independence of Tests and Audits 

Institutions frequently use independent organizations to test aspects of their information security programs. Independent tests have the potential to reduce bias, increase capabilities, and increase knowledge about threats and technologies. Independence gives credibility to the test results. To be considered independent, testing personnel should not be responsible for the design, installation, maintenance, and operation of the tested system, or the policies and procedures that guide its operation. The reports generated from the tests should be prepared by individuals who similarly are independent. 

#### IV.A.4 Assurance Reporting 

Reporting of self-assessments, penetration tests, vulnerability assessments, and audits supports management decision making. Those decisions may support a range of ITRM activities, including the prioritization and funding of resource allocations and improvement to existing information security policies and procedures. 

Management should provide reports that are timely, complete, transparent, and relevant to management decisions. The reports should prioritize risk and findings in the order of importance, suggest options for remediation, and highlight repeat issues. Additionally, reports should address root causes. The reporting should be to individuals with authority and responsibility to act on the reports and to those accountable for the outcomes, as well as those responsible for advising or influencing risk decisions. Reporting should trigger appropriate, timely, and reliable escalation and response procedures. Summary reports should be made available to the board as appropriate. 

# Appendix A: Examination Procedures 

## Examination Objective 

Determine the quality and effectiveness of the institution’s information security. Examiners should use these procedures to measure the adequacy of the institution's culture, governance, information security program, security operations, and assurance processes. In addition, controls should be evaluated as additional evidence of program quality and effectiveness. Controls also should be evaluated for conformance with contracts, indicators of legal liability, and conformance with regulatory policy and guidance. Failure of management to implement appropriate controls may expose the institution to potential loss from fines, penalties, and customer litigation. 

These examination procedures (commonly referred to as the work program) are intended to help examiners determine the effectiveness of the institution’s information security process. Examiners may choose, however, to use only particular components of the work program based on the size, complexity, and nature of the institution’s business. Examiners should also use these procedures to measure the adequacy of the institution’s cybersecurity risk management processes. 

Objective 1: Determine the appropriate scope and objectives for the examination. 

* 1. Review past reports for outstanding issues or previous problems. Consider the following: 
	+ a. Regulatory reports of examination.
	+ b. Internal and external audit reports.
	+ c. Independent security tests.d. Regulatory, audit, and security reports on service providers.
* 2. Review management’s response to issues raised at, or since, the last examination. Consider the following: 
	+ a. Adequacy and timing of corrective action.
	+ b. Resolution of root causes rather than just specific issues.
	+ c. Existence of any outstanding issues.
* 3. Interview management and review responses to pre-examination information requests to identify changes to technology infrastructure or new products and services that might increase the institution’s risk. Consider the following: 
	+ a. Products or services delivered to either internal or external users.
	+ b. Network topology or diagram including changes to configuration or components and all internal and external connections.
	+ c. Hardware and software inventories.d. Loss, addition, or change in duties of key personnel. 


	+ e. Technology service providers and software vendor listings.
	+ f. Communication lines with other business units (e.g., loan review, credit risk management, line of business quality assurance, and internal audit).
	+ g. Credit or operating losses primarily attributable (or thought to be attributable) to IT (e.g., system problems, fraud occurring due to poor controls, and improperly implemented changes to systems).
	+ h. Changes to internal business processes.
	+ i. Internal reorganizations.
* 4. Determine the complexity of the institution’s information security environment.
* a. Determine the degree of reliance on service providers for information processing and technology support, including security operation management.
* b. Identify unique products and services and any required third-party access requirements.
* c. Determine the extent of network connectivity internally and externally and the boundaries and functions of security domains.
* d. Identify the systems that have recently undergone significant change, such as new hardware, software, configuration, and connectivity. Correlate the changed systems with the business processes they support, the extent of customer data available to those processes, and the effect of those changes on institution operations.

Objective 2: Determine whether management promotes effective governance of the information security program through a strong information security culture, defined information security responsibilities and accountability, and adequate resources to support the program. 

* 1. Determine whether the institution has a culture that contributes to the effectiveness of the information security program. 
	+ a. Determine whether the institution’s board and management understand and support information security and provide appropriate resources for the implementation of an effective security program.
	+ b. Determine whether the information security program is integrated with the institution’s lines of business, support functions, and management of third parties.
	+ c. Review for indicators of an effective information security culture (e.g., method of introducing new business initiatives and manner in which the institution holds lines of business and employees accountable for promoting information security).
* 2. Determine whether the board, or a committee of the board, is responsible for overseeing the development, implementation, and maintenance of the institution’s information security program.
* 3. Determine whether the board holds management accountable for the following: 
	+ a. Central oversight and coordination.
	+ b. Assignment of responsibility.
	+ c. Support of the information security program.
	+ d. Effectiveness of the information security program.
* 4. Determine whether the board approves a written information security program and receives a report on the effectiveness of the information security program at least annually. Determine whether the report to the board describes the overall status of the information security program and discusses material matters related to the program such as the following: 
	+ a. Risk assessment process, including threat identification and assessment.
	+ b. Risk management and control decisions.
	+ c. Service provider arrangements.
	+ d. Results of security operations activities and summaries of assurance reports.
	+ e. Security breaches or violations and management’s responses.
	+ f. Recommendations for changes or updates to the information security program.
* 5. Determine whether management responsibilities are appropriate and include the following: 
	+ a. Implementation of the information security program by clearly communicating responsibilities and holding appropriate individuals accountable for carrying out these responsibilities.
	+ b. Establishment of appropriate policies, standards, and procedures to support the information security program.
	+ c. Participation in assessing the effect of security threats or incidents on the institution and its business lines and processes.
	+ d. Delineation of clear lines of responsibility and communication of accountability for information security.
	+ e. Adherence to risk thresholds established by the board relating to information security threats or incidents, including those relating to cybersecurity.
	+ f. Oversight of risk mitigation activities that support the information security program.
	+ g. Establishment of appropriate segregation of duties.
	+ h. Coordination of both information and physical security.
	+ i. Integration of security controls throughout the institution.
	+ j. Protection of data consistently throughout the institution.
	+ k. Definition of the information security responsibilities of third parties.
	+ l. Facilitation of annual information security and awareness training and ongoing security- related communications to employees.
* 6. Determine whether management has designated one or more individuals as an information security officer and determine appropriateness of the reporting line.
* 7. Determine whether security officers and employees know, understand, and are accountable for fulfilling their security responsibilities.
* 8. Determine the adequacy of audit coverage and reporting of the information security program by reviewing appropriate audit reports and board or audit committee minutes. (For further questions, refer to the IT Handbook’s “Audit” booklet examination procedures.)63
* 9. Determine whether the board provides adequate funding to develop and implement a successful information security function. Review whether the institution has the following: 
	+ a. Appropriate staff with the necessary skills to meet the institution’s technical and managerial needs.
	+ b. Personnel with knowledge of technology standards, practices, and risk methodologies.
	+ c. Training to prepare staff for their short- and long-term security responsibilities.
	+ d. Oversight of third parties when they supplement an institution’s technical and managerial capabilities.
* 10. Determine whether management has adequately incorporated information security into its overall ITRM process. (For further questions, refer to the IT Handbook’s “Management” booklet examination procedures.)64

Objective 3: Determine whether management of the information security program is appropriate and supports the institution’s ITRM process, integrates with lines of business and support functions, and integrates third-party service provider activities with the information security program. 

* 1. Determine whether the institution has an effective information security program that supports the ITRM process. Review whether the program includes the following: 
	+ a. Identification of threats and risks.
	+ b. Measurement of risks.
	+ c. Implementation of risk mitigation.
	+ d. Monitoring and reporting of risks.
	+ e. Methods to assess the program’s effectiveness.
* 2. Determine whether management appropriately integrates the information security program across the institution’s lines of business and support functions. Review whether management has the following: 
	+ a. Security policies, standards, and procedures that are designed to support and to align with the policies in the lines of business.
	+ b. Incident response programs that include all affected lines of business and support units.
	+ c. Common awareness and enforcement mechanisms between lines of business and information security.
	+ d. Visibility to assess the likelihood of threats and potential damage to the institution.
	+ e. The ability to identify and implement controls over the root causes of an incident. 63 See the IT Handbook’s “Audit” booklet examination procedures. 
	
	64 See the IT Handbook’s “Management” booklet examination procedures.
* 3. If the institution outsources activities to a third-party service provider, determine whether management integrates those activities with the information security program. Verify that the third-party management program evidences expectations that align with the institution’s information security program.

Objective 4: As part of the information security program, determine whether management has established risk identification processes. 

* 1. Determine whether management effectively identifies threats and vulnerabilities continuously.
* 2. Determine whether the risk identification process produces manageable groupings of information security threats, including cybersecurity threats. Review whether management has the following: 
	+ a. A threat assessment to help focus the risk identification efforts.
	+ b. A method or taxonomy for categorizing threats, sources, and vulnerabilities.
	+ c. A process to determine the institution’s information security risk profile.
	+ d. A validation of the risk identification process through audits, self-assessments, penetration tests, and vulnerability assessments.
	+ e. A validation though audits, self-assessments, penetration tests, and vulnerability assessments that risk decisions are informed by appropriate identification and analysis of threats and other potential causes of loss.
* 3. Determine whether management has a means to collect data on potential threats to identify information security risks. Determine whether management uses threat modeling (e.g., development of attack trees) to assist in identifying and quantifying risk and in better understanding the nature, frequency, and sophistication of threats.
* 4. Determine whether management has continuous, established routines to identify and assess vulnerabilities. Determine whether management has processes to receive vulnerability information disclosed by external individuals or groups, such as security or vulnerability researchers.
* 5. Determine whether management adjusts the information security program for institutional changes and changes in legislation, regulation, regulatory policy, guidance, and industry practices. Review whether management has processes to do the following: 
	+ a. Maintain awareness of new legal and regulatory requirements or changes to industry practices.
	+ b. Update the information security program to reflect changes.
	+ c. Report changes of the information security program to the board.Objective 5: Determine whether management measures the risk to guide its recommendations for and use of mitigating controls. 


	+ 1. Determine whether management uses tools to perform threat analysis and analyzes information security events to help do the following: 
		- a. Map threats and vulnerabilities.
		- b. Incorporate legal and regulatory requirements.
		- c. Improve consistency in risk measurement.
		- d. Highlight potential areas for mitigation.
		- e. Allow comparisons among different threats, events, and potential mitigating controls.Objective 6: Determine whether management effectively implements controls to mitigate identified risk. 
	
	
		- 1. Determine whether policies, standards, and procedures are of sufficient scope and depth to guide information security-related decisions. Review whether policies, standards, and procedures have the following characteristics: 
			* a. Are appropriately implemented and enforced.
			* b. Delineate areas of responsibility.
			* c. Are communicated in a clear and understandable manner.
			* d. Are reviewed and agreed to by employees.
			* e. Are appropriately flexible to address changes in the environment.
		- 2. Determine whether the information security policy is annually reviewed and approved by the board.
		- 3. Determine whether the institution continually assesses the capability of technology needed to sustain an appropriate level of information security based on the size, complexity, and risk appetite of the institution.
		- 4. Determine whether management implements an integrated control system characterized by the use of different control types that mitigates identified risks. Review whether management does the following: 
			* a. Implements a layered control system using different controls at different points in a transaction process.
			* b. Uses controls of different classifications, including preventive, detective, and corrective.
			* c. Verifies that compensating controls are used appropriately to compensate for weaknesses with the system or process.
		- 5. Determine whether management implements controls that appropriately align security with the nature of the institution’s operations and strategic direction. Specifically, review whether management does the following: 
			* a. Implements controls based on the institution’s risk assessment to mitigate risk from information security threats and vulnerabilities, such as interconnectivity risk.
			* b. Evaluates whether the institution has the necessary resources, personnel training, and testing to maximize the effectiveness of the controls.
			* c. Reviews and improves or updates the security controls, where necessary.
		- 6. Determine whether management effectively maintains an inventory(ies) of hardware, software, information, and connections. Review whether management does the following: 
			* a. Identifies assets that require protection, such as those that store, transmit, or process sensitive customer information, or trade secrets.
			* b. Classifies assets appropriately.
			* c. Uses the classification to determine the sensitivity and criticality of assets.
			* d. Uses the classification to implement controls required to safeguard the institution’s assets.
			* e. Updates the inventory(ies) appropriately.
		- 7. Determine whether management comprehensively and effectively identifies, measures, mitigates, monitors, and reports interconnectivity risk. Review whether management does the following: 
			* a. Identifies connections with third parties.
			* b. Identifies access points and connection types that pose risk.
			* c. Identifies connections between and access across low-risk and high-risk systems.
			* d. Measures the risk associated with connections with third parties with remote access.
			* e. Implements and assesses the adequacy of appropriate controls to ensure the security of connections.
			* f. Monitors and reports on the institution’s interconnectivity risk.
		- 8. Determine whether management effectively mitigates risks posed by users. Review whether management does the following: 
			* a. Develops and maintains a culture that fosters responsible and controlled access for users.
			* b. Establishes and effectively administers appropriate security screening in IT hiring practices.
			* c. Establishes and appropriately administers a user access program for physical and logical access.
			* d. Employs appropriate segregation of duties.
			* e. Obtains agreements from employees, contractors, and service providers covering confidentiality, nondisclosure, and authorized use.
			* f. Provides training to support awareness and policy compliance.
		- 9. Determine whether management applies appropriate physical security controls to protect its premises and more sensitive areas, such as its data center(s).
		- 10. Determine whether management secures access to its computer networks through multiple layers of access controls. Review whether management does the following: 
			* a. Establishes zones (e.g., trusted and untrusted) according to risk with appropriate access requirements within and between each zone.
			* b. Maintains accurate network diagrams and data flow charts.
			* c. Implements appropriate controls over wired and wireless networks.
		- 11. Determine whether management has a process to introduce changes to the environment (e.g., configuration management of IT systems and applications, hardening of systems and applications, use of standard builds, and patch management) in a controlled manner. Determine whether management does the following: 
			* a. Maintains procedures to guide the process of introducing changes to the environment.
			* b. Defines change requirements.
			* c. Restricts changes to authorized users.
			* d. Reviews the potential impact changes have on security controls.
			* e. Identifies all system components affected by the changes.
			* f. Develops test scripts and implementation plans.
			* g. Performs necessary tests of all changes to the environment (e.g., systems testing, integration testing, functional testing, user acceptance testing, and security testing).
			* h. Defines rollback procedures in the event of unintended or negative consequences with the introduced changes.
			* i. Verifies the application or system owner has authorized changes in advance.
			* j. Maintains strict version control of all software updates.
			* k. Validates that new hardware complies with institution policies and guidelines.
			* l. Verifies network devices are properly configured and function appropriately within the environment
			* m. Maintains an audit trail of all changes.
		- 12. Determine whether appropriate processes exist for configuration management (managing and controlling configurations of systems, applications, and other technology).
		- 13. Determine whether management has processes to harden applications and systems (e.g., installing minimum services, installing necessary patches, configuring appropriate security settings, enforcing principle of least privilege, changing default passwords, and enabling logging).
		- 14. Determine whether management uses standard builds, allowing one documented configuration to be applied to multiple computers in a controlled manner, to create hardware and software inventories, update or patch systems, restore systems, investigate anomalies, and audit configurations.
		- 15. Determine whether management has a process to update and patch operating systems, network devices, and software applications, including internally developed software provided to customers, for newly discovered vulnerabilities. Review whether patch management processes include the following: 
			* a. An effective monitoring process that identifies the availability of software patches.
			* b. A process to evaluate the patches against the threat and network environment.
			* c. A prioritization process to determine which patches to apply across classes of computers and applications.
			* d. A process for obtaining, testing, and securely installing the patches.
			* e. An exception process, with appropriate documentation, for patches that an institution decides to delay or not apply.
			* f. A process to ensure that all patches installed in the production environment are also installed in the disaster recovery environment.
			* g. A documentation process to ensure the institution’s information assets and technology inventory and disaster recovery plans are updated as appropriate when patches are applied.
			* h. Actions to ensure that patches do not compromise the security of the institution’s systems.
		- 16. Determine whether management plans for the life cycles of the institution’s systems, eventual end of life, and any corresponding business impacts. Review whether the institution’s life cycle management includes the following: 
			* a. Maintaining inventories of systems and applications.
			* b. Adhering to an approved end-of-life or sunset policy for older systems.
			* c. Tracking changes made to the systems and applications, availability of updates, and the planned end of support by the vendor.
			* d. Planning for the update or replacement of systems nearing obsolescence.
			* e. Outlining procedures for the secure destruction or wiping of hard drives being returned to vendors or donated to prevent the inadvertent disclosure of sensitive information.
		- 17. Determine whether management has implemented defense-in-depth to protect, detect, and respond to malware.
		- 18. Determine whether management maintains policies and effectively controls and protects access to and transmission of information to avoid loss or damage. Review whether management does the following: 
			* a. Requires secure storage of all types of sensitive information, whether on computer systems, portable devices, physical media, or hard-copy documents.
			* b. Establishes controls to limit access to data.
			* c. Requires appropriate controls over data stored in a cloud environment.
			* d. Implements appropriate controls over the electronic transmission of information or, if appropriate safeguards are unavailable, restricts the type of information that can be transmitted.
			* e. Has appropriate disposal procedures for both paper-based and electronic information.
			* f. Maintains the security of physical media, including backup tapes, containing sensitive information while in transit, including to off-site storage, or when shared with third parties.
			* g. Has policies restricting the use of unsanctioned or unapproved IT resources (e.g., online storage services, unapproved mobile device applications, and unapproved devices).
		- 19. Determine whether management identifies factors that may increase risk from supply chain attacks and responds with appropriate risk mitigation. Review whether management implements the following as appropriate: 
			* a. Purchases are made only through reputable sellers.
			* b. Purchases are made through a third party to shield the institution’s identity.
			* c. Hardware is reviewed for anomalies.
			* d. Software is reviewed through both automated software testing and code reviews.
			* e. Reliability of the items purchased is regularly reviewed post-implementation.
		- 20. Determine whether management has an effective process to administer logical security access rights for the network, operating systems, applications, databases, and network devices. Review whether management has the following: 
			* a. An enrollment process to add new users to the system.
			* b. An authorization process to add, delete, or modify authorized user access to operating systems, applications, directories, files, and specific types of information.
			* c. A monitoring process to oversee and manage the access rights granted to each user on the system.
			* d. A process to control privileged access.
			* e. A process to change or disable default user accounts and passwords.
		- 21. As part of management’s process to secure the operating system and all system components, determine whether management does the following: 
			* a. Limits the number of employees with access to operating system and system utilities and grants only the minimum level of access required to perform job responsibilities.
			* b. Restricts and logs access to and activity on operating system parameters, system utilities (especially those with data-altering capabilities), and sensitive system resources (including files, programs, and processes), and supplements with additional security software, as necessary.
			* c. Restricts operating system access to specific terminals in physically secure and monitored locations.
			* d. Secures or removes external drives and portable media from system consoles, terminals, or PCs running terminal emulations, residing outside of physically secure locations.
			* e. Prohibits remote access to operating system and system utilities, where feasible, and, at a minimum, requires strong authentication and encrypted sessions before allowing such remote access.
			* f. Filters and reviews logs for potential security events and provides adequate reports and alerts.
			* g. Independently monitors operating system access by user, terminal, date, and time of access.
		- 22. Determine whether management controls access to applications. Review whether management does the following: 
			* a. Implements a robust authentication method consistent with the criticality and sensitivity of the application.
			* b. Manages application access rights by using group profiles.
			* c. Periodically reviews and approves the application access assigned to users for appropriateness.
			* d. Communicates and enforces the responsibilities of programmers, security administrators, and application owners in maintaining effective application access control.
			* e. Sets time-of-day or terminal limitations for some applications or for more sensitive functions within an application.
			* f. Logs access and events, defines alerts for significant events, and develops processes to monitor and respond to anomalies and alerts.
		- 23. Determine whether management has policies and procedures to ensure that remote access by employees, whether using institution or personally owned devices, is provided in a safe and sound manner. Review whether management does the following: 
			* a. Provides remote access in a safe and sound manner.
			* b. Implements the controls necessary to offer remote access securely (e.g., disables unnecessary remote access, obtains approvals for and performs audits of remote access, maintains robust configurations, enables logging and monitoring, secures devices, restricts remote access during specific times, controls applications, enables strong authentication, and uses encryption).
		- 24. Determine whether management effectively controls employees’ use of remote devices. Review whether management does the following: 
			* a. Implements controls over institution owned and personally owned devices used by employees to access the network (e.g., disallows remote access without business justification, requires management approval, reviews remote access approvals, restricts access to authorized network areas, logs remote access, implements robust authentication, uses encryption, and uses application white-listing).
			* b. Implements controls over remote devices provided by the institution (e.g., securely configures remote access devices, protects devices against malware, patches and updates software, encrypts sensitive data, implements secure containers, audits device access, uses remote disable and wipe capabilities, and uses geolocation).
			* c. Uses an effective method to ensure personally owned devices meet defined institution security standards (e.g., such as operating system version, patch levels, and anti-malware solutions).
		- 25. Determine whether management effectively provides secure customer access to financial services and plans for potential interruptions in service. Review whether management does the following: 
			* a. Develops and maintains policies and procedures to securely offer and ensure the resilience of remote financial services (e.g., using appropriate authentication, layered security controls, and fraud detection monitoring). (For additional questions, refer to the “Mobile Financial Services” examination procedures.)65
			* b. Plans and coordinates with ISPs and third parties to minimize exposure to incidents and continue services when faced with an incident (e.g., monitors threat alerts, service availability, applications, and network traffic for indicators of nefarious activity, and ensures traffic filtering).
			* c. Develops and tests a response plan in conjunction with the institution’s ISPs and third- party service providers to mitigate the interruption of mobile or remote financial services.
		- 26. Determine whether management develops customer awareness and education efforts that address both retail (consumer) and commercial account holders.
		- 27. Determine whether management uses applications that were developed by following secure development practices and that meet a prudent level of security. Determine whether management develops security control requirements for applications, whether they are developed in-house or externally. Determine whether information security personnel are involved in monitoring the application development process to verify secure development practices. Review whether applications in use provide the following capabilities: 
			* a. Provide a prudent level of security (e.g., password and audit policies), audit trails of security and access changes, and user activity logs.
			* b. Have user and group profiles to manage user access for applications if they are not part of a centralized identity access management system.
			* c. Provide the ability to change and disable default application accounts upon installation.
			* d. Allow administrators to review and install patches for applications in a timely manner.
			* e. Use validation controls for data entry and data processing.
			* f. Integrate additional authentication and encryption controls, as necessary.
			* g. Protect web or Internet-facing applications through additional controls, including web application firewalls, regular scanning for new or recurring vulnerabilities, mitigation or remediation of common security weaknesses, and network segregation.
		- 28. With respect to developed software, determine whether institution management does the following: 
			* a. Reviews mitigation of potential flaws in applications.
			* b. Obtains attestation or evidence from third-party developers that the applications acquired by the institution meet the necessary security requirements and that noted vulnerabilities or flaws are remediated in a timely manner. 65 Refer to appendix E of the IT Handbook’s “Retail Payment Systems” booklet.
			* c. Performs ongoing risk assessments to consider the adequacy of application-level controls in light of changing threat, network, and host environments.
			* d. Implements minimum controls recommended by third-party service providers and considers supplemental controls as appropriate.
			* e. Reviews available audit reports, and considers and implements appropriate control recommendations.
			* f. Collects data to build metrics and reporting of configuration management compliance, and vulnerability management.
		- 29. For database security, determine whether management implemented or enabled controls commensurate with the sensitivity of the data stored in or accessed by the database(s). Determine whether management appropriately restricts access and applies the rule of least privilege in assigning authorizations.
		- 30. Determine how and where management uses encryption and if the type and strength are sufficient to protect information appropriately. Additionally, determine whether management has effective controls over encryption key management.
		- 31. Determine whether management appropriately oversees the effectiveness of information security controls over outsourced operations and is accountable for the mitigation of risks involved with the use of third-party service providers. Review the due diligence involved, security controls to mitigate risk, and monitoring capabilities over the institution’s third parties. Review the institution’s policies, standards, and procedures related to the use of the following: 
			* a. Third-party service providers that facilitate operational activities (e.g., core processing, mobile financial services, cloud storage and computing, and managed security services).
			* b. Due diligence in research and selection of third-party service providers.
			* c. Contractual assurances from third-party service providers for security responsibilities, controls, and reporting.
			* d. Nondisclosure agreements with third-party service providers with access to the institution’s systems and data (including before, during, and following termination of the contract).
			* e. Independent review of the third-party service provider’s security through appropriate reports from audits and tests.
			* f. Coordination of incident response policies and contractual notification requirements.
			* g. Verification that information and cybersecurity risks are appropriately identified, measured, mitigated, monitored, and reported.
		- 32. If the institution outsources cloud computing or storage to a third-party service provider, refer to the FFIEC’s “Outsourced Cloud Computing” statement.66 66 See the FFIEC’s “Outsourced Cloud Computing” statement.
		- 33. If the institution outsources the management of security services to a third-party service provider, refer to the information available in appendix D of the IT Handbook’s “Outsourcing Technology Services” booklet and the related examination procedures.67
		- 34. Determine whether management effectively manages the following information security considerations related to business continuity planning. Review management’s ability to do the following: 
			* a. Identify personnel with key information security roles during a disaster and training of personnel in those roles.
			* b. Define information security needs for backup sites and alternate communication networks.
			* c. Develop policies that address the concepts of information security incident response and resilience and test information security incident scenarios.
		- 35. Determine whether management has an effective log management process that involves a central logging repository, timely transmission of log files, and effective log analysis. Review whether management has the following: 
			* a. Log retention policies that meet incident response and analysis needs.
			* b. Processes for the security and integrity of log files (e.g., encryption of log files, adequate storage capacity, secure backup and disposal of logs, logging to a separate computer, use of read-only media, controlled log parameters, and restricted access to log files).
			* c. Independent review of logging practices.
			* d. Processes to effectively collect, aggregate, analyze, and correlate security event information from discrete systems and applications. Objective 7: Determine whether management has effective risk monitoring and reporting processes. 
			
			
				+ 1. Determine whether the institution has risk monitoring and reporting processes that address changing threat conditions in both the institution and the greater financial industry. Determine whether these processes address information security events faced by the institution, the effectiveness of management’s response, and the institution’s resilience to those events. Review whether the reporting process includes a method of disseminating those reports to appropriate members of management.
				+ 2. Determine whether the risk monitoring and reporting process is regular and prompts action, when necessary, in a timely manner.
				+ 3. Determine whether program monitoring and reporting instigate appropriate changes that are effective in maintaining an acceptable level of risk. 67 Refer to the IT Handbook’s “Outsourcing Technology Services” booklet for the MSSP Examination Procedures.
				+ 4. Determine whether management develops and effectively uses metrics as part of the risk monitoring and reporting processes for the information security program. Review whether management does the following: 
					- a. Uses metrics that are timely, comprehensive, and actionable to improve the program’s effectiveness and efficiency.
					- b. Develops metrics that demonstrate the extent to which the information security program is implemented and whether the program is effective.
					- c. Uses metrics to measure security policy implementation, the adequacy of security services delivery, and the impact of security events on business processes.
					- d. Establishes metrics to measure conformance to the standards and procedures that are used to implement policies.
					- e. Uses metrics to quantify and report risks in the information security program.Objective 8: Determine whether management has security operations that encompass necessary security-related functions, are guided by defined processes, are integrated with lines of business and activities outsourced to third-party service providers, and have adequate resources (e.g., staff and technology). 
				
				
					- 1. Determine whether the institution’s security operations activities include the following: 
						* a. Security software and device management (e.g., maintaining the signatures on signature- based devices and firewall rules).
						* b. Forensics (e.g., analysis of potentially compromised systems).
						* c. Vulnerability identification (e.g., operation or supervision of vulnerability scans, self- assessments, penetration tests, and analysis of audit results).
						* d. Vulnerability cataloging and remediation tracking.
						* e. Physical security management (e.g., CCTV, guards, and badge systems).
						* f. Law enforcement interface (e.g., data retention and lawful intercepts).
						* g. Third-party integration (e.g., managed security services and incident detection services).
						* h. Monitoring of network, host, and application activity.
						* i. Threat identification and assessment.
						* j. Incident detection and management.
						* k. Enforcement of access controls.
					- 2. Determine whether management establishes defined processes and appropriate governance to facilitate the performance of security operations. Determine whether management coordinates security operations activities with the institution’s lines of business and with the institution’s third-party service providers.
					- 3. Determine whether management has effective threat identification and assessment processes, including the following: 
						* a. Maintaining procedures for obtaining, monitoring, assessing, and responding to evolving threat and vulnerability information.
						* b. Identifying and assessing threats (e.g., threat information is often ad hoc, although some providers present threat information within a defined framework that readily lends itself to analytical operations).
						* c. Using tools to assist in the analysis of vulnerabilities (e.g., design of system, operation of the system, security procedures, business line controls, and implementation of the system and controls).
						* d. Using threat knowledge to drive risk assessment and response.
						* e. Designing policies to allow immediate and consequential threats to be dealt with expeditiously.
						* f. Developing appropriate processes to evaluate and respond to vulnerability information from external groups or individuals.
					- 4. Determine whether management has effective threat monitoring processes, including the following: 
						* a. Defining threat monitoring policies that provide for both continual and ad hoc monitoring of communications and systems, effective incident detection and response, and the use of monitoring reports in subsequent legal proceedings.
						* b. Establishing responsibility and accountability for security personnel and system administrators for monitoring.
						* c. Appropriately reviewing and providing approval of the monitoring tools used.
						* d. Monitoring of indicators, including vulnerabilities, attacks, compromised systems, and suspicious users.
						* e. Monitoring both incoming and outgoing network traffic to identify malicious activity and data exfiltration.
						* f. Establishing and documenting a process to independently monitor administrators and other users with higher privileges.
					- 5. Determine whether management has effective incident identification and assessment processes to do the following: 
						* a. Identify indicators of compromise.
						* b. Analyze the event associated with the indicators.
						* c. Classify the event.
						* d. Enable the use of response teams and responses depending on the type of event.
						* e. Escalate the event consistent with the classification.
						* f. Report internally and externally as appropriate.
						* g. Identify personnel empowered to declare an incident.
						* h. Develop procedures to test the incident escalation, response, and reporting processes.
					- 6. Determine whether management has effective incident response processes, including the following: 
						* a. Protocols defined in the incident response policy to declare and respond to an incident once identified.
						* b. Procedures to minimize damage through the containment of the incident, restoration of systems, preservation of data and evidence, and notification, as appropriate, to customers and others as needed.
						* c. Appropriate balance of adequate people and technologies in the response.
						* d. A plan that is comprehensive, coordinated, integrated, and periodically tested with appropriate internal and external parties.
						* e. Policies and procedures to guide the response, assigning responsibilities to individuals; providing appropriate training; formalizing information flows; and selecting, installing, and understanding the tools used in the response effort.
						* f. Thresholds for reporting significant security incidents and processes to notify, as appropriate, the institution’s regulators of those incidents that may affect the institution or the financial system.
						* g. Assignment of responsibilities, training, and testing.
						* h. Containment strategies.
						* i. Restoration and follow-up strategies.Objective 9: Determine whether management has an effective information security program. 
					
					
						* 1. Determine whether the information security program is subject to periodic review and whether management provides for continual improvement in the program’s effectiveness. Verify whether that review does the following: 
							+ a. Addresses the program in its current environment.
							+ b. Demonstrates that lessons learned from experience, audit findings, and other opportunities for improvement are identified and applied.Objective 10: Determine whether assurance activities provide sufficient confidence that the security program is operating as expected and reaching intended goals. 
						
						
							+ 1. Review whether management ascertains assurance through the following: 
								- a. Testing and evaluations through a combination of self-assessments, penetration tests, vulnerability assessments, and audits with appropriate coverage, depth, and independence.
								- b. Alignment of personnel skills and program needs.
								- c. Reporting that is timely, complete, transparent, and relevant to management decisions.
							+ 2. Determine whether management considers the following key testing factors when developing and implementing independent tests: 
								- a. Scope.
								- b. Personnel.
								- c. Notifications.d. Confidentiality, integrity, and availability of the institution’s information.
			* e. Confidentiality of test plans and data.
			* f. Frequency.
			* g. Proxy testing. 
				+ 3. Determine whether management uses the following types of tests and evaluations to determine the effectiveness of the information security program. Verify whether management ensures the following are done: 
					- a. Periodic self-assessments performed by the organizational unit being assessed.
					- b. Penetration tests that subject a system to real-world attacks and identify weaknesses.
					- c. Vulnerability assessments that define, identify, and classify the security holes found in the system.
					- d. Audits performed by independent internal departments or third parties.
				+ 4. Determine whether management uses independent organizations to test aspects of its information security programs.
				+ 5. Determine whether management uses reporting of the results of self-assessments, penetration tests, vulnerability assessments, and audits to support management decision making.
				+ 6. Determine whether the annual information security report is timely and contains adequate information.Objective 11: Discuss corrective action and communicate findings. 
		
		
			* 1. Review preliminary conclusions with the examiner-in-charge regarding the following: 
				+ a. Violations of laws or regulations.
				+ b. Significant issues warranting inclusion as matters requiring attention or recommendations in the report of examination.
				+ c. The proposed Uniform Rating System for Information Technology management component rating and the potential impact of the conclusion on the composite or other component IT ratings.
				+ d. Potential impact of conclusions on the institution’s risk assessment.
			* 2. Discuss findings with management and obtain proposed corrective action for significant deficiencies.
			* 3. Document conclusions in a memo to the examiner-in-charge that provides report-ready comments for all relevant sections of the report of examination and guidance to future examiners.
			* 4. Organize work papers to ensure clear support for significant findings by examination objective.
# Appendix B: Glossary 

Acceptable use policy: A document that establishes an agreement between users and the enterprise and defines for all parties the ranges of use that are approved before users can gain access to a network or the Internet. 

Access: The ability to physically or logically enter or make use of an IT system or area (secured or unsecured). The process of interacting with a system. 

Administrator privileges: Computer system access to resources that are unavailable to most users. Administrator privileges permit execution of actions that would otherwise be restricted. 

Air-gapped environment: Security measure that isolates a secure network from unsecure networks physically, electrically, and electromagnetically. 

Anomalous activity: Activity that deviates from normal. The result of the process of comparing definitions of what activity is considered normal against observed events to identify significant deviations. 

Antivirus/anti-malware software: A program that monitors a computer or network to identify all types of malware and prevent or contain malware incidents. 

Asset: In computer security, a major application, a general-support system, a high-impact program, a physical plant, a mission-critical system, personnel, equipment, or a logically related group of systems. 

Attack signature: A specific sequence of events indicative of an unauthorized access attempt. 

Authentication: The process of verifying the identity of an individual user, machine, software component, or any other entity. 

Availability: Whether or how often a system is available for use by its intended users. Because downtime is usually costly, availability is an integral component of security. 

Baseline configuration: A set of specifications for a system, or configuration item within a system, that has been formally reviewed and agreed on at a given point in time and that can be changed only through change control procedures. The baseline configuration is used as a basis for future builds, releases, or changes. 

Black holing: A method typically used by ISPs to stop a distributed denial-of-service (DDoS) attack on one of its customers. This approach to blocking DDoS attacks makes the site in question completely inaccessible to all traffic, both malicious attack traffic and legitimate user traffic. 

Border router: A device located at the organization’s boundary to an external network. 

Change management: The broad processes for managing organizational change. Change management encompasses planning, oversight or governance, project management, testing, and implementation. 

Checksum: A mathematical value that is assigned to a file and used to “test” the file at a later date to verify that the data contained in the file has not been maliciously or erroneously changed. 

Classification: Categorization (e.g., “confidential,” “sensitive,” or “public”) of the information processed by the service provider on behalf of the receiver company. 

Cloud computing: Generally a migration from owned resources to shared resources in which client users receive IT services on demand from third-party service providers via the Internet “cloud.” In cloud environments, a client or customer relocates its resources—such as data, applications, and services—to computing facilities outside the corporate firewall, which the end user then accesses via the Internet. 

Cloud storage: A model of data storage in which the digital data is stored in logical pools, the physical storage spans multiple servers (and often locations), and the physical environment is typically owned and managed by a hosting company. 

Compensating control: A management, operational, and/or technical control (e.g., safeguard or countermeasure) employed by an organization in lieu of a recommended security control in the low, moderate, or high baselines that provides equivalent or comparable protection for an information system. 

Computer security: Technological and managerial procedures applied to computer systems to ensure the availability, integrity, and confidentiality of information managed by the computer system. 

Confidentiality: Assuring information will be kept secret, with access limited to appropriate persons. 

Configuration management: The management of security features and assurances through control of changes made to a system’s hardware, software, firmware, documentation, testing, test fixtures, and test documentation throughout the development and operational life of the system. 

Consumer information: For purposes of the Information Security Standards, “consumer information” means any record about an individual, whether in paper, electronic, or other form, that is a consumer report or is derived from a consumer report that is maintained by or on behalf of a financial institution for a business purpose, such as information that an institution obtains about a loan applicant or a prospective employee from a consumer report. 

Control: The means of managing risk, including policies, procedures, guidelines, practices, or organizational structures, which can be of an administrative, technical, management, or legal nature. 

Control requirements: Process used to document and/or track internal processes to determine that those established procedures and/or physical security policies are being followed. 

Control self-assessment: A technique used to internally assess the effectiveness of risk management and control processes. 

Corrective control: A mitigating technique designed to lessen the impact to the institution when adverse events occur. 

Crisis management: The process of managing an institution’s operations in response to an emergency or event that threatens business continuity. An institution’s ability to communicate with employees, customers, and the media, using various communications devices and methods, is a key component of crisis management. 

Critical system (infrastructure): The systems and assets, whether physical or virtual, that are so vital that the incapacity or destruction of them may have a debilitating impact. 

Customer: For purposes of the Information Security Standards, “customer” means a consumer with whom a financial institution has a continuing relationship under which the institution provides one or more financial products or services to the consumer that are to be used primarily for personal, family, or household purposes. In the case of a credit union, a customer relationship will exist between a credit union and certain consumers that are not the credit union’s members. 

Customer information: A term used in the Information Security Standards to mean any record containing non-public personal information about a customer, whether in paper, electronic, or other form, that is maintained by or on behalf of a financial institution. 

Customer information systems: For purposes of the Information Security Standards, “customer information systems” means any methods used to access, collect, store, use, transmit, protect, or dispose of customer information. 

Cyber attack: An attempt to damage, disrupt, or gain unauthorized access to a computer, computer system, or electronic communications network. An attack, via cyberspace, targeting an institution for the purpose of disrupting, disabling, destroying, or maliciously controlling a computing environment/infrastructure; destroying the integrity of the data; or stealing controlled information. 

Cyber event: A cybersecurity change or occurrence that may have an impact on organizational operations (including mission, capabilities, or reputation). 

Cyber incident: Actions taken through the use of computer networks that result in an actual or potentially adverse effect on an information system or the information residing therein. 

Cyber resilience: The ability of a system or domain to withstand cyber attacks or failures and, in such events, to reestablish itself quickly. 

Cyber threat: An internal or external circumstance, event, action, occurrence, or person with the potential to exploit technology-based vulnerabilities and to adversely affect (create adverse consequences for) organizational operations, organizational assets (including information and information systems), individuals, other organizations, or society. 

Cybersecurity: The process of protecting consumer and bank information by preventing, detecting, and responding to attacks. 

Data classification program: A program that categorizes data to convey required safeguards for information confidentiality, integrity, and availability, and establishes required controls based on value and level of sensitivity. 

Data corruption: Errors in computer data that occur during writing, reading, storage, transmission, or processing, which introduce unintended changes to the original data. 

Data integrity: The property that data have not been destroyed or corrupted in an unauthorized manner; maintaining and assuring the accuracy and consistency of data over their entire life cycle. 

Data loss prevention (DLP) program: A comprehensive approach (covering people, processes, and systems) of implementing policies and controls designed specifically to discover, monitor, and protect confidential data while it is stored, used, or in transit over the network and at the perimeter. 

Database: A collection of data that is stored on any type of computer storage medium and may be used for more than one purpose. 

Defense-in-depth: Information security strategy integrating people, technology, and operations capabilities to establish variable barriers across multiple layers and dimensions of the organization. 

Demilitarized zone (DMZ): A computer or small subnetwork that sits between a trusted internal network, such as a corporate private LAN, and an untrusted external network, such as the public Internet. 

Detection device: A device designed to recognize an event and alert management when events occur. 

Detective control: A mitigating technique designed to recognize an event and alert management when events occur. 

Device: A generic term for any machine or component that attaches to a computer or connects to a network. 

Distributed denial of service (DDoS): A type of attack that makes a computer resource or resources unavailable to its intended users. Although the means to carry out, motives for, and targets of a DDoS attack may vary, it generally consists of the concerted efforts of a group that intends to affect an institution’s reputation by preventing an Internet site, service, or application from functioning efficiently. 

Due diligence for service provider selection: Technical, functional, and financial review to verify a third-party service provider’s ability to deliver the requirements specified in its proposal. The intent is to verify that the service provider has a well-developed plan and adequate resources and experience to ensure acceptable service, controls, systems backup, availability, and continuity of service to its clients. 

End-of-life: All software products have life cycles. End-of-life refers to the date when a software development company no longer provides automatic fixes, updates, or online technical assistance for the product. 

End-point security: Refers to a methodology of protecting the corporate network when accessed with remote devices, such as laptops, or other wireless and mobile devices. Each device with a remote connection to the network creates a potential entry (or exit) point for security threats. 

End-to-end process flow: Document that details the flow of the processes, considering automated and manual control points, hardware, databases, network protocols, and real-time versus periodic processing characteristics. 

Enterprise-wide: Across an entire organization, rather than a single business department or function. 

Exploit: A technique or code that uses a vulnerability to provide system access to the attacker. An exploit is an intentional attack to affect an operating system or application program. 

External connections: An information system or component of an information system that is outside of the authorization boundary established by the organization and for which the organization typically has no direct control over the application of required security controls or the assessment of security control effectiveness. 

File transfer protocol (FTP): A standard high-level protocol for transferring files from one computer to another, usually implemented as an application-level program. 

Financial Services Information Sharing and Analysis Center (FS-ISAC): A nonprofit, information-sharing forum established by financial services industry participants to facilitate the public and private sectors’ sharing of physical and cybersecurity threat and vulnerability information. 

Firewall: A hardware or software link in a network that relays only data packets clearly intended and authorized to reach the other side. 

Frame relay: A high-performance wide area network protocol that operates at the physical and data link layers of the Open Systems Interconnection reference model. Frame relay is an example of a packet-switched technology. Packet-switched networks enable end stations to dynamically share the network medium and the available bandwidth. 

Governance: In computer security, governance means setting clear expectations for the conduct (behaviors and actions) of the entity being governed and directing, controlling, and strongly influencing the entity to achieve these expectations. Governance includes specifying a framework for decision making, with assigned decision rights and accountability, intended to consistently produce desired behaviors and actions. 

Gramm–Leach–Bliley Act: The act, also known as the Financial Services Modernization Act of 1999 (Pub.L. 106-102, 113 Stat. 1338, enacted November 12, 1999), required the federal banking agencies to establish information security standards for financial institutions. 

Hardening: The process of securing a computer’s administrative functions or inactivating those features not needed for the computer’s intended business purpose. 

Hardware: The physical elements of a computer system; the computer equipment as opposed to the programs or information stored in a machine. 

Hash: A fixed-length cryptographic output of variables, such as a message, being operated on by a formula or cryptographic algorithm. 

Hijacking: An attacker’s use of an authenticated user’s communication session to communicate with system components. 

Homing beacons: Devices that send messages to the institution when they connect to a network and that enable recovery of the device. 

Host: A computer that is accessed by a user from a remote location. 

Incident management: The process of identifying, analyzing, and correcting disruptions to operations and preventing future recurrences. The goal of incident management is to limit the disruption and restore operations as quickly as possible. 

Incident response plan: A plan that defines the action steps, involved resources, and communication strategy upon identification of a threat or potential threat event, such as a breach in security protocol, power or telecommunications outage, severe weather, or workplace violence. 

Information security: The process by which an organization protects the creation, collection, storage, use, transmission, and disposal of information. 

Information systems: Electronic systems and physical components used to access, store, transmit, protect, and eventually dispose of information. Information systems can include networks (computer systems, connections to business partners and the Internet, and the interconnections between internal and external systems). Other examples are backup tapes, mobile devices, and other media. 

Information technology (IT): Any services or equipment, or interconnected system(s) or subsystem(s) of equipment that compose the institution’s IT architecture or infrastructure. IT can include computers; ancillary equipment (including imaging peripherals, input, output, and storage devices necessary for security and surveillance); peripheral equipment designed to be controlled by the central processing unit of a computer; software; firmware and similar procedures; services (including cloud computing and help-desk services or other professional services that support any point of the life cycle of the equipment or service); and related resources. 

Infrastructure: Describes what has been implemented by IT architecture and often includes support facilities such as power, cooling, ventilation, server and data redundancy and resilience, and telecommunications lines. Specific architecture types may exist for the following: enterprise, data (information), technology, security, and application. 

Integrity: Assurance that information is trustworthy and accurate; ensuring that information will not be accidentally or maliciously altered or destroyed (see “Data integrity”). 

Interconnectivity: The state or quality of being connected together. The interaction of a financial institution’s internal and external systems and applications and the entities with which they are linked. 

Interdependencies: When two or more departments, processes, functions, or third-party service providers support one another in some fashion. 

Internal “trusted” zone: A channel in which the end points are known and data integrity is protected in transit. Depending on the communications protocol used, data privacy may be protected in transit. Examples include SSLIP security and a secure physical connection. 

International Organization for Standardization (ISO): An independent, non-governmental, international organization that brings together experts to share knowledge and develop voluntary, consensus-based, market-relevant international standards. 

Internet: The global system of interconnected computer networks that use the Internet protocol suite (TCP/IP) to link billions of devices worldwide. 

Internet service provider (ISP): A company that provides its customers with access to the Internet (e.g., AT&T, Verizon, and CenturyLink). 

Intrusion detection: Techniques that attempt to detect unauthorized entry or access into a computer or network by observation of actions, security logs, or audit data; detection of break- ins or attempts, either manually or via software expert systems that operate on logs or other information available on the network. 

Intrusion detection system (IDS): Software or hardware product that detects and logs inappropriate, incorrect, or anomalous activity. It gathers and analyzes information from various areas within a computer or a network to identify possible security breaches, which include both intrusions (attacks from outside the organizations) and misuse (attacks from within the organizations). IDS are typically characterized based on the source of the data they monitor: host or network. A host-based IDS uses system log files and other electronic audit data to identify suspicious activity. A network-based IDS uses a sensor to monitor packets on the network to which it is attached. 

Intrusion prevention system (IPS): A system that can detect an intrusive activity and can also attempt to stop the activity, ideally before it reaches its target. 

IT system inventory: A list containing information about the information resources owned or operated by an organization. 

Life-cycle process: The multistep process that starts with the initiation, analysis, design, and implementation, and continues through the maintenance and disposal of the system. 

Log: A record of information or events in an organized system, usually sequenced in the order in which the events occurred. 

Logical access: Ability to interact with computer resources granted using identification, authentication, and authorization. 

Logical access controls: The policies, procedures, organizational structure, and electronic access controls designed to restrict access to computer software and data files. 

Malware: Software designed to secretly access a computer system without the owner’s informed consent. The expression is a general term (short for malicious software) used to mean a variety of forms of hostile, intrusive, or annoying software or program code. Malware includes computer viruses, worms, Trojan horses, spyware, dishonest adware, ransomware, crimeware, most rootkits, and other malicious and unwanted software or programs. 

Media: Physical objects that store data, such as paper, hard disk drives, tapes, and compact disks. 

Metric: A quantitative measurement. 

Middleware: Software that connects two or more software components or applications. It is another term for an application programmer interface or API, and it allows programmers to access lower- or higher-level services by providing an intermediary layer that includes function calls to the services. 

Mobile device: A portable computing and communications device with information-storage capability. Examples include notebook and laptop computers, cellular telephones and smart phones, tablets, digital cameras, and audio recording devices. 

Multi-factor authentication: The process of using two or more factors to achieve authentication. Factors include something you know (e.g., password or personal identification number); something you have (e.g., cryptographic identification device or token); and something you are (e.g., biometric). 

National Institute of Standards and Technology (NIST): An agency of the U.S. Department of Commerce that works to develop and apply technology, measurements, and standards. NIST developed a voluntary cybersecurity framework based on existing standards, guidelines, and practices for reducing cyber risks to critical infrastructures. 

Network: Two or more computer systems grouped together to share information, software, and hardware. 

Network activity baseline: A base for determining typical utilization patterns so that significant deviations can be detected. 

Network administrator: The individual responsible for the installation, management, and control of a network. 

Network diagram: A description of any kind of locality in terms of its physical layout. In the context of communication networks, a topology describes pictorially the configuration or arrangement of a network, including its nodes and connecting communication lines. 

Network security: The protection of computer networks and their services from unauthorized entry, modification, destruction, or disclosure, and provision of assurance that the network performs its critical functions correctly and that there are no harmful side effects. Network security includes providing for data integrity. 

Non-public personal information: For purposes of the Information Security Standards, non- public personal information means (i) “personally identifiable financial information”; and (ii) any list, description, or other grouping of consumers (and publicly available information pertaining to them) that is derived using any “personally identifiable financial information” that is not publicly available. 

Non-repudiation: Ensuring that a transferred message has been sent and received by the parties claiming to have sent and received the message. Non-repudiation is a way to guarantee that the sender of a message cannot later deny having sent the message and that the recipient cannot deny having received the message. 

Operating system: A system that supports and manages software applications. Operating systems allocate system resources, provide access and security controls, maintain file systems, and manage communications between end users and hardware devices. 

Out-of-band: Activity outside of the primary means of interfacing with the customer. For example, if a user is performing activity online, he or she may be authenticated through a one- time password sent via text message. 

Outsourcing: The practice of contracting with another entity to perform services that might otherwise be conducted in-house; a contractual relationship with a third party to provide services, systems, or support. 

Packet: The data unit that is routed from source to destination in a packet-switched network. 

Patch: Software code that replaces or updates other code. Patches frequently are used to correct security flaws. 

Penetration test: The process of using approved, qualified personnel to conduct real-world attacks against a system to identify and correct security weaknesses before they are discovered and exploited by others. 

Personally identifiable financial information: For purposes of the Information Security Standards, personally identifiable financial information means information (i) a consumer provides to a financial institution to obtain a financial product or service; (ii) about a consumer resulting from any transaction involving a financial product or service between the financial institution and a consumer; or (iii) that a financial institution otherwise obtains about a consumer in connection with providing a financial product or service, such as account balance information, payment history, overdraft history, and credit or debit card purchase information; or the fact that an individual is one of the financial institution’s customers. 

Phishing: A digital form of social engineering that uses authentic-looking—but bogus—e-mail to request information from users or direct them to fake websites that request information. 

Policy: A document that records a high-level principle or an agreed-upon course of action; overall intention and direction as formally expressed by management. 

Port: Either an end point to a logical connection or a physical connection to a computer. 

Positive pay: A technique that can reduce check fraud by requesting businesses to send electronic files of information to the financial institution on all checks the business has issued. 

Preventive control: A mitigating technique designed to prevent an event from occurring. 

Principle of least privilege: The security objective of granting users only the access needed to perform official duties. 

Privilege: The level of trust with which a system object is imbued. 

Privileged access: Individuals with the ability to override system or application controls. 

Protocol: A format for transmitting data between devices. 

Real-time network monitoring: Immediate response to a penetration attempt that is detected and diagnosed in time to prevent access. 

Remote access: The ability to obtain access to a computer or network from a remote location. 

Remote deletions: Use of a technology to remove data from a portable device without touching the device. 

Removable media: Portable electronic storage media, such as magnetic, optical, and solid-state devices that can be inserted into and removed from a computing device and that are used to store text, video, audio, and image information. Such devices have no independent processing capabilities. Examples include hard disks, floppy disks, zip drives, compact disks, thumb drives, pen drives, and similar storage devices. 

Resource: Any enterprise asset that can help the organization achieve its objectives. 

Retention requirement: Requirement established by a company or by regulation for the length of time and/or for the amount of information that should be retained. 

Risk analysis: The process of identifying risks, determining their probability and impact, and identifying areas needing safeguards. 

Risk assessment: A prioritization of potential business disruptions based on severity and likelihood of occurrence. The risk assessment includes an analysis of threats based on the impact to the institution, its customers, and financial markets, rather than the nature of the threat. 

Rogue wireless access: An unauthorized wireless node on a network. 

Routing: The process of moving information from its source to the destination. 

Sandbox: A restricted, controlled execution environment that prevents potentially malicious software, such as mobile code, from accessing any system resources except those for which the software is authorized. 

Scenario analysis: The process of analyzing possible future events by considering alternative possible outcomes. 

Secure shell: Network protocol that uses cryptography to secure communication, remote command line log-in, and remote command execution between two networked computers. 

Secure Sockets Layer (SSL): A protocol that is used to transmit private documents through the Internet. 

Security architecture: A detailed description of all aspects of the system that relate to security, along with a set of principles to guide the design. A security architecture describes how the system is put together to satisfy the security requirements. 

Security audit: An independent review and examination of system records and activities to test for adequacy of system controls, ensure compliance with established policy and operational procedures, and recommend any indicated changes in control, policy, and procedures. 

Security breach: A security event that results in unauthorized access of data, applications, services, networks, or devices by bypassing underlying security mechanisms. 

Security event: An event that potentially compromises the confidentiality, integrity, availability, or accountability of an information system. 

Security log: A record that contains log-in and logout activity and other security-related events and that is used to track security-related information on a computer system. 

Security posture: The security status of an enterprise’s networks, information, and systems based on information security and assurance resources (e.g., people, hardware, software, and policies) and capabilities in place to manage the defense of the enterprise and to react as the situation changes. 

Security violation: An instance in which a user or other person circumvents or defeats the controls of a system to obtain unauthorized access to information or system resources. 

Sensitive customer information: A customer’s name, address, or telephone number, in conjunction with the customer’s social security number, driver’s license number, account number, credit or debit card number, or personal identification number or password that would permit access to the customer’s account. Sensitive customer information also includes any combination of components of customer information that would allow someone to log into or access the customer’s account, such as user name and password or password and account number. 

Server: A computer or other device that manages a network service. An example is a print server, which is a device that manages network printing. 

Service level agreement (SLA): Formal documents between an institution and its third-party service provider that outline an institution’s predetermined requirements for a service and establish incentives to meet, or penalties for failure to meet, the requirements. SLAs should specify and clarify performance expectations, establish accountability, and detail remedies or consequences if performance or service quality standards are not met. 

Service provider: For purposes of the Information Security Standards, service provider means any person or entity that maintains, processes, or otherwise is permitted access to customer information or consumer information through its provision of services directly to a financial institution. 

Shadow IT: A term used to describe IT systems or applications used inside institutions without explicit approval. 

Sniffing: The passive interception of data transmissions. 

Social engineering: A general term for trying to trick people into revealing confidential information or performing certain actions. 

Spear phishing: An attack targeting a specific user or group of users, and attempts to deceive the user into performing an action that launches an attack, such as opening a document or clicking a link. Spear phishers rely on knowing some personal piece of information about their target, such as an event, interest, travel plans, or current issues. Sometimes this information is gathered by hacking into the targeted network. 

Spoofing: A form of masquerading in which a trusted IP address is used instead of the true IP address as a means of gaining access to a computer system. 

SQL Injection Attack: An exploit of target software that constructs structured query language (SQL) statements based on user input. An attacker crafts input strings so that when the target software constructs SQL statements based on the input, the resulting SQL statement performs actions other than those the application intended. SQL injection enables an attacker to talk directly to the database, thus bypassing the application completely. Successful injection can cause information disclosure as well as the ability to add or modify data in the database. 

Stateful inspection: A firewall inspection technique that examines the claimed purpose of a communication for validity. For example, a communication claiming to respond to a request is compared to a table of outstanding requests. 

System administration: The process of maintaining, configuring, and operating computer systems. 

System resources: Capabilities that can be accessed by a user or program either on the user’s machine or across the network. Capabilities can be services, such as file or print services, or devices, such as routers. 

Third-party relationship: Any business arrangement between a financial institution and another entity, by contract or otherwise. 

Third-party service provider: Any third party to whom a financial institution outsources activities that the institution itself is authorized to perform, including a technology service provider. 

Threat intelligence: The acquisition and analysis of information to identify, track, and predict cyber capabilities, intentions, and activities that offer courses of action to enhance decision making. 

Trojan horse: Malicious code hidden in software that has an apparently beneficial or harmless use. 

Tunnel: The path that encapsulated packets follow in an Internet VPN. 

U.S. Computer Emergency Readiness Team (US-CERT): US-CERT is part of the U.S. Department of Homeland Security’s National Cybersecurity and Communications Integration Center in the Office of Cybersecurity and Communications. US-CERT is a partnership between the Department of Homeland Security and the public and private sectors, established to protect the nation’s Internet infrastructure. US-CERT coordinates defense against and responses to cyber attacks across the nation. 

User identification: The process, control, or information by which a user identifies himself or herself to the system as a valid user (as opposed to authentication). 

Utility: A program used to configure or maintain systems, or to make changes to stored or transmitted data. 

Virtual local area network (VLAN): Logical segmentation of a LAN into different broadcast domains. 

Virtual machine: A software emulation of a physical computing environment. 

Virtual private network (VPN): A computer network that uses public telecommunication infrastructure, such as the Internet, to provide remote offices or individual users with secure access to their organization's network. 

Virus: Malicious code that replicates itself within a computer. 

Vulnerability: A hardware, firmware, or software flaw that leaves an information system open to potential exploitation; a weakness in automated system security procedures, administrative controls, physical layout, internal controls, etc., that could be exploited to gain unauthorized access to information or to disrupt critical processing. 

Vulnerability assessment: Systematic examination of systems to identify, quantify, and prioritize the security deficiencies of the systems. 

Worm: A self-replicating malware computer program. It uses a computer network to send copies of itself to other nodes (computers on the network), possibly without any user intervention. This occurs primarily because of security vulnerabilities on the target computers. 

Zero-day attack: An attack on a piece of software that has a vulnerability for which there is no known patch. 

# Appendix C: Laws, Regulations, and Guidance 

## Laws 

12 USC 1861–1867, “Bank Service Company Act” 12 USC 1882, “Bank Protection Act” 

15 USC 1681w, “Fair and Accurate Credit Transactions Act” 15 USC 6801 and 6805(b), “Gramm–Leach–Bliley Act” 

18 USC 1030, “Fraud and Related Activity in Connection With Computers” 

## Consumer Financial Protection Bureau 

### Regulations 

### Regulations 

Federal Deposit Insurance Corporation 

12 CFR 1005, “Electronic Fund Transfers (Regulation E)” 

12 CFR 1016, “Privacy of Consumer Financial Information (Regulation P)” 

12 CFR 326, subpart A, “Minimum Security Procedures” 

12 CFR 326, subpart B, “Procedures for Monitoring Bank Secrecy Act Compliance” 12 CFR 332, “Privacy of Consumer Financial Information” 12 CFR 353, “Suspicious Activity Reports” 

12 CFR 364, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 364, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

### Guidance 

FIL-28-2015, “Cybersecurity Assessment Tool” (July 2, 2015) FIL-13-2015, “FFIEC Joint Statements on Destructive Malware and Compromised Credentials” (March 30, 2015) 

FIL-9-2015, “Business Continuity Planning Booklet Appendix J Update to FFIEC IT Examination Handbook Series” (February 23, 2015) 

FIL-49-2014, “Technology Alert GNU Bourne-Again Shell (Bash) Vulnerability” (September 29, 2014) 

FIL-16-2014, “Technology Alert OpenSSL Heartbleed Vulnerability” (April 11, 2014) FIL-11-2014, “Distributed Denial of Service (DDoS) Attacks” (April 2, 2014) FIL-10-2014, “ATM and Card Authorization Systems” (April 2, 2014) FIL-50-2011, “FFIEC Supplement to Authentication in an Internet Banking Environment” (June 29, 2011) 

FIL-56-2010, “Guidance on Mitigating Risk Posed by Information Stored on Photocopiers, Fax Machines and Printers” (September 15, 2010) 

FIL-6-2010, “Retail Payment Systems Booklet” (February 25, 2010) FIL-30-2009, “Identity Theft Red Flags, Address Discrepancies, and Change of Address Regulations Frequently Asked Questions” (June 11, 2009) 

FIL-105-2008, “Identity Theft Red Flags, Address Discrepancies, and Change of Address Regulations Examination Procedures” (October 16, 2008) 

FIL-100-2007, “Identity Theft Red Flags—Interagency Final Regulation and Guidelines” (November 15, 2007) 

FIL-32-2007, “FDIC’s Supervisory Policy on Identity Theft” (April 11, 2007) FIL-77-2006, “Authentication in an Internet Banking Environment Frequently Asked Questions” (August 21, 2006) 

FIL-103-2005, “FFIEC Guidance Authentication in an Internet Banking Environment” (October 12, 2005) 

FIL-69-2005, “Guidance on the Security Risks of Voice Over Internet Protocol (VoIP)” (July 27, 2005) 

FIL-66-2005, “Spyware—Guidance on Mitigating Risks From Spyware” (July 22, 2005) FIL-64-2005, “Pharming”—Guidance on How Financial Institutions Can Protect Against Pharming Attacks” (July 18, 2005) 

FIL-59-2005, “Identity Theft Study Supplement on ‘Account Hijacking Identity Theft’” (July 5, 2005) 

FIL-27-2005, “Final Guidance on Response Programs for Unauthorized Access to Customer Information and Customer Notice” (April 1, 2005) 

FIL-7-2005, “Fair and Accurate Credit Transactions Act of 2003 Guidelines Requiring the Proper Disposal of Customer Information” (February 2, 2005) 

FIL-132-2004, “Identity Theft Study on ‘Account Hijacking’ Identity Theft and Suggestions for Reducing Online Fraud” (December 14, 2004) 

FIL-121-2004, “Computer Software Due Diligence—Guidance on Developing an Effective Software Evaluation Program to Assure Quality and Regulatory Compliance” (November 16, 2004) 

FIL-114-2004, “Risk Management of Free and Open Source Software FFIEC Guidance” (October 21, 2004) 

FIL-103-2004, “Interagency Informational Brochure on Internet ‘‘Phishing’ Scams” (September 13, 2004) 

FIL-84-2004, “Guidance on Instant Messaging” (July 21, 2004) 

FIL-62-2004, “Guidance on Developing an Effective Computer Virus Protection Program” (June 7, 2004) 

FIL-27-2004, “Guidance on Safeguarding Customers Against E-Mail and Internet Related Fraud Schemes” (March 12, 2004) 

FIL-63-2003, “Guidance on Identity Theft Response Programs” (August 13, 2003) FIL-43-2003, “Guidance on Developing an Effective Software Patch Management Program” (May 29, 2003) 

FIL-30-2003, “Federal Bank and Credit Union Regulatory Agencies Jointly Issue Guidance on the Risks Associated With Weblinking” (April 23, 2003) 

FIL-8-2002, “Wireless Networks and Customer Access” (February 1, 2002) FIL-69-2001, “Authentication in an Electronic Banking Environment” (August 24, 2001) 

FIL-68-2001, “501(b) Examination Guidance” (August 24, 2001) FIL-39-2001, “Guidance on Identity Theft and Pretext Calling” (May 9, 2001) FIL-22-2001, “Security Standards for Customer Information” (March 14, 2001) FIL-77-2000, “Bank Technology Bulletin: Protecting Internet Domain Names” (November 9, 2000) 

FIL-67-2000, “Security Monitoring of Computer Networks” (October 3, 2000) FIL-68-99, “Risk Assessment Tools and Practices” (July 7, 1999) FIL-98-98, “Pretext Phone Calling” (September 2, 1998) 

FIL-131-97, “Security Risks Associated With the Internet” (December 18, 1997) FIL-124-97, “Suspicious Activity Reporting” (December 5, 1997) FIL-82-96, “Risks Involving Client/Server Computer Systems” (October 8, 1996) 

## Federal Reserve 

### Regulations 

12 CFR 208.61, “Minimum Security Devices and Procedures” 12 CFR 208.62, “Reports of Suspicious Activities” 

12 CFR 208.63, “Procedures for Monitoring Bank Secrecy Act Compliance” 

12 CFR 208, appendix D-1, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 208, appendix D-2, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 211.5(l), “Interagency Guidelines Establishing Information Security Standards” 12 CFR 211.9, “Interagency Guidelines Establishing Standards for Safeguarding Customer Information” 

12 CFR 211.24(i), “Interagency Guidelines Establishing Information Security Standards” 12 CFR 225, appendix F, “Interagency Guidelines Establishing Information Security Standards” 

### Guidance 

SR Letter 15-9, “FFIEC Cybersecurity Assessment Tool for Chief Executive Officers and Boards of Directors” 

SR Letter 05-19, “Interagency Guidance on Authentication in an Internet Banking Environment” 

SR Letter 04-17, “FFIEC Guidance on the Use of Free and Open Source Software” SR Letter 04-14, “FFIEC Brochure With Information on Internet ‘Phishing’” 

SR Letter 02-18, “Section 312 of the USA Patriot Act—Due Diligence for Correspondent and Private Banking Accounts” 

SR Letter 02-6, “Information Sharing Pursuant to Section 314(b) of the USA Patriot Act” SR Letter 01-15, “Safeguarding Customer Information” 

SR Letter 01-11, “Identity Theft and Pretext Calling” 

SR Letter 00-17, “Guidance on the Risk Management of Outsourced Technology Services” SR Letter 00-04, “Outsourcing of Information and Transaction Processing” 

SR Letter 99-08, “Uniform Rating System for Information Technology” 

SR Letter 97-32, “Sound Practices Guidance for Information Security for Networks” 

## National Credit Union Administration 

### Regulations 

12 CFR 716, “Privacy of Consumer Financial Information & Appendix” 12 CFR 721, “Federal Credit Union Incidental Powers Activities” 12 CFR 741, “Requirements for Insurance” 

12 CFR 748, “Security Program, Report of Crime and Catastrophic Act and Bank Secrecy Act Compliance & Appendices” 

### Guidance 

NCUA Letter to Credit Unions 05-CU-20, “Phishing Guidance for Credit Unions and Their Members” 

NCUA Letter to Credit Unions 05-CU-18, “Guidance on Authentication in Internet Banking Environment” (November 2005) 

NCUA Letter to Credit Unions 04-CU-12, “Phishing Guidance for Credit Union Members” (September 2004) 

NCUA Letter to Credit Unions 04-CU-06, “E-Mail and Internet Related Fraudulent Schemes Guidance” (May 2004) 

NCUA Letter to Credit Unions 04-CU-05, “Fraudulent E-Mail Schemes” (May 2004) NCUA Letter to Credit Unions 03-CU-14, “Computer Software Patch Management” (September 2003) 

NCUA Letter to Credit Unions 03-CU-12, “Fraudulent Newspaper Advertisements, and Websites by Entities Claiming to Be Credit Unions” (August 2003) 

NCUA Letter to Credit Unions 03-CU-08, “Weblinking: Identifying Risks & Risk Management Techniques” (April 2003) 

NCUA Letter to Credit Unions 03-CU-03, “Wireless Technology” (March 2003) NCUA Letter to Credit Unions 02-CU-13, “Vendor Information Systems & Technology Reviews—Summary Results” (July 2002) 

NCUA Letter to Federal Credit Unions 02-FCU-11, “Tips to Safely Conduct Financial Transactions Over the Internet—An NCUA Brochure for Credit Union Members” (July 2002) 

NCUA Letter to Credit Unions 02-CU-08, “Account Aggregation Services” (April 2002) NCUA Letter to Federal Credit Unions 02-FCU-04, “Weblinking Relationship” (March 2002) 

NCUA Letter to Credit Unions 01-CU-21, “Disaster Recovery and Business Resumption Contingency Plans” (December 2001) 

NCUA Letter to Credit Unions 01-CU-20, “Due Diligence Over Third-Party Service Providers” (November 2001) 

NCUA Letter to Credit Unions 01-CU-12, “E-Commerce Insurance Considerations” (October 2001) 

NCUA Letter to Credit Unions 01-CU-11, “Electronic Data Security Overview” (August 2001) 

NCUA Letter to Credit Unions 01-CU-10, “Authentication in an Electronic Banking Environment” (August 2001) 

NCUA Letter to Credit Unions 01-CU-09, “Identity Theft and Pretext Calling” (September 2001) 

NCUA Regulatory Alert 01-RA-03, “Electronic Signatures in Global and National Commerce Act (E-Sign Act)” (March 2001) 

NCUA Letter to Credit Unions 01-CU-04, “Integrating Financial Services and Emerging Technology” (March 2001) 

NCUA Letter to Credit Unions 01-CU-02, “Privacy of Consumer Financial Information” (February 2001) 

NCUA Letter to Credit Unions 00-CU-11, “Risk Management of Outsourced Technology Services (With Enclosure)” (December 2000) 

NCUA Letter to Credit Unions 00-CU-07, “NCUA’s Information Systems & Technology Examination Program” (October 2000) 

NCUA Letter to Credit Unions 00-CU-04, “Suspicious Activity Reporting” (June 2000) NCUA Letter to Credit Unions 00-CU-02, “Identity Theft Prevention” (May 2000) NCUA Regulatory Alert 99-RA-3, “Pretext Phone Calling by Account Information Brokers” (February 1999) 

NCUA Regulatory Alert 98-RA-4, “Interagency Guidance on Electronic Financial Services and Consumer Compliance” (July 1998) 

NCUA Letter to Credit Unions 97-CU-05, “Interagency Statement on Retail On-Line PC Banking” (April 1997) 

NCUA Letter to Credit Unions 97-CU-01, “Automated Response System Controls” (January 1997) 

NCUA Letter to Credit Unions 109, “Information Processing Issues” (September 1989) 

## Office of the Comptroller of the Currency 

### Regulations 

12 CFR 21, subpart A, “Minimum Security Devices and Procedures” 12 CFR 21, subpart B, “Reports of Suspicious Activities” 

12 CFR 21, subpart C, “Procedures for Monitoring Bank Secrecy Act Compliance” 12 CFR 30, appendix A, “Interagency Guidelines Establishing Standards for Safety and Soundness” 

12 CFR 30, appendix B, “Interagency Guidelines Establishing Information Security Standards” 

12 CFR 41.83, “Proper Disposal of Records Containing Customer Information” 

### Guidance 

OCC Bulletin 2016-18, “Cybersecurity of Interbank Messaging and Wholesale Payment Networks: FFIEC Statement” (June 7, 2016) 

OCC Bulletin 2016-14, “FFIEC Information Technology Examination Handbook: Mobile Financial Services, New Appendix to the Retail Payment Systems Booklet” (April 29, 2016) 

OCC Bulletin 2015-44, “FFIEC Information Technology Examination Handbook: Revised Management Booklet” (November 10, 2015) 

OCC Bulletin 2015-40, “Cybersecurity: Joint Statement on Cyber Attacks Involving Extortion” (November 3, 2015) 

OCC Bulletin 2015-31, “FFIEC Cybersecurity Assessment Tool” (June 30, 2015) OCC Bulletin 2015-20, “Cybersecurity: Destructive Malware Joint Statement” (March 30, 2015) 

OCC Bulletin 2015-19, “Cybersecurity: Cyber Attacks Compromising Credentials Joint Statement” (March 30, 2015) 

OCC Bulletin 2015–9, “FFIEC Information Technology Examination Handbook: Strengthening the Resilience of Outsourced Technology Services, New Appendix for Business Continuity Planning Booklet” (February 6, 2015) 

OCC Bulletin 2014-53, “Cybersecurity Assessment General Observations and Statement” (November 3, 2014) 

OCC Bulletin 2014-17, “Information Security Vulnerability in OpenSSL Encryption Tool (Heartbleed): Joint Statement” (April 25, 2014) 

OCC Bulletin 2014-14, “Distributed Denial-of-Service Cyber Attacks, Risk Mitigation, and Additional Resources: Joint Statement” (April 3, 2014) 

OCC Bulletin 2014-13, “Cyber Attacks on Financial Institutions’ Automated Teller Machine and Card Authorization Systems: Joint Statement” (April 2, 2014) 

OCC Bulletin 2013-29, “Third-Party Relationships: Risk Management Guidance” (October 30, 2013) 

OCC Bulletin 2013-22, “Windows XP Operating System: Joint Statement” (October 7, 2013) OCC Bulletin 2011-26, “Authentication in an Internet Banking Environment: Supplement” (June 28, 2011) 

OCC Bulletin 2008-16, “Information Security: Application Security” (May 8, 2008) OCC Bulletin 2007-45, “Identity Theft Red Flags and Address Discrepancies: Final Rulemaking” (November 14, 2007) 

OCC Bulletin 2005-35, “Authentication in an Internet Banking Environment: Interagency Guidance” (October 12, 2005) 

OCC Bulletin 2005-24, “Threats From Fraudulent Bank Web Sites: Risk Mitigation and Response Guidance for Web Site Spoofing Incidents” (July 1, 2005) 

OCC Bulletin 2005-13, “Response Programs for Unauthorized Access to Customer Information and Customer Notice: Final Guidance: Interagency Guidance” (April 14, 2005) 

OCC Bulletin 2005-1, “Proper Disposal of Consumer Information: Final Rule” (January 12, 2005) 

OCC Bulletin 2001-35, “Examination Procedures to Evaluate Compliance With the Guidelines to Safeguard Customer Information: Examination Procedures” (July 18, 2001) OCC Bulletin 2001-8, “Guidelines Establishing Standards for Safeguarding Customer Information: Final Guidelines” (February 15, 2001) 

OCC Bulletin 2000-14, “Infrastructure Threats—Intrusion Risks: Message to Bankers and Examiners” (May 15, 2000) 

OCC Bulletin 1999-20, “Certificate Authority Systems: Guidance for Bankers and Examiners” (May 4, 1999) 

OCC Bulletin 1998-3, “Technology Risk Management: Guidance for Bankers and Examiners” (February 4, 1998) 

OCC Alert 2001-4, “Network Security Vulnerabilities” (April 24, 2001) 

OCC Alert 2000-9, “Protecting Internet Addresses of National Banks” (July 19, 2000) 

## Other References 

Basel Committee on Banking Supervision, “Sound Practices for the Management and Supervision of Operational Risk” (February 2003) 

ISACA Control Objectives for Enterprise IT Governance 

